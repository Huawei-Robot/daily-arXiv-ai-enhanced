<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 266]
- [cs.CV](#cs.CV) [Total: 378]
- [cs.MA](#cs.MA) [Total: 4]
- [eess.AS](#eess.AS) [Total: 4]
- [cs.AI](#cs.AI) [Total: 28]
- [cs.CR](#cs.CR) [Total: 8]
- [stat.ML](#stat.ML) [Total: 2]
- [cs.MM](#cs.MM) [Total: 2]
- [cs.RO](#cs.RO) [Total: 18]
- [q-fin.ST](#q-fin.ST) [Total: 2]
- [cs.LG](#cs.LG) [Total: 64]
- [cs.AR](#cs.AR) [Total: 4]
- [eess.IV](#eess.IV) [Total: 18]
- [cs.CY](#cs.CY) [Total: 10]
- [cs.GR](#cs.GR) [Total: 18]
- [cs.IR](#cs.IR) [Total: 12]
- [physics.ed-ph](#physics.ed-ph) [Total: 2]
- [eess.SP](#eess.SP) [Total: 6]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [How Significant Are the Real Performance Gains? An Unbiased Evaluation Framework for GraphRAG](https://arxiv.org/abs/2506.06331)
*Qiming Zeng,Xiao Yan,Hao Luo,Yuhao Lin,Yuxiang Wang,Fangcheng Fu,Bo Du,Quanqing Xu,Jiawei Jiang*

Main category: cs.CL

TL;DR: 该论文提出了一种无偏的评估框架，用于解决现有图检索增强生成(GraphRAG)方法在答案评估时存在的两个关键缺陷：无关问题和评估偏见。


<details>
  <summary>Details</summary>
Motivation: 研究发现现有GraphRAG评估框架存在两个严重缺陷：1. 使用不相关问题进行测试；2.在答案评估过程中存在偏见。这些问题会导致评估结论出现偏差甚至错误。

Method: 通过基于图-文本的问题生成产生与基础数据集更相关的问题，并采用无偏的评估程序消除基于LLM的答案评估中的偏见。

Result: 将无偏框架应用于评估3种GraphRAG方法，发现它们的效果提升比先前报道的结果保守得多（即实际提升程度远低于先前报道）。

Conclusion: 现有评估框架的科学性问题导致GraphRAG研究有偏差，该研究呼吁建立更科学的评估框架作为GraphRAG研究的基础。

Abstract: By retrieving contexts from knowledge graphs, graph-based retrieval-augmented
generation (GraphRAG) enhances large language models (LLMs) to generate quality
answers for user questions. Many GraphRAG methods have been proposed and
reported inspiring performance in answer quality. However, we observe that the
current answer evaluation framework for GraphRAG has two critical flaws, i.e.,
unrelated questions and evaluation biases, which may lead to biased or even
wrong conclusions on performance. To tackle the two flaws, we propose an
unbiased evaluation framework that uses graph-text-grounded question generation
to produce questions that are more related to the underlying dataset and an
unbiased evaluation procedure to eliminate the biases in LLM-based answer
assessment. We apply our unbiased framework to evaluate 3 representative
GraphRAG methods and find that their performance gains are much more moderate
than reported previously. Although our evaluation framework may still have
flaws, it calls for scientific evaluations to lay solid foundations for
GraphRAG research.

</details>


### [2] [TESU-LLM: Training Speech-LLMs Without Speech via Unified Encoder Alignment](https://arxiv.org/abs/2506.06343)
*Taesoo Kim,Jong Hwan Ko*

Main category: cs.CL

TL;DR: TESU-LLM is a novel framework for training speech-capable language models using only text data, bypassing the need for paired speech-text data or extensive computational resources.


<details>
  <summary>Details</summary>
Motivation: Existing speech-enabled language models rely on large-scale paired speech-text data and significant computational resources, creating scalability and accessibility challenges. To overcome this limitation, TESU-LLM is introduced.

Method: The framework uses a unified encoder to map semantically equivalent text and speech inputs to a shared latent space. This encoder is aligned with an LLM embedding space via a lightweight projection network, enabling generalization from text-only training to speech-based inference.

Result: TESU-LLM achieves strong performance on various speech-related benchmarks, comparable to baselines trained with multimodal datasets and extensive computational resources.

Conclusion: The approach provides an effective and efficient solution for building speech LLMs without speech data, highlighting a scalable path forward.

Abstract: Recent advances in speech-enabled language models have shown promising
results in building intelligent voice assistants. However, most existing
approaches rely on large-scale paired speech-text data and extensive
computational resources, which pose challenges in terms of scalability and
accessibility. In this paper, we present \textbf{TESU-LLM}, a novel framework
that enables training speech-capable language models using only text data. Our
key insight is to leverage a unified encoder that maps semantically equivalent
text and speech inputs to a shared latent space. By aligning the encoder output
with the embedding space of a LLM via a lightweight projection network, we
enable the model to generalize from text-only supervision to speech-based
inference. Despite being trained exclusively on text, TESU-LLM achieves strong
performance on various speech-related benchmarks, comparable to baseline
methods trained with large-scale multimodal datasets and substantial
computational resources. These results highlight the effectiveness and
efficiency of our approach, offering a scalable path toward building speech
LLMs without speech data.

</details>


### [3] [Unified Game Moderation: Soft-Prompting and LLM-Assisted Label Transfer for Resource-Efficient Toxicity Detection](https://arxiv.org/abs/2506.06347)
*Zachary Yang,Domenico Tullo,Reihaneh Rabbany*

Main category: cs.CL

TL;DR: 本文针对游戏社区多语言实时毒性检测的扩展挑战，提出两大解决方案：1）通过软提示技术实现单一模型跨游戏检测，性能媲美课程学习但扩展性更强；2）采用GPT-4o-mini辅助标签迁移框架支持7种语言。新方法在德法等语言表现优异（宏观F1最高58.88%），资源消耗降低50%


<details>
  <summary>Details</summary>
Motivation: 解决多游戏多语言场景下实时毒性检测的扩展性问题：传统方法需为每种游戏/语言组合维护独立模型，导致计算资源和维护成本过高

Method: 1) 游戏上下文软提示：在ToxBuster模型中加入游戏标识token实现跨游戏统一建模；2) GPT-4o-mini辅助多语言扩展：利用大模型迁移英语标签至七种新语言

Result: 1) 跨游戏性能与课程学习相当；2) 四语言宏观F1：法语32.96%/德语58.88%/葡萄牙语49.38%/俄语52.36%（英语基准45.39%）；3) 资源消耗降低50%，Ubisoft生产环境每日每游戏平均识别50名违规玩家

Conclusion: 软提示与LLM标签迁移的组合方案可高效扩展实时毒性检测系统，在显著降低资源消耗的同时，实现德语等语言超越基准的表现，验证了统一框架的工业化可行性

Abstract: Toxicity detection in gaming communities faces significant scaling challenges
when expanding across multiple games and languages, particularly in real-time
environments where computational efficiency is crucial. We present two key
findings to address these challenges while building upon our previous work on
ToxBuster, a BERT-based real-time toxicity detection system. First, we
introduce a soft-prompting approach that enables a single model to effectively
handle multiple games by incorporating game-context tokens, matching the
performance of more complex methods like curriculum learning while offering
superior scalability. Second, we develop an LLM-assisted label transfer
framework using GPT-4o-mini to extend support to seven additional languages.
Evaluations on real game chat data across French, German, Portuguese, and
Russian achieve macro F1-scores ranging from 32.96% to 58.88%, with
particularly strong performance in German, surpassing the English benchmark of
45.39%. In production, this unified approach significantly reduces
computational resources and maintenance overhead compared to maintaining
separate models for each game and language combination. At Ubisoft, this model
successfully identifies an average of 50 players, per game, per day engaging in
sanctionable behavior.

</details>


### [4] [Relationship Detection on Tabular Data Using Statistical Analysis and Large Language Models](https://arxiv.org/abs/2506.06371)
*Panagiotis Koletsis,Christos Panagiotopoulos,Georgios Th. Papadopoulos,Vasilis Efthymiou*

Main category: cs.CL

TL;DR: 结合知识图谱与统计分析的混合方法提升表格列关系识别（CPA任务），通过域范围约束和关系共现减小搜索空间，在不同量化级别的LLMs上实验，竞品性能结果。


<details>
  <summary>Details</summary>
Motivation: 表格自动理解在KG中列关系识别任务重要，但搜索空间巨大；提出利用统计方法约束搜索空间，结合LLMs提升CPA性能。

Method: 混合方法：1) 检测域和范围约束 2) 关系共现分析 → 缩小KG关系搜索空间 → 输入LLMs预测列关系。实验测试不同量化LLMs及提示技巧。

Result: 在两个SemTab基准测试中与SOTA方法竞争，代码已开源。模块分析显示各组件有效，LLMs性能受量化程度影响。

Conclusion: 统计分析与LLMs结合的混合策略有效，可缩小搜索空间并提高CPA准确性。未来研究方向包括优化模块及探索更高效LLMs部署。

Abstract: Over the past few years, table interpretation tasks have made significant
progress due to their importance and the introduction of new technologies and
benchmarks in the field. This work experiments with a hybrid approach for
detecting relationships among columns of unlabeled tabular data, using a
Knowledge Graph (KG) as a reference point, a task known as CPA. This approach
leverages large language models (LLMs) while employing statistical analysis to
reduce the search space of potential KG relations. The main modules of this
approach for reducing the search space are domain and range constraints
detection, as well as relation co-appearance analysis. The experimental
evaluation on two benchmark datasets provided by the SemTab challenge assesses
the influence of each module and the effectiveness of different
state-of-the-art LLMs at various levels of quantization. The experiments were
performed, as well as at different prompting techniques. The proposed
methodology, which is publicly available on github, proved to be competitive
with state-of-the-art approaches on these datasets.

</details>


### [5] [Enhancing Decision-Making of Large Language Models via Actor-Critic](https://arxiv.org/abs/2506.06376)
*Heng Dong,Kefei Duan,Chongjie Zhang*

Main category: cs.CL

TL;DR: 本文提出了一种名为LAC的新颖基于大型语言模型的Actor-Critic框架，通过长期动作评估改进LLM决策能力，在多个环境中超越现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有方法在需要长期推理的复杂决策场景中存在局限：短时序自回归动作生成不适用于长程规划，传统方法难以准确模拟推演和评估结果。

Method: LAC框架通过量化与正负结果相关的token对数概率计算Q值（增强版轨迹推演推理），并采用无梯度优化机制改进策略。

Result: 在ALFWorld、BabyAI-Text和WebShop等多样环境中均超越SOTA，7B/8B参数LLM性能媲美使用GPT-4的基线方法。

Conclusion: 结构化策略优化与LLM内在知识结合可显著提升多步决策能力，LAC框架具有普适性与扩展性。

Abstract: Large Language Models (LLMs) have achieved remarkable advancements in natural
language processing tasks, yet they encounter challenges in complex
decision-making scenarios that require long-term reasoning and alignment with
high-level objectives. Existing methods either rely on short-term
auto-regressive action generation or face limitations in accurately simulating
rollouts and assessing outcomes, leading to sub-optimal decisions. This paper
introduces a novel LLM-based Actor-Critic framework, termed LAC, that
effectively improves LLM policies with long-term action evaluations in a
principled and scalable way. Our approach addresses two key challenges: (1)
extracting robust action evaluations by computing Q-values via token logits
associated with positive/negative outcomes, enhanced by future trajectory
rollouts and reasoning; and (2) enabling efficient policy improvement through a
gradient-free mechanism. Experiments across diverse environments -- including
high-level decision-making (ALFWorld), low-level action spaces (BabyAI-Text),
and large action spaces (WebShop) -- demonstrate the framework's generality and
superiority over state-of-the-art methods. Notably, our approach achieves
competitive performance using 7B/8B parameter LLMs, even outperforming baseline
methods employing GPT-4 in complex tasks. These results underscore the
potential of integrating structured policy optimization with LLMs' intrinsic
knowledge to advance decision-making capabilities in multi-step environments.

</details>


### [6] [Detection Method for Prompt Injection by Integrating Pre-trained Model and Heuristic Feature Engineering](https://arxiv.org/abs/2506.06384)
*Yi Ji,Runzhi Li,Baolei Mao*

Main category: cs.CL

TL;DR: 提出双通道特征融合检测框架DMPI-PMHFE，结合预训练语言模型和启发式特征工程检测提示注入攻击，实验表明在多指标和主流LLMs上优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有提示注入攻击防御方法在效果和泛化性之间存在显著权衡，亟需适用于各类LLM的高效检测方法。

Method: 1) 使用DeBERTa-v3-base提取语义向量 2) 基于攻击模式设计启发式规则提取显式结构特征 3) 双通道特征融合后通过全连接网络分类。

Result: 在多个基准数据集上取得更高准确率、召回率和F1值，实际部署显著降低GLM-4/LLaMA 3/Qwen 2.5/GPT-4o等主流模型的攻击成功率。

Conclusion: 双通道设计有效弥补单一模型特征提取局限，为跨LLM的提示注入检测提供高效解决方案。

Abstract: With the widespread adoption of Large Language Models (LLMs), prompt
injection attacks have emerged as a significant security threat. Existing
defense mechanisms often face critical trade-offs between effectiveness and
generalizability. This highlights the urgent need for efficient prompt
injection detection methods that are applicable across a wide range of LLMs. To
address this challenge, we propose DMPI-PMHFE, a dual-channel feature fusion
detection framework. It integrates a pretrained language model with heuristic
feature engineering to detect prompt injection attacks. Specifically, the
framework employs DeBERTa-v3-base as a feature extractor to transform input
text into semantic vectors enriched with contextual information. In parallel,
we design heuristic rules based on known attack patterns to extract explicit
structural features commonly observed in attacks. Features from both channels
are subsequently fused and passed through a fully connected neural network to
produce the final prediction. This dual-channel approach mitigates the
limitations of relying only on DeBERTa to extract features. Experimental
results on diverse benchmark datasets demonstrate that DMPI-PMHFE outperforms
existing methods in terms of accuracy, recall, and F1-score. Furthermore, when
deployed actually, it significantly reduces attack success rates across
mainstream LLMs, including GLM-4, LLaMA 3, Qwen 2.5, and GPT-4o.

</details>


### [7] [Confidence Is All You Need: Few-Shot RL Fine-Tuning of Language Models](https://arxiv.org/abs/2506.06395)
*Pengyi Li,Matvey Skripkin,Alexander Zubrey,Andrey Kuznetsov,Ivan Oseledets*

Main category: cs.CL

TL;DR: 强化学习自信机制（RLSC）为语言模型提供了一种自我监督的后训练方法，基于模型自身置信度作为奖励信号，无需外部标注或奖励模型。在数学推理任务上显著提升模型性能，最高达+52.5%的准确性提升。


<details>
  <summary>Details</summary>
Motivation: 现存强化学习方法依赖成本高昂的人工标注或外部奖励模型。研究旨在开发一种简单可扩展的后训练方法，仅利用模型自身生成的置信度信号来优化推理能力。

Method: 提出RLSC方法：在少样本场景下（每题仅8样本），将模型自我评估的置信分数转化为强化学习奖励信号，替代传统人工标注。以Qwen2.5-Math-7B为基础模型进行4轮训练。

Result: 在三大数学基准测试取得突破性提升：AIME2024 +20.10%, MATH500 +49.40%, AMC23 +52.50%。证明自我置信奖励机制的有效性。

Conclusion: RLSC首次证明语言模型可仅凭自身置信信号完成强化训练，为轻量化监督的推理模型训练提供了新范式。

Abstract: Large language models (LLMs) excel at reasoning, yet post-training remains
critical for aligning their behavior with task goals. Existing reinforcement
learning (RL) methods often depend on costly human annotations or external
reward models. We propose Reinforcement Learning via Self-Confidence (RLSC),
which uses the model's own confidence as reward signals-eliminating the need
for labels, preference models, or reward engineering. Applied to
Qwen2.5-Math-7B with only 8 samples per question and 4 training epochs, RLSC
improves accuracy by +20.10% on AIME2024, +49.40% on MATH500, and +52.50% on
AMC23. RLSC offers a simple, scalable post-training method for reasoning models
with minimal supervision.

</details>


### [8] [Natural Language Interaction with Databases on Edge Devices in the Internet of Battlefield Things](https://arxiv.org/abs/2506.06396)
*Christopher D. Molek,Roberto Fronteddu,K. Brent Venable,Niranjan Suri*

Main category: cs.CL

TL;DR: 论文提出的两步工作流程使用边缘设备上的大型语言模型（LLM），将自然语言问题转换为图形数据库查询（Cypher）并返回自然语言摘要，在战场物联网（IoBT）中提升态势感知决策支持，并在实验中实现了19.4%的准确率提升。


<details>
  <summary>Details</summary>
Motivation: 为应对战场物联网（IoBT）设备数据难以转化为决策可用信息的挑战，需要开发能自然语言交互的系统，使决策者能实时查询动态网络数据。

Method: 1. 采用适合边缘设备的中等规模LLM（如80亿参数Llama 3.1）
2. 用NLP将自然语言问题转换为图形数据库（Cypher）查询
3. 再将查询结果用NLP总结为自然语言
4. 通过两步法放松对数据库查询语句的精确匹配要求

Result: 1. Llama 3.1在US Army传感器数据集上优于同类模型
2. 新方法使Cypher查询无需精确匹配（EM）即可提升效果
3. 准确率提升19.4%

Conclusion: 该工作流证明了边缘部署LLM实现自然语言数据库交互的可行性，为战场关键决策中的即时信息获取奠定了基础。

Abstract: The expansion of the Internet of Things (IoT) in the battlefield, Internet of
Battlefield Things (IoBT), gives rise to new opportunities for enhancing
situational awareness. To increase the potential of IoBT for situational
awareness in critical decision making, the data from these devices must be
processed into consumer-ready information objects, and made available to
consumers on demand. To address this challenge we propose a workflow that makes
use of natural language processing (NLP) to query a database technology and
return a response in natural language. Our solution utilizes Large Language
Models (LLMs) that are sized for edge devices to perform NLP as well as
graphical databases which are well suited for dynamic connected networks which
are pervasive in the IoBT. Our architecture employs LLMs for both mapping
questions in natural language to Cypher database queries as well as to
summarize the database output back to the user in natural language. We evaluate
several medium sized LLMs for both of these tasks on a database representing
publicly available data from the US Army's Multipurpose Sensing Area (MSA) at
the Jornada Range in Las Cruces, NM. We observe that Llama 3.1 (8 billion
parameters) outperforms the other models across all the considered metrics.
Most importantly, we note that, unlike current methods, our two step approach
allows the relaxation of the Exact Match (EM) requirement of the produced
Cypher queries with ground truth code and, in this way, it achieves a 19.4%
increase in accuracy. Our workflow lays the ground work for deploying LLMs on
edge devices to enable natural language interactions with databases containing
information objects for critical decision making.

</details>


### [9] [Direct Behavior Optimization: Unlocking the Potential of Lightweight LLMs](https://arxiv.org/abs/2506.06401)
*Hongming Yang,Shi Lin,Jun Shao,Changting Lin,Donghai Zhu,Meng Han,Qinglei Kong*

Main category: cs.CL

TL;DR: DeBoP是一种针对轻量级大模型(LwLLMs)的直接行为优化范式，采用蒙特卡洛树搜索自动优化模型行为，在七个任务上显著超越现有提示优化方法，推理速度快60%且性能优于GPT-3.5。


<details>
  <summary>Details</summary>
Motivation: 解决LwLLMs推理能力弱且现有提示优化方法依赖手工或顶级大模型的问题

Method: 将复杂提示优化转为离散执行序列优化，采用无梯度蒙特卡洛树搜索(DeBoP)

Result: 在多数任务上超越现有提示优化方法；优化后LwLLMs性能优于GPT-3.5；计算时间减少60%

Conclusion: DeBoP为LwLLMs提供了高效自动的优化方案，拓展了轻量模型的实用边界

Abstract: Lightweight Large Language Models (LwLLMs) are reduced-parameter, optimized
models designed to run efficiently on consumer-grade hardware, offering
significant advantages in resource efficiency, cost-effectiveness, and data
privacy. However, these models often struggle with limited inference and
reasoning capabilities, which restrict their performance on complex tasks and
limit their practical applicability. Moreover, existing prompt optimization
methods typically rely on extensive manual effort or the meta-cognitive
abilities of state-of-the-art LLMs, making them less effective for LwLLMs. To
address these challenges, we introduce DeBoP, a new Direct Behavior
Optimization Paradigm, original from the Chain-of-Thought (CoT) prompting
technique. Unlike CoT Prompting, DeBoP is an automatic optimization method,
which focuses on the optimization directly on the behavior of LwLLMs. In
particular, DeBoP transforms the optimization of complex prompts into the
optimization of discrete, quantifiable execution sequences using a
gradient-free Monte Carlo Tree Search. We evaluate DeBoP on seven challenging
tasks where state-of-the-art LLMs excel but LwLLMs generally underperform.
Experimental results demonstrate that DeBoP significantly outperforms recent
prompt optimization methods on most tasks. In particular, DeBoP-optimized
LwLLMs surpass GPT-3.5 on most tasks while reducing computational time by
approximately 60% compared to other automatic prompt optimization methods.

</details>


### [10] [Unintended Harms of Value-Aligned LLMs: Psychological and Empirical Insights](https://arxiv.org/abs/2506.06404)
*Sooyung Choi,Jaehyeok Lee,Xiaoyuan Yi,Jing Yao,Xing Xie,JinYeong Bak*

Main category: cs.CL

TL;DR: 摘要


<details>
  <summary>Details</summary>
Motivation: 研究动机

Method: 研究方法

Result: 研究结果

Conclusion: 研究结论

Abstract: The application scope of Large Language Models (LLMs) continues to expand,
leading to increasing interest in personalized LLMs that align with human
values. However, aligning these models with individual values raises
significant safety concerns, as certain values may correlate with harmful
information. In this paper, we identify specific safety risks associated with
value-aligned LLMs and investigate the psychological principles behind these
challenges. Our findings reveal two key insights. (1) Value-aligned LLMs are
more prone to harmful behavior compared to non-fine-tuned models and exhibit
slightly higher risks in traditional safety evaluations than other fine-tuned
models. (2) These safety issues arise because value-aligned LLMs genuinely
generate text according to the aligned values, which can amplify harmful
outcomes. Using a dataset with detailed safety categories, we find significant
correlations between value alignment and safety risks, supported by
psychological hypotheses. This study offers insights into the "black box" of
value alignment and proposes in-context alignment methods to enhance the safety
of value-aligned LLMs.

</details>


### [11] [SMAR: Soft Modality-Aware Routing Strategy for MoE-based Multimodal Large Language Models Preserving Language Capabilities](https://arxiv.org/abs/2506.06406)
*Guoyang Xia,Yifeng Ding,Fengfa Li,Lei Ren,Chen Wei,Fangxiang Feng,Xiaojie Wang*

Main category: cs.CL

TL;DR: 提出了一种用于多模态专家混合模型的新正则化方法 SMAR，用于平衡模态区分和语言能力。


<details>
  <summary>Details</summary>
Motivation: 现有构建多模态 MoE 模型的方法要么训练成本高昂，要么在适应预训练模型时破坏语言能力

Method: SMAR 使用 KL 散度控制跨模态路由概率分布，促进专家专业化

Result: 在视觉指令微调中保留 86.6% 语言能力（仅用 2.5% 纯文本），优于基线且保持强大多模态性能

Conclusion: 为多模态 MoE 模型提供了平衡模态区分和语言能力的实用高效解决方案

Abstract: Mixture of Experts (MoE) architectures have become a key approach for scaling
large language models, with growing interest in extending them to multimodal
tasks. Existing methods to build multimodal MoE models either incur high
training costs or suffer from degraded language capabilities when adapting
pretrained models. To address this, we propose Soft ModalityAware Routing
(SMAR), a novel regularization technique that uses Kullback Leibler divergence
to control routing probability distributions across modalities, encouraging
expert specialization without modifying model architecture or heavily relying
on textual data. Experiments on visual instruction tuning show that SMAR
preserves language ability at 86.6% retention with only 2.5% pure text,
outperforming baselines while maintaining strong multimodal performance. Our
approach offers a practical and efficient solution to balance modality
differentiation and language capabilities in multimodal MoE models.

</details>


### [12] [Canonical Autoregressive Generation](https://arxiv.org/abs/2506.06446)
*Ivi Chatzi,Nina Corvelo Benz,Stratis Tsirtsis,Manuel Gomez-Rodriguez*

Main category: cs.CL

TL;DR: 本文揭示了大型语言模型在生成时可能产生非规范标记序列的问题，并提出了"规范采样"方法确保生成的序列始终符合规范标记化，从而提升生成质量。


<details>
  <summary>Details</summary>
Motivation: 现有大语言模型在推理过程中可能出现非规范标记序列的生成，导致多种负面影响（如语义偏差）。实证研究表明模型并非总是生成规范序列，因此需要确保模型在每一步自回归生成中输出规范部分序列。

Method: 提出"规范采样"算法：在自回归生成的每一步，根据预定义规范（tokenizer规则），限制模型仅从当前可用的规范子标记集中采样。该方法通过动态修剪非规范候选标记实现高效约束。

Result: 理论证明规范采样生成的序列分布更接近训练数据的真实分布（缩小分布间隙），同时实验验证其有效避免非规范序列生成（提升下游任务一致性）。

Conclusion: 规范采样是一种轻量级解决方案，通过强制约束自回归过程中的标记选择，确保LLM始终输出规范序列。这既改善了生成质量，又提供更可控的文本生成机制。

Abstract: State of the art large language models are trained using large amounts of
tokens derived from raw text using what is called a tokenizer. Crucially, the
tokenizer determines the (token) vocabulary a model will use during inference
as well as, in principle, the (token) language. This is because, while the
token vocabulary may allow for different tokenizations of a string, the
tokenizer always maps the string to only one of these tokenizations--the
canonical tokenization. However, multiple lines of empirical evidence suggest
that large language models do not always generate canonical token sequences,
and this comes with several negative consequences. In this work, we first show
that, to generate a canonical token sequence, a model needs to generate
(partial) canonical token sequences at each step of the autoregressive
generation process underpinning its functioning. Building upon this theoretical
result, we introduce canonical sampling, a simple and efficient sampling method
that precludes a given model from generating non-canonical token sequences.
Further, we also show that, in comparison with standard sampling, the
distribution of token sequences generated using canonical sampling is provably
closer to the true distribution of token sequences used during training.

</details>


### [13] [What Is Seen Cannot Be Unseen: The Disruptive Effect of Knowledge Conflict on Large Language Models](https://arxiv.org/abs/2506.06485)
*Kaiser Sun,Fan Bai,Mark Dredze*

Main category: cs.CL

TL;DR: 本文提出了一个诊断框架来评估LLM在上下文与参数知识冲突时的行为，发现知识冲突对无需知识运用的任务影响很小，但当二者一致时模型表现更好；模型无法完全抑制内部知识，而提供解释冲突的理性会增加对上下文的依赖。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型同时依赖上下文输入和参数知识，但二者可能冲突（尤其是检索文档与参数知识矛盾时），需系统评估冲突下模型行为。

Method: 构建上下文与参数知识冲突的诊断数据集，分析多任务类型下模型表现（包括无冲突/冲突设定，以及指令抑制内部知识、提供冲突解释等场景）。

Result: 发现：1）知识冲突对非知识型任务无影响；2）上下文与参数一致时模型表现最优；3）即使被要求忽略，模型也无法完全抑制参数知识；4）提供冲突解释能增强上下文依赖。

Conclusion: 知识冲突会影响模型评估结果的有效性，实际部署LLM时需考虑此因素；模型无法完全抑制参数知识的现象揭示其行为机制局限。

Abstract: Large language models frequently rely on both contextual input and parametric
knowledge to perform tasks. However, these sources can come into conflict,
especially when retrieved documents contradict the model's parametric
knowledge. We propose a diagnostic framework to systematically evaluate LLM
behavior under context-memory conflict, where the contextual information
diverges from their parametric beliefs. We construct diagnostic data that
elicit these conflicts and analyze model performance across multiple task
types. Our findings reveal that (1) knowledge conflict has minimal impact on
tasks that do not require knowledge utilization, (2) model performance is
consistently higher when contextual and parametric knowledge are aligned, (3)
models are unable to fully suppress their internal knowledge even when
instructed, and (4) providing rationales that explain the conflict increases
reliance on contexts. These insights raise concerns about the validity of
model-based evaluation and underscore the need to account for knowledge
conflict in the deployment of LLMs.

</details>


### [14] [Improving LLM-Powered EDA Assistants with RAFT](https://arxiv.org/abs/2506.06500)
*Luyao Shi,Michael Kazda,Charles Schmitter,Hemlata Gupta*

Main category: cs.CL

TL;DR: 提出使用合成Q/A数据集增强LLM的RAFT方法，提升EDA任务性能，并探讨了真实用户问题作为RAFS示例、安全访问控制及数据泄露风险的影响。


<details>
  <summary>Details</summary>
Motivation: 电子设计工程师在EDA任务中难以高效获取相关信息，开源LLMs缺乏领域知识，且标注数据获取困难。

Method: 利用合成Q/A数据进行检索增强微调(RAFT)，研究真实用户问题作为RAFS示例，实施安全访问控制，评估数据泄露风险。

Result: 合成数据显著提升LLM在RAG任务中的表现，并为安全风险提供实用洞察。

Conclusion: RAFT与合成数据结合是增强EDA领域LLMs的有效方案，同时需注意数据安全。

Abstract: Electronic design engineers often struggle to efficiently access relevant
information for tasks like design verification and technology development.
While large language models (LLMs) can enhance productivity as conversational
agents, pre-trained open-source LLMs lack domain-specific knowledge for
Electronic Design Automation (EDA). In a Retrieval-Augmented Generation (RAG)
context, LLMs rely on external context but may still produce inaccurate
responses. Retrieval-Augmented Fine-Tuning (RAFT) improves LLM performance, but
acquiring labeled question/answer (Q/A) data in EDA is difficult. To address
this, we propose using synthetic Q/A datasets to enhance LLMs with RAFT. Our
results show that RAFT with synthetic data significantly boosts LLM performance
for RAG-based EDA tasks. We also investigate the impact of using real user
questions as Retrieval-Augmented Few-Shot (RAFS) examples for synthetic data
generation. Additionally, we implement secure access control to ensure
sensitive information is only accessible to authorized personnel. Finally, we
assess the risk of data leakage and unintended memorization during fine-tuning
with synthetic data, providing practical insights.

</details>


### [15] [Biases Propagate in Encoder-based Vision-Language Models: A Systematic Analysis From Intrinsic Measures to Zero-shot Retrieval Outcomes](https://arxiv.org/abs/2506.06506)
*Kshitish Ghate,Tessa Charlesworth,Mona Diab,Aylin Caliskan*

Main category: cs.CL

TL;DR: 该研究建立了基础视觉语言模型（VLM）内在社会群体偏见向下游零样本检索任务传播的关联框架，发现内在与外在偏见高度相关（平均ρ = 0.83 ± 0.10）。大型/高性能模型传播偏见更大，且未被充分代表的群体传播鲁棒性更低。


<details>
  <summary>Details</summary>
Motivation: 探究基础视觉语言模型中固有的社会群体偏见如何传播至下游任务，揭示深层偏见如何系统性地影响模型输出。

Method: 开发受控框架，通过关联 (a)表征空间的内在偏见度量 (b)零样本图文互检索任务的外在偏见度量，覆盖114项分析、双向检索、六类社会群体及三种VLM。

Result: 1. 内在与外在偏见呈现强相关性（平均ρ=0.83） 2. 模型性能越高则偏见传播越强 3. 未被充分代表群体传播鲁棒性更低

Conclusion: 基础模型偏见系统性传播至下游任务的现象需警惕；当前'越大越好'的模型开发范式加剧偏见传播；提出基线评估任务用于量化群体/情感信号传播能力。

Abstract: To build fair AI systems we need to understand how social-group biases
intrinsic to foundational encoder-based vision-language models (VLMs) manifest
in biases in downstream tasks. In this study, we demonstrate that intrinsic
biases in VLM representations systematically ``carry over'' or propagate into
zero-shot retrieval tasks, revealing how deeply rooted biases shape a model's
outputs. We introduce a controlled framework to measure this propagation by
correlating (a) intrinsic measures of bias in the representational space with
(b) extrinsic measures of bias in zero-shot text-to-image (TTI) and
image-to-text (ITT) retrieval. Results show substantial correlations between
intrinsic and extrinsic bias, with an average $\rho$ = 0.83 $\pm$ 0.10. This
pattern is consistent across 114 analyses, both retrieval directions, six
social groups, and three distinct VLMs. Notably, we find that
larger/better-performing models exhibit greater bias propagation, a finding
that raises concerns given the trend towards increasingly complex AI models.
Our framework introduces baseline evaluation tasks to measure the propagation
of group and valence signals. Investigations reveal that underrepresented
groups experience less robust propagation, further skewing their model-related
outcomes.

</details>


### [16] [Fixing It in Post: A Comparative Study of LLM Post-Training Data Quality and Model Performance](https://arxiv.org/abs/2506.06522)
*Aladin Djuhera,Swanand Ravindra Kadhe,Syed Zawad,Farhan Ahmed,Heiko Ludwig,Holger Boche*

Main category: cs.CL

TL;DR: 本研究对两种主流开源后训练数据集(Tulu-3-SFT-Mix和SmolTalk)进行了首次系统比较分析，创建了包含质量指标的注释数据集，并提出新的高效数据集构建方法TuluTalk，在减少14%数据量的情况下性能相当或更好。


<details>
  <summary>Details</summary>
Motivation: 主流LLM使用的后训练数据集缺乏透明度，且现有开源替代品缺乏系统比较，难以评估数据质量对性能的影响。

Method: 使用Magpie框架对数据集样本进行标注（对话轮次结构、任务类别、输入质量、响应质量），基于分析设计新数据混合配方TuluTalk。

Result: TuluTalk比原始数据集少14%样本，但在关键基准测试中性能相当或更优。注释数据集和优化配方已开源。

Conclusion: 通过系统性分析提出可操作的数据集构建策略，在资源限制下有效提升模型性能；开放资源促进未来研究。

Abstract: Recent work on large language models (LLMs) has increasingly focused on
post-training and alignment with datasets curated to enhance instruction
following, world knowledge, and specialized skills. However, most post-training
datasets used in leading open- and closed-source LLMs remain inaccessible to
the public, with limited information about their construction process. This
lack of transparency has motivated the recent development of open-source
post-training corpora. While training on these open alternatives can yield
performance comparable to that of leading models, systematic comparisons remain
challenging due to the significant computational cost of conducting them
rigorously at scale, and are therefore largely absent. As a result, it remains
unclear how specific samples, task types, or curation strategies influence
downstream performance when assessing data quality. In this work, we conduct
the first comprehensive side-by-side analysis of two prominent open
post-training datasets: Tulu-3-SFT-Mix and SmolTalk. Using the Magpie
framework, we annotate each sample with detailed quality metrics, including
turn structure (single-turn vs. multi-turn), task category, input quality, and
response quality, and we derive statistics that reveal structural and
qualitative similarities and differences between the two datasets. Based on
these insights, we design a principled curation recipe that produces a new data
mixture, TuluTalk, which contains 14% fewer samples than either source dataset
while matching or exceeding their performance on key benchmarks. Our findings
offer actionable insights for constructing more effective post-training
datasets that improve model performance within practical resource limits. To
support future research, we publicly release both the annotated source datasets
and our curated TuluTalk mixture.

</details>


### [17] [Beyond Facts: Evaluating Intent Hallucination in Large Language Models](https://arxiv.org/abs/2506.06539)
*Yijie Hao,Haofei Yu,Jiaxuan You*

Main category: cs.CL

TL;DR: 本研究提出了'意图幻觉'的概念，指大型语言模型（LLMs）在处理复杂多条件查询时出现遗漏或误解用户意图的问题，并发布了首个专注于该问题的评估基准FAITHQA。研究发现该现象普遍存在，并提出自动化评估指标CONSTRAINT SCORE。


<details>
  <summary>Details</summary>
Motivation: 现有大型语言模型处理复杂多条件查询时存在部分满足查询而忽略某些条件的问题，需要系统性研究这种'意图幻觉'现象。

Method: 构建FAITHQA基准（含20,068个问题），覆盖纯查询和检索增强生成场景；提出自动化评估指标CONSTRAINT SCORE；通过该基准评估多个LLMs模型性能。

Result: 1) 意图幻觉在顶尖模型中普遍存在；2) 该现象源于模型对查询条件的遗漏或曲解；3) 新指标CONSTRAINT SCORE在人类评估中优于基线方法。

Conclusion: 意图幻觉是LLMs的核心缺陷，FAITHQA基准和CONSTRAINT SCORE指标为未来研究提供了系统评估工具。

Abstract: When exposed to complex queries containing multiple conditions, today's large
language models (LLMs) tend to produce responses that only partially satisfy
the query while neglecting certain conditions. We therefore introduce the
concept of Intent Hallucination. In this phenomenon, LLMs either omit
(neglecting to address certain parts) or misinterpret (responding to invented
query parts) elements of the given query, leading to intent hallucinated
generation. To systematically evaluate intent hallucination, we introduce
FAITHQA, a novel benchmark for intent hallucination that contains 20,068
problems, covering both query-only and retrieval-augmented generation (RAG)
setups with varying topics and difficulty. FAITHQA is the first hallucination
benchmark that goes beyond factual verification, tailored to identify the
fundamental cause of intent hallucination. By evaluating various LLMs on
FAITHQA, we find that (1) intent hallucination is a common issue even for
state-of-the-art models, and (2) the phenomenon stems from omission or
misinterpretation of LLMs. To facilitate future research, we introduce an
automatic LLM generation evaluation metric, CONSTRAINT SCORE, for detecting
intent hallucination. Human evaluation results demonstrate that CONSTRAINT
SCORE is closer to human performance for intent hallucination compared to
baselines.

</details>


### [18] [LaMP-Cap: Personalized Figure Caption Generation With Multimodal Figure Profiles](https://arxiv.org/abs/2506.06561)
*Ho Yin 'Sam' Ng,Ting-Yao Hsu,Aashish Anantha Ramakrishnan,Branislav Kveton,Nedim Lipka,Franck Dernoncourt,Dongwon Lee,Tong Yu,Sungchul Kim,Ryan A. Rossi,Ting-Hao 'Kenneth' Huang*

Main category: cs.CL

TL;DR: LaMP-Cap is a multimodal dataset for personalized figure caption generation, using images and other figures' context as profiles. Experiments show using these profiles improves caption similarity to author-written ones, with images being more helpful than text.


<details>
  <summary>Details</summary>
Motivation: Existing caption generation models require authors to revise generic AI captions to match their style and domain. Current personalization techniques are text-only and neglect multimodal inputs and profiles.

Method: Introduction of LaMP-Cap dataset containing figure images plus up to three related figures (each with image, caption, and mentioning paragraphs) as context profiles. Tested four large language models (LLMs) using profile information.

Result: Using profile information consistently improved caption generation similarity to original author captions. Ablation studies showed profile images contributed more than figure-mentioning paragraphs.

Conclusion: Multimodal profiles (especially images) enhance personalized caption generation compared to text-only methods. LaMP-Cap demonstrates the value of incorporating contextual figure information from the same document.

Abstract: Figure captions are crucial for helping readers understand and remember a
figure's key message. Many models have been developed to generate these
captions, helping authors compose better quality captions more easily. Yet,
authors almost always need to revise generic AI-generated captions to match
their writing style and the domain's style, highlighting the need for
personalization. Despite language models' personalization (LaMP) advances,
these technologies often focus on text-only settings and rarely address
scenarios where both inputs and profiles are multimodal. This paper introduces
LaMP-Cap, a dataset for personalized figure caption generation with multimodal
figure profiles. For each target figure, LaMP-Cap provides not only the needed
inputs, such as figure images, but also up to three other figures from the same
document--each with its image, caption, and figure-mentioning paragraphs--as a
profile to characterize the context. Experiments with four LLMs show that using
profile information consistently helps generate captions closer to the original
author-written ones. Ablation studies reveal that images in the profile are
more helpful than figure-mentioning paragraphs, highlighting the advantage of
using multimodal profiles over text-only ones.

</details>


### [19] [Precise Information Control in Long-Form Text Generation](https://arxiv.org/abs/2506.06589)
*Jacqueline He,Howard Yen,Margaret Li,Shuyue Stella Li,Zhiyuan Zeng,Weijia Shi,Yulia Tsvetkov,Danqi Chen,Pang Wei Koh,Luke Zettlemoyer*

Main category: cs.CL

TL;DR: 这篇论文提出了精确信息控制(PIC)任务——要求模型仅基于给定的可验证声明集生成长文本而不添加不实信息，并通过PIC-Bench基准评估了当前主流语言模型固有幻觉严重(70%输出含虚构)，最后训练出能够显著提升事实一致性的PIC-LM模型(在完整PIC设置上F1从69.1%提升至91.0%)。


<details>
  <summary>Details</summary>
Motivation: 解决语言模型生成内容时产生的本质性幻觉问题(看似合理但无事实依据的信息)，需要建立能精确控制信息的评估体系和改进方法。

Method: 1）定义PIC任务：包含完整模式(必须包含所有输入声明)和部分模式(仅选择相关声明)；2）构建PIC-Bench基准测试集(含8个长文本生成任务)；3）设计弱监督偏好数据训练框架改进模型(PIC-LM)。

Result: 1）主流模型在PIC-Bench上固有幻觉率超70%；2）所提PIC-LM显著提升性能：完整PIC设置的F1达91.0%(提升21.9pp)；3）集成PIC-LM的端到端系统在模糊问答任务中召回率提升17.1%，在生源地验证中事实精度提升30.5%。

Conclusion: PIC任务为控制幻觉提供了新方法，经训练的PIC-LM证明可通过精确信息控制大幅改善语言模型的事实一致性，为可靠文本生成系统开辟了道路。

Abstract: A central challenge in modern language models (LMs) is intrinsic
hallucination: the generation of information that is plausible but
unsubstantiated relative to input context. To study this problem, we propose
Precise Information Control (PIC), a new task formulation that requires models
to generate long-form outputs grounded in a provided set of short
self-contained statements, known as verifiable claims, without adding any
unsupported ones. For comprehensiveness, PIC includes a full setting that tests
a model's ability to include exactly all input claims, and a partial setting
that requires the model to selectively incorporate only relevant claims. We
present PIC-Bench, a benchmark of eight long-form generation tasks (e.g.,
summarization, biography generation) adapted to the PIC setting, where LMs are
supplied with well-formed, verifiable input claims. Our evaluation of a range
of open and proprietary LMs on PIC-Bench reveals that, surprisingly,
state-of-the-art LMs still intrinsically hallucinate in over 70% of outputs. To
alleviate this lack of faithfulness, we introduce a post-training framework,
using a weakly supervised preference data construction method, to train an 8B
PIC-LM with stronger PIC ability--improving from 69.1% to 91.0% F1 in the full
PIC setting. When integrated into end-to-end factual generation pipelines,
PIC-LM improves exact match recall by 17.1% on ambiguous QA with retrieval, and
factual precision by 30.5% on a birthplace verification task, underscoring the
potential of precisely grounded generation.

</details>


### [20] [MedCite: Can Language Models Generate Verifiable Text for Medicine?](https://arxiv.org/abs/2506.06605)
*Xiao Wang,Mengjue Tan,Qiao Jin,Guangzhi Xiong,Yu Hu,Aidong Zhang,Zhiyong Lu,Minjia Zhang*

Main category: cs.CL

TL;DR: 该论文介绍了第一个端到端框架，用于医学任务中基于LLM的引用生成与评估，提出了一种新颖的多重检索引用方法，在准确率和召回率上优于基线方法。


<details>
  <summary>Details</summary>
Motivation: 现有基于LLM的医疗问答系统缺乏引用生成和评估能力，阻碍了实际应用。

Method: 提出了一个名为\name的端到端框架，设计了新颖的多重检索引用方法（multi-pass retrieval-citation）。

Result: 所提方法在引用准确率和召回率上显著超越基线方法，且评估结果与专家标注高度相关。

Conclusion: 该研究解决了医疗QA系统中引用生成的难题，通过框架设计和评估机制为实际部署提供了重要指导。

Abstract: Existing LLM-based medical question-answering systems lack citation
generation and evaluation capabilities, raising concerns about their adoption
in practice. In this work, we introduce \name, the first end-to-end framework
that facilitates the design and evaluation of citation generation with LLMs for
medical tasks. Meanwhile, we introduce a novel multi-pass retrieval-citation
method that generates high-quality citations. Our evaluation highlights the
challenges and opportunities of citation generation for medical tasks, while
identifying important design choices that have a significant impact on the
final citation quality. Our proposed method achieves superior citation
precision and recall improvements compared to strong baseline methods, and we
show that evaluation results correlate well with annotation results from
professional experts.

</details>


### [21] [Training-Free Tokenizer Transplantation via Orthogonal Matching Pursuit](https://arxiv.org/abs/2506.06607)
*Charles Goddard,Fernando Fernandes Neto*

Main category: cs.CL

TL;DR: 本文提出了一种无需训练、基于正交匹配追踪（OMP）的tokenizer移植方法，通过共享token的稀疏线性组合重建新词嵌入，在跨tokenizer任务中零样本性能优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 解决预训练大语言模型中更换tokenizer时的嵌入失配问题，避免重新训练的巨大开销，实现跨tokenizer的知识迁移。

Method: 使用两阶段OMP算法：首先通过共享锚token在捐赠模型空间生成新token表示，再将相同稀疏系数转移回基础模型空间重建嵌入。

Result: 在Llama→Mistral和Qwen→Llama等任务中，OMP零样本性能超越所有基线（如WECHSEL），尤其在数学推理任务中有效缓解了数值tokenization不一致问题。

Conclusion: 该方法无需梯度更新即可对齐tokenizer差异，已集成到开源工具mergekit-tokensurgeon，支持知识蒸馏、推测解码等跨tokenizer应用。

Abstract: We present a training-free method to transplant tokenizers in pretrained
large language models (LLMs) by reconstructing unseen token embeddings via
Orthogonal Matching Pursuit (OMP). Specifically, we approximate each
out-of-vocabulary token as a sparse linear combination of shared tokens, in two
phases: first, compute each new token's representation in the donor embedding
space with a small dictionary of shared anchor tokens, then transfer these same
sparse coefficients back into the base model's embedding space.
  On two challenging cross-tokenizer tasks--Llama$\to$Mistral NeMo (12B) and
Qwen$\to$Llama (1B)--we show that OMP achieves best zero-shot preservation of
the base model's performance across multiple benchmarks, while other zero-shot
approaches degrade significantly. Compared to baselines (zero-init, mean-init,
and existing approaches like WECHSEL, FOCUS, ZETT), OMP consistently achieves
the best overall performance, effectively bridging large tokenizer
discrepancies without gradient updates. Our analysis further identifies
mismatched numerical tokenization schemes as a critical challenge for
preserving mathematical reasoning capabilities. This technique enables direct
reuse of pretrained model weights with new tokenizers, facilitating
cross-tokenizer knowledge distillation, speculative decoding, ensembling,
merging, and domain-specific vocabulary adaptations. We integrate our method
into the open-source mergekit-tokensurgeon tool for post hoc vocabulary
realignment.

</details>


### [22] [Transferring Features Across Language Models With Model Stitching](https://arxiv.org/abs/2506.06609)
*Alan Chen,Jack Merullo,Alessandro Stolfo,Ellie Pavlick*

Main category: cs.CL

TL;DR: 该论文提出了一种通过仿射映射在语言模型残差流之间转移特征表示的低成本方法，实现SAE（稀疏自编码器）在不同大小模型间的权重迁移，实验表明小模型和大模型学习到的表示空间高度相似，从而可通过在小模型上训练SAEs再迁移到大模型来节省训练成本（例如减少50%训练开销）。研究还发现转移后的探测器和导向向量能有效恢复真实性能，深入分析揭示了语义/结构特征与特定功能特征在迁移中的不同表现，最终展示了一种提升SAE训练效率的方法。


<details>
  <summary>Details</summary>
Motivation: 针对语言模型中特征表示迁移的高成本问题，研究旨在验证小模型和大模型表示空间的相似性，探索通过低成本仿射映射技术实现SAEs等组件在模型间的迁移，从而降低大模型相关训练的开销。

Method: 使用仿射映射作为残差流特征表示的传输桥梁，在不同规模语言模型间迁移稀疏自编码器（SAEs）权重。通过比较迁移前后特征表示的效果，评估小模型与大模型表示空间的一致性，并测试转移后的探测器和导向向量的性能恢复能力。

Result: 1) 小模型和大模型的表示空间高度相似，SAE从小模型迁移到大模型可节省50%训练成本；2) 转移后的探测器和导向向量能有效恢复真实性能；3) 语义/结构特征迁移效果存在差异，而特定功能特征能忠实映射。

Conclusion: 研究证实了通过低成本仿射映射在模型间转移特征表示的可行性，揭示了不同规模模型表示空间的相似性与差异（尤其特征级迁移的特性），并提出了提升SAE训练效率的有效迁移策略。

Abstract: In this work, we demonstrate that affine mappings between residual streams of
language models is a cheap way to effectively transfer represented features
between models. We apply this technique to transfer the weights of Sparse
Autoencoders (SAEs) between models of different sizes to compare their
representations. We find that small and large models learn highly similar
representation spaces, which motivates training expensive components like SAEs
on a smaller model and transferring to a larger model at a FLOPs savings. For
example, using a small-to-large transferred SAE as initialization can lead to
50% cheaper training runs when training SAEs on larger models. Next, we show
that transferred probes and steering vectors can effectively recover ground
truth performance. Finally, we dive deeper into feature-level transferability,
finding that semantic and structural features transfer noticeably differently
while specific classes of functional features have their roles faithfully
mapped. Overall, our findings illustrate similarities and differences in the
linear representation spaces of small and large models and demonstrate a method
for improving the training efficiency of SAEs.

</details>


### [23] [Interpretable Depression Detection from Social Media Text Using LLM-Derived Embeddings](https://arxiv.org/abs/2506.06616)
*Samuel Kim,Oghenemaro Imieye,Yunting Yin*

Main category: cs.CL

TL;DR: 比较大型语言模型（LLMs）与传统机器学习在社交媒体抑郁文本检测中的表现，发现零样本LLMs在二分类中表现良好但在细粒度分类中不佳，而基于LLM生成摘要嵌入的监督分类器性能更优。


<details>
  <summary>Details</summary>
Motivation: 社交媒体中抑郁语言的准确检测对心理健康早期干预至关重要，可助力临床实践和公共卫生。

Method: 实验评估零样本LLMs与监督分类器在抑郁二分类、严重程度分类及抑郁症/PTSD/焦虑症鉴别诊断中的效果；监督分类器使用传统文本嵌入和LLM生成摘要嵌入作为特征。

Result: 零样本LLMs在二分类任务中泛化能力强，但细粒度分类表现差；基于LLM摘要嵌入的分类器性能优于传统文本嵌入模型，部分任务达最优效果。

Conclusion: LLMs在心理健康预测中潜力显著，未来应优化其零样本能力与情境感知摘要技术。

Abstract: Accurate and interpretable detection of depressive language in social media
is useful for early interventions of mental health conditions, and has
important implications for both clinical practice and broader public health
efforts. In this paper, we investigate the performance of large language models
(LLMs) and traditional machine learning classifiers across three classification
tasks involving social media data: binary depression classification, depression
severity classification, and differential diagnosis classification among
depression, PTSD, and anxiety. Our study compares zero-shot LLMs with
supervised classifiers trained on both conventional text embeddings and
LLM-generated summary embeddings. Our experiments reveal that while zero-shot
LLMs demonstrate strong generalization capabilities in binary classification,
they struggle with fine-grained ordinal classifications. In contrast,
classifiers trained on summary embeddings generated by LLMs demonstrate
competitive, and in some cases superior, performance on the classification
tasks, particularly when compared to models using traditional text embeddings.
Our findings demonstrate the strengths of LLMs in mental health prediction, and
suggest promising directions for better utilization of their zero-shot
capabilities and context-aware summarization techniques.

</details>


### [24] [BriefMe: A Legal NLP Benchmark for Assisting with Legal Briefs](https://arxiv.org/abs/2506.06619)
*Jesse Woo,Fateme Hashemi Chaleshtori,Ana Marasović,Kenneth Marino*

Main category: cs.CL

TL;DR: 介绍了一个专注于法律摘要的新数据集BRIEFME，该数据集包含三个任务：论点总结、论点补全和案件检索，旨在帮助法律专业人士撰写摘要。评估发现大型语言模型在总结和引导补全任务上表现良好，但在现实论点补全和案件检索任务中表现较差。


<details>
  <summary>Details</summary>
Motivation: 法律摘要的撰写和编辑在法律NLP中尚未得到充分探索，该领域不仅要求对法域内的法律有全面理解，还需要能够提出创新论点和具有说服力的论证，因此需要构建一个数据集推动模型发展以为法律专业人员提供有效辅助。

Method: 提出了BRIEFME数据集，包含三个核心任务：(1) 论点总结 – 根据内容摘要论点核心；(2) 论点补全 – 提供提示完成更具说服力的论点；(3) 案例检索 – 找出支持论点的相关判例。构建并分析了这三个任务，并对当前模型进行了性能评估，对比了人类基线表现。

Result: 当前大型语言模型在论点总结和引导补全任务上表现出色，其表现优于人类生成的摘要标题；但在现实论证补全和精确案例检索任务中表现显著较差。例如在检索任务中模型难以准确识别相关案例。

Conclusion: BRIEFME数据集揭示了LLMs在法律应用中的能力差异，并为进一步推动法律NLP发展指明方向——特别是在现实论证构建和精准案例匹配任务上仍有巨大改进空间，鼓励社区为此类实际法律任务开发更有效的模型。

Abstract: A core part of legal work that has been under-explored in Legal NLP is the
writing and editing of legal briefs. This requires not only a thorough
understanding of the law of a jurisdiction, from judgments to statutes, but
also the ability to make new arguments to try to expand the law in a new
direction and make novel and creative arguments that are persuasive to judges.
To capture and evaluate these legal skills in language models, we introduce
BRIEFME, a new dataset focused on legal briefs. It contains three tasks for
language models to assist legal professionals in writing briefs: argument
summarization, argument completion, and case retrieval. In this work, we
describe the creation of these tasks, analyze them, and show how current models
perform. We see that today's large language models (LLMs) are already quite
good at the summarization and guided completion tasks, even beating
human-generated headings. Yet, they perform poorly on other tasks in our
benchmark: realistic argument completion and retrieving relevant legal cases.
We hope this dataset encourages more development in Legal NLP in ways that will
specifically aid people in performing legal work.

</details>


### [25] [Psychological Counseling Cannot Be Achieved Overnight: Automated Psychological Counseling Through Multi-Session Conversations](https://arxiv.org/abs/2506.06626)
*Junzhe Wang,Bichen Wang,Xing Fu,Yixin Sun,Yanyan Zhao,Bing Qin*

Main category: cs.CL

TL;DR: 论文针对现有大型语言模型（LLMs）在心理辅导中仅关注单次对话的局限，提出了多轮心理辅导数据集（MusPsy-Dataset）及配套模型（MusPsy-Model），实现了跨会话持续跟踪用户状态的能力。


<details>
  <summary>Details</summary>
Motivation: 现有心理辅导研究集中在单次对话，但真实场景需多次连续会话才能逐步解决用户问题，为解决单次对话无法反映辅导过程的缺陷。

Method: 1. 基于公开心理案例报告构建多轮心理对话数据集（MusPsy-Dataset）
2. 开发能追踪用户状态演变的自适应模型（MusPsy-Model）

Result: 在连续会话场景中，MusPsy-Model在多个指标上超越基线模型

Conclusion: 该研究填补了多轮心理辅导的技术空白，数据集和模型证明了跨会话持续跟踪对提升辅导效果的重要性

Abstract: In recent years, Large Language Models (LLMs) have made significant progress
in automated psychological counseling. However, current research focuses on
single-session counseling, which doesn't represent real-world scenarios. In
practice, psychological counseling is a process, not a one-time event,
requiring sustained, multi-session engagement to progressively address clients'
issues. To overcome this limitation, we introduce a dataset for Multi-Session
Psychological Counseling Conversation Dataset (MusPsy-Dataset). Our
MusPsy-Dataset is constructed using real client profiles from publicly
available psychological case reports. It captures the dynamic arc of
counseling, encompassing multiple progressive counseling conversations from the
same client across different sessions. Leveraging our dataset, we also
developed our MusPsy-Model, which aims to track client progress and adapt its
counseling direction over time. Experiments show that our model performs better
than baseline models across multiple sessions.

</details>


### [26] [SafeLawBench: Towards Safe Alignment of Large Language Models](https://arxiv.org/abs/2506.06636)
*Chuxue Cao,Han Zhu,Jiaming Ji,Qichao Sun,Zhenghao Zhu,Yinyu Wu,Juntao Dai,Yaodong Yang,Sirui Han,Yike Guo*

Main category: cs.CL

TL;DR: 该论文提出了 SafeLawBench 安全评测基准，首次从法律角度评估大语言模型的安全性，包含 24,860 道选择题和 1,106 道开放问答任务。评测结果显示现有模型平均准确率仅 68.8%，最高未超 80.5%，呼吁业界重视 LLM 安全性研究。


<details>
  <summary>Details</summary>
Motivation: 当前 LLM 安全性评估缺乏客观标准，现有基准存在主观性问题，需要建立法律视角的系统性评估框架。

Method: 1) 按法律标准将安全风险分为三级构建 SafeLawBench 基准；2) 对 20 个 LLM（含闭源/开源模型）进行零样本/少样本提示测试；3) 评估模型的安全推理稳定性与拒绝行为；4) 探索多数投票机制对性能的影响。

Result: 1) 顶尖模型 Claude-3.5/GPT-4o 在选择题中准确率 ≤80.5%；2) 20 个模型平均准确率 68.8%；3) 多数投票可提升性能；4) 发现模型存在安全推理不一致问题。

Conclusion: 现有 LLM 安全性存在显著不足，亟需通过法律标准化评估推动安全研究，SafeLawBench 为领域提供首个法律评测基准。

Abstract: With the growing prevalence of large language models (LLMs), the safety of
LLMs has raised significant concerns. However, there is still a lack of
definitive standards for evaluating their safety due to the subjective nature
of current safety benchmarks. To address this gap, we conducted the first
exploration of LLMs' safety evaluation from a legal perspective by proposing
the SafeLawBench benchmark. SafeLawBench categorizes safety risks into three
levels based on legal standards, providing a systematic and comprehensive
framework for evaluation. It comprises 24,860 multi-choice questions and 1,106
open-domain question-answering (QA) tasks. Our evaluation included 2
closed-source LLMs and 18 open-source LLMs using zero-shot and few-shot
prompting, highlighting the safety features of each model. We also evaluated
the LLMs' safety-related reasoning stability and refusal behavior.
Additionally, we found that a majority voting mechanism can enhance model
performance. Notably, even leading SOTA models like Claude-3.5-Sonnet and
GPT-4o have not exceeded 80.5% accuracy in multi-choice tasks on SafeLawBench,
while the average accuracy of 20 LLMs remains at 68.8\%. We urge the community
to prioritize research on the safety of LLMs.

</details>


### [27] [Quantile Regression with Large Language Models for Price Prediction](https://arxiv.org/abs/2506.06657)
*Nikhita Vedula,Dushyanta Dhyani,Laleh Jalali,Boris Oreshkin,Mohsen Bayati,Shervin Malmasi*

Main category: cs.CL

TL;DR: 该论文研究了使用大型语言模型（LLMs）进行概率回归，针对非结构化输入（如价格估算）实现文本到分布的预测。作者提出了一种新型分位数回归方法，使LLMs能够生成完整的预测分布。在三个价格预测数据集上，微调的Mistral-7B模型在预测准确性和分布校准方面均显著优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 现有方法主要关注点估计，缺乏系统比较。针对需要文本理解和不确定性量化的任务（如价格估计），需要更全面的概率回归方法。

Method: 提出分位数回归方法，让LLM生成预测分布；使用Mistral-7B模型微调并添加分位数头；通过LLM辅助标签校正提升精度；系统比较了LLM方法、模型架构、训练方式和数据规模。

Result: 微调后的Mistral-7B在三个数据集上均显著优于传统方法（编码器架构、嵌入方法、少样本学习）；在预测准确性（三项指标）和分布校准（三项指标）上均表现更好；LLM辅助标签校正达到人类水平精度且无系统偏差。

Conclusion: LLM分位数回归能有效解决文本到分布的预测任务；微调Mistral-7B是当前最佳方案；公开数据集支持未来研究。

Abstract: Large Language Models (LLMs) have shown promise in structured prediction
tasks, including regression, but existing approaches primarily focus on point
estimates and lack systematic comparison across different methods. We
investigate probabilistic regression using LLMs for unstructured inputs,
addressing challenging text-to-distribution prediction tasks such as price
estimation where both nuanced text understanding and uncertainty quantification
are critical. We propose a novel quantile regression approach that enables LLMs
to produce full predictive distributions, improving upon traditional point
estimates. Through extensive experiments across three diverse price prediction
datasets, we demonstrate that a Mistral-7B model fine-tuned with quantile heads
significantly outperforms traditional approaches for both point and
distributional estimations, as measured by three established metrics each for
prediction accuracy and distributional calibration. Our systematic comparison
of LLM approaches, model architectures, training approaches, and data scaling
reveals that Mistral-7B consistently outperforms encoder architectures,
embedding-based methods, and few-shot learning methods. Our experiments also
reveal the effectiveness of LLM-assisted label correction in achieving
human-level accuracy without systematic bias. Our curated datasets are made
available at https://github.com/vnik18/llm-price-quantile-reg/ to support
future research.

</details>


### [28] [Learning Distribution-Wise Control in Representation Space for Language Models](https://arxiv.org/abs/2506.06686)
*Chunyuan Deng,Ruidi Chang,Hanjie Chen*

Main category: cs.CL

TL;DR: 论文提出了一种分布层面的干预方法，通过扩展点态控制学习概念子空间及其周围区域，在常识和算术推理任务中显著提升了语言模型的可控性和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有对语言模型的干预主要集中在逐点控制上，虽能调整高层行为，但未充分利用概念子空间的整体分布信息。

Method: 将干预扩展到分布层面，使模型能够学习概念子空间及其周围区域的变换，较大标准差与性能提升强相关。

Result: 在8个常识推理和7个算术推理基准测试中，分布层面干预均优于点态干预，可控性和鲁棒性显著提高。

Conclusion: 分布层面干预为语言模型行为控制提供了更全面的方案，支持更细粒度的模型调控。

Abstract: Interventions in language models (LMs) are applied strategically to steer
model behavior during the forward pass. Learnable interventions, also known as
representation fine-tuning, aim to apply pointwise control within the concept
subspace and have proven effective in altering high-level behaviors. In this
work, we extend this approach to the distribution level, enabling the model to
learn not only pointwise transformations but also the surrounding regions of
the concept subspace. We demonstrate that these methods perform effectively in
early layers, with larger standard deviations correlating strongly with
improved performance. Across eight commonsense reasoning and seven arithmetic
reasoning benchmarks, our distribution-wise interventions consistently
outperform pointwise interventions in controllability and robustness. These
results illustrate that distribution-wise interventions provide a more
comprehensive method for steering model behavior and enabling finer-grained
control over language models. The code is at:
\href{https://github.com/chili-lab/D-Intervention}{https://github.com/chili-lab/D-Intervention}.

</details>


### [29] [Dynamic and Parametric Retrieval-Augmented Generation](https://arxiv.org/abs/2506.06704)
*Weihang Su,Qingyao Ai,Jingtao Zhan,Qian Dong,Yiqun Liu*

Main category: cs.CL

TL;DR: 该论文介绍了检索增强生成（RAG）的两种新兴研究方向：动态RAG和参数化RAG，以解决传统静态RAG在复杂任务中的局限性。


<details>
  <summary>Details</summary>
Motivation: 传统RAG采用的静态检索-生成流程和上下文知识注入方式在处理多跳推理、自适应信息访问和知识深度整合的复杂任务时存在不足，因此需要发展更先进的方法。

Method: 提出动态RAG（根据生成过程实时决定检索时机和内容）和参数化RAG（将知识注入从输入级提升到参数级）两种互补方案。

Result: 两种方法分别提升了LLM在复杂任务中的自适应能力和知识整合效率，为RAG领域提供了新的理论基础和实践方向。

Conclusion: 动态RAG和参数化RAG代表RAG演进的重要方向，通过自适应检索和深层知识整合机制突破现有范式局限，为知识密集型应用开辟新路径。

Abstract: Retrieval-Augmented Generation (RAG) has become a foundational paradigm for
equipping large language models (LLMs) with external knowledge, playing a
critical role in information retrieval and knowledge-intensive applications.
However, conventional RAG systems typically adopt a static
retrieve-then-generate pipeline and rely on in-context knowledge injection,
which can be suboptimal for complex tasks that require multihop reasoning,
adaptive information access, and deeper integration of external knowledge.
Motivated by these limitations, the research community has moved beyond static
retrieval and in-context knowledge injection. Among the emerging directions,
this tutorial delves into two rapidly growing and complementary research areas
on RAG: Dynamic RAG and Parametric RAG. Dynamic RAG adaptively determines when
and what to retrieve during the LLM's generation process, enabling real-time
adaptation to the LLM's evolving information needs. Parametric RAG rethinks how
retrieved knowledge should be injected into LLMs, transitioning from
input-level to parameter-level knowledge injection for enhanced efficiency and
effectiveness. This tutorial offers a comprehensive overview of recent advances
in these emerging research areas. It also shares theoretical foundations and
practical insights to support and inspire further research in RAG.

</details>


### [30] [DivScore: Zero-Shot Detection of LLM-Generated Text in Specialized Domains](https://arxiv.org/abs/2506.06705)
*Zhihui Chen,Kai He,Yucheng Huang,Yunxiao Zhu,Mengling Feng*

Main category: cs.CL

TL;DR: 本文提出一种在专业领域检测大语言生成文本的框架，通过归一化熵评分和领域知识蒸馏解决现有方法面临的域迁移问题。


<details>
  <summary>Details</summary>
Motivation: 当前零样本检测器在通用文本上有效，但在医疗和法律等高专业领域由于域偏移常失败，对抗专业错误信息和确保真实性的需求是动机所在。

Method: 提出一个名为DivScore的零样本检测框架，使用归一化熵评分和领域知识蒸馏技术，能够鲁棒地识别专业领域中机器生成的文本。

Result: 在提出的专业领域基准测试上，DivScore的AUROC提升14.4%，召回率（0.1%假阳性率时）提升64.0%；在对抗场景下的AUROC和召回率分别领先22.8%和29.5%。

Conclusion: DivScore在专业领域文本检测任务中有效克服了域漂移问题，显著优于现有方案，并开源了相关医疗和法律领域数据集。

Abstract: Detecting LLM-generated text in specialized and high-stakes domains like
medicine and law is crucial for combating misinformation and ensuring
authenticity. However, current zero-shot detectors, while effective on general
text, often fail when applied to specialized content due to domain shift. We
provide a theoretical analysis showing this failure is fundamentally linked to
the KL divergence between human, detector, and source text distributions. To
address this, we propose DivScore, a zero-shot detection framework using
normalized entropy-based scoring and domain knowledge distillation to robustly
identify LLM-generated text in specialized domains. We also release a
domain-specific benchmark for LLM-generated text detection in the medical and
legal domains. Experiments on our benchmark show that DivScore consistently
outperforms state-of-the-art detectors, with 14.4% higher AUROC and 64.0%
higher recall (0.1% false positive rate threshold). In adversarial settings,
DivScore demonstrates superior robustness than other baselines, achieving on
average 22.8% advantage in AUROC and 29.5% in recall. Code and data are
publicly available.

</details>


### [31] [A Survey of Retentive Network](https://arxiv.org/abs/2506.06708)
*Haiqi Yang,Zhiyuan Li,Yi Chang,Yuan Wu*

Main category: cs.CL

TL;DR: RetNet 是一种新型神经网络架构，它通过保留机制克服了 Transformer 在处理长序列时的高内存成本和可扩展性限制。该架构在保持高效并行训练的同时，实现了线性时间推理，并在多个领域展现出强大性能。本文首次对 RetNet 进行全面综述，分析其创新、应用、挑战及未来方向。


<details>
  <summary>Details</summary>
Motivation: Transformer 的自注意力机制导致处理长序列时存在二次复杂度问题，限制了其可扩展性和效率。RetNet 旨在通过统一的保留机制解决这些问题，结合循环的归纳偏置和注意力的全局依赖建模能力。

Method: 引入保留机制，该机制统一了循环的归纳偏置和全局注意力建模。在推理阶段实现线性时间计算（类似 RNN 的循环），同时支持完全的并行化训练（类似 Transformer）。

Result: RetNet 在自然语言处理、语音识别和时间序列分析等多个领域表现出强大且一致的性能，在处理长序列任务上比 Transformer 更具效率和可扩展性。

Conclusion: RetNet 是 Transformer 的高效替代方案，但当前文献缺乏系统综述。本文通过全面分析其架构、创新和应用填补了这一空白，同时提出了未来研究挑战和方向，旨在推动其在学术和工业领域的进一步发展。

Abstract: Retentive Network (RetNet) represents a significant advancement in neural
network architecture, offering an efficient alternative to the Transformer.
While Transformers rely on self-attention to model dependencies, they suffer
from high memory costs and limited scalability when handling long sequences due
to their quadratic complexity. To mitigate these limitations, RetNet introduces
a retention mechanism that unifies the inductive bias of recurrence with the
global dependency modeling of attention. This mechanism enables linear-time
inference, facilitates efficient modeling of extended contexts, and remains
compatible with fully parallelizable training pipelines. RetNet has garnered
significant research interest due to its consistently demonstrated cross-domain
effectiveness, achieving robust performance across machine learning paradigms
including natural language processing, speech recognition, and time-series
analysis. However, a comprehensive review of RetNet is still missing from the
current literature. This paper aims to fill that gap by offering the first
detailed survey of the RetNet architecture, its key innovations, and its
diverse applications. We also explore the main challenges associated with
RetNet and propose future research directions to support its continued
advancement in both academic research and practical deployment.

</details>


### [32] [C-PATH: Conversational Patient Assistance and Triage in Healthcare System](https://arxiv.org/abs/2506.06737)
*Qi Shi,Qiwei Han,Cláudia Soares*

Main category: cs.CL

TL;DR: 本论文介绍了基于LLaMA3架构微调的对话式AI系统C-PATH，它能通过自然对话帮助患者识别症状并推荐医疗科室。核心创新包括利用GPT转化结构化临床知识为对话数据，以及可扩展的对话历史管理策略。评估显示C-PATH在清晰度、信息量和推荐准确性方面优于领域基线。


<details>
  <summary>Details</summary>
Motivation: 医疗系统的复杂性阻碍患者及时获得适当医疗服务，需要开发能够通过自然对话辅助患者分诊的AI工具。

Method: 基于LLaMA3架构的多阶段微调：1) 利用GPT将DDXPlus临床知识转化为通俗对话数据；2) 实施可扩展对话历史管理策略确保长程连贯性。

Result: GPTScore评估显示在清晰度、信息量和推荐准确性方面表现优异；在GPT重构的对话数据集上显著优于领域专用基线模型。

Conclusion: C-PATH作为以用户为中心的数字健康辅助工具，在可访问性和分诊准确性方面取得进展，为医疗AI发展提供新方向。

Abstract: Navigating healthcare systems can be complex and overwhelming, creating
barriers for patients seeking timely and appropriate medical attention. In this
paper, we introduce C-PATH (Conversational Patient Assistance and Triage in
Healthcare), a novel conversational AI system powered by large language models
(LLMs) designed to assist patients in recognizing symptoms and recommending
appropriate medical departments through natural, multi-turn dialogues. C-PATH
is fine-tuned on medical knowledge, dialogue data, and clinical summaries using
a multi-stage pipeline built on the LLaMA3 architecture. A core contribution of
this work is a GPT-based data augmentation framework that transforms structured
clinical knowledge from DDXPlus into lay-person-friendly conversations,
allowing alignment with patient communication norms. We also implement a
scalable conversation history management strategy to ensure long-range
coherence. Evaluation with GPTScore demonstrates strong performance across
dimensions such as clarity, informativeness, and recommendation accuracy.
Quantitative benchmarks show that C-PATH achieves superior performance in
GPT-rewritten conversational datasets, significantly outperforming
domain-specific baselines. C-PATH represents a step forward in the development
of user-centric, accessible, and accurate AI tools for digital health
assistance and triage.

</details>


### [33] [Geopolitical biases in LLMs: what are the "good" and the "bad" countries according to contemporary language models](https://arxiv.org/abs/2506.06751)
*Mikhail Salnikov,Dmitrii Korzh,Ivan Lazichny,Elvir Karimov,Artyom Iudin,Ivan Oseledets,Oleg Y. Rogov,Alexander Panchenko,Natalia Loukachevitch,Elena Tutubalina*

Main category: cs.CL

TL;DR: 本文通过分析不同国家（美、英、苏、中）对历史事件的解释，评估了LLMs的地缘政治偏见。研究引入了一个新数据集，包含中性事件描述和各国对立观点。研究发现LLMs存在显著偏见，偏好特定国家叙事；简单去偏见提示效果有限；标签操纵实验显示模型对来源归属敏感，可能放大偏见。


<details>
  <summary>Details</summary>
Motivation: 评估大型语言模型（LLMs）在处理历史事件时对不同国家视角（美国、英国、苏联、中国）的地缘政治偏见。

Method: 1. 构建新颖数据集：包含中性事件描述和不同国家的对立观点
2. 评估LLMs对不同国家叙事的偏好
3. 测试简单去偏见提示的效果
4. 通过交换参与者标签进行敏感性实验

Result: 1. 发现LLMs存在显著地缘政治偏见，偏好特定国家叙事
2. 简单去偏见提示效果有限
3. 标签操纵实验显示：模型对来源归属敏感，可能放大偏见或识别不一致（尤其标签交换时）

Conclusion: 1. 揭示LLMs存在国家叙事偏见
2. 质疑简单去偏见方法的有效性
3. 为未来地缘政治偏见研究提供框架和数据集

Abstract: This paper evaluates geopolitical biases in LLMs with respect to various
countries though an analysis of their interpretation of historical events with
conflicting national perspectives (USA, UK, USSR, and China). We introduce a
novel dataset with neutral event descriptions and contrasting viewpoints from
different countries. Our findings show significant geopolitical biases, with
models favoring specific national narratives. Additionally, simple debiasing
prompts had a limited effect in reducing these biases. Experiments with
manipulated participant labels reveal models' sensitivity to attribution,
sometimes amplifying biases or recognizing inconsistencies, especially with
swapped labels. This work highlights national narrative biases in LLMs,
challenges the effectiveness of simple debiasing methods, and offers a
framework and dataset for future geopolitical bias research.

</details>


### [34] [They want to pretend not to understand: The Limits of Current LLMs in Interpreting Implicit Content of Political Discourse](https://arxiv.org/abs/2506.06775)
*Walter Paci,Alessandro Panunzi,Sandro Pezzelle*

Main category: cs.CL

TL;DR: 该论文探讨大型语言模型在政治话语中检测隐含内容的能力，发现现有模型在处理预设和隐含意义时存在困难，但仍指出有希望的改进方向。


<details>
  <summary>Details</summary>
Motivation: 政治话语中常使用隐晦表达影响受众，虽然LLMs在复杂语义理解上表现优异，但其在政治隐含内容解析能力尚未充分研究。

Method: 基于IMPAQTS意大利政治演讲语料库，设计多选题和开放生成任务测试多个LLMs解析预设和隐含意义的能力。

Result: 所有测试模型在解释预设和隐含意义时均表现不佳，表明当前LLMs缺乏准确解读政治隐晦语言所需的关键语用能力。

Conclusion: 现有LLMs尚不能胜任政治隐含内容解析任务，但研究揭示了提升模型表现的方向（如语料标注优化），并公开了数据和代码。

Abstract: Implicit content plays a crucial role in political discourse, where speakers
systematically employ pragmatic strategies such as implicatures and
presuppositions to influence their audiences. Large Language Models (LLMs) have
demonstrated strong performance in tasks requiring complex semantic and
pragmatic understanding, highlighting their potential for detecting and
explaining the meaning of implicit content. However, their ability to do this
within political discourse remains largely underexplored. Leveraging, for the
first time, the large IMPAQTS corpus, which comprises Italian political
speeches with the annotation of manipulative implicit content, we propose
methods to test the effectiveness of LLMs in this challenging problem. Through
a multiple-choice task and an open-ended generation task, we demonstrate that
all tested models struggle to interpret presuppositions and implicatures. We
conclude that current LLMs lack the key pragmatic capabilities necessary for
accurately interpreting highly implicit language, such as that found in
political discourse. At the same time, we highlight promising trends and future
directions for enhancing model performance. We release our data and code at
https://github.com/WalterPaci/IMPAQTS-PID

</details>


### [35] [Extending dependencies to the taggedPBC: Word order in transitive clauses](https://arxiv.org/abs/2506.06785)
*Hiram Ring*

Main category: cs.CL

TL;DR: 摘要介绍了一个名为taggedPBC的语料库的CoNLLU格式版本，该版本在原有POS标注的基础上添加了依存关系标注。尽管标注质量存在一定问题，但从该数据集提取的词序信息（及物从句中核心谓词和论元的位置）与三大语言类型学数据库（WALS、Grambank、Autotyp）中的专家判断结果高度相关。这证明了基于大规模噪声标注数据的语料库类型学研究价值，所有依存标注语料已通过GitHub开源。


<details>
  <summary>Details</summary>
Motivation: 虽然taggedPBC语料库已包含1800多句来自1500多种语言的POS标注数据（涉及133个语系和111个孤立语），远超现有资源，但原始版本缺乏依存关系标注。为弥补这一缺口，本研究开发了CoNLLU格式的依存标注版本，旨在探索:1)如何将依存关系跨语言迁移;2)从含噪声的标注数据中能否获取有效的语言类型学洞见。

Method: 1)扩展标注:在已有POS标注的taggedPBC平行语料基础上，通过跨语言迁移技术添加依存关系标注;2)验证方法:从标注数据中提取及物从句的核心谓词与论元位置信息，并与三大权威类型学数据库(WALS, Grambank, Autotyp)的专家标注结果进行相关性验证。

Result: 1)成功构建覆盖1500+语言的依存树库，通过GitHub开源;2)关键发现:尽管标注存在噪声，但提取的语序特征（特别是S/V/O在及物从句中的线性顺序）与三个数据库的专家判断呈显著正相关(p<0.001);3)证实即使含噪声的标注数据，经适当处理仍能支撑可靠的跨语言比较。

Conclusion: 这项研究证明:①基于语料库的类型学方法可有效扩展离散语言范畴的比较研究;②大规模但存在噪声的标注数据经过充分处理，仍能产生重要语言学洞见;③开源的多语言依存树库为语言类型学和计算语言学提供了新资源。结果为前人研究(Baylor 2023, Bjerva 2024)提供了实证支持。

Abstract: The taggedPBC (Ring 2025a) contains more than 1,800 sentences of pos-tagged
parallel text data from over 1,500 languages, representing 133 language
families and 111 isolates. While this dwarfs previously available resources,
and the POS tags achieve decent accuracy, allowing for predictive
crosslinguistic insights (Ring 2025b), the dataset was not initially annotated
for dependencies. This paper reports on a CoNLLU-formatted version of the
dataset which transfers dependency information along with POS tags to all
languages in the taggedPBC. Although there are various concerns regarding the
quality of the tags and the dependencies, word order information derived from
this dataset regarding the position of arguments and predicates in transitive
clauses correlates with expert determinations of word order in three
typological databases (WALS, Grambank, Autotyp). This highlights the usefulness
of corpus-based typological approaches (as per Baylor et al. 2023; Bjerva 2024)
for extending comparisons of discrete linguistic categories, and suggests that
important insights can be gained even from noisy data, given sufficient
annotation. The dependency-annotated corpora are also made available for
research and collaboration via GitHub.

</details>


### [36] [On the Adaptive Psychological Persuasion of Large Language Models](https://arxiv.org/abs/2506.06800)
*Tianjie Ju,Yujia Chen,Hao Fei,Mong-Li Lee,Wynne Hsu,Pengzhou Cheng,Zongru Wu,Zhuosheng Zhang,Gongshen Liu*

Main category: cs.CL

TL;DR: 提出自适应心理劝导框架，增强大型语言模型在劝导性对话中的效果。


<details>
  <summary>Details</summary>
Motivation: 现有大型语言模型（LLMs）在劝导任务中策略单一且效果有限，缺乏对心理策略的系统探索和应用，需要一种自适应策略选择方法提升劝导成功率。

Method: 1. 评估四种常用LLM作为劝导者/倾听者的表现；2. 引入11种心理策略；3. 提出基于偏好优化的自适应框架（DPO），训练LLM根据对话上下文自主选择最优策略。

Result: 实验证明：1. 明确使用策略（如流畅性效应、重复效应）可提升成功率；2. 无普适策略，效果依赖上下文；3. 所提框架使劝导成功率显著提升，同时保持模型通用性。

Conclusion: 自适应心理劝导框架通过动态策略选择机制，解决了现有LLM劝导策略单一问题，为构建更灵活的人机交互系统提供新方向。

Abstract: Previous work has showcased the intriguing capabilities of Large Language
Models (LLMs) in instruction-following and rhetorical fluency. However,
systematic exploration of their dual capabilities to autonomously persuade and
resist persuasion, particularly in contexts involving psychological rhetoric,
remains unexplored. In this paper, we first evaluate four commonly adopted LLMs
by tasking them to alternately act as persuaders and listeners in adversarial
dialogues. Empirical results show that persuader LLMs predominantly employ
repetitive strategies, leading to low success rates. Then we introduce eleven
comprehensive psychological persuasion strategies, finding that explicitly
instructing LLMs to adopt specific strategies such as Fluency Effect and
Repetition Effect significantly improves persuasion success rates. However, no
``one-size-fits-all'' strategy proves universally effective, with performance
heavily dependent on contextual counterfactuals. Motivated by these
observations, we propose an adaptive framework based on direct preference
optimization that trains LLMs to autonomously select optimal strategies by
leveraging persuasion results from strategy-specific responses as preference
pairs. Experiments on three open-source LLMs confirm that the proposed adaptive
psychological persuasion method effectively enables persuader LLMs to select
optimal strategies, significantly enhancing their success rates while
maintaining general capabilities. Our code is available at
https://github.com/KalinaEine/PsychologicalPersuasion.

</details>


### [37] [Label-semantics Aware Generative Approach for Domain-Agnostic Multilabel Classification](https://arxiv.org/abs/2506.06806)
*Subhendu Khatuya,Shashwat Naidu,Saptarshi Ghosh,Pawan Goyal,Niloy Ganguly*

Main category: cs.CL

TL;DR: 本文提出了一种通用、高效的生成性多标签文本分类框架LAGAMC，该框架使用标签描述生成方法，配合双重目标损失函数，在多个数据集上取得SOTA结果。


<details>
  <summary>Details</summary>
Motivation: 解决海量文本数据下人工分类的困难，提出不将标签视为原子符号，而是利用预定义标签描述提升分类效果。

Method: 训练模型生成标签描述，使用微调后的句子Transformer匹配生成的描述与预定义标签；采用交叉熵损失和余弦相似度的双重目标损失函数。

Result: 在所有评估数据集上取得新的SOTA性能：相比最强基线，Micro-F1提升24.85%，所有数据集的平均提升为13.94%。（原始文本表述为：提升13.94%的Micro-F1和24.85%的Macro-F1）

Conclusion: LAGAMC模型的参数效率和跨数据集适用性使其成为实际应用的理想选择，双重目标损失确保了语义对齐和精度提升。

Abstract: The explosion of textual data has made manual document classification
increasingly challenging. To address this, we introduce a robust, efficient
domain-agnostic generative model framework for multi-label text classification.
Instead of treating labels as mere atomic symbols, our approach utilizes
predefined label descriptions and is trained to generate these descriptions
based on the input text. During inference, the generated descriptions are
matched to the pre-defined labels using a finetuned sentence transformer. We
integrate this with a dual-objective loss function, combining cross-entropy
loss and cosine similarity of the generated sentences with the predefined
target descriptions, ensuring both semantic alignment and accuracy. Our
proposed model LAGAMC stands out for its parameter efficiency and versatility
across diverse datasets, making it well-suited for practical applications. We
demonstrate the effectiveness of our proposed model by achieving new
state-of-the-art performances across all evaluated datasets, surpassing several
strong baselines. We achieve improvements of 13.94% in Micro-F1 and 24.85% in
Macro-F1 compared to the closest baseline across all datasets.

</details>


### [38] [Not quite Sherlock Holmes: Language model predictions do not reliably differentiate impossible from improbable events](https://arxiv.org/abs/2506.06808)
*James A. Michaelov,Reeka Estacio,Zhien Zhang,Benjamin K. Bergen*

Main category: cs.CL

TL;DR: 语言模型在区分可能事件与不可能事件时表现脆弱，即使是最新模型在特定条件下也会赋予不可能句子更高概率。


<details>
  <summary>Details</summary>
Motivation: 验证语言模型是否能稳健地预测可能事件比不可能事件更可能发生，并分离可能性、典型性和上下文相关性等因素的影响。

Method: 通过设计对比实验，让语言模型评估可能句子（例如'汽车被探险家开罚单'）和不可能句子（例如'汽车被刹车开罚单'）的概率，测试包括Llama 3、Gemma 2、Mistral NeMo等模型。

Result: 所有模型在特定条件下都表现低于随机水平：常为不可能句子分配比可能句子更高的概率。

Conclusion: 当前语言模型对可能性判断的鲁棒性不足，其概率预测易受上下文干扰，揭示模型理解的局限性。

Abstract: Can language models reliably predict that possible events are more likely
than merely improbable ones? By teasing apart possibility, typicality, and
contextual relatedness, we show that despite the results of previous work,
language models' ability to do this is far from robust. In fact, under certain
conditions, all models tested - including Llama 3, Gemma 2, and Mistral NeMo -
perform at worse-than-chance level, assigning higher probabilities to
impossible sentences such as 'the car was given a parking ticket by the brake'
than to merely unlikely sentences such as 'the car was given a parking ticket
by the explorer'.

</details>


### [39] [Advancing Question Generation with Joint Narrative and Difficulty Control](https://arxiv.org/abs/2506.06812)
*Bernardo Leite,Henrique Lopes Cardoso*

Main category: cs.CL

TL;DR: 该论文提出了联合控制叙事和难度的方法，用于生成阅读理解问题，以弥补现有研究中单独控制难度或叙事的不足。初步评估表明该方法可行但在某些情况下效果有限。


<details>
  <summary>Details</summary>
Motivation: 现有问题生成研究主要集中在难度控制或叙事控制，而教育场景需要同时控制两者以生成适应学习者能力的问题。

Method: 提出了联合叙事和难度控制的策略，实现在生成阅读理解问题时同步控制这两个属性。

Result: 初步评估显示该方法可行，但在部分案例中无效。研究明确了策略适用的条件和应用中的权衡（trade-offs）。

Conclusion: 通过联合控制叙事和难度策略可以满足教育目标的问题生成需求。

Abstract: Question Generation (QG), the task of automatically generating questions from
a source input, has seen significant progress in recent years.
Difficulty-controllable QG (DCQG) enables control over the difficulty level of
generated questions while considering the learner's ability. Additionally,
narrative-controllable QG (NCQG) allows control over the narrative aspects
embedded in the questions. However, research in QG lacks a focus on combining
these two types of control, which is important for generating questions
tailored to educational purposes. To address this gap, we propose a strategy
for Joint Narrative and Difficulty Control, enabling simultaneous control over
these two attributes in the generation of reading comprehension questions. Our
evaluation provides preliminary evidence that this approach is feasible, though
it is not effective across all instances. Our findings highlight the conditions
under which the strategy performs well and discuss the trade-offs associated
with its application.

</details>


### [40] [BTPD: A Multilingual Hand-curated Dataset of Bengali Transnational Political Discourse Across Online Communities](https://arxiv.org/abs/2506.06813)
*Dipto Das,Syed Ishtiaque Ahmed,Shion Guha*

Main category: cs.CL

TL;DR: 本文提出一个新的多语言数据集 BTPD，用于研究孟加拉语跨国政治话语，解决资源匮乏语言研究数据不足的问题


<details>
  <summary>Details</summary>
Motivation: 在线政治话语分析对理解公众意见和意识形态极化至关重要，但当前研究集中于英语，孟加拉语等资源匮乏语言缺乏可用数据集

Method: 从三个体现不同社区结构和互动动态的在线平台收集数据，通过社区知情的关键词检索人工整理数据集

Result: 构建了 BTPD 数据集，涵盖多语言内容，并对数据集主题和语言组成进行了总体概述

Conclusion: 该数据集填补了孟加拉语政治话语研究空白，有助于促进对资源匮乏语言的跨文化政治分析

Abstract: Understanding political discourse in online spaces is crucial for analyzing
public opinion and ideological polarization. While social computing and
computational linguistics have explored such discussions in English, such
research efforts are significantly limited in major yet under-resourced
languages like Bengali due to the unavailability of datasets. In this paper, we
present a multilingual dataset of Bengali transnational political discourse
(BTPD) collected from three online platforms, each representing distinct
community structures and interaction dynamics. Besides describing how we
hand-curated the dataset through community-informed keyword-based retrieval,
this paper also provides a general overview of its topics and multilingual
content.

</details>


### [41] [How do datasets, developers, and models affect biases in a low-resourced language?](https://arxiv.org/abs/2506.06816)
*Dipto Das,Shion Guha,Bryan Semaan*

Main category: cs.CL

TL;DR: 本文对孟加拉语进行了一项算法审计，评估了使用mBERT和BanglaBERT构建的情感分析模型中存在的身份偏见（如性别、宗教和国籍）。


<details>
  <summary>Details</summary>
Motivation: 低资源情境下的身份偏见问题常被忽视，尤其是对于使用广泛但资源匮乏的语言如孟加拉语。建议通过针对特定语言或多语言的模型或数据集来缓解这些偏见，但此类方法的有效性尚缺乏实证检验。

Method: 对Google Dataset Search中所有孟加拉语情感分析数据集进行审计，并在mBERT和BanglaBERT基础上训练模型。关注不同身份类型（性别、宗教、国籍）下模型的偏见表现。

Result: 尽管语义内容和结构相似，模型在这些身份上均出现偏见。整合不同背景创建者开发的预训练模型和数据集会产生不一致性和不确定性。

Conclusion: 研究结果揭示了针对低资源语言的模型存在身份偏见，需要关注认知不公、人工智能对齐以及算法审计的方法学问题。

Abstract: Sociotechnical systems, such as language technologies, frequently exhibit
identity-based biases. These biases exacerbate the experiences of historically
marginalized communities and remain understudied in low-resource contexts.
While models and datasets specific to a language or with multilingual support
are commonly recommended to address these biases, this paper empirically tests
the effectiveness of such approaches in the context of gender, religion, and
nationality-based identities in Bengali, a widely spoken but low-resourced
language. We conducted an algorithmic audit of sentiment analysis models built
on mBERT and BanglaBERT, which were fine-tuned using all Bengali sentiment
analysis (BSA) datasets from Google Dataset Search. Our analyses showed that
BSA models exhibit biases across different identity categories despite having
similar semantic content and structure. We also examined the inconsistencies
and uncertainties arising from combining pre-trained models and datasets
created by individuals from diverse demographic backgrounds. We connected these
findings to the broader discussions on epistemic injustice, AI alignment, and
methodological decisions in algorithmic audits.

</details>


### [42] [Beyond Classification: Towards Speech Emotion Reasoning with Multitask AudioLLMs](https://arxiv.org/abs/2506.06820)
*Wenyu Zhang,Yingxu He,Geyu Lin,Zhuohan Liu,Shuo Sun,Bin Wang,Xunlong Zou,Jeremy H. M. Wong,Qiongqiong Wang,Hardik B. Sailor,Nancy F. Chen,Ai Ti Aw*

Main category: cs.CL

TL;DR: 提出了EmoIQ框架，通过增强情感推理能力来提升音频大语言模型在情感识别任务中的性能，并生成可解释的响应。该方法结合了推理增强数据监督、双编码器架构和任务交替训练，在IEMOCAP和MELD数据集上取得了更高的准确率和更好的解释质量。


<details>
  <summary>Details</summary>
Motivation: 现有音频大语言模型在情感识别任务中存在局限：1) 将情感视为分类问题，缺乏对预测依据的解释 2) 未能充分利用生成能力进行情感推理。这导致模型可解释性差，无法揭示预测背后的依据。

Method: 提出三阶段框架EmoIQ：1) 推理增强数据监督：构建包含情感解释的合成数据集 2) 双编码器架构：独立处理声学特征和文本特征 3) 任务交替训练：在情感分类和解释生成任务间交替训练，增强模型多任务协作能力。

Result: 在IEMOCAP和MELD数据集上：1) 情感识别准确率分别提升4.2%和3.8% 2) 生成解释的连贯性和证据支撑性显著提升（人工评估+22.7%相关性得分）3）消融实验证实双编码器和任务交替训练的有效性。

Conclusion: 情感推理范式能同时提升音频大语言模型在情感识别的性能和可解释性；所提统一框架通过协调数据、架构和训练策略，为未来赋予大模型情感智能提供新方向。

Abstract: Audio Large Language Models (AudioLLMs) have achieved strong results in
semantic tasks like speech recognition and translation, but remain limited in
modeling paralinguistic cues such as emotion. Existing approaches often treat
emotion understanding as a classification problem, offering little insight into
the underlying rationale behind predictions. In this work, we explore emotion
reasoning, a strategy that leverages the generative capabilities of AudioLLMs
to enhance emotion recognition by producing semantically aligned,
evidence-grounded explanations. To support this in multitask AudioLLMs, we
introduce a unified framework combining reasoning-augmented data supervision,
dual-encoder architecture, and task-alternating training. This approach enables
AudioLLMs to effectively learn different tasks while incorporating emotional
reasoning. Experiments on IEMOCAP and MELD show that our approach not only
improves emotion prediction accuracy but also enhances the coherence and
evidential grounding of the generated responses.

</details>


### [43] [Can LLMs Generate Reliable Test Case Generators? A Study on Competition-Level Programming Problems](https://arxiv.org/abs/2506.06821)
*Yuhan Cao,Zian Chen,Kun Quan,Ziliang Zhang,Yu Wang,Xiaoning Dong,Yeqi Feng,Guanzhong He,Jingcheng Huang,Jianhao Li,Yixuan Tan,Jiafu Tang,Yilin Tang,Junlei Wu,Qianyu Xiao,Can Zheng,Shouchen Zhou,Yuxiang Zhu,Yiming Huang,Tian Xie,Tianxing He*

Main category: cs.CL

TL;DR: 提出了TCGBench基准，用于评估大语言模型生成测试用例生成器用于竞争式编程代码检查的能力。实验显示先进模型能生成有效但难以暴露代码缺陷的测试用例，但可通过构建高质量数据集提升性能。


<details>
  <summary>Details</summary>
Motivation: 大规模语言模型展示了出色的代码生成能力，但缺乏其在生成测试用例进行代码调试中的能力研究。该论文旨在评估LLM在竞争式编程中测试用例生成能力。

Method: 构建TCGBench基准，包含两个任务：生成有效的测试用例生成器和针对人类代码缺陷的针对性生成器。实验评估多种LLM，并构建人工标注数据集用于性能提升研究。

Result: 最先进的大模型可生成有效测试用例生成器（任务1），但在针对暴露代码缺陷的生成任务中表现不佳，显著落后于人类水平（任务2）。构建的数据集通过提示微调能提升LLM表现。

Conclusion: LLM具备生成测试用例生成器的能力，但生成针对性（暴露缺陷）测试用例的能力有限。构建高质量数据集可通过提示和微调提升性能。

Abstract: Large Language Models (LLMs) have demonstrated remarkable capabilities in
code generation, capable of tackling complex tasks during inference. However,
the extent to which LLMs can be utilized for code checking or debugging through
test case generation remains largely unexplored. We investigate this problem
from the perspective of competition-level programming (CP) programs and propose
TCGBench, a Benchmark for (LLM generation of) Test Case Generators. This
benchmark comprises two tasks, aimed at studying the capabilities of LLMs in
(1) generating valid test case generators for a given CP problem, and further
(2) generating targeted test case generators that expose bugs in human-written
code. Experimental results indicate that while state-of-the-art LLMs can
generate valid test case generators in most cases, most LLMs struggle to
generate targeted test cases that reveal flaws in human code effectively.
Especially, even advanced reasoning models (e.g., o3-mini) fall significantly
short of human performance in the task of generating targeted generators.
Furthermore, we construct a high-quality, manually curated dataset of
instructions for generating targeted generators. Analysis demonstrates that the
performance of LLMs can be enhanced with the aid of this dataset, by both
prompting and fine-tuning.

</details>


### [44] [PCoT: Persuasion-Augmented Chain of Thought for Detecting Fake News and Social Media Disinformation](https://arxiv.org/abs/2506.06842)
*Arkadiusz Modzelewski,Witold Sosnowski,Tiziano Labruna,Adam Wierzbicki,Giovanni Da San Martino*

Main category: cs.CL

TL;DR: 这篇论文提出了一种名为Persuasion-Augmented Chain of Thought (PCoT)的新方法，通过融入说服知识来增强大型语言模型在零样本虚假信息检测中的性能。


<details>
  <summary>Details</summary>
Motivation: 受心理学研究的启发，该研究认为掌握说服谬误的知识有助于人们识别虚假信息，因此作者尝试在大型语言模型中融入说服知识以提高虚假信息检测能力。

Method: 引入了Persuasion-Augmented Chain of Thought (PCoT)，一种利用说服知识改进零样本分类中虚假信息检测的新方法。

Result: 在五个大型语言模型和五个数据集上的评估表明，PCoT平均优于竞争方法15%，并发布了两个新的虚假信息数据集EUDisinfo和MultiDis。

Conclusion: 研究结果表明，融入说服知识能显著加强语言模型在零样本虚假信息检测中的能力，突出了说服知识在该领域的价值。

Abstract: Disinformation detection is a key aspect of media literacy. Psychological
studies have shown that knowledge of persuasive fallacies helps individuals
detect disinformation. Inspired by these findings, we experimented with large
language models (LLMs) to test whether infusing persuasion knowledge enhances
disinformation detection. As a result, we introduce the Persuasion-Augmented
Chain of Thought (PCoT), a novel approach that leverages persuasion to improve
disinformation detection in zero-shot classification. We extensively evaluate
PCoT on online news and social media posts. Moreover, we publish two novel,
up-to-date disinformation datasets: EUDisinfo and MultiDis. These datasets
enable the evaluation of PCoT on content entirely unseen by the LLMs used in
our experiments, as the content was published after the models' knowledge
cutoffs. We show that, on average, PCoT outperforms competitive methods by 15%
across five LLMs and five datasets. These findings highlight the value of
persuasion in strengthening zero-shot disinformation detection.

</details>


### [45] [Adapt Once, Thrive with Updates: Transferable Parameter-Efficient Fine-Tuning on Evolving Base Models](https://arxiv.org/abs/2506.06844)
*Naibin Gu,Peng Fu,Xiyu Liu,Ke Ma,Zheng Lin,Weiping Wang*

Main category: cs.CL

TL;DR: Trans-PEFT方法通过专注于任务特定模式减少对基础模型更新的依赖，使PEFT模块在更新后的基础模型中无需重新调整即可保持性能。


<details>
  <summary>Details</summary>
Motivation: 当基础模型更新后，原有PEFT模块性能显著下降，重新调整所有模块的计算成本过高。研究发现基础模型更新主要影响FFN中的任务特定知识，而对注意力机制的任务特定模式影响较小。

Method: 提出Trans-PEFT方法，增强PEFT模块的任务特定模式，降低其对基础模型特定知识的依赖。通过理论分析和实验验证。

Result: 在7个基础模型和12个数据集上的广泛实验表明，Trans-PEFT训练的模块在更新后的基础模型上无需重新调整即可保持性能。

Conclusion: Trans-PEFT可显著减少实际应用中的维护开销，为解决PEFT模块更新问题提供了有效方案。

Abstract: Parameter-efficient fine-tuning (PEFT) has become a common method for
fine-tuning large language models, where a base model can serve multiple users
through PEFT module switching. To enhance user experience, base models require
periodic updates. However, once updated, PEFT modules fine-tuned on previous
versions often suffer substantial performance degradation on newer versions.
Re-tuning these numerous modules to restore performance would incur significant
computational costs. Through a comprehensive analysis of the changes that occur
during base model updates, we uncover an interesting phenomenon: continual
training primarily affects task-specific knowledge stored in Feed-Forward
Networks (FFN), while having less impact on the task-specific pattern in the
Attention mechanism. Based on these findings, we introduce Trans-PEFT, a novel
approach that enhances the PEFT module by focusing on the task-specific pattern
while reducing its dependence on certain knowledge in the base model. Further
theoretical analysis supports our approach. Extensive experiments across 7 base
models and 12 datasets demonstrate that Trans-PEFT trained modules can maintain
performance on updated base models without re-tuning, significantly reducing
maintenance overhead in real-world applications.

</details>


### [46] [Right Is Not Enough: The Pitfalls of Outcome Supervision in Training LLMs for Math Reasoning](https://arxiv.org/abs/2506.06877)
*Jiaxing Guo,Wenjie Yang,Shengzhong Zhang,Tongshan Xu,Lun Du,Da Zheng,Zengfeng Huang*

Main category: cs.CL

TL;DR: MathOlympiadEval数据集揭示了大型语言模型在数学解题中答案正确但推理过程错误的问题，现有方法难以检测。作者提出ParaStepVerifier方法进行逐步验证，有效识别错误推理步骤，显著改善检测准确率。


<details>
  <summary>Details</summary>
Motivation: 现有基于结果奖励的大型语言模型在数学解题中存在‘奖励破解’现象：模型常通过错误推理得出正确答案，现有评估方法（如LLM-as-a-judge）无法可靠检测此类缺陷。

Method: 提出ParaStepVerifier方法——通过细粒度逐步验证数学解题步骤：1) 创建带精细标注的MathOlympiadEval数据集；2) 设计新型验证框架逐段识别错误推理步骤。

Result: 实验表明：1) 现有模型答案正确率与过程正确率存在显著差距；2) ParaStepVerifier在复杂多步骤问题上识别错误方案的准确率显著超越基线方法。

Conclusion: ParaStepVerifier为评估和训练真实数学推理能力的LLMs提供了更鲁棒的路径，解决了奖励机制导致的表面正确性问题。

Abstract: Outcome-rewarded Large Language Models (LLMs) have demonstrated remarkable
success in mathematical problem-solving. However, this success often masks a
critical issue: models frequently achieve correct answers through fundamentally
unsound reasoning processes, a phenomenon indicative of reward hacking. We
introduce MathOlympiadEval, a new dataset with fine-grained annotations, which
reveals a significant gap between LLMs' answer correctness and their low
process correctness. Existing automated methods like LLM-as-a-judge struggle to
reliably detect these reasoning flaws. To address this, we propose
ParaStepVerifier, a novel methodology for meticulous, step-by-step verification
of mathematical solutions. ParaStepVerifier identifies incorrect reasoning
steps. Empirical results demonstrate that ParaStepVerifier substantially
improves the accuracy of identifying flawed solutions compared to baselines,
especially for complex, multi-step problems. This offers a more robust path
towards evaluating and training LLMs with genuine mathematical reasoning.

</details>


### [47] [Mixture of Small and Large Models for Chinese Spelling Check](https://arxiv.org/abs/2506.06887)
*Ziheng Qiao,Houquan Zhou,Zhenghua Li*

Main category: cs.CL

TL;DR: 提出了一种动态混合方法，在解码阶段结合小模型和大型语言模型的概率分布，提升中文拼写检查的精确性和流畅性，无需微调LLM，达到SOTA。


<details>
  <summary>Details</summary>
Motivation: 现有的LLM在中文拼写检查任务中表现不佳，而基于BERT的小模型依赖于高质量领域数据且容易过拟合。需要一种方法结合两者的优势。

Method: 在集束搜索解码阶段动态融合小模型和LLM的概率分布，利用小模型的精确纠正能力和LLM的语言流畅性，无需微调LLM。

Result: 在多个数据集上显著提升纠错能力，取得最先进（state-of-the-art）的结果。

Conclusion: 动态混合方法有效平衡了精确性和流畅性，节省资源并便于领域适应，为CSC任务提供了高效解决方案。

Abstract: In the era of large language models (LLMs), the Chinese Spelling Check (CSC)
task has seen various LLM methods developed, yet their performance remains
unsatisfactory. In contrast, fine-tuned BERT-based models, relying on
high-quality in-domain data, show excellent performance but suffer from edit
pattern overfitting. This paper proposes a novel dynamic mixture approach that
effectively combines the probability distributions of small models and LLMs
during the beam search decoding phase, achieving a balanced enhancement of
precise corrections from small models and the fluency of LLMs. This approach
also eliminates the need for fine-tuning LLMs, saving significant time and
resources, and facilitating domain adaptation. Comprehensive experiments
demonstrate that our mixture approach significantly boosts error correction
capabilities, achieving state-of-the-art results across multiple datasets. Our
code is available at https://github.com/zhqiao-nlp/MSLLM.

</details>


### [48] [Automatic Speech Recognition of African American English: Lexical and Contextual Effects](https://arxiv.org/abs/2506.06888)
*Hamid Mojarad,Kevin Tang*

Main category: cs.CL

TL;DR: 抽象概括说明自动语音识别（ASR）模型在处理非裔美国英语（AAE）特征时存在困难，研究了辅音簇简化（CCR）和ING弱化对ASR错误率的影响，以及有无外部语言模型（LM）对词汇邻域效应的影响。使用CORAAL语料和wav2vec 2.0进行分析，发现CCR和ING弱化对词错误率有小而显著的影响，无LM的ASR系统受词汇邻域效应影响更大。


<details>
  <summary>Details</summary>
Motivation: 非洲裔美国英语（AAE）中的语音、音系和形态句法特征会导致自动语音识别（ASR）系统识别错误。本研究重点关注AAE的两个变量：辅音簇简化（CCR）和ING弱化，探究它们是否增加ASR错误率。同时，探索没有外部语言模型（LM）的端到端ASR系统是否更易受词汇邻域效应影响，而更少受语境可预测性影响。

Method: 利用wav2vec 2.0模型（有/无外部语言模型）转录区域非洲裔美国英语语料库（CORAAL），使用蒙特利尔强制对齐器（MFA）配合发音扩展检测CCR和ING弱化现象。

Result: 研究发现CCR和ING弱化对词错误率（WER）有显著（但较小）的影响；未使用语言模型（LM）的ASR系统表现出更强的词汇邻域效应。

Conclusion: AAE的特定语音特征（CCR和ING弱化）会降低ASR性能；端到端无LM的ASR模型更依赖词汇相似度而非上下文语境，表明当前ASR系统在方言处理上存在结构偏差。

Abstract: Automatic Speech Recognition (ASR) models often struggle with the phonetic,
phonological, and morphosyntactic features found in African American English
(AAE). This study focuses on two key AAE variables: Consonant Cluster Reduction
(CCR) and ING-reduction. It examines whether the presence of CCR and
ING-reduction increases ASR misrecognition. Subsequently, it investigates
whether end-to-end ASR systems without an external Language Model (LM) are more
influenced by lexical neighborhood effect and less by contextual predictability
compared to systems with an LM. The Corpus of Regional African American
Language (CORAAL) was transcribed using wav2vec 2.0 with and without an LM. CCR
and ING-reduction were detected using the Montreal Forced Aligner (MFA) with
pronunciation expansion. The analysis reveals a small but significant effect of
CCR and ING on Word Error Rate (WER) and indicates a stronger presence of
lexical neighborhood effect in ASR systems without LMs.

</details>


### [49] [Hybrid Extractive Abstractive Summarization for Multilingual Sentiment Analysis](https://arxiv.org/abs/2506.06929)
*Mikhail Krasitskii,Grigori Sidorov,Olga Kolesnikova,Liliana Chanona Hernandez,Alexander Gelbukh*

Main category: cs.CL

TL;DR: 提出一个混合提取和抽象摘要的多语言情感分析方法，结合TF-IDF提取和微调XLM-R抽象模块，通过动态阈值和文化适应增强。在10种语言的实验显示基准显著提升：英语准确率0.90、低资源语言0.84，计算效率高22%。应用于实时品牌监控和跨文化分析，未来将优化低资源语言的8位量化。


<details>
  <summary>Details</summary>
Motivation: 针对独立方法在跨语言情感分析中的局限性（如语境丢失和文化差异），需要融合提取式和抽象式摘要优势，提升多语言场景的准确率和效率。

Method: 1) 结合TF-IDF提取关键句和微调XLM-R的抽象摘要模块；2) 动态阈值调整摘要长度；3) 加入文化适应机制处理语言差异。

Result: 1) 10种语言测试：英语准确率0.90，低资源语言平均0.84；2) 比传统方法计算效率提升22%；3) 显著优于BERT、mBERT等基线。

Conclusion: 混合方法有效解决多语言情感分析问题，平衡精度与效率。动态阈值和文化适应是关键创新。未来通过8位量化可进一步优化低资源语言性能。

Abstract: We propose a hybrid approach for multilingual sentiment analysis that
combines extractive and abstractive summarization to address the limitations of
standalone methods. The model integrates TF-IDF-based extraction with a
fine-tuned XLM-R abstractive module, enhanced by dynamic thresholding and
cultural adaptation. Experiments across 10 languages show significant
improvements over baselines, achieving 0.90 accuracy for English and 0.84 for
low-resource languages. The approach also demonstrates 22% greater
computational efficiency than traditional methods. Practical applications
include real-time brand monitoring and cross-cultural discourse analysis.
Future work will focus on optimization for low-resource languages via 8-bit
quantization.

</details>


### [50] [DiscoSum: Discourse-aware News Summarization](https://arxiv.org/abs/2506.06930)
*Alexander Spangher,Tenghao Huang,Jialiang Gu,Jiatong Shi,Muhao Chen*

Main category: cs.CL

TL;DR: 本论文提出了一种整合话语结构到新闻摘要生成的新方法，包括新的数据集、话语架构和DiscoSum算法，旨在解决语言模型在维持新闻文章长期组织结构上的不足，并通过人力和自动评估验证其有效性。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在文本摘要中虽取得进展，但难以维持新闻文章的长期话语结构，而文章的组织结构对读者参与有重要影响。

Method: 开发新闻话语架构描述摘要结构，创建多平台不同风格摘要的数据集，提出基于束搜索技术的结构感知摘要算法DiscoSum。

Result: 实验结果表明，该方法在保持叙事忠实度和满足结构要求方面有效，通过人和自动评估验证。

Conclusion: 整合话语结构可显著提升新闻摘要质量，尤其适应不同社交媒体的风格需求，DiscoSum算法为此提供可行解决方案。

Abstract: Recent advances in text summarization have predominantly leveraged large
language models to generate concise summaries. However, language models often
do not maintain long-term discourse structure, especially in news articles,
where organizational flow significantly influences reader engagement. We
introduce a novel approach to integrating discourse structure into
summarization processes, focusing specifically on news articles across various
media. We present a novel summarization dataset where news articles are
summarized multiple times in different ways across different social media
platforms (e.g. LinkedIn, Facebook, etc.). We develop a novel news discourse
schema to describe summarization structures and a novel algorithm, DiscoSum,
which employs beam search technique for structure-aware summarization, enabling
the transformation of news stories to meet different stylistic and structural
demands. Both human and automatic evaluation results demonstrate the efficacy
of our approach in maintaining narrative fidelity and meeting structural
requirements.

</details>


### [51] [What Makes a Good Natural Language Prompt?](https://arxiv.org/abs/2506.06950)
*Do Xuan Long,Duy Dinh,Ngoc-Hai Nguyen,Kenji Kawaguchi,Nancy F. Chen,Shafiq Joty,Min-Yen Kan*

Main category: cs.CL

TL;DR: 针对自然语言提示质量评估缺失共识的问题，本文通过对150多篇论文和博客的元分析，提出了包含6个维度21项属性的评估框架，并通过实验验证单属性增强对推理任务效果最显著，同时发现基于属性增强提示的指令微调能提升模型性能。


<details>
  <summary>Details</summary>
Motivation: 由于大语言模型的发展使得人机交互普及，但缺乏对自然语言提示质量的统一评估标准，阻碍了提示研究的推进与应用。

Method: 1) 元分析150+篇相关文献建立提示质量评估框架
2) 实证测试多属性增强在推理任务中的效果
3) 验证基于属性增强提示的指令微调对模型性能的影响

Result: 1) 发现现有研究对属性和任务的覆盖不均衡
2) 单属性增强在提示优化中效果最显著
3) 属性增强的指令微调可提升语言模型推理能力

Conclusion: 本框架为提示质量评估和优化奠定基础，弥合人机交互研究空白，同时开启提示工程新研究方向。

Abstract: As large language models (LLMs) have progressed towards more human-like and
human--AI communications have become prevalent, prompting has emerged as a
decisive component. However, there is limited conceptual consensus on what
exactly quantifies natural language prompts. We attempt to address this
question by conducting a meta-analysis surveying more than 150
prompting-related papers from leading NLP and AI conferences from 2022 to 2025
and blogs. We propose a property- and human-centric framework for evaluating
prompt quality, encompassing 21 properties categorized into six dimensions. We
then examine how existing studies assess their impact on LLMs, revealing their
imbalanced support across models and tasks, and substantial research gaps.
Further, we analyze correlations among properties in high-quality natural
language prompts, deriving prompting recommendations. We then empirically
explore multi-property prompt enhancements in reasoning tasks, observing that
single-property enhancements often have the greatest impact. Finally, we
discover that instruction-tuning on property-enhanced prompts can result in
better reasoning models. Our findings establish a foundation for
property-centric prompt evaluation and optimization, bridging the gaps between
human--AI communication and opening new prompting research directions.

</details>


### [52] [BIS Reasoning 1.0: The First Large-Scale Japanese Benchmark for Belief-Inconsistent Syllogistic Reasoning](https://arxiv.org/abs/2506.06955)
*Ha-Thanh Nguyen,Chaoran Liu,Hirokazu Kiyomaru,Koichi Takeda,Yusuke Miyao,Maki Matsuda,Yusuke Oda,Pontus Stenetorp,Qianying Liu,Su Myat Noe,Hideyuki Tachibana,Kouta Nakayama,Sadao Kurohashi*

Main category: cs.CL

TL;DR: BIS Reasoning 1.0为首个日本信仰不一致三段论数据集，揭示LLMs在逻辑有效但违背常识情境下的推理缺陷。榜单显示GPT-4o达79.54%准确率，但现有模型在涉及法律/医疗等高危领域仍存在重大隐患。


<details>
  <summary>Details</summary>
Motivation: 现有数据集（如NeuBAROCO/JFLD）主要关注常规或信仰一致的三段论，无法有效检测LLMs在信仰冲突时的逻辑推理偏差。此研究旨在填补该空白。

Method: 构建日本首个大型信仰不一致三段论数据集BIS Reasoning 1.0，在逻辑有效前提下设计违背常识的命题。测试包括GPT/Claude系列及日本本土LLMs的推理能力。

Result: 各模型表现差异显著：最优模型GPT-4o准确率79.54%，其他模型存在明显缺陷。证明当前LLMs处理逻辑有效但信仰冲突时存在系统性弱点。

Conclusion: 研究暴露了LLMs在高危领域应用的潜在风险，强调需开发能区分逻辑真理与直觉信仰的新方法以保障决策安全。

Abstract: We present BIS Reasoning 1.0, the first large-scale Japanese dataset of
syllogistic reasoning problems explicitly designed to evaluate
belief-inconsistent reasoning in large language models (LLMs). Unlike prior
datasets such as NeuBAROCO and JFLD, which focus on general or belief-aligned
reasoning, BIS Reasoning 1.0 introduces logically valid yet belief-inconsistent
syllogisms to uncover reasoning biases in LLMs trained on human-aligned
corpora. We benchmark state-of-the-art models - including GPT models, Claude
models, and leading Japanese LLMs - revealing significant variance in
performance, with GPT-4o achieving 79.54% accuracy. Our analysis identifies
critical weaknesses in current LLMs when handling logically valid but
belief-conflicting inputs. These findings have important implications for
deploying LLMs in high-stakes domains such as law, healthcare, and scientific
literature, where truth must override intuitive belief to ensure integrity and
safety.

</details>


### [53] [Learning to Clarify by Reinforcement Learning Through Reward-Weighted Fine-Tuning](https://arxiv.org/abs/2506.06964)
*Subhojyoti Mukherjee,Viet Dac Lai,Raghavendra Addanki,Ryan Rossi,Seunghyun Yoon,Trung Bui,Anup Rao,Jayakumar Subramanian,Branislav Kveton*

Main category: cs.CL

TL;DR: 该研究提出在问答系统中使用离线强化学习方法，通过模拟含澄清问题的对话进行学习，以优化奖励并提升语言质量，相比监督微调和直接偏好优化方法具有优势。


<details>
  <summary>Details</summary>
Motivation: 现有的问答代理在面对模糊问题时无法主动澄清，导致回答不准确。为提高代理在模糊问题下的表现，需研究主动询问澄清问题的能力。

Method: 利用强化学习（RL）模拟含澄清问题的对话。采用离线RL目标函数（类似奖励加权的监督微调），可在大型语言模型中高效优化，避免超参数调整问题。

Result: 相比监督微调（SFT）和直接偏好优化（DPO）方法，所提方法在优化的奖励分数和生成语言质量上均取得提升。

Conclusion: 离线强化学习框架能有效训练问答代理主动提出澄清问题，在奖励优化和语言质量上超越现有方法，且免除了超参数调整负担。

Abstract: Question answering (QA) agents automatically answer questions posed in
natural language. In this work, we learn to ask clarifying questions in QA
agents. The key idea in our method is to simulate conversations that contain
clarifying questions and learn from them using reinforcement learning (RL). To
make RL practical, we propose and analyze offline RL objectives that can be
viewed as reward-weighted supervised fine-tuning (SFT) and easily optimized in
large language models. Our work stands in a stark contrast to recently proposed
methods, based on SFT and direct preference optimization, which have additional
hyper-parameters and do not directly optimize rewards. We compare to these
methods empirically and report gains in both optimized rewards and language
quality.

</details>


### [54] [A dependently-typed calculus of event telicity and culminativity](https://arxiv.org/abs/2506.06968)
*Pavel Kovalev,Carlo Angiuli*

Main category: cs.CL

TL;DR: 本文提出了一种依赖类型的跨语言框架，用于分析事件的终止性和完成性。该框架包含两个部分：名词域中，建模名词短语的有界性及其与子类型、限定数量和形容词修饰的关系；动词域中，定义依赖事件演算，将终止事件建模为经历者具有有界性的事件，将完成事件建模为达到固有终点的终止事件，并考虑副词修饰。两个部分都特别关注相关的蕴含关系。框架基于扩展的Martin-Löf依赖类型理论，并在Agda证明助手中实现。


<details>
  <summary>Details</summary>
Motivation: 旨在建立统一的形式化框架分析语言中的事件特质（如终结性）及其与名词短语结构的交互关系，弥补传统方法在处理依存关系时的不足。

Method: 1. 名词域：通过有界性建模名词短语，关联子类型/定量/修饰 2. 动词域：构建依赖事件演算，基于经历者边界性定义终止事件，通过达到终点定义完成事件 3. 形式化工具：扩展Martin-Löf依赖类型理论，在Agda中实现语法规则和验证。

Result: 1. 实现英语句子建模示范 2. 形式化框架捕获了终止性/完成性的关键语言学特征 3. 完整展示名词域与动词域之间的理论联系

Conclusion: 该依赖类型框架成功统一了事件终结性的跨域分析，为计算语言学和形式语义学提供了可验证的新工具，Agda实现保障了理论严谨性。

Abstract: We present a dependently-typed cross-linguistic framework for analyzing the
telicity and culminativity of events, accompanied by examples of using our
framework to model English sentences. Our framework consists of two parts. In
the nominal domain, we model the boundedness of noun phrases and its
relationship to subtyping, delimited quantities, and adjectival modification.
In the verbal domain we define a dependent event calculus, modeling telic
events as those whose undergoer is bounded, culminating events as telic events
that achieve their inherent endpoint, and consider adverbial modification. In
both domains we pay particular attention to associated entailments. Our
framework is defined as an extension of intensional Martin-L\"of dependent type
theory, and the rules and examples in this paper have been formalized in the
Agda proof assistant.

</details>


### [55] [Break-The-Chain: Reasoning Failures in LLMs via Adversarial Prompting in Code Generation](https://arxiv.org/abs/2506.06971)
*Jaechul Roh,Varun Gandhi,Shivani Anilkumar,Arin Garg*

Main category: cs.CL

TL;DR: 该研究通过对抗性提示扰动（如故事重构、无关约束注入等）系统性评估大语言模型（LLM）在代码生成任务中的推理鲁棒性，发现表面提示变动会导致模型性能剧烈波动（-42.1%~+35.3%），揭示了当前推理系统的脆弱性。


<details>
  <summary>Details</summary>
Motivation: 探究大语言模型是真正具备推理能力，还是仅仅利用表面的统计模式。通过设计语义忠实但结构对抗的提示扰动，检验模型在复杂任务（如代码生成）中的稳健性。

Method: 构建包含700个扰动代码生成样本的测试集（基于LeetCode式问题），应用四种扰动策略：1) 故事化重构 2) 注入无关约束 3) 示例重排序 4) 数值扰动，并测量模型性能变化。

Result: 1. 部分扰动导致性能急剧下降（最大跌幅42.1%）
2. 意外发现某些扰动提升准确率（最高+35.3%）
3. 模型表现对提示的表面结构高度敏感，且变化不可预测

Conclusion: 当前LLM的推理能力具有显著脆弱性，其表现受提示表面结构影响大于语义忠实度。亟需开发更鲁棒的推理对齐方法与提示工程技术，相关数据集和评估框架已开源。

Abstract: Large Language Models (LLMs) have achieved remarkable success in tasks
requiring complex reasoning, such as code generation, mathematical problem
solving, and algorithmic synthesis -- especially when aided by reasoning tokens
and Chain-of-Thought prompting. Yet, a core question remains: do these models
truly reason, or do they merely exploit shallow statistical patterns? In this
paper, we systematically investigate the robustness of reasoning LLMs by
introducing a suite of semantically faithful yet adversarially structured
prompt perturbations. Our evaluation -- spanning 700 perturbed code generations
derived from LeetCode-style problems -- applies transformations such as
storytelling reframing, irrelevant constraint injection, example reordering,
and numeric perturbation. We observe that while certain modifications severely
degrade performance (with accuracy drops up to -42.1%), others surprisingly
improve model accuracy by up to 35.3%, suggesting sensitivity not only to
semantics but also to surface-level prompt dynamics. These findings expose the
fragility and unpredictability of current reasoning systems, underscoring the
need for more principles approaches to reasoning alignments and prompting
robustness. We release our perturbation datasets and evaluation framework to
promote further research in trustworthy and resilient LLM reasoning.

</details>


### [56] [Atomic Reasoning for Scientific Table Claim Verification](https://arxiv.org/abs/2506.06972)
*Yuji Zhang,Qingyun Wang,Cheng Qian,Jiateng Liu,Chenkai Sun,Denghui Zhang,Tarek Abdelzaher,Chengxiang Zhai,Preslav Nakov,Heng Ji*

Main category: cs.CL

TL;DR: 科学表格的复杂性和高信息密度容易导致非专家被误导，现有模型在细粒度推理上存在不足。受认知负荷理论启发，本文提出通过原子技能链降低认知负荷，提升表格声明验证的准确性和泛化能力，并在新基准SciAtomicBench上以少量数据超越GPT-4o。


<details>
  <summary>Details</summary>
Motivation: 科学文本因其技术性语言和复杂数据具有权威性，但也可能导致误传。非专家尤其容易受基于科学表格的误导性声明影响，因为表格具有高信息密度和可信度。现有表格声明验证模型（包括SOTA大语言模型）在细粒度推理上表现不佳。

Method: 受认知负荷理论启发，提出降低模型认知负荷的方案：开发模块化、可复用的原子技能，并通过技能链模式动态组合这些技能。构建跨领域基准SciAtomicBench（含细粒度推理标注），仅用350个微调样本训练原子推理模型。

Result: 原子推理模型在少量训练数据下超越GPT-4o的思维链方法：在表格声明验证任务中取得SOTA效果，证明该方法能显著提升细粒度推理的准确性和泛化能力。

Conclusion: 通过分解复杂推理为原子技能并动态组合，可有效降低模型认知负荷，提高科学声明的验证精度。该方法在跨领域场景中展现出强泛化能力，为未来可信AI系统提供新思路。

Abstract: Scientific texts often convey authority due to their technical language and
complex data. However, this complexity can sometimes lead to the spread of
misinformation. Non-experts are particularly susceptible to misleading claims
based on scientific tables due to their high information density and perceived
credibility. Existing table claim verification models, including
state-of-the-art large language models (LLMs), often struggle with precise
fine-grained reasoning, resulting in errors and a lack of precision in
verifying scientific claims. Inspired by Cognitive Load Theory, we propose that
enhancing a model's ability to interpret table-based claims involves reducing
cognitive load by developing modular, reusable reasoning components (i.e.,
atomic skills). We introduce a skill-chaining schema that dynamically composes
these skills to facilitate more accurate and generalizable reasoning with a
reduced cognitive load. To evaluate this, we create SciAtomicBench, a
cross-domain benchmark with fine-grained reasoning annotations. With only 350
fine-tuning examples, our model trained by atomic reasoning outperforms
GPT-4o's chain-of-thought method, achieving state-of-the-art results with far
less training data.

</details>


### [57] [Chain of Methodologies: Scaling Test Time Computation without Training](https://arxiv.org/abs/2506.06982)
*Cong Liu,Jie Wu,Weigang Wu,Xu Chen,Liang Lin,Wei-Shi Zheng*

Main category: cs.CL

TL;DR: 介绍Chain of Methodologies (CoM)：一种无需微调的创新提示框架，通过整合人类方法论增强大语言模型的结构化思维，在复杂推理任务中超越基准表现。


<details>
  <summary>Details</summary>
Motivation: 解决大语言模型因训练数据缺乏深度洞见而难以处理复杂推理任务的问题，利用人类方法论激发系统化推理能力。

Method: CoM框架通过用户自定义方法论激活模型的元认知能力，引导模型进行扩展推理，无需显式微调。

Result: 实验证明CoM超越竞争基线方法，展现训练无关提示法解决复杂推理任务的潜力。

Conclusion: CoM通过人类方法论洞见缩小与人类水平推理的差距，为非微调方案提供强健路径。

Abstract: Large Language Models (LLMs) often struggle with complex reasoning tasks due
to insufficient in-depth insights in their training data, which are typically
absent in publicly available documents. This paper introduces the Chain of
Methodologies (CoM), an innovative and intuitive prompting framework that
enhances structured thinking by integrating human methodological insights,
enabling LLMs to tackle complex tasks with extended reasoning. CoM leverages
the metacognitive abilities of advanced LLMs, activating systematic reasoning
throught user-defined methodologies without explicit fine-tuning. Experiments
show that CoM surpasses competitive baselines, demonstrating the potential of
training-free prompting methods as robust solutions for complex reasoning tasks
and bridging the gap toward human-level reasoning through human-like
methodological insights.

</details>


### [58] [Cultural Bias Matters: A Cross-Cultural Benchmark Dataset and Sentiment-Enriched Model for Understanding Multimodal Metaphors](https://arxiv.org/abs/2506.06987)
*Senqi Yang,Dongyu Zhang,Jing Ren,Ziqi Xu,Xiuzhen Zhang,Yiliao Song,Hongfei Lin,Feng Xia*

Main category: cs.CL

TL;DR: 该论文针对NLP中隐喻处理的文化偏见问题，构建了包含中文和英语广告的多文化多模态隐喻数据集MultiMM，并提出了融入情感感知的基线模型SEMD。


<details>
  <summary>Details</summary>
Motivation: 现有隐喻处理研究主要基于反映欧美文化偏见的英语样本，导致模型性能和贡献被高估。缺少文化偏见对多模态隐喻影响的研究，存在文化偏见的挑战。

Method: 1.建立MultiMM数据集：包含8,461个中英文图文广告对，标注多模态隐喻；2.提出Sentiment-Enriched Metaphor Detection (SEMD)模型，整合情感向量提升跨文化隐喻理解。

Result: 实验表明SEMD在隐喻检测和情感分析任务上有效；数据集公开促进跨文化研究；

Conclusion: 该研究揭示了文化偏见问题，MultiMM数据集和SEMD模型为开发更公平、包容的NLP模型奠定基础。

Abstract: Metaphors are pervasive in communication, making them crucial for natural
language processing (NLP). Previous research on automatic metaphor processing
predominantly relies on training data consisting of English samples, which
often reflect Western European or North American biases. This cultural skew can
lead to an overestimation of model performance and contributions to NLP
progress. However, the impact of cultural bias on metaphor processing,
particularly in multimodal contexts, remains largely unexplored. To address
this gap, we introduce MultiMM, a Multicultural Multimodal Metaphor dataset
designed for cross-cultural studies of metaphor in Chinese and English. MultiMM
consists of 8,461 text-image advertisement pairs, each accompanied by
fine-grained annotations, providing a deeper understanding of multimodal
metaphors beyond a single cultural domain. Additionally, we propose
Sentiment-Enriched Metaphor Detection (SEMD), a baseline model that integrates
sentiment embeddings to enhance metaphor comprehension across cultural
backgrounds. Experimental results validate the effectiveness of SEMD on
metaphor detection and sentiment analysis tasks. We hope this work increases
awareness of cultural bias in NLP research and contributes to the development
of fairer and more inclusive language models. Our dataset and code are
available at https://github.com/DUTIR-YSQ/MultiMM.

</details>


### [59] [What makes Reasoning Models Different? Follow the Reasoning Leader for Efficient Decoding](https://arxiv.org/abs/2506.06998)
*Ming Li,Zhengyuan Yang,Xiyao Wang,Dianqi Li,Kevin Lin,Tianyi Zhou,Lijuan Wang*

Main category: cs.CL

TL;DR: 大型推理模型（LRM）通过长思维链实现强推理性能，但冗长的轨迹减慢推理速度，并常陷入不必要的细节（过度思考）。本文分析推理与非推理模型间的词级偏差，发现全局偏差反弹和局部偏差减小现象。基于后者，提出FoReaL-Decoding方法：用强模型引导每句开头，弱模型补全剩余部分，实现计算效率与性能平衡。该方法在数学推理基准测试中节省30-50%计算量，缩短40%思维链长度，保持86-100%性能。


<details>
  <summary>Details</summary>
Motivation: 大型推理模型生成冗长的思维链会降低推理效率并产生过度细节。通过分析其与非推理模型的词级偏差，发现关键未充分研究的现象：全局偏差反弹（随输出增长偏差持续或增加）和局部偏差减小（偏差集中在句首'思维线索'，后续快速下降）。基于局部偏差减小现象，需开发能平衡质量与效率的解码方法。

Method: 提出FoReaL-Decoding：协作式快慢思考解码。由强模型（Leading）生成每句开头的少量词汇，弱模型（draft）补全句子剩余部分。通过随机门控机制平滑切换大小模型，控制质量与成本权衡。

Result: 在四个数学推理基准（AIME24/GPQA-Diamond/MATH500/AMC23）上：FoReaL-Decoding减少理论FLOPs 30-50%，缩短40%思维链长度，同时保留86-100%模型性能。

Conclusion: FoReaL-Decoding作为即插即用方案，为推理任务提供可控的成本-质量权衡路径；局部偏差减小的发现为未来高效推理模型设计提供新视角。

Abstract: Large reasoning models (LRMs) achieve strong reasoning performance by
emitting long chains of thought. Yet, these verbose traces slow down inference
and often drift into unnecessary detail, known as the overthinking phenomenon.
To better understand LRMs' behavior, we systematically analyze the token-level
misalignment between reasoning and non-reasoning models. While it is expected
that their primary difference lies in the stylistic "thinking cues", LRMs
uniquely exhibit two pivotal, previously under-explored phenomena: a Global
Misalignment Rebound, where their divergence from non-reasoning models persists
or even grows as response length increases, and more critically, a Local
Misalignment Diminish, where the misalignment concentrates at the "thinking
cues" each sentence starts with but rapidly declines in the remaining of the
sentence. Motivated by the Local Misalignment Diminish, we propose
FoReaL-Decoding, a collaborative fast-slow thinking decoding method for
cost-quality trade-off. In FoReaL-Decoding, a Leading model leads the first few
tokens for each sentence, and then a weaker draft model completes the following
tokens to the end of each sentence. FoReaL-Decoding adopts a stochastic gate to
smoothly interpolate between the small and the large model. On four popular
math-reasoning benchmarks (AIME24, GPQA-Diamond, MATH500, AMC23),
FoReaL-Decoding reduces theoretical FLOPs by 30 to 50% and trims CoT length by
up to 40%, while preserving 86 to 100% of model performance. These results
establish FoReaL-Decoding as a simple, plug-and-play route to controllable
cost-quality trade-offs in reasoning-centric tasks.

</details>


### [60] [Adversarial Paraphrasing: A Universal Attack for Humanizing AI-Generated Text](https://arxiv.org/abs/2506.07001)
*Yize Cheng,Vinu Sankar Sadasivan,Mehrdad Saberi,Shoumik Saha,Soheil Feizi*

Main category: cs.CL

TL;DR: 提出了一种名为Adversarial Paraphrasing的训练免费攻击框架，通过使用现成的LLM在AI文本检测器指导下改写文本，能有效规避多种AI生成文本检测系统。


<details>
  <summary>Details</summary>
Motivation: 现有AI生成文本检测器对简单改写攻击具有鲁棒性，但作者发现通过对抗性改写能更有效地规避检测，暴露检测系统的脆弱性。

Method: 利用现成的指令跟随型LLM，在AI文本检测器的指导下改写AI生成内容，生成专门优化以绕过检测的对抗样本。

Result: 在RADAR和Fast-DetectGPT等检测器上，T@1%F指标分别降低64.49%和98.96%；在包含神经网络、水印和零样本方法的多样化检测器集合中平均降低87.88%

Conclusion: 该方法揭示现有检测策略在复杂规避技术下的脆弱性，强调需要开发更鲁棒的检测方案，同时指出该方法在文本质量下降较小的情况下显著降低检测率

Abstract: The increasing capabilities of Large Language Models (LLMs) have raised
concerns about their misuse in AI-generated plagiarism and social engineering.
While various AI-generated text detectors have been proposed to mitigate these
risks, many remain vulnerable to simple evasion techniques such as
paraphrasing. However, recent detectors have shown greater robustness against
such basic attacks. In this work, we introduce Adversarial Paraphrasing, a
training-free attack framework that universally humanizes any AI-generated text
to evade detection more effectively. Our approach leverages an off-the-shelf
instruction-following LLM to paraphrase AI-generated content under the guidance
of an AI text detector, producing adversarial examples that are specifically
optimized to bypass detection. Extensive experiments show that our attack is
both broadly effective and highly transferable across several detection
systems. For instance, compared to simple paraphrasing attack--which,
ironically, increases the true positive at 1% false positive (T@1%F) by 8.57%
on RADAR and 15.03% on Fast-DetectGPT--adversarial paraphrasing, guided by
OpenAI-RoBERTa-Large, reduces T@1%F by 64.49% on RADAR and a striking 98.96% on
Fast-DetectGPT. Across a diverse set of detectors--including neural
network-based, watermark-based, and zero-shot approaches--our attack achieves
an average T@1%F reduction of 87.88% under the guidance of
OpenAI-RoBERTa-Large. We also analyze the tradeoff between text quality and
attack success to find that our method can significantly reduce detection
rates, with mostly a slight degradation in text quality. Our adversarial setup
highlights the need for more robust and resilient detection strategies in the
light of increasingly sophisticated evasion techniques.

</details>


### [61] [A Culturally-diverse Multilingual Multimodal Video Benchmark & Model](https://arxiv.org/abs/2506.07032)
*Bhuiyan Sanjid Shafique,Ashmal Vayani,Muhammad Maaz,Hanoona Abdul Rasheed,Dinura Dissanayake,Mohammed Irfan Kurpath,Yahya Hmaiti,Go Inoue,Jean Lahoud,Md. Safirur Rashid,Shadid Intisar Quasem,Maheen Fatima,Franco Vidal,Mykola Maslych,Ketan Pravin More,Sanoojan Baliah,Hasindri Watawana,Yuhao Li,Fabian Farestam,Leon Schaller,Roman Tymtsiv,Simon Weber,Hisham Cholakkal,Ivan Laptev,Shin'ichi Satoh,Michael Felsberg,Mubarak Shah,Salman Khan,Fahad Shahbaz Khan*

Main category: cs.CL

TL;DR: 提出ViMUL-Bench基准测试和ViMUL多语言视频大模型，解决视频大语言模型语言文化包容性问题


<details>
  <summary>Details</summary>
Motivation: 现有视频大型多模态模型多局限于英语，需要提升其语言文化包容性

Method: 开发含14门语言、8K样本的手工基准ViMUL-Bench；构建120万样本的多语言训练集；设计ViMUL视频大模型

Result: ViMUL模型在高资源与低资源语言视频理解任务中实现更好平衡

Conclusion: 发布ViMUL-Bench基准、ViMUL模型及训练数据集，促进多语言视频大模型发展

Abstract: Large multimodal models (LMMs) have recently gained attention due to their
effectiveness to understand and generate descriptions of visual content. Most
existing LMMs are in English language. While few recent works explore
multilingual image LMMs, to the best of our knowledge, moving beyond the
English language for cultural and linguistic inclusivity is yet to be
investigated in the context of video LMMs. In pursuit of more inclusive video
LMMs, we introduce a multilingual Video LMM benchmark, named ViMUL-Bench, to
evaluate Video LMMs across 14 languages, including both low- and high-resource
languages: English, Chinese, Spanish, French, German, Hindi, Arabic, Russian,
Bengali, Urdu, Sinhala, Tamil, Swedish, and Japanese. Our ViMUL-Bench is
designed to rigorously test video LMMs across 15 categories including eight
culturally diverse categories, ranging from lifestyles and festivals to foods
and rituals and from local landmarks to prominent cultural personalities.
ViMUL-Bench comprises both open-ended (short and long-form) and multiple-choice
questions spanning various video durations (short, medium, and long) with 8k
samples that are manually verified by native language speakers. In addition, we
also introduce a machine translated multilingual video training set comprising
1.2 million samples and develop a simple multilingual video LMM, named ViMUL,
that is shown to provide a better tradeoff between high-and low-resource
languages for video understanding. We hope our ViMUL-Bench and multilingual
video LMM along with a large-scale multilingual video training set will help
ease future research in developing cultural and linguistic inclusive
multilingual video LMMs. Our proposed benchmark, video LMM and training data
will be publicly released at https://mbzuai-oryx.github.io/ViMUL/.

</details>


### [62] [KG2QA: Knowledge Graph-enhanced Retrieval-Augmented Generation for Communication Standards Question Answering](https://arxiv.org/abs/2506.07037)
*Zhongze Luo,Weixuan Wan,Qizhi Zheng,Yanhong Bai,Jingyun Sun,Jian Wang,Dan Wang*

Main category: cs.CL

TL;DR: 本文通过结合大型语言模型微调和知识图谱，构建了一个智能通信标准咨询问答系统。实验显示，经LoRA微调的Qwen2.5-7B模型在评估指标上显著提升，优于Llama-3-8B，同时构建的领域知识图谱有效提升了问答效果。


<details>
  <summary>Details</summary>
Motivation: 传统通信标准咨询周期长且依赖专家经验，难以满足快速发展的技术需求，因此需要开发智能化解决方案。

Method: 1) 使用6,587个通信标准QA数据集对Qwen2.5-7B进行LoRA微调；2) 基于包含6种实体属性+10种关系属性的本体框架构建13,906实体/13,524关系的知识图谱；3) 在服务端实现微调模型与知识图谱的RAG协同检索。

Result: 1) 微调后BLEU-4从18.8564提升至66.8993，ROUGE等指标显著增长；2) 知识图谱查询准确率高；3) RAG框架使DeepSeek评估的5个维度平均分提升2.26%；4) 结合Web/API实现良好交互体验。

Conclusion: 该系统有效解决传统咨询痛点，在专业能力、问答效果和实用价值方面表现优异，具有重要应用前景。

Abstract: There are many types of standards in the field of communication. The
traditional consulting model has a long cycle and relies on the knowledge and
experience of experts, making it difficult to meet the rapidly developing
technological demands. This paper combines the fine-tuning of large language
models with the construction of knowledge graphs to implement an intelligent
consultation and question-answering system for communication standards. The
experimental results show that after LoRA tuning on the constructed dataset of
6,587 questions and answers in the field of communication standards,
Qwen2.5-7B-Instruct demonstrates outstanding professional capabilities in the
field of communication standards on the test set. BLEU-4 rose from 18.8564 to
66.8993, and evaluation indicators such as ROUGE also increased significantly,
outperforming the fine-tuning effect of the comparison model
Llama-3-8B-Instruct. Based on the ontology framework containing 6 entity
attributes and 10 relation attributes, a knowledge graph of the communication
standard domain containing 13,906 entities and 13,524 relations was
constructed, showing a relatively good query accuracy rate. The intelligent
consultation and question-answering system enables the fine-tuned model on the
server side to access the locally constructed knowledge graph and conduct
graphical retrieval of key information first, which is conducive to improving
the question-answering effect. The evaluation using DeepSeek as the Judge on
the test set shows that our RAG framework enables the fine-tuned model to
improve the scores at all five angles, with an average score increase of 2.26%.
And combined with web services and API interfaces, it has achieved very good
results in terms of interaction experience and back-end access, and has very
good practical application value.

</details>


### [63] [Reasoning with RAGged events: RAG-Enhanced Event Knowledge Base Construction and reasoning with proof-assistants](https://arxiv.org/abs/2506.07042)
*Stergios Chatzikyriakidis*

Main category: cs.CL

TL;DR: 本文提出一种自动化提取历史事件的方法，使用多种LLM（GPT-4, Claude, Llama 3.2）和三种增强策略（基本生成、知识图谱增强、RAG），并在修昔底德历史文本上评估。发现增强策略在不同维度各有优劣，最终开发了将RDF转换为Coq规范的流程，支持高阶历史因果推理。


<details>
  <summary>Details</summary>
Motivation: 手动构建历史事件计算表示成本高昂，且现有RDF/OWL推理机仅支持一阶逻辑片段，无法进行深度时空语义分析。

Method: 采用三种LLM配合三重增强策略：1) 基础生成 2) 知识图谱增强 3) RAG，建立自动事件提取模型。通过历史文本评估后，开发RDF到Coq证明助手的转换流程。

Result: 增强策略呈现特异性优化：基础生成（Claude/GPT-4）在事件覆盖度最优，RAG则提升坐标精度和元数据完整性。模型规模决定敏感度——大模型基线稳健，Llama 3.2表现波动剧烈。Coq形式化验证证实RAG提取的事件类型符合领域语义。

Conclusion: 多策略LLM方法可自动提取历史事件结构，其RAG增强结果经Coq转换后支持高阶时序推理和因果验证，突破了RDF的逻辑限制。

Abstract: Extracting structured computational representations of historical events from
narrative text remains computationally expensive when constructed manually.
While RDF/OWL reasoners enable graph-based reasoning, they are limited to
fragments of first-order logic, preventing deeper temporal and semantic
analysis. This paper addresses both challenges by developing automatic
historical event extraction models using multiple LLMs (GPT-4, Claude, Llama
3.2) with three enhancement strategies: pure base generation, knowledge graph
enhancement, and Retrieval-Augmented Generation (RAG). We conducted
comprehensive evaluations using historical texts from Thucydides. Our findings
reveal that enhancement strategies optimize different performance dimensions
rather than providing universal improvements. For coverage and historical
breadth, base generation achieves optimal performance with Claude and GPT-4
extracting comprehensive events. However, for precision, RAG enhancement
improves coordinate accuracy and metadata completeness. Model architecture
fundamentally determines enhancement sensitivity: larger models demonstrate
robust baseline performance with incremental RAG improvements, while Llama 3.2
shows extreme variance from competitive performance to complete failure. We
then developed an automated translation pipeline converting extracted RDF
representations into Coq proof assistant specifications, enabling higher-order
reasoning beyond RDF capabilities including multi-step causal verification,
temporal arithmetic with BC dates, and formal proofs about historical
causation. The Coq formalization validates that RAG-discovered event types
represent legitimate domain-specific semantic structures rather than
ontological violations.

</details>


### [64] [Lingshu: A Generalist Foundation Model for Unified Multimodal Medical Understanding and Reasoning](https://arxiv.org/abs/2506.07044)
*LASA Team,Weiwen Xu,Hou Pong Chan,Long Li,Mahani Aljunied,Ruifeng Yuan,Jianyu Wang,Chenghao Xiao,Guizhen Chen,Chaoqun Liu,Zhaodonghui Li,Yu Sun,Junao Shen,Chaojun Wang,Jie Tan,Deli Zhao,Tingyang Xu,Hao Zhang,Yu Rong*

Main category: cs.CL

TL;DR: 该论文提出了医学专用多模态大语言模型Lingshu，通过全面的数据整理和多种训练方法，克服了现有医学MLLMs的三大限制（知识覆盖不全、易产生幻觉、缺乏医学推理能力），并在三个医学任务中均优于现有多模态开源模型。


<details>
  <summary>Details</summary>
Motivation: 现有医学MLLMs存在知识覆盖不全、易产生幻觉、缺乏专业推理能力三大局限性，无法有效满足医疗场景需求。

Method: 1. 提出全面医学数据整理流程：收集医学图文数据并生成精标注样本；2. 构建Lingshu模型进行多阶段训练；3. 初步探索强化学习提升医学推理；4. 开发标准化评估框架MedEvalKit。

Result: 在医疗QA、文本QA及报告生成任务中，Lingshu持续超越现有开源多模态模型。

Conclusion: 全面的数据整理与渐进式训练策略能有效解决医学MLLM的核心缺陷，Lingshu的创新结构为医学AI模型发展树立了新基准。

Abstract: Multimodal Large Language Models (MLLMs) have demonstrated impressive
capabilities in understanding common visual elements, largely due to their
large-scale datasets and advanced training strategies. However, their
effectiveness in medical applications remains limited due to the inherent
discrepancies between data and tasks in medical scenarios and those in the
general domain. Concretely, existing medical MLLMs face the following critical
limitations: (1) limited coverage of medical knowledge beyond imaging, (2)
heightened susceptibility to hallucinations due to suboptimal data curation
processes, (3) lack of reasoning capabilities tailored for complex medical
scenarios. To address these challenges, we first propose a comprehensive data
curation procedure that (1) efficiently acquires rich medical knowledge data
not only from medical imaging but also from extensive medical texts and
general-domain data; and (2) synthesizes accurate medical captions, visual
question answering (VQA), and reasoning samples. As a result, we build a
multimodal dataset enriched with extensive medical knowledge. Building on the
curated data, we introduce our medical-specialized MLLM: Lingshu. Lingshu
undergoes multi-stage training to embed medical expertise and enhance its
task-solving capabilities progressively. Besides, we preliminarily explore the
potential of applying reinforcement learning with verifiable rewards paradigm
to enhance Lingshu's medical reasoning ability. Additionally, we develop
MedEvalKit, a unified evaluation framework that consolidates leading multimodal
and textual medical benchmarks for standardized, fair, and efficient model
assessment. We evaluate the performance of Lingshu on three fundamental medical
tasks, multimodal QA, text-based QA, and medical report generation. The results
show that Lingshu consistently outperforms the existing open-source multimodal
models on most tasks ...

</details>


### [65] [Com$^2$: A Causal-Guided Benchmark for Exploring Complex Commonsense Reasoning in Large Language Models](https://arxiv.org/abs/2506.07064)
*Kai Xiong,Xiao Ding,Yixin Cao,Yuxiong Yan,Li Du,Yufei Zhang,Jinglong Gao,Jiaqian Liu,Bing Qin,Ting Liu*

Main category: cs.CL

TL;DR: 提出了一个名为Com²的新基准测试,专注于复杂常识推理。现有LLM在简单常识上表现良好,但在复杂隐含常识(如事件长期影响)上存在困难。该工作利用因果事件图构建结构化知识,并通过因果干预生成多样化场景,再由LLM'慢思考'生成测试样本。实验发现LLM在推理深度和广度上存在不足,但微调和慢思考策略能改善表现。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型(LLM)在简单显性常识推理上已达到类人水平,但在复杂隐性常识推理(如理解事件的长期影响)上仍有困难。现有研究集中于数学/代码等结构化任务,而复杂常识推理因不确定性和非结构化特点研究不足。本文旨在填补这一空白,使模型更贴近现实关注点。

Method: 1) 整合因果事件图作为结构化复杂常识表示;2) 应用因果理论(如干预)修改事件图,生成符合人类关注的不同情境;3) 引导LLM通过'慢思考'方式(基于修改后因果图的逻辑关系)综合生成测试样本;4) 附加使用侦探故事构造更具挑战性的子集。

Result: 实验表明LLM在推理深度(处理因果链长度)和广度(处理多结局场景)上存在显著困难,但通过领域微调和引入慢思考策略可有效缓解这些问题。

Conclusion: Com²基准测试有效揭示了LLM在复杂常识推理上的不足,提出基于因果图的数据构建方法和慢思考策略,为提升复杂推理能力提供了新方向。代码和数据集已开源。

Abstract: Large language models (LLMs) have mastered abundant simple and explicit
commonsense knowledge through pre-training, enabling them to achieve human-like
performance in simple commonsense reasoning. Nevertheless, LLMs struggle to
reason with complex and implicit commonsense knowledge that is derived from
simple ones (such as understanding the long-term effects of certain events), an
aspect humans tend to focus on more. Existing works focus on complex tasks like
math and code, while complex commonsense reasoning remains underexplored due to
its uncertainty and lack of structure. To fill this gap and align with
real-world concerns, we propose a benchmark Com$^2$ focusing on complex
commonsense reasoning. We first incorporate causal event graphs to serve as
structured complex commonsense. Then we adopt causal theory~(e.g.,
intervention) to modify the causal event graphs and obtain different scenarios
that meet human concerns. Finally, an LLM is employed to synthesize examples
with slow thinking, which is guided by the logical relationships in the
modified causal graphs. Furthermore, we use detective stories to construct a
more challenging subset. Experiments show that LLMs struggle in reasoning depth
and breadth, while post-training and slow thinking can alleviate this. The code
and data are available at https://github.com/Waste-Wood/Com2.

</details>


### [66] [Representation Decomposition for Learning Similarity and Contrastness Across Modalities for Affective Computing](https://arxiv.org/abs/2506.07086)
*Yuanhe Tian,Pengsen Cheng,Guoqing Jin,Lei Zhang,Yan Song*

Main category: cs.CL

TL;DR: 论文提出了一种基于LLM的多模态情感计算方法，通过解耦共享和特定模态的表示，结合注意力机制动态生成软提示，在多项任务中超越现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有方法无法有效捕捉多模态间复杂且冲突的情感证据，常依赖单模态分析或简单融合。

Method: 1. 使用预训练多模态编码器对齐输入
2. 表征解框架分离共有情感内容与独特线索
3. 通过注意力机制整合解耦信号生成动态软提示输入多模态LLM

Result: 在多模态方面情感分析、多模态情绪分析、有害表情包检测三个任务上稳定超越基准模型和SOTA。

Conclusion: 显式解耦模态不变与模态特定成分能有效提升多模态情感理解，该方法具有普适性和优越性。

Abstract: Multi-modal affective computing aims to automatically recognize and interpret
human attitudes from diverse data sources such as images and text, thereby
enhancing human-computer interaction and emotion understanding. Existing
approaches typically rely on unimodal analysis or straightforward fusion of
cross-modal information that fail to capture complex and conflicting evidence
presented across different modalities. In this paper, we propose a novel
LLM-based approach for affective computing that explicitly deconstructs visual
and textual representations into shared (modality-invariant) and
modality-specific components. Specifically, our approach firstly encodes and
aligns input modalities using pre-trained multi-modal encoders, then employs a
representation decomposition framework to separate common emotional content
from unique cues, and finally integrates these decomposed signals via an
attention mechanism to form a dynamic soft prompt for a multi-modal LLM.
Extensive experiments on three representative tasks for affective computing,
namely, multi-modal aspect-based sentiment analysis, multi-modal emotion
analysis, and hateful meme detection, demonstrate the effectiveness of our
approach, which consistently outperforms strong baselines and state-of-the-art
models.

</details>


### [67] [How Far Are We from Optimal Reasoning Efficiency?](https://arxiv.org/abs/2506.07104)
*Jiaxuan Gao,Shu Yan,Qixin Tan,Lu Yang,Shusheng Xu,Wei Fu,Zhiyu Mei,Kaifeng Lyu,Yi Wu*

Main category: cs.CL

TL;DR: 针对大型推理模型推理效率低的问题，本文引入了推理效率前沿和REG指标，并提出REO-RL解决算法


<details>
  <summary>Details</summary>
Motivation: 当前大型推理模型的推理过程冗余冗长，导致推理成本高、部署困难。现有微调方法评估不统一，难以准确衡量效率提升程度

Method: 提出1)推理效率前沿(不同训练配置下的上限曲线) 2)REG指标(量化模型与效率前沿的差距) 3)REO-RL强化学习算法(通过稀疏token预算选择降低REG)

Result: REO-RL在16K token预算下使REG降低50%+，逼近理想效率前沿并保持精度。消融实验证明指数级预算策略有效

Conclusion: REG是有效的效率评估指标；REO-RL显著缩小效率差距；但完全达到效率前沿仍是开放挑战

Abstract: Large Reasoning Models (LRMs) demonstrate remarkable problem-solving
capabilities through extended Chain-of-Thought (CoT) reasoning but often
produce excessively verbose and redundant reasoning traces. This inefficiency
incurs high inference costs and limits practical deployment. While existing
fine-tuning methods aim to improve reasoning efficiency, assessing their
efficiency gains remains challenging due to inconsistent evaluations. In this
work, we introduce the reasoning efficiency frontiers, empirical upper bounds
derived from fine-tuning base LRMs across diverse approaches and training
configurations. Based on these frontiers, we propose the Reasoning Efficiency
Gap (REG), a unified metric quantifying deviations of any fine-tuned LRMs from
these frontiers. Systematic evaluation on challenging mathematical benchmarks
reveals significant gaps in current methods: they either sacrifice accuracy for
short length or still remain inefficient under tight token budgets. To reduce
the efficiency gap, we propose REO-RL, a class of Reinforcement Learning
algorithms that minimizes REG by targeting a sparse set of token budgets.
Leveraging numerical integration over strategically selected budgets, REO-RL
approximates the full efficiency objective with low error using a small set of
token budgets. Through systematic benchmarking, we demonstrate that our
efficiency metric, REG, effectively captures the accuracy-length trade-off,
with low-REG methods reducing length while maintaining accuracy. Our approach,
REO-RL, consistently reduces REG by >=50 across all evaluated LRMs and matching
Qwen3-4B/8B efficiency frontiers under a 16K token budget with minimal accuracy
loss. Ablation studies confirm the effectiveness of our exponential token
budget strategy. Finally, our findings highlight that fine-tuning LRMs to
perfectly align with the efficiency frontiers remains an open challenge.

</details>


### [68] [Theorem-of-Thought: A Multi-Agent Framework for Abductive, Deductive, and Inductive Reasoning in Language Models](https://arxiv.org/abs/2506.07106)
*Samir Abdaljalil,Hasan Kurban,Khalid Qaraqe,Erchin Serpedin*

Main category: cs.CL

TL;DR: ToTh (Theorem-of-Thought) 是新的推理框架，使用三个代理（溯因、演绎、归纳）协同构建结构化推理图并通过贝叶斯置信传播评估一致性。在WebOfLies和MultiArith等任务中超越CoT等方法。


<details>
  <summary>Details</summary>
Motivation: 现有提示技术（如CoT）缺乏对逻辑结构的约束和内部一致性的评估机制，导致LLM推理过程脆弱且不可解释。

Method: 使用三个并行的代理（模式：溯因/演绎/归纳）各生成推理迹，组成形式化推理图。通过NLI引导的贝叶斯置信传播为步骤分配置信度，选择最一致的图导出答案。

Result: 在符号推理（WebOfLies）和数值推理（MultiArith）基准测试中，ToTh持续优于CoT、Self-Consistency和CoT-Decoding，同时生成可解释的推理链。

Conclusion: ToTh为构建更稳健的LLM推理提供了新方向，其结构化协作机制和一致性评估提升了逻辑性与认知合理性。代码已开源。

Abstract: Large language models (LLMs) have shown strong performance across natural
language reasoning tasks, yet their reasoning processes remain brittle and
difficult to interpret. Prompting techniques like Chain-of-Thought (CoT)
enhance reliability by eliciting intermediate reasoning steps or aggregating
multiple outputs. However, they lack mechanisms for enforcing logical structure
and assessing internal coherence. We introduce Theorem-of-Thought (ToTh), a
novel framework that models reasoning as collaboration among three parallel
agents, each simulating a distinct mode of inference: abductive, deductive, and
inductive. Each agent produces a reasoning trace, which is structured into a
formal reasoning graph. To evaluate consistency, we apply Bayesian belief
propagation guided by natural language inference (NLI), assigning confidence
scores to each step. The most coherent graph is selected to derive the final
answer. Experiments on symbolic (WebOfLies) and numerical (MultiArith)
reasoning benchmarks show that ToTh consistently outperforms CoT,
Self-Consistency, and CoT-Decoding across multiple LLMs, while producing
interpretable and logically grounded reasoning chains. Our findings suggest a
promising direction for building more robust and cognitively inspired LLM
reasoning. The implementation is available at
https://github.com/KurbanIntelligenceLab/theorem-of-thought.

</details>


### [69] [Prompting Science Report 2: The Decreasing Value of Chain of Thought in Prompting](https://arxiv.org/abs/2506.07142)
*Lennart Meincke,Ethan Mollick,Lilach Mollick,Dan Shapiro*

Main category: cs.CL

TL;DR: 研究显示CoT提示在不同模型和任务上效果不一：非推理模型小幅提升性能但增加变异性；自带推理的模型增益微乎其微，且显著增加成本。


<details>
  <summary>Details</summary>
Motivation: 厘清CoT提示的实际效果边界，帮助企业/教育/政策制定者理解AI技术细节。

Method: 通过严谨测试分析CoT在不同类型模型（推理型/非推理型）和任务上的表现差异。

Result: 1) 非推理模型：CoT小幅提升平均性能但增加答案波动性，且耗资源；2) 推理模型：精度增益微弱却显著增加时间与token消耗。

Conclusion: CoT并非通用优化方案，其效果取决于模型架构与任务属性，实际应用需权衡性能收益与资源成本。

Abstract: This is the second in a series of short reports that seek to help business,
education, and policy leaders understand the technical details of working with
AI through rigorous testing. In this report, we investigate Chain-of-Thought
(CoT) prompting, a technique that encourages a large language model (LLM) to
"think step by step" (Wei et al., 2022). CoT is a widely adopted method for
improving reasoning tasks, however, our findings reveal a more nuanced picture
of its effectiveness. We demonstrate two things:
  - The effectiveness of Chain-of-Thought prompting can vary greatly depending
on the type of task and model. For non-reasoning models, CoT generally improves
average performance by a small amount, particularly if the model does not
inherently engage in step-by-step processing by default. However, CoT can
introduce more variability in answers, sometimes triggering occasional errors
in questions the model would otherwise get right. We also found that many
recent models perform some form of CoT reasoning even if not asked; for these
models, a request to perform CoT had little impact. Performing CoT generally
requires far more tokens (increasing cost and time) than direct answers.
  - For models designed with explicit reasoning capabilities, CoT prompting
often results in only marginal, if any, gains in answer accuracy. However, it
significantly increases the time and tokens needed to generate a response.

</details>


### [70] [Semantic-preserved Augmentation with Confidence-weighted Fine-tuning for Aspect Category Sentiment Analysis](https://arxiv.org/abs/2506.07148)
*Yaping Chai,Haoran Xie,Joe S. Qin*

Main category: cs.CL

TL;DR: 我们提出了一种用于方面类别情感分析（ACSA）的数据增强策略，利用LLM生成多样性句子并通过后处理确保语义一致性。同时，采用置信度加权微调策略提升模型性能，在四个基准数据集上超过所有基线方法。


<details>
  <summary>Details</summary>
Motivation: 解决低资源场景下数据稀缺问题，现有手工设计提示方法效率较低。需在保持原句语义的前提下增强语言多样性，并优化模型对方面类别与情感极性关系的理解。

Method: 1. 设计结构化提示模板指导LLM生成预设内容 2. 采用后处理技术确保生成句与原句语义一致 3. 提出置信度加权微调策略增强预测置信度

Result: 在四种基准数据集上持续优于现有最强基线方法

Conclusion: 该方法通过可控数据生成和置信度优化，显著提升ACSA任务性能，为低资源场景提供有效解决方案。

Abstract: Large language model (LLM) is an effective approach to addressing data
scarcity in low-resource scenarios. Recent existing research designs
hand-crafted prompts to guide LLM for data augmentation. We introduce a data
augmentation strategy for the aspect category sentiment analysis (ACSA) task
that preserves the original sentence semantics and has linguistic diversity,
specifically by providing a structured prompt template for an LLM to generate
predefined content. In addition, we employ a post-processing technique to
further ensure semantic consistency between the generated sentence and the
original sentence. The augmented data increases the semantic coverage of the
training distribution, enabling the model better to understand the relationship
between aspect categories and sentiment polarities, enhancing its inference
capabilities. Furthermore, we propose a confidence-weighted fine-tuning
strategy to encourage the model to generate more confident and accurate
sentiment polarity predictions. Compared with powerful and recent works, our
method consistently achieves the best performance on four benchmark datasets
over all baselines.

</details>


### [71] [Syntactic Control of Language Models by Posterior Inference](https://arxiv.org/abs/2506.07154)
*Vicky Xefteri,Tim Vieira,Ryan Cotterell,Afra Amini*

Main category: cs.CL

TL;DR: 通过后验推断的采样算法控制语言模型生成的语法结构，提升准确率和流畅性


<details>
  <summary>Details</summary>
Motivation: 控制文本生成的语法结构对于需要清晰度、风格一致性和可解释性的应用很重要，但仍是挑战

Method: 结合序贯蒙特卡罗方法和语法标注器，确保每个生成标记符合目标语法结构

Result: GPT2-large和Llama3-8B的F1分数分别从12.35和35.33提升至93左右，保持流畅性

Conclusion: 该方法有效解决语法控制难题，为需要精确语法控制的应用提供新途径

Abstract: Controlling the syntactic structure of text generated by language models is
valuable for applications requiring clarity, stylistic consistency, or
interpretability, yet it remains a challenging task. In this paper, we argue
that sampling algorithms based on the posterior inference can effectively
enforce a target constituency structure during generation. Our approach
combines sequential Monte Carlo, which estimates the posterior distribution by
sampling from a proposal distribution, with a syntactic tagger that ensures
that each generated token aligns with the desired syntactic structure. Our
experiments with GPT2 and Llama3-8B models show that with an appropriate
proposal distribution, we can improve syntactic accuracy, increasing the F1
score from $12.31$ (GPT2-large) and $35.33$ (Llama3-8B) to about $93$ in both
cases without compromising the language model's fluency. These results
underscore both the complexity of syntactic control and the effectiveness of
sampling algorithms, offering a promising approach for applications where
precise control over syntax is essential.

</details>


### [72] [GeometryZero: Improving Geometry Solving for LLM with Group Contrastive Policy Optimization](https://arxiv.org/abs/2506.07160)
*Yikun Wang,Yibin Wang,Dianyi Wang,Zimian Peng,Qipeng Guo,Dacheng Tao,Jiaqi Wang*

Main category: cs.CL

TL;DR: 提出了GCPO强化学习框架和GeometryZero几何推理模型，在较小模型规模下通过条件奖励优化辅助构造，显著提升几何问题解答性能。


<details>
  <summary>Details</summary>
Motivation: 现有大型语言模型依赖过大计算资源，而GRPO等强化学习方法在几何领域无条件奖励导致辅助构造滥用，需要上下文感知的优化方案。

Method: 开发Group Contrastive Policy Optimization：1) 基于语境效用的正负奖励掩码 2) 长推理链奖励；构建GeometryZero模型族实现条件辅助构造。

Result: 在Geometry3K和MathVista基准测试平均提升4.29%，超越GRPO等基线方法。

Conclusion: GCPO机制有效解决无条件奖励的缺陷，验证了小型模型通过强化学习实现高效几何推理的可行性。

Abstract: Recent advances in large language models (LLMs) have demonstrated remarkable
capabilities across diverse domains, particularly in mathematical reasoning,
amid which geometry problem solving remains a challenging area where auxiliary
construction plays a enssential role. Existing approaches either achieve
suboptimal performance or rely on massive LLMs (e.g., GPT-4o), incurring
massive computational costs. We posit that reinforcement learning with
verifiable reward (e.g., GRPO) offers a promising direction for training
smaller models that effectively combine auxiliary construction with robust
geometric reasoning. However, directly applying GRPO to geometric reasoning
presents fundamental limitations due to its dependence on unconditional
rewards, which leads to indiscriminate and counterproductive auxiliary
constructions. To address these challenges, we propose Group Contrastive Policy
Optimization (GCPO), a novel reinforcement learning framework featuring two key
innovations: (1) Group Contrastive Masking, which adaptively provides positive
or negative reward signals for auxiliary construction based on contextual
utility, and a (2) length reward that promotes longer reasoning chains.
Building on GCPO, we develop GeometryZero, a family of affordable-size
geometric reasoning models that judiciously determine when to employ auxiliary
construction. Our extensive empirical evaluation across popular geometric
benchmarks (Geometry3K, MathVista) demonstrates that GeometryZero models
consistently outperform baselines (e.g. GRPO), achieving an average improvement
of 4.29% across all benchmarks.

</details>


### [73] [CTDGSI: A comprehensive exploitation of instance selection methods for automatic text classification. VII Concurso de Teses, Dissertações e Trabalhos de Graduação em SI -- XXI Simpósio Brasileiro de Sistemas de Informação](https://arxiv.org/abs/2506.07169)
*Washington Cunha,Leonardo Rocha,Marcos André Gonçalves*

Main category: cs.CL

TL;DR: 该博士论文提出了一种名为实例选择（Instance Selection）的技术，用于减少自然语言处理任务中的训练数据规模，从而降低计算资源需求和训练成本。


<details>
  <summary>Details</summary>
Motivation: 随着自然语言处理领域的发展，模型普遍遵循

Method: 该论文为自动文本分类任务设计和评估了多种实例选择方法，并研发了两种新型IS方案:专注于噪声过滤和冗余识别的方案，适用于大型数据集和Transformer架构。

Result: 提出的最终解决方案实现了平均41%的训练集缩减，同时保持效果不变；训练速度提升1.67倍(最高达2.46倍)，可扩展到数十万文档规模。

Conclusion: 实例选择技术在自然语言处理领域拥有巨大的应用潜力，能够有效降低训练资源消耗并保持模型质量，尤其适合大型数据集场景。

Abstract: Progress in Natural Language Processing (NLP) has been dictated by the rule
of more: more data, more computing power and more complexity, best exemplified
by the Large Language Models. However, training (or fine-tuning) large dense
models for specific applications usually requires significant amounts of
computing resources. This \textbf{Ph.D. dissertation} focuses on an
under-investi\-gated NLP data engineering technique, whose potential is
enormous in the current scenario known as Instance Selection (IS). The IS goal
is to reduce the training set size by removing noisy or redundant instances
while maintaining the effectiveness of the trained models and reducing the
training process cost. We provide a comprehensive and scientifically sound
comparison of IS methods applied to an essential NLP task -- Automatic Text
Classification (ATC), considering several classification solutions and many
datasets. Our findings reveal a significant untapped potential for IS
solutions. We also propose two novel IS solutions that are noise-oriented and
redundancy-aware, specifically designed for large datasets and transformer
architectures. Our final solution achieved an average reduction of 41\% in
training sets, while maintaining the same levels of effectiveness in all
datasets. Importantly, our solutions demonstrated speedup improvements of 1.67x
(up to 2.46x), making them scalable for datasets with hundreds of thousands of
documents.

</details>


### [74] [RULE: Reinforcement UnLEarning Achieves Forget-Retain Pareto Optimality](https://arxiv.org/abs/2506.07171)
*Chenlong Zhang,Zhuoran Jin,Hongbang Yuan,Jiaheng Wei,Tong Zhou,Kang Liu,Jun Zhao,Yubo Chen*

Main category: cs.CL

TL;DR: 提出了强化学习框架RULE用于LLM选择性遗忘，只需少量遗忘数据和合成边界数据就能有效移除特定信息且保持模型效果


<details>
  <summary>Details</summary>
Motivation: 现有LLM去学习方法需要大量数据集,且导致回答不自然/泛化性差/模型性能下降

Method: 将去学习建模为拒绝边界优化问题,使用可验证奖励函数训练模型安全拒绝遗忘类查询同时保持正常响应

Result: 仅用12%遗忘集和8%边界数据,比基线遗忘质量提升17.5%,自然度提升16.3%,保持通用性能并实现遗忘-保留帕累托最优

Conclusion: RULE框架有效实现定向去学习,提升回答自然度/训练效率/泛化能力,对语义相关未见查询也能泛化拒绝行为

Abstract: The widespread deployment of Large Language Models (LLMs) trained on massive,
uncurated corpora has raised growing concerns about the inclusion of sensitive,
copyrighted, or illegal content. This has led to increasing interest in LLM
unlearning: the task of selectively removing specific information from a model
without retraining from scratch or degrading overall utility. However, existing
methods often rely on large-scale forget and retain datasets, and suffer from
unnatural responses, poor generalization, or catastrophic utility loss. In this
work, we propose Reinforcement UnLearning (RULE), an efficient framework that
formulates unlearning as a refusal boundary optimization problem. RULE is
trained with a small portion of the forget set and synthesized boundary
queries, using a verifiable reward function that encourages safe refusal on
forget--related queries while preserving helpful responses on permissible
inputs. We provide both theoretical and empirical evidence demonstrating the
effectiveness of RULE in achieving targeted unlearning without compromising
model utility. Experimental results show that, with only $12%$ forget set and
$8%$ synthesized boundary data, RULE outperforms existing baselines by up to
$17.5%$ forget quality and $16.3%$ naturalness response while maintaining
general utility, achieving forget--retain Pareto optimality. Remarkably, we
further observe that RULE improves the naturalness of model outputs, enhances
training efficiency, and exhibits strong generalization ability, generalizing
refusal behavior to semantically related but unseen queries.

</details>


### [75] [Flattery in Motion: Benchmarking and Analyzing Sycophancy in Video-LLMs](https://arxiv.org/abs/2506.07180)
*Wenrui Zhou,Shu Yang,Qingsong Yang,Zikun Guo,Lijie Hu,Di Wang*

Main category: cs.CL

TL;DR: 本篇论文提出了VISE基准，这是首个专门评估视频大语言模型（Video-LLMs）在用户误导输入下奉承行为的工具，填补了该领域系统性评估的空白。通过引入语言学视角和多类型分析，并探索了基于关键帧选择的缓解策略。


<details>
  <summary>Details</summary>
Motivation: 视频大语言模型在现实应用中需要可靠的多模态推理能力，但其奉承行为（盲从用户错误主张）会损害可信度。现有研究未针对性解决视频语言领域的这一问题。

Method: 构建VISE基准，涵盖多样化问题形式、提示偏见及视觉任务；创新地将语言学奉承类型引入视觉领域，实现细粒度分析；探索关键帧选择作为无需训练的缓解方法。

Result: 创建首个视频领域奉承行为专用评测集；证实关键帧选择能强化视觉基础，可能成为降低模型奉承偏见的可行路径；揭示不同模型在多种奉承场景下的表现特性。

Conclusion: VISE填补了视频大语言模型奉承行为评估的空白，为未来可信视频推理系统提供诊断工具；关键帧选择展现无训练缓解潜力，呼吁社区关注多模态语境下的模型可靠性问题。

Abstract: As video large language models (Video-LLMs) become increasingly integrated
into real-world applications that demand grounded multimodal reasoning,
ensuring their factual consistency and reliability is of critical importance.
However, sycophancy, the tendency of these models to align with user input even
when it contradicts the visual evidence, undermines their trustworthiness in
such contexts. Current sycophancy research has largely overlooked its specific
manifestations in the video-language domain, resulting in a notable absence of
systematic benchmarks and targeted evaluations to understand how Video-LLMs
respond under misleading user input. To fill this gap, we propose VISE
(Video-LLM Sycophancy Benchmarking and Evaluation), the first dedicated
benchmark designed to evaluate sycophantic behavior in state-of-the-art
Video-LLMs across diverse question formats, prompt biases, and visual reasoning
tasks. Specifically, VISE pioneeringly brings linguistic perspectives on
sycophancy into the visual domain, enabling fine-grained analysis across
multiple sycophancy types and interaction patterns. In addition, we explore
key-frame selection as an interpretable, training-free mitigation strategy,
which reveals potential paths for reducing sycophantic bias by strengthening
visual grounding.

</details>


### [76] [SDE-SQL: Enhancing Text-to-SQL Generation in Large Language Models via Self-Driven Exploration with SQL Probes](https://arxiv.org/abs/2506.07245)
*Wenxuan Xie,Yaxun Dai,Wenhao Jiang*

Main category: cs.CL

TL;DR: 论文提出了SDE-SQL框架，允许大语言模型在推理过程中自驱动地探索数据库，通过生成和执行SQL探针来动态更新对数据的理解。该方法在BIRD基准测试中取得显著提升，零设置下相对基线改进8.02%，经监督微调后可进一步提升0.52%。


<details>
  <summary>Details</summary>
Motivation: 现有Text-to-SQL方法依赖静态数据库信息，限制了模型动态理解数据的能力。需要使大语言模型能够自主探索数据库内容，以突破固定上下文带来的限制。

Method: 提出SDE-SQL框架：让大语言模型自主生成和执行SQL探针，通过主动检索数据库信息迭代更新对数据的认知。该方法在零样本设置下运行，无需上下文示例。

Result: 在BIRD基准测试中使用Qwen2.5-72B-Instruct模型：零样本设置下执行准确率相对提高8.02%，创下开源模型（无监督微调或集成）的新SOTA；监督微调后性能可再提高0.52%。

Conclusion: 动态数据库探索显著提升Text-to-SQL性能，SDE-SQL通过自驱动查询有效解决静态上下文局限问题，零样本/监督微调设置均优于现有方案，证明主动数据访问对增强模型数据库理解能力至关重要。

Abstract: Recent advancements in large language models (LLMs) have significantly
improved performance on the Text-to-SQL task. However, prior approaches
typically rely on static, pre-processed database information provided at
inference time, which limits the model's ability to fully understand the
database contents. Without dynamic interaction, LLMs are constrained to fixed,
human-provided context and cannot autonomously explore the underlying data. To
address this limitation, we propose SDE-SQL, a framework that enables large
language models to perform self-driven exploration of databases during
inference. This is accomplished by generating and executing SQL probes, which
allow the model to actively retrieve information from the database and
iteratively update its understanding of the data. Unlike prior methods, SDE-SQL
operates in a zero-shot setting, without relying on any question-SQL pairs as
in-context demonstrations. When evaluated on the BIRD benchmark with
Qwen2.5-72B-Instruct, SDE-SQL achieves an 8.02% relative improvement in
execution accuracy over the vanilla Qwen2.5-72B-Instruct baseline, establishing
a new state-of-the-art among methods based on open-source models without
supervised fine-tuning (SFT) or model ensembling. Moreover, with SFT, the
performance of SDE-SQL can be further enhanced, yielding an additional 0.52%
improvement.

</details>


### [77] [Improving the Efficiency of Long Document Classification using Sentence Ranking Approach](https://arxiv.org/abs/2506.07248)
*Prathamesh Kokate,Mitali Sarnaik,Manavi Khopade,Raviraj Joshi*

Main category: cs.CL

TL;DR: 提出了基于TF-IDF的句子排序方法，通过选择信息量最大的句子来提高长文档分类效率，在MahaNews数据集上实现了几乎相同的准确率，同时减少50%输入大小和43%延迟。


<details>
  <summary>Details</summary>
Motivation: 解决长文档分类中因Transformer模型固定输入长度和二次注意力复杂度的计算限制，以及文档冗余问题，仅小部分句子提供分类所需信息。

Method: 使用归一化TF-IDF分数结合句子长度的增强评分策略，探索固定数量与百分比句子选择，选出信息量最大的句子替代完整文档作为分类输入。

Result: 在Maraathi新闻数据集上超越基线方法（首尾/随机句选择），仅分类准确率下降0.33%，输入尺寸减少超50%，推理延迟降低43%。

Conclusion: 证明无需牺牲性能即可大幅缩减上下文，使方法对现实世界长文档分类任务具有实用价值。

Abstract: Long document classification poses challenges due to the computational
limitations of transformer-based models, particularly BERT, which are
constrained by fixed input lengths and quadratic attention complexity.
Moreover, using the full document for classification is often redundant, as
only a subset of sentences typically carries the necessary information. To
address this, we propose a TF-IDF-based sentence ranking method that improves
efficiency by selecting the most informative content. Our approach explores
fixed-count and percentage-based sentence selection, along with an enhanced
scoring strategy combining normalized TF-IDF scores and sentence length.
Evaluated on the MahaNews LDC dataset of long Marathi news articles, the method
consistently outperforms baselines such as first, last, and random sentence
selection. With MahaBERT-v2, we achieve near-identical classification accuracy
with just a 0.33 percent drop compared to the full-context baseline, while
reducing input size by over 50 percent and inference latency by 43 percent.
This demonstrates that significant context reduction is possible without
sacrificing performance, making the method practical for real-world long
document classification tasks.

</details>


### [78] [Bias Attribution in Filipino Language Models: Extending a Bias Interpretability Metric for Application on Agglutinative Languages](https://arxiv.org/abs/2506.07249)
*Lance Calvin Lim Gamboa,Yue Feng,Mark Lee*

Main category: cs.CL

TL;DR: 将基于信息论的偏见归因分数方法应用于粘着语（特别是菲律宾语），在单语和多语言模型上测试，发现菲律宾语模型中的偏见主要由人物、物体和关系主题驱动，与英语模型的行动主题（犯罪、性行为等）不同。


<details>
  <summary>Details</summary>
Motivation: 现有研究主要针对英语文本分析语言模型中的偏见贡献token，但针对粘着语（如菲律宾语）的偏见归因研究尚未充分探索。

Method: 将信息论偏见归因评分指标适配到处理粘着语言（菲律宾语）的模型上，并在一个纯菲律宾语模型和三个多语言模型（全球训练、两个东南亚专用）上进行测试。

Result: 发现菲律宾语模型的偏见驱动因素是与人物、对象、关系相关的实体主题，而英语模型则主要由犯罪、性、亲社会等行为主题驱动。这表明不同语言模型处理社会人口群体相关输入时存在根本差异。

Conclusion: 英语与非英语语言模型在偏见的表达方式和驱动因素上存在显著差异，这要求跨语言NLP研究需开发针对特定语言特性的偏见检测框架。

Abstract: Emerging research on bias attribution and interpretability have revealed how
tokens contribute to biased behavior in language models processing English
texts. We build on this line of inquiry by adapting the information-theoretic
bias attribution score metric for implementation on models handling
agglutinative languages, particularly Filipino. We then demonstrate the
effectiveness of our adapted method by using it on a purely Filipino model and
on three multilingual models: one trained on languages worldwide and two on
Southeast Asian data. Our results show that Filipino models are driven towards
bias by words pertaining to people, objects, and relationships, entity-based
themes that stand in contrast to the action-heavy nature of bias-contributing
themes in English (i.e., criminal, sexual, and prosocial behaviors). These
findings point to differences in how English and non-English models process
inputs linked to sociodemographic groups and bias.

</details>


### [79] [Question Answering under Temporal Conflict: Evaluating and Organizing Evolving Knowledge with LLMs](https://arxiv.org/abs/2506.07270)
*Atahan Özer,Çağatay Yıldız*

Main category: cs.CL

TL;DR: LLMs struggle with evolving knowledge. Two new benchmarks (Temporal Wiki and Unified Clark) test this. Proposed lightweight agentic framework for structured external memory improves performance over baselines.


<details>
  <summary>Details</summary>
Motivation: LLMs have static knowledge bases that fail to handle continuously updating real-world information. Retraining is costly and in-context learning scales poorly with volatile data.

Method: A lightweight agentic framework that incrementally builds structured external memory from source documents, enabling temporally filtered retrieval at inference.

Result: The method outperforms in-context learning (ICL) and retrieval-augmented generation (RAG) baselines on both benchmarks, particularly for complex reasoning or conflicting facts.

Conclusion: Structured external memory effectively addresses LLMs' limitations in handling evolving knowledge without retraining, showing significant gains in temporal reasoning tasks.

Abstract: Large language models (LLMs) exhibit remarkable capabilities in question
answering and reasoning thanks to their extensive parametric memory. However,
their knowledge is inherently limited by the scope of their pre-training data,
while real-world information evolves continuously. Updating this knowledge
typically requires costly and brittle re-training, or in-context learning
(ICL), which becomes impractical at scale given the volume and volatility of
modern information. Motivated by these limitations, we investigate how LLMs
perform when exposed to temporal text corpora, or documents that reflect
evolving knowledge over time, such as sports biographies where facts like a
player's "current team" change year by year. To this end, we introduce two new
benchmarks: Temporal Wiki, which captures factual drift across historical
Wikipedia snapshots, and Unified Clark, which aggregates timestamped news
articles to simulate real-world information accumulation. Our analysis reveals
that LLMs often struggle to reconcile conflicting or outdated facts and can be
misled when multiple versions of a fact appear in context. To address these
issues, we propose a lightweight, agentic framework that incrementally builds a
structured, external memory from source documents without requiring
re-training. This knowledge organization strategy enables models to retrieve
and reason over temporally filtered, relevant information at inference time.
Empirically, our method outperforms ICL and RAG baselines across both
benchmarks, especially on questions requiring more complex reasoning or
integration of conflicting facts.

</details>


### [80] [Parsing the Switch: LLM-Based UD Annotation for Complex Code-Switched and Low-Resource Languages](https://arxiv.org/abs/2506.07274)
*Olga Kellert,Nemika Tyagi,Muhammad Imran,Nelvin Licona-Guevara,Carlos Gómez-Rodríguez*

Main category: cs.CL

TL;DR: 论文介绍了BiLingua Parser，一种基于大语言模型（LLM）的注释流程，为语码转换文本生成通用依存关系（UD）标注。该方法包括提示框架、专家评审和发布两个新的标注数据集。实验结果显示，在专家评审后，其标记准确率达到95.29%，显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 语码转换环境下的句法分析存在难度，尤其在低资源语言场景中缺乏标注数据。现有基于单语树库训练的解析器难以处理多语及混合语言输入。本研究旨在解决这一空白。

Method: 1. 开发基于提示的框架（支持西班牙语-英语和西班牙语-瓜拉尼语），结合少量示例的LLM提示和专家评审；2. 发布两个标注数据集（含首个西班牙语-瓜拉尼语UD语料库）；3. 对跨语言转换点进行详细句法分析。

Result: BiLingua Parser经专家修订后达到95.29%的LAS（标记准确率），显著超越现有基线模型和多语种解析器。证明在适当引导下，LLM可有效用于低资源语码转换环境的句法资源构建。

Conclusion: 精心设计的LLM提示框架配合专家评审，能高效生成高质量语码转换数据标注，为低资源混合语言场景提供实用语法分析工具。代码和数据已在GitHub开源。

Abstract: Code-switching presents a complex challenge for syntactic analysis,
especially in low-resource language settings where annotated data is scarce.
While recent work has explored the use of large language models (LLMs) for
sequence-level tagging, few approaches systematically investigate how well
these models capture syntactic structure in code-switched contexts. Moreover,
existing parsers trained on monolingual treebanks often fail to generalize to
multilingual and mixed-language input. To address this gap, we introduce the
BiLingua Parser, an LLM-based annotation pipeline designed to produce Universal
Dependencies (UD) annotations for code-switched text. First, we develop a
prompt-based framework for Spanish-English and Spanish-Guaran\'i data,
combining few-shot LLM prompting with expert review. Second, we release two
annotated datasets, including the first Spanish-Guaran\'i UD-parsed corpus.
Third, we conduct a detailed syntactic analysis of switch points across
language pairs and communicative contexts. Experimental results show that
BiLingua Parser achieves up to 95.29% LAS after expert revision, significantly
outperforming prior baselines and multilingual parsers. These results show that
LLMs, when carefully guided, can serve as practical tools for bootstrapping
syntactic resources in under-resourced, code-switched environments. Data and
source code are available at https://github.com/N3mika/ParsingProject

</details>


### [81] [Exploring the Impact of Temperature on Large Language Models:Hot or Cold?](https://arxiv.org/abs/2506.07295)
*Lujun Li,Lama Sleem,Niccolo' Gentile,Geoffrey Nichil,Radu State*

Main category: cs.CL

TL;DR: 该研究系统评估了采样温度（0-2范围）对不同规模开源源语言模型六种能力的影响，发现温度对模型性能有技能特异性影响，提出了基于BERT的温度选择器提升模型表现，并验证了温度效应在量化和FP16精度下的一致性。


<details>
  <summary>Details</summary>
Motivation: 针对温度对LLM性能影响的复杂性，研究旨在揭示温度对不同模型规模、不同能力的差异化影响，并为实际应用提供最优温度选择方案。

Method: 在0-2温度范围内测试三个规模的开源模型在小、中、大规模的六种能力数据集上的性能，通过统计方法分析；此外提出基于BERT的分类器预测最优温度，并在SuperGLUE验证；还测试了FP16及最高4.0温度下的量化模型表现。

Result: 温度影响具有技能特异性；温度选择器显著提升中小模型在SuperGLUE的性能；4-bit量化和FP16模型温度效应一致；突变温度点随模型规模增大而升高。

Conclusion: 温度调控对LLM性能影响复杂且与模型规模/任务类型相关，提出的温度选择器为优化推理提供实用方案，量化模型的温度效应规律为部署提供参考。

Abstract: The sampling temperature, a critical hyperparameter in large language models
(LLMs), modifies the logits before the softmax layer, thereby reshaping the
distribution of output tokens. Recent studies have challenged the Stochastic
Parrots analogy by demonstrating that LLMs are capable of understanding
semantics rather than merely memorizing data and that randomness, modulated by
sampling temperature, plays a crucial role in model inference. In this study,
we systematically evaluated the impact of temperature in the range of 0 to 2 on
data sets designed to assess six different capabilities, conducting statistical
analyses on open source models of three different sizes: small (1B--4B), medium
(6B--13B), and large (40B--80B). Our findings reveal distinct skill-specific
effects of temperature on model performance, highlighting the complexity of
optimal temperature selection in practical applications. To address this
challenge, we propose a BERT-based temperature selector that takes advantage of
these observed effects to identify the optimal temperature for a given prompt.
We demonstrate that this approach can significantly improve the performance of
small and medium models in the SuperGLUE datasets. Furthermore, our study
extends to FP16 precision inference, revealing that temperature effects are
consistent with those observed in 4-bit quantized models. By evaluating
temperature effects up to 4.0 in three quantized models, we find that the
Mutation Temperature -- the point at which significant performance changes
occur -- increases with model size.

</details>


### [82] [Subjectivity in the Annotation of Bridging Anaphora](https://arxiv.org/abs/2506.07297)
*Lauren Levine,Amir Zeldes*

Main category: cs.CL

TL;DR: 该研究探讨了桥接指代标注中的主观性问题，通过在新标注试验中使用改进的分类系统，发现以往资源可能存在严重标注不足，且标注者间一致性较低。


<details>
  <summary>Details</summary>
Motivation: 桥接指代标注涉及实体间关联关系判定，存在固有主观性，导致标注一致性低。本文旨在探究标注过程中三个层面的主观性表现：指代识别、先行词解析和桥接子类型选择。

Method: 在GUM语料库测试集上进行标注试验，提出新型桥接子类型分类系统，并与已有方案比较；通过标注者间一致性评估主观性程度。

Result: 1) 发现既有资源可能存在严重标注不足 2) 桥接子类型标注一致性中等，但桥接实例的穷尽性识别标注者重叠率低 3) 多数分歧源于对实体的主观理解差异。

Conclusion: 桥接标注的主观性对语料构建与模型训练提出挑战，需开发更明确的标注指南。新分类系统的对比研究为未来标注框架优化提供依据。

Abstract: Bridging refers to the associative relationship between inferable entities in
a discourse and the antecedents which allow us to understand them, such as
understanding what "the door" means with respect to an aforementioned "house".
As identifying associative relations between entities is an inherently
subjective task, it is difficult to achieve consistent agreement in the
annotation of bridging anaphora and their antecedents. In this paper, we
explore the subjectivity involved in the annotation of bridging instances at
three levels: anaphor recognition, antecedent resolution, and bridging subtype
selection. To do this, we conduct an annotation pilot on the test set of the
existing GUM corpus, and propose a newly developed classification system for
bridging subtypes, which we compare to previously proposed schemes. Our results
suggest that some previous resources are likely to be severely under-annotated.
We also find that while agreement on the bridging subtype category was
moderate, annotator overlap for exhaustively identifying instances of bridging
is low, and that many disagreements resulted from subjective understanding of
the entities involved.

</details>


### [83] [ConfQA: Answer Only If You Are Confident](https://arxiv.org/abs/2506.07309)
*Yin Huang,Yifan Ethan Xu,Kai Sun,Vera Yan,Alicia Sun,Haidar Khan,Jimmy Nguyen,Mohammad Kachuee,Zhaojiang Lin,Yue Liu,Aaron Colak,Anuj Kumar,Wen-tau Yih,Xin Luna Dong*

Main category: cs.CL

TL;DR: ConfQA 是一種微調策略，透過訓練 LLMs 在回答正確時繼續輸出答案，在不確定時回答「我不確定」，結合「僅在自信回答時作答」的提示與知識圖譜屬性值校準信心機制，在保持低外部檢索下提升事實回答準確性。


<details>
  <summary>Details</summary>
Motivation: 解決大型語言模型在生成事實陳述時出現幻覺（hallucination）的問題，即模型產生不實資訊的現象。透過降低幻覺率提升模型回答的真實性。

Method: 1. 提出ConfQA策略：正確回答時訓練模型繼續生成答案，錯誤時訓練承認不確定。2. 引入特定提示語引導行為。3. 透過知識圖譜中的屬性值校準模型信心。4. 擴展為雙重神經知識框架，根據ConfQA信心自動切換參數化知識與符號知識來源。

Result: 1. 在多個事實基準測試中將20-40%的幻覺率降至5%以下。2. 加入提示語後幻覺率從15-25%進一步改善。3. 雙框架實現95%以上準確率，同時減少30%不必要的外部檢索。

Conclusion: ConfQA的關鍵在於特定提示語和信心校準機制的設計，透過雙重知識框架動態選擇知識源，不僅降低幻覺率，同時優化外部知識檢索效率，達成高精準回答。

Abstract: Can we teach Large Language Models (LLMs) to refrain from hallucinating
factual statements? In this paper we present a fine-tuning strategy that we
call ConfQA, which can reduce hallucination rate from 20-40% to under 5% across
multiple factuality benchmarks. The core idea is simple: when the LLM answers a
question correctly, it is trained to continue with the answer; otherwise, it is
trained to admit "I am unsure". But there are two key factors that make the
training highly effective. First, we introduce a dampening prompt "answer only
if you are confident" to explicitly guide the behavior, without which
hallucination remains high as 15%-25%. Second, we leverage simple factual
statements, specifically attribute values from knowledge graphs, to help LLMs
calibrate the confidence, resulting in robust generalization across domains and
question types. Building on this insight, we propose the Dual Neural Knowledge
framework, which seamlessly select between internally parameterized neural
knowledge and externally recorded symbolic knowledge based on ConfQA's
confidence. The framework enables potential accuracy gains to beyond 95%, while
reducing unnecessary external retrievals by over 30%.

</details>


### [84] [Reward Model Interpretability via Optimal and Pessimal Tokens](https://arxiv.org/abs/2506.07326)
*Brian Christian,Hannah Rose Kirk,Jessica A. F. Thompson,Christopher Summerfield,Tsvetomira Dumbalska*

Main category: cs.CL

TL;DR: 本文通过分析奖励模型对完整词汇空间中单token响应的评分，揭示了模型之间的异质性、高低分token编码的不对称性、对提示框架的敏感性以及高频token的过度评价。研究发现奖励模型编码了针对特定身份群体的偏见，可能通过下游大语言模型传播风险。


<details>
  <summary>Details</summary>
Motivation: 尽管奖励模型在将大语言模型与人类价值观对齐中扮演关键角色，但其自身机制相对缺乏研究。本文旨在提升奖励模型的可解释性，研究其如何编码人类价值判断。

Method: 对十个不同规模和架构的开源奖励模型进行全词汇空间分析，即量化每个可能单token响应在价值导向提示下的评分模式。

Result: 发现四种核心现象：(1) 同目标模型间存在显著异质性；(2) 高低分token编码存在系统性不对称；(3) 提示框架敏感性反映人类认知偏见；(4) 高频token被系统性高估。同时揭示无害训练可能引发针对特定身份群体的偏见。

Conclusion: 挑战了奖励模型可互换性假设，警示其作为复杂人类价值观代理的局限性。指出模型偏见可能通过下游LLM大规模传播，呼吁加强模型透明度研究和偏见干预。

Abstract: Reward modeling has emerged as a crucial component in aligning large language
models with human values. Significant attention has focused on using reward
models as a means for fine-tuning generative models. However, the reward models
themselves -- which directly encode human value judgments by turning
prompt-response pairs into scalar rewards -- remain relatively understudied. We
present a novel approach to reward model interpretability through exhaustive
analysis of their responses across their entire vocabulary space. By examining
how different reward models score every possible single-token response to
value-laden prompts, we uncover several striking findings: (i) substantial
heterogeneity between models trained on similar objectives, (ii) systematic
asymmetries in how models encode high- vs low-scoring tokens, (iii) significant
sensitivity to prompt framing that mirrors human cognitive biases, and (iv)
overvaluation of more frequent tokens. We demonstrate these effects across ten
recent open-source reward models of varying parameter counts and architectures.
Our results challenge assumptions about the interchangeability of reward
models, as well as their suitability as proxies of complex and
context-dependent human values. We find that these models can encode concerning
biases toward certain identity groups, which may emerge as unintended
consequences of harmlessness training -- distortions that risk propagating
through the downstream large language models now deployed to millions.

</details>


### [85] [Improving LLM Reasoning through Interpretable Role-Playing Steering](https://arxiv.org/abs/2506.07335)
*Anyi Wang,Dong Shu,Yifan Wang,Yunpu Ma,Mengnan Du*

Main category: cs.CL

TL;DR: 该论文提出了一种名为SRPS的新框架，通过操纵内部模型特征来稳定、可控地增强大语言模型在角色扮演中的推理能力。


<details>
  <summary>Details</summary>
Motivation: 现有依赖提示工程的角色扮演方法缺乏稳定性和可解释性，需要直接干预内部特征来增强模型推理能力。

Method: SRPS框架：1) 提取角色文本的潜在表征 2) 根据激活模式筛选关键特征 3) 构建可调节强度的转向向量注入残差流

Result: Llama3.1-8B在CSQA准确率从31.86%提升至39.80%；Gemma2-9B在SVAMP从37.50%提升至45.10%，多基准测试展示持续改进

Conclusion: SRPS比传统提示方法更具稳定性和可解释性，为模型角色特征控制提供了新途径，显著增强零样本推理能力。

Abstract: Role-playing has emerged as an effective technique for enhancing the
reasoning capabilities of large language models (LLMs). However, existing
methods primarily rely on prompt engineering, which often lacks stability and
interpretability. In this paper, we introduce Sparse Autoencoder Role-Playing
Steering (SRPS), a novel framework that identifies and manipulates internal
model features associated with role-playing behavior. Our approach extracts
latent representations from role-play prompts, selects the most relevant
features based on activation patterns, and constructs a steering vector that
can be injected into the model's residual stream with controllable intensity.
Our method enables fine-grained control over role-specific behavior and offers
insights into how role information influences internal model activations.
Extensive experiments across various reasoning benchmarks and model sizes
demonstrate consistent performance gains. Notably, in the zero-shot
chain-of-thought (CoT) setting, the accuracy of Llama3.1-8B on CSQA improves
from 31.86% to 39.80%, while Gemma2-9B on SVAMP increases from 37.50% to
45.10%. These results highlight the potential of SRPS to enhance reasoning
ability in LLMs, providing better interpretability and stability compared to
traditional prompt-based role-playing.

</details>


### [86] [Refusal-Feature-guided Teacher for Safe Finetuning via Data Filtering and Alignment Distillation](https://arxiv.org/abs/2506.07356)
*Seokil Ham,Yubin Choi,Seungju Cho,Yujin Yang,Younghun Kim,Changick Kim*

Main category: cs.CL

TL;DR: 该论文提出Refusal-Feature-guided Teacher (ReFT)方法，通过在微调过程中过滤有害提示并注入对齐知识，解决Finetuning-as-a-Service中LLM安全对齐退化问题。


<details>
  <summary>Details</summary>
Motivation: 现有Finetuning-as-a-Service在用户数据包含有害提示时会导致LLM安全对齐退化，而现有方法未能从根本上过滤有害数据。作者观察到安全对齐LLM的'拒绝特征'能区分有害/无害提示，由此提出新方法。

Method: 训练ReFT模型（基于提示特征与拒绝特征的相似性识别有害提示），在微调时作为教师模型：1) 过滤用户数据中的有害提示；2) 将对齐知识蒸馏到基础模型中。

Result: 实验证明ReFT微调策略能有效减少有害输出，同时提升用户特定任务的微调准确性，为安全可靠部署提供解决方案。

Conclusion: ReFT通过拒绝特征指导的过滤和知识蒸馏，解决了FaaS中的安全对齐退化问题，实现了安全性与任务性能的平衡。

Abstract: Recently, major AI service providers such as Google and OpenAI have
introduced Finetuning-as-a-Service, which enables users to customize Large
Language Models (LLMs) for specific downstream tasks using their own data.
However, this service is vulnerable to degradation of LLM safety-alignment when
user data contains harmful prompts. While some prior works address this issue,
fundamentally filtering harmful data from user data remains unexplored.
Motivated by our observation that a directional representation reflecting
refusal behavior (called the refusal feature) obtained from safety-aligned LLMs
can inherently distinguish between harmful and harmless prompts, we propose the
Refusal-Feature-guided Teacher (ReFT). Our ReFT model is trained to identify
harmful prompts based on the similarity between input prompt features and its
refusal feature. During finetuning, the ReFT model serves as a teacher that
filters harmful prompts from user data and distills alignment knowledge into
the base model. Extensive experiments demonstrate that our ReFT-based
finetuning strategy effectively minimizes harmful outputs and enhances
finetuning accuracy for user-specific tasks, offering a practical solution for
secure and reliable deployment of LLMs in Finetuning-as-a-Service.

</details>


### [87] [SEED: Enhancing Text-to-SQL Performance and Practical Usability Through Automatic Evidence Generation](https://arxiv.org/abs/2506.07423)
*Janghyeon Yun,Sang-goo Lee*

Main category: cs.CL

TL;DR: 


<details>
  <summary>Details</summary>
Motivation: 

Method: 

Result: 

Conclusion: 

Abstract: Text-to-SQL enables non-experts to retrieve data from databases by converting
natural language queries into SQL. However, state-of-the-art text-to-SQL
studies rely on the BIRD dataset, which assumes that evidence is provided along
with questions. Although BIRD facilitates research advancements, it assumes
that users have expertise and domain knowledge, contradicting the fundamental
goal of text-to-SQL. In addition, human-generated evidence in BIRD contains
defects, including missing or erroneous evidence, which affects model
performance. To address this issue, we propose SEED (System for Evidence
Extraction and Domain knowledge generation), an approach that automatically
generates evidence to improve performance and practical usability in real-world
scenarios. SEED systematically analyzes database schema, description files, and
values to extract relevant information. We evaluated SEED on BIRD and Spider,
demonstrating that it significantly improves SQL generation accuracy in the
no-evidence scenario, and in some cases, even outperforms the setting where
BIRD evidence is provided. Our results highlight that SEED-generated evidence
not only bridges the gap between research and real-world deployment but also
improves the adaptability and robustness of text-to-SQL models. Our code is
available at https://github.com/felix01189/SEED

</details>


### [88] [Plug-in and Fine-tuning: Bridging the Gap between Small Language Models and Large Language Models](https://arxiv.org/abs/2506.07424)
*Kyeonghyun Kim,Jinhee Jang,Juhwan Choi,Yoonji Lee,Kyohoon Jin,YoungBin Kim*

Main category: cs.CL

TL;DR: PiFi是一个结合大型语言模型（LLMs）和小型语言模型（SLMs）的框架，通过引入LLM的一个冻结层来增强SLMs的性能，同时保持计算效率。


<details>
  <summary>Details</summary>
Motivation: LLMs在计算资源有限的环境中部署困难，而SLMs虽计算高效但泛化能力不足。PiFi旨在结合二者的优势，提升性能而不显著增加成本。

Method: PiFi框架：1）从LLM中提取一个冻结层；2）整合到SLM中；3）对结合后的模型进行特定任务微调。

Result: PiFi在多类NLP任务（理解和生成）上均表现出性能提升，能有效利用LLMs知识，增强对未见领域的泛化能力和语言能力迁移。

Conclusion: PiFi在保持计算效率的同时，通过引入LLMs的知识显著提升SLMs性能，为资源受限环境提供了实用解决方案。

Abstract: Large language models (LLMs) are renowned for their extensive linguistic
knowledge and strong generalization capabilities, but their high computational
demands make them unsuitable for resource-constrained environments. In
contrast, small language models (SLMs) are computationally efficient but often
lack the broad generalization capacity of LLMs. To bridge this gap, we propose
PiFi, a novel framework that combines the strengths of both LLMs and SLMs to
achieve high performance while maintaining efficiency. PiFi integrates a single
frozen layer from an LLM into a SLM and fine-tunes the combined model for
specific tasks, boosting performance without a significant increase in
computational cost. We show that PiFi delivers consistent performance
improvements across a range of natural language processing tasks, including
both natural language understanding and generation. Moreover, our findings
demonstrate PiFi's ability to effectively leverage LLM knowledge, enhancing
generalization to unseen domains and facilitating the transfer of linguistic
abilities.

</details>


### [89] [Conjoined Predication and Scalar Implicature](https://arxiv.org/abs/2506.07429)
*Ratna Kandala*

Main category: cs.CL

TL;DR: 该论文分析了Magri(2016)提出的第一个未解难题，即特定连词句的不恰当性问题，认为这种不恰当性源于连词谓语的集体/并发解读造成的间接语境矛盾，并指出标量含义的语用机制超出语法化解释范围。


<details>
  <summary>Details</summary>
Motivation: 解决Magri(2016)遗留的第一个难题：特定形式的连词句（如'只有一些意大利人来自温暖国家并且是金发'）为何在缺乏明显冲突标量含义的情况下仍显得不恰当，揭示量化、集体解读与语境更新的隐藏互动关系。

Method: 将问题置于原有理论框架内进行概念分析，论证连词谓语的集体/并发解读导致间接语境矛盾，同时探讨标量含义生成的语用机制超越语法化理论解释范围。

Result: 揭示了特定连词句不恰当性的成因——集体解读引发的语境矛盾，并证明了标量含义的语用机制比语法化模型描述的更复杂。

Conclusion: 该研究不仅解决了Magri遗留的语义学难题，还拓展了对话用机制与语法接口的理解，表明标量含义生成涉及更丰富的语用过程。

Abstract: Magri (2016) investigates two puzzles arising from conjunction. Although
Magri has proposed a solution to the second puzzle, the first remains
unresolved. This first puzzle reveals a hidden interaction among
quantification, collective/concurrent interpretation, and contextual updating
dimensions that have yet to be explored. In essence, the problem is that
certain forms of sentences like "Some Italians come from a warm country," when
conjoined as in "(Only) Some Italians come from a warm country and are blond,"
sound infelicitous, even though no obvious alternative triggers a conflicting
scalar implicature. In this paper, we offer a conceptual analysis of Magri's
first puzzle by situating it within its original theoretical framework. We
argue that the oddness arises from the collective or concurrent reading of the
conjunctive predicate: in examples such as "(Only) Some Italians come from a
warm country and are blond," this interpretation generates an indirect
contextual contradiction. Moreover, we suggest that the pragmatic mechanisms
governing scalar implicature generation extend beyond what is captured by
exhaustification-based grammatical licensing accounts.

</details>


### [90] [Well Begun is Half Done: Low-resource Preference Alignment by Weak-to-Strong Decoding](https://arxiv.org/abs/2506.07434)
*Feifan Song,Shaohang Wei,Wen Luo,Yuxuan Fan,Tianyu Liu,Guoyin Wang,Houfeng Wang*

Main category: cs.CL

TL;DR: 论文提出了Weak-to-Strong Decoding (WSD)框架，利用小型对齐模型指导基础模型生成对齐内容，通过在解码初期使用小模型生成对齐的开头、大模型继续后续内容，结合自动切换机制缓解对齐任务中的降级问题。


<details>
  <summary>Details</summary>
Motivation: 现有低资源LLM对齐方法难以同时保证生成内容的质量和对齐性，作者观察到对齐困难主要集中于解码初期，因此提出利用小型对齐模型引导大模型解码的策略。

Method: 1. 设计Weak-to-Strong Decoding框架：小模型（Pilot-3B）首先生成对齐的开头段落，大模型接着续写剩余内容 2. 开发自动切换机制控制模型转换 3. 收集GenerAlign数据集微调小模型

Result: WSD框架显著提升不同基础模型的对齐能力，超越所有基线方法，同时在下游任务上避免性能降级（alignment tax），并通过实验验证了时间效率和机制有效性。

Conclusion: WSD证明通过小型对齐模型引导大模型解码初期能高效解决对齐难题，为低资源对齐提供了新视角，自动切换机制和专用数据集是关键创新。

Abstract: Large Language Models (LLMs) require alignment with human preferences to
avoid generating offensive, false, or meaningless content. Recently,
low-resource methods for LLM alignment have been popular, while still facing
challenges in obtaining both high-quality and aligned content. Motivated by the
observation that the difficulty of generating aligned responses is concentrated
at the beginning of decoding, we propose a novel framework, Weak-to-Strong
Decoding (WSD), to enhance the alignment ability of base models by the guidance
of a small aligned model. The small model first drafts well-aligned beginnings,
followed by the large base model to continue the rest, controlled by a
well-designed auto-switch mechanism. We also collect a new dataset, GenerAlign,
to fine-tune a small-sized Pilot-3B as the draft model, which effectively
enhances different base models under the WSD framework to outperform all
baseline methods, while avoiding degradation on downstream tasks, termed as the
alignment tax. Extensive experiments are further conducted to examine the
impact of different settings and time efficiency, as well as analyses on the
intrinsic mechanisms of WSD in depth.

</details>


### [91] [LG-ANNA-Embedding technical report](https://arxiv.org/abs/2506.07438)
*Jooyoung Choi,Hyun Kim,Hansol Jang,Changwook Jun,Kyunghoon Bae,Hyewon Choi,Stanley Jungkyu Choi,Honglak Lee,Chulmin Yun*

Main category: cs.CL

TL;DR: 提出的基于指令的统一框架利用Mistral-7B模型，通过上下文学习、软监督和自适应困难负样本挖掘，在无需任务特定微调的情况下生成通用文本嵌入，在MTEB基准测试中41项任务上表现优异。


<details>
  <summary>Details</summary>
Motivation: 解决传统文本嵌入模型在IR与非IR任务之间泛化能力不足的问题，同时降低对任务特定微调的依赖。

Method: 1) 使用结构化指令和少样本示例进行上下文学习 2) 利用稠密检索器/排序器提取的连续相关性分数作为软监督信号 3) 设计基于边界的自适应困难负样本挖掘机制过滤语义模糊负样本

Result: 在MTEB v2基准的41项任务上达到顶级性能（通过Borda分数评估），超越更大规模或全微调的基线模型

Conclusion: 结合上下文提示、软监督和自适应采样的方法能有效生成可扩展的高质量通用嵌入，显著提升跨任务泛化能力

Abstract: This report presents a unified instruction-based framework for learning
generalized text embeddings optimized for both information retrieval (IR) and
non-IR tasks. Built upon a decoder-only large language model (Mistral-7B), our
approach combines in-context learning, soft supervision, and adaptive
hard-negative mining to generate context-aware embeddings without task-specific
fine-tuning. Structured instructions and few-shot examples are used to guide
the model across diverse tasks, enabling strong performance on classification,
semantic similarity, clustering, and reranking benchmarks. To improve semantic
discrimination, we employ a soft labeling framework where continuous relevance
scores, distilled from a high-performance dense retriever and reranker, serve
as fine-grained supervision signals. In addition, we introduce adaptive
margin-based hard-negative mining, which filters out semantically ambiguous
negatives based on their similarity to positive examples, thereby enhancing
training stability and retrieval robustness. Our model is evaluated on the
newly introduced MTEB (English, v2) benchmark, covering 41 tasks across seven
categories. Results show that our method achieves strong generalization and
ranks among the top-performing models by Borda score, outperforming several
larger or fully fine-tuned baselines. These findings highlight the
effectiveness of combining in-context prompting, soft supervision, and adaptive
sampling for scalable, high-quality embedding generation.

</details>


### [92] [Understanding Cross-Domain Adaptation in Low-Resource Topic Modeling](https://arxiv.org/abs/2506.07453)
*Pritom Saha Akash,Kevin Chen-Chuan Chang*

Main category: cs.CL

TL;DR: 本文介绍了名为DALTA的领域对齐潜在主题适应框架，解决低资源主题建模中的知识迁移挑战。


<details>
  <summary>Details</summary>
Motivation: 现有主题模型在低资源环境下因数据有限导致主题推断不稳定和不连贯，需要有效利用高资源源域信息而不引入无关内容。

Method: 提出DALTA框架，使用共享编码器提取领域不变特征、专用解码器处理领域特定细节，并通过对抗性对齐选择性迁移信息。

Result: 在多样化低资源数据集上，DALTA在主题连贯性、稳定性和可迁移性方面持续优于最先进方法。

Conclusion: DALTA通过领域对齐和选择性知识转移，显著提升了低资源主题建模的性能。

Abstract: Topic modeling plays a vital role in uncovering hidden semantic structures
within text corpora, but existing models struggle in low-resource settings
where limited target-domain data leads to unstable and incoherent topic
inference. We address this challenge by formally introducing domain adaptation
for low-resource topic modeling, where a high-resource source domain informs a
low-resource target domain without overwhelming it with irrelevant content. We
establish a finite-sample generalization bound showing that effective knowledge
transfer depends on robust performance in both domains, minimizing latent-space
discrepancy, and preventing overfitting to the data. Guided by these insights,
we propose DALTA (Domain-Aligned Latent Topic Adaptation), a new framework that
employs a shared encoder for domain-invariant features, specialized decoders
for domain-specific nuances, and adversarial alignment to selectively transfer
relevant information. Experiments on diverse low-resource datasets demonstrate
that DALTA consistently outperforms state-of-the-art methods in terms of topic
coherence, stability, and transferability.

</details>


### [93] [KScope: A Framework for Characterizing the Knowledge Status of Language Models](https://arxiv.org/abs/2506.07458)
*Yuxin Xiao,Shan Chen,Jack Gallifant,Danielle Bitterman,Thomas Hartvigsen,Marzyeh Ghassemi*

Main category: cs.CL

TL;DR: 该研究引入了一个用于评估大语言模型知识状态的五级分类法，并提出了名为KScope的分层框架。这一框架通过统计测试分析模型在不同知识模式下的表现，以确定知识状态。实验覆盖九种模型和四个数据集，揭示了语境支持、关键特征对知识更新的影响，以及特征约束下的语境总结提升模型表现的有效性。


<details>
  <summary>Details</summary>
Motivation: 现有研究主要关注知识冲突下LLM的行为（即内部参数记忆与外部语境信息矛盾），但未能全面评估模型对问题的实际掌握程度。这阻碍了对模型真实知识状态的系统理解。因此，本工作旨在建立更细化的知识状态评估体系。

Method: 1. 定义五级知识状态分类法（基于知识模式的一致性与正确性）
2. 提出KScope框架：采用分层统计检验逐步验证假设，将模型知识归类到五级状态之一
3. 在九种LLM和四个数据集上应用该框架
4. 分析语境支持、特征（难度/相关性/熟悉度）与知识更新的关系
5. 实施特征约束的语境总结及可信度增强策略

Result: 1. 外部语境支持显著缩小模型知识差距
2. 难度/相关性/熟悉度特征共同驱动成功知识更新
3. 当模型处于部分正确/冲突状态时特征偏好相似，但在持续错误时偏好分化
4. 特征约束的语境总结结合可信度增强可持续提升更新效果，且具备跨模型泛化能力

Conclusion: KScope框架实现了对LLM知识状态的精细量化，揭示语境特征对知识更新的关键作用。所提出的特征约束总结方法能有效改善模型表现，为理解与优化LLM知识机制提供新途径。

Abstract: Characterizing a large language model's (LLM's) knowledge of a given question
is challenging. As a result, prior work has primarily examined LLM behavior
under knowledge conflicts, where the model's internal parametric memory
contradicts information in the external context. However, this does not fully
reflect how well the model knows the answer to the question. In this paper, we
first introduce a taxonomy of five knowledge statuses based on the consistency
and correctness of LLM knowledge modes. We then propose KScope, a hierarchical
framework of statistical tests that progressively refines hypotheses about
knowledge modes and characterizes LLM knowledge into one of these five
statuses. We apply KScope to nine LLMs across four datasets and systematically
establish: (1) Supporting context narrows knowledge gaps across models. (2)
Context features related to difficulty, relevance, and familiarity drive
successful knowledge updates. (3) LLMs exhibit similar feature preferences when
partially correct or conflicted, but diverge sharply when consistently wrong.
(4) Context summarization constrained by our feature analysis, together with
enhanced credibility, further improves update effectiveness and generalizes
across LLMs.

</details>


### [94] [From Calibration to Collaboration: LLM Uncertainty Quantification Should Be More Human-Centered](https://arxiv.org/abs/2506.07461)
*Siddartha Devic,Tejas Srinivasan,Jesse Thomason,Willie Neiswanger,Vatsal Sharan*

Main category: cs.CL

TL;DR: 论文指出当前LLM不确定性量化方法存在三个问题：生态效度低的基准测试、只考虑认知不确定性、使用非实用导向的指标，并提出了以人为中心的改进方向。


<details>
  <summary>Details</summary>
Motivation: 现有LLM不确定性量化方法未能有效提升人机协作的可信度，需优化以真正辅助用户决策。

Method: 分析40种LLM不确定性量化方法，归纳三大缺陷并提出用户中心化的解决方案。

Result: 识别出生态效度不足、忽视决策不确定性评估、指标偏离实际效用三大核心问题。

Conclusion: 呼吁转向以用户为中心的不确定性量化研究，强调决策导向的评估框架与实践改进。

Abstract: Large Language Models (LLMs) are increasingly assisting users in the real
world, yet their reliability remains a concern. Uncertainty quantification (UQ)
has been heralded as a tool to enhance human-LLM collaboration by enabling
users to know when to trust LLM predictions. We argue that current practices
for uncertainty quantification in LLMs are not optimal for developing useful UQ
for human users making decisions in real-world tasks. Through an analysis of 40
LLM UQ methods, we identify three prevalent practices hindering the community's
progress toward its goal of benefiting downstream users: 1) evaluating on
benchmarks with low ecological validity; 2) considering only epistemic
uncertainty; and 3) optimizing metrics that are not necessarily indicative of
downstream utility. For each issue, we propose concrete user-centric practices
and research directions that LLM UQ researchers should consider. Instead of
hill-climbing on unrepresentative tasks using imperfect metrics, we argue that
the community should adopt a more human-centered approach to LLM uncertainty
quantification.

</details>


### [95] [CCI4.0: A Bilingual Pretraining Dataset for Enhancing Reasoning in Large Language Models](https://arxiv.org/abs/2506.07463)
*Guang Liu,Liangdong Wang,Jijie Li,Yang Yu,Yao Xu,Jiabei Chen,Yu Bai,Feng Liao,Yonghua Lin*

Main category: cs.CL

TL;DR: CCI4.0是一个35TB的双语预训练数据集，通过创新的数据处理流程和分阶段思维链提取，提升大语言模型的训练质量和推理能力，尤其在数学和编码任务中表现优异


<details>
  <summary>Details</summary>
Motivation: 现有预训练数据质量参差不齐，需要动态质量标准和大量人工处理经验；同时需要多样化的人类推理模式来降低模型幻觉

Method: 提出两阶段去重+多分类器质量评分+领域感知流畅度过滤的数据处理流程；通过分阶段思维链模板提取技术(非大模型蒸馏)获得45亿条多样化推理范式

Result: 在CCI4.0上预训练的LLM获得更干净可靠的训练信号，在数学和代码反射等下游任务中持续提升性能

Conclusion: 严格的数据处理和人类思维模板对提升LLM性能至关重要，为自动处理预训练语料提供新思路

Abstract: We introduce CCI4.0, a large-scale bilingual pre-training dataset engineered
for superior data quality and diverse human-like reasoning trajectory. CCI4.0
occupies roughly $35$ TB of disk space and comprises two sub-datasets:
CCI4.0-M2-Base and CCI4.0-M2-CoT. CCI4.0-M2-Base combines a $5.2$ TB carefully
curated Chinese web corpus, a $22.5$ TB English subset from Nemotron-CC, and
diverse sources from math, wiki, arxiv, and code. Although these data are
mostly sourced from well-processed datasets, the quality standards of various
domains are dynamic and require extensive expert experience and labor to
process. So, we propose a novel pipeline justifying data quality mainly based
on models through two-stage deduplication, multiclassifier quality scoring, and
domain-aware fluency filtering. We extract $4.5$ billion pieces of
CoT(Chain-of-Thought) templates, named CCI4.0-M2-CoT. Differing from the
distillation of CoT from larger models, our proposed staged CoT extraction
exemplifies diverse reasoning patterns and significantly decreases the
possibility of hallucination. Empirical evaluations demonstrate that LLMs
pre-trained in CCI4.0 benefit from cleaner, more reliable training signals,
yielding consistent improvements in downstream tasks, especially in math and
code reflection tasks. Our results underscore the critical role of rigorous
data curation and human thinking templates in advancing LLM performance,
shedding some light on automatically processing pretraining corpora.

</details>


### [96] [Improving Fairness of Large Language Models in Multi-document Summarization](https://arxiv.org/abs/2506.07479)
*Haoyuan Li Yusen Zhang,Snigdha Chaturvedi*

Main category: cs.CL

TL;DR: 本文提出了FairPO，一种同时关注摘要级和语料库级公平性的偏好调整方法，用于改善多文档摘要中的公平性。


<details>
  <summary>Details</summary>
Motivation: 多文档摘要中的公平性对于提供跨文档的全面视角至关重要，但现有方法主要关注摘要级公平性，忽略了语料库级公平性。

Method: FairPO方法：1）通过扰动文档集生成偏好对以提升摘要级公平性；2）通过动态调整偏好对权重进行公平感知偏好调优以提升语料库级公平性。

Result: 实验表明FairPO优于强基线，同时保持摘要的关键质量指标。

Conclusion: 该算法有效解决了多文档摘要中两个层次的公平性问题，代码已开源。

Abstract: Fairness in multi-document summarization (MDS) is crucial for providing
comprehensive views across documents with diverse social attribute values,
which can significantly impact decision-making. For example, a summarization
system that tends to overrepresent negative reviews of products can mislead
customers into disregarding good products. Previous works measure fairness in
MDS at two levels: summary-level and corpus-level. While summary-level fairness
focuses on individual summaries, corpus-level fairness focuses on a corpus of
summaries. Recent methods primarily focus on summary-level fairness. We propose
FairPO, a preference tuning method that focuses on both summary-level and
corpus-level fairness in MDS. To improve summary-level fairness, we propose to
generate preference pairs by perturbing document sets. To improve corpus-level
fairness, we propose fairness-aware preference tuning by dynamically adjusting
the weights of preference pairs. Our experiments show that FairPO outperforms
strong baselines while maintaining the critical qualities of summaries. The
code is available at https://github.com/leehaoyuan/coverage_fairnes.

</details>


### [97] [A Hybrid GA LLM Framework for Structured Task Optimization](https://arxiv.org/abs/2506.07483)
*Berry Feng,Jonas Lin,Patrick Lau*

Main category: cs.CL

TL;DR: 摘要提出了一种名为GA LLM的混合框架，将遗传算法（GA）与大型语言模型（LLM）相结合，用于在严格约束下处理结构化生成任务。该框架将每个输出视为基因，利用语言模型指导进化操作（选择、交叉、变异）来迭代改进解决方案。GA LLM在行程规划、学术大纲和商业报告等任务中表现出色，相比单一语言模型能更好地满足约束条件并生成更高质量的解决方案。


<details>
  <summary>Details</summary>
Motivation: 解决大型语言模型在结构化生成任务中难以严格满足约束条件的问题。传统语言模型在保证输出结构完整性和全局优化方面存在局限，需要结合优化算法提升性能。

Method: 1. 将每个输出视为基因
2. 利用语言模型指导遗传算法中的选择、交叉和变异操作
3. 语言模型提供领域知识和创新变异，遗传算法确保结构完整性和全局优化
4. 采用模块化设计以适应新任务。

Result: 在多个任务（行程规划、学术大纲、商业报告）中验证有效，相比单一语言模型具备以下优势:
- 更好地满足约束条件
- 生成更高质量的解决方案
- 保持输出结构良好

Conclusion: 该工作证明: 1) GA+LLM混合框架能有效融合语言模型的创造性和遗传算法的结构化优化能力；2) 在结构化生成任务中显著优于单一模型；3) 模块化设计提供良好扩展性。

Abstract: GA LLM is a hybrid framework that combines Genetic Algorithms with Large
Language Models to handle structured generation tasks under strict constraints.
Each output, such as a plan or report, is treated as a gene, and evolutionary
operations like selection, crossover, and mutation are guided by the language
model to iteratively improve solutions. The language model provides domain
knowledge and creative variation, while the genetic algorithm ensures
structural integrity and global optimization. GA LLM has proven effective in
tasks such as itinerary planning, academic outlining, and business reporting,
consistently producing well structured and requirement satisfying results. Its
modular design also makes it easy to adapt to new tasks. Compared to using a
language model alone, GA LLM achieves better constraint satisfaction and higher
quality solutions by combining the strengths of both components.

</details>


### [98] [DEBATE: A Dataset for Disentangling Textual Ambiguity in Mandarin Through Speech](https://arxiv.org/abs/2506.07502)
*Haotian Guo,Jing Han,Yongfeng Tu,Shihao Gao,Shengfan Shen,Wulong Xiang,Weihao Gan,Zixing Zhang*

Main category: cs.CL

TL;DR: 介绍了DEBATE数据集，用于研究如何通过语音线索（如发音、停顿、重音和语调）来消除文本歧义，揭示说话者真实意图。该数据集包含1,001个有歧义的中文语句，每个由10名母语者录音。论文详细描述了数据收集流程并进行了质量分析，还用现有的大型语音和音频-语言模型进行了基准测试，显示机器与人类在理解口语意图上的巨大差距。


<details>
  <summary>Details</summary>
Motivation: 过去关于文本和视觉消歧的研究较多，但语音消歧（DTS）研究不足，主要由于缺乏高质量语音和歧义文本配对的数据集。DEBATE数据集旨在填补这一空白。

Method: 提出DEBATE数据集：包含1,001个歧义中文语句，每个由10名母语者录音；详细描述数据收集流程；进行严格质量分析；使用三种先进的语音和音频语言模型进行基准测试。

Result: 人类在数据集中表现良好；但三种先进的模型测试结果显示，机器和人类在理解口语意图上存在明显且巨大的差距。测试中的先进模型表现与人类相比差距显著。

Conclusion: DEBATE是首个通过语音线索解决文本歧义的公开数据集，为跨语言和文化构建类似数据集提供基础；模型基准测试突显目前DTS任务的挑战性；代码和数据集公开可用。

Abstract: Despite extensive research on textual and visual disambiguation,
disambiguation through speech (DTS) remains underexplored. This is largely due
to the lack of high-quality datasets that pair spoken sentences with richly
ambiguous text. To address this gap, we present DEBATE, a unique public Chinese
speech-text dataset designed to study how speech cues and
patterns-pronunciation, pause, stress and intonation-can help resolve textual
ambiguity and reveal a speaker's true intent. DEBATE contains 1,001 carefully
selected ambiguous utterances, each recorded by 10 native speakers, capturing
diverse linguistic ambiguities and their disambiguation through speech. We
detail the data collection pipeline and provide rigorous quality analysis.
Additionally, we benchmark three state-of-the-art large speech and
audio-language models, illustrating clear and huge performance gaps between
machine and human understanding of spoken intent. DEBATE represents the first
effort of its kind and offers a foundation for building similar DTS datasets
across languages and cultures. The dataset and associated code are available
at: https://github.com/SmileHnu/DEBATE.

</details>


### [99] [What Do Indonesians Really Need from Language Technology? A Nationwide Survey](https://arxiv.org/abs/2506.07506)
*Muhammad Dehan Al Kautsar,Lucky Susanto,Derry Wijaya,Fajri Koto*

Main category: cs.CL

TL;DR: 印尼本土语言技术需求调查显示，机器翻译和信息检索是首要需求，但隐私和偏见问题阻碍AI应用。


<details>
  <summary>Details</summary>
Motivation: 当前印度尼西亚700多种本土语言的NLP研究成本高昂，但缺乏对语言社群实际需求的了解。

Method: 通过全国性调查评估印尼母语使用者的真实需求。

Result: 消除语言障碍（尤其机器翻译和信息检索）是最紧迫需求；社群对语言技术热情高，但担忧隐私、偏见及公开数据用于AI训练的问题。

Conclusion: 需提高透明度和明确沟通以支持AI技术推广，同时优先开发翻译和检索工具满足核心需求。

Abstract: There is an emerging effort to develop NLP for Indonesias 700+ local
languages, but progress remains costly due to the need for direct engagement
with native speakers. However, it is unclear what these language communities
truly need from language technology. To address this, we conduct a nationwide
survey to assess the actual needs of native speakers in Indonesia. Our findings
indicate that addressing language barriers, particularly through machine
translation and information retrieval, is the most critical priority. Although
there is strong enthusiasm for advancements in language technology, concerns
around privacy, bias, and the use of public data for AI training highlight the
need for greater transparency and clear communication to support broader AI
adoption.

</details>


### [100] [DeRAGEC: Denoising Named Entity Candidates with Synthetic Rationale for ASR Error Correction](https://arxiv.org/abs/2506.07510)
*Solee Im,Wonjun Lee,Jinmyeong An,Yunsu Kim,Jungseul Ok,Gary Geunbae Lee*

Main category: cs.CL

TL;DR: DeRAGEC方法通过合成去噪原理来过滤噪声命名实体候选，从而改进ASR系统中命名实体的纠正。该方法利用语音相似性和增强定义，无需额外训练。在实验中，DeRAGEC在WER和NE命中率上显著优于基线ASR和RAGEC方法，实现28%的WER相对降低。


<details>
  <summary>Details</summary>
Motivation: 为了改进自动语音识别（ASR）系统中命名实体（NE）的纠正，解决RAGEC框架可能存在的噪声问题。

Method: 扩展RAGEC框架，引入合成去噪原理过滤噪声NE候选：1.利用语音相似性匹配实体 2.通过上下文学习精炼NE定义 3.无需额外训练。

Result: 在CommonVoice和STOP数据集上：Word Error Rate (WER)相对基线ASR降低28%，NE命中率提升，超越原始RAGEC方法。

Conclusion: DeRAGEC通过结合语音相似性和上下文学习，有效过滤噪声NE候选，显著提高ASR纠正性能，且无须额外训练开销。源码已开源。

Abstract: We present DeRAGEC, a method for improving Named Entity (NE) correction in
Automatic Speech Recognition (ASR) systems. By extending the
Retrieval-Augmented Generative Error Correction (RAGEC) framework, DeRAGEC
employs synthetic denoising rationales to filter out noisy NE candidates before
correction. By leveraging phonetic similarity and augmented definitions, it
refines noisy retrieved NEs using in-context learning, requiring no additional
training. Experimental results on CommonVoice and STOP datasets show
significant improvements in Word Error Rate (WER) and NE hit ratio,
outperforming baseline ASR and RAGEC methods. Specifically, we achieved a 28%
relative reduction in WER compared to ASR without postprocessing. Our source
code is publicly available at: https://github.com/solee0022/deragec

</details>


### [101] [Towards Large Language Models with Self-Consistent Natural Language Explanations](https://arxiv.org/abs/2506.07523)
*Sahar Admoni,Ofra Amir,Assaf Hallak,Yftah Ziser*

Main category: cs.CL

TL;DR: 该论文发现大语言模型(LLM)的事后解释与其实际决策特征不一致的问题，开发了PSCB基准数据集进行评估，进而提出新评估指标并通过DPO微调模型提高自洽性。


<details>
  <summary>Details</summary>
Motivation: 现有研究表明，LLM的事后解释常与其真实的决策特征重要性不一致，但受限于评估成本高，缺乏系统解决方案。因此需要构建大规模基准测试工具来解决这一可解释性问题。

Method: 1) 建立Post-hoc Self-Consistency Bank (PSCB)基准数据集，包含多任务多模型的决策结果、LLM生成的解释及对应特征重要性分数；2) 分析暴露标准指标的不足；3) 提出新评估指标；4) 采用直接偏好优化(DPO)微调LLM。

Result: 1) 发现自洽性评分在正确/错误预测间无显著差异；2) 新指标能更有效区分解释质量；3) DPO微调显著提升了解释与决策特征的对齐程度（包括跨域场景）。

Conclusion: PSCB提供了量化LLM解释自洽性的工具；新度量和DPO微调是提升LLM可信度和自洽性的可扩展路径

Abstract: Large language models (LLMs) seem to offer an easy path to interpretability:
just ask them to explain their decisions. Yet, studies show that these post-hoc
explanations often misrepresent the true decision process, as revealed by
mismatches in feature importance. Despite growing evidence of this
inconsistency, no systematic solutions have emerged, partly due to the high
cost of estimating feature importance, which limits evaluations to small
datasets. To address this, we introduce the Post-hoc Self-Consistency Bank
(PSCB) - a large-scale benchmark of decisions spanning diverse tasks and
models, each paired with LLM-generated explanations and corresponding feature
importance scores. Analysis of PSCB reveals that self-consistency scores barely
differ between correct and incorrect predictions. We also show that the
standard metric fails to meaningfully distinguish between explanations. To
overcome this limitation, we propose an alternative metric that more
effectively captures variation in explanation quality. We use it to fine-tune
LLMs via Direct Preference Optimization (DPO), leading to significantly better
alignment between explanations and decision-relevant features, even under
domain shift. Our findings point to a scalable path toward more trustworthy,
self-consistent LLMs.

</details>


### [102] [Bit-level BPE: Below the byte boundary](https://arxiv.org/abs/2506.07541)
*Sangwhan Moon,Tatsuya Hiraoka,Naoaki Okazaki*

Main category: cs.CL

TL;DR: 针对大型语言模型中子词分词时的字节级回退机制导致中文、日文、韩文及表情符号等字符序列变长的问题，本文提出了一种无损压缩技术来缩短序列长度，减少计算开销。


<details>
  <summary>Details</summary>
Motivation: 字节级回退虽能有效防止OOV（未登录词），但在处理CJK字符和表情符号时会显著增加序列长度，导致训练和推理的计算耗时增加。

Method: 作者提出了一种简单的无损压缩技术，专门针对字节级分词后的长序列进行压缩。

Result: 该方法能有效减少序列长度，从而降低计算负担，但论文未在摘要中明确量化效果。

Conclusion: 该压缩技术是解决字节分词导致序列过长问题的实用方案，尤其对CJK等字符密集型场景具有优化意义。

Abstract: Byte-level fallbacks for subword tokenization have become a common practice
in large language models. In particular, it has been demonstrated to be
incredibly effective as a pragmatic solution for preventing OOV, especially in
the context of larger models. However, breaking a character down to individual
bytes significantly increases the sequence length for long-tail tokens in
languages such as Chinese, Japanese, and Korean (CJK) and other
character-diverse contexts such as emoji. The increased sequence length results
in longer computation during both training and inference. In this work, we
propose a simple compression technique that reduces the sequence length
losslessly.

</details>


### [103] [SELT: Self-Evaluation Tree Search for LLMs with Task Decomposition](https://arxiv.org/abs/2506.07557)
*Mengsong Wu,Di Zhang,Yuqiang Li,Dongzhan Zhou,Wenliang Chen*

Main category: cs.CL

TL;DR: SELT 是一个使用改进的蒙特卡洛树搜索框架来增强大型语言模型在复杂推理任务中表现的新方法，不依赖外部奖励模型，能减少推理冗余和幻觉问题。


<details>
  <summary>Details</summary>
Motivation: 现有大型语言模型在复杂推理任务中表现下降，需要一种无需外部奖励模型的改进方法。

Method: SELT 重新设计了置信度上界评分以利用语言模型的内在自评估能力，将推理分解为原子子任务，并在每个节点进行语义聚类。

Result: 在 MMLU 和 Seal-Tools 等基准测试中，SELT 在答案准确性和推理鲁棒性上显著优于基线方法，且无需任务特定微调。

Conclusion: SELT 展示了在不同推理任务中的强泛化能力，平衡探索与利用，减少冗余推理路径。

Abstract: While Large Language Models (LLMs) have achieved remarkable success in a wide
range of applications, their performance often degrades in complex reasoning
tasks. In this work, we introduce SELT (Self-Evaluation LLM Tree Search), a
novel framework that leverages a modified Monte Carlo Tree Search (MCTS) to
enhance LLM reasoning without relying on external reward models. By redefining
the Upper Confidence Bound scoring to align with intrinsic self-evaluation
capabilities of LLMs and decomposing the inference process into atomic subtasks
augmented with semantic clustering at each node, SELT effectively balances
exploration and exploitation, reduces redundant reasoning paths, and mitigates
hallucination. We validate our approach on challenging benchmarks, including
the knowledge-based MMLU and the Tool Learning dataset Seal-Tools, where SELT
achieves significant improvements in answer accuracy and reasoning robustness
compared to baseline methods. Notably, our framework operates without
task-specific fine-tuning, demonstrating strong generalizability across diverse
reasoning tasks. Relevant results and code are available at
https://github.com/fairyshine/SELT .

</details>


### [104] [Beyond the Sentence: A Survey on Context-Aware Machine Translation with Large Language Models](https://arxiv.org/abs/2506.07583)
*Ramakrishna Appicharla,Baban Gain,Santanu Pal,Asif Ekbal*

Main category: cs.CL

TL;DR: 本文回顾了大语言模型（LLMs）在上下文感知机器翻译（CAMT）中的应用，评估了提示和微调两种方法，发现商用LLMs（如ChatGPT）优于开源模型（如Llama）。提示方法可作为基准评估指标，同时指出了未来研究方向如自动后编辑和翻译代理开发。


<details>
  <summary>Details</summary>
Motivation: 尽管大语言模型（LLMs）广泛应用，但其在上下文感知机器翻译（CAMT）领域的探索相对不足。本文旨在系统梳理该领域现状，填补这一研究空白。

Method: 1）文献综述法：全面收集分析LLMs用于上下文感知翻译的研究；2）对比分析法：比较商用与开源LLMs性能（如BLEU等指标）；3）方法分类：将现有技术分为提示工程（prompting）和模型微调（fine-tuning）两类。

Result: 1）商用LLMs（如ChatGPT）翻译质量显著优于开源模型（如Llama/Bloom）；2）提示方法可作为快速有效的质量评估基线；3）自动后编辑（APE）和翻译代理等方向研究稀缺。

Conclusion: 当前LLMs在上下文感知翻译中展现潜力，但存在模型选择和方法创新空间。未来应重点突破：1）开发专用翻译代理系统；2）加强自动后编辑技术研究；3）探索多语言上下文迁移学习。

Abstract: Despite the popularity of the large language models (LLMs), their application
to machine translation is relatively underexplored, especially in context-aware
settings. This work presents a literature review of context-aware translation
with LLMs. The existing works utilise prompting and fine-tuning approaches,
with few focusing on automatic post-editing and creating translation agents for
context-aware machine translation. We observed that the commercial LLMs (such
as ChatGPT and Tower LLM) achieved better results than the open-source LLMs
(such as Llama and Bloom LLMs), and prompt-based approaches serve as good
baselines to assess the quality of translations. Finally, we present some
interesting future directions to explore.

</details>


### [105] [Instructing Large Language Models for Low-Resource Languages: A Systematic Study for Basque](https://arxiv.org/abs/2506.07597)
*Oscar Sainz,Naiara Perez,Julen Etxaniz,Joseba Fernandez de Landa,Itziar Aldabe,Iker García-Ferrero,Aimar Zabala,Ekhi Azurmendi,German Rigau,Eneko Agirre,Mikel Artetxe,Aitor Soroa*

Main category: cs.CL

TL;DR: 该论文探索在低资源语言场景下的指令适应替代方案。假设只有目标语言语料库、开放权重的多语言基础模型和指令调整的骨干大语言模型（LLM），以及从该骨干模型生成的合成指令可用。通过巴斯克语实验得出：目标语言语料库至关重要；合成指令能构建稳健模型；使用指令调整骨干模型优于非指令基础模型；扩大规模能提升效果。


<details>
  <summary>Details</summary>
Motivation: 解决低资源语言缺乏大型指令数据集的问题，探索在有限资源（仅目标语言语料库、多语言基础模型和合成指令）下有效指令适应方法。

Method: 在巴斯克语场景下，系统组合以下组件：1）目标语言语料库；2）多语言基础/指令型骨干LLM（如Llama 3.1 instruct 70B）；3）从指令骨干生成的合成指令。通过大规模人类偏好评估（1,680名参与者）和基准测试进行验证。

Result: 使用指令调整骨干（Llama 3.1 instruct 70B）的模型效果显著优于基础模型，扩大规模可提升性能。仅用1.2B单词巴斯克语料库，模型性能接近更大规模的前沿模型。

Conclusion: 在低资源语言适应中：1）目标语言语料库不可或缺；2）合成指令方案有效；3）指令骨干模型比普通骨干模型更优；4）扩大模型规模是可行的优化方向。开源代码、模型、指令数据集和人类偏好数据支持后续研究。

Abstract: Instructing language models with user intent requires large instruction
datasets, which are only available for a limited set of languages. In this
paper, we explore alternatives to conventional instruction adaptation pipelines
in low-resource scenarios. We assume a realistic scenario for low-resource
languages, where only the following are available: corpora in the target
language, existing open-weight multilingual base and instructed backbone LLMs,
and synthetically generated instructions sampled from the instructed backbone.
We present a comprehensive set of experiments for Basque that systematically
study different combinations of these components evaluated on benchmarks and
human preferences from 1,680 participants. Our conclusions show that target
language corpora are essential, with synthetic instructions yielding robust
models, and, most importantly, that using as backbone an instruction-tuned
model outperforms using a base non-instructed model, and improved results when
scaling up. Using Llama 3.1 instruct 70B as backbone our model comes near
frontier models of much larger sizes for Basque, without using any Basque data
apart from the 1.2B word corpora. We release code, models, instruction
datasets, and human preferences to support full reproducibility in future
research on low-resource language adaptation.

</details>


### [106] [PolitiSky24: U.S. Political Bluesky Dataset with User Stance Labels](https://arxiv.org/abs/2506.07606)
*Peyman Rostami,Vahid Rahimzadeh,Ali Adibi,Azadeh Shakery*

Main category: cs.CL

TL;DR: 研究者开发了PolitiSky24，首个关于2024年美国大选的Bluesky平台用户级立场检测数据集，针对Kamala Harris和Donald Trump，包含16,044条用户-目标立场对，并提供了互动元数据和透明标注方法。


<details>
  <summary>Details</summary>
Motivation: 现有立场检测数据集主要关注推文级分析且集中在成熟平台，缺乏新兴平台(如Bluesky)的用户级立场资源。用户级分析能通过完整发帖历史提供更全面的观点洞察。

Method: 使用结合高级信息检索和大语言模型(LLMs)的标注流程生成立场标签，包含支持性理由和文本片段，LLMs标注准确率达81%。数据集包含用户参与元数据、互动图和发帖历史。

Result: 构建了包含16,044对用户-目标立场样本的数据集PolitiSky24，标注方法具有高透明度且可扩展。

Conclusion: 该数据集以其及时性、开放数据特性和用户级视角填补了政治立场分析空白，数据集已公开。

Abstract: Stance detection identifies the viewpoint expressed in text toward a specific
target, such as a political figure. While previous datasets have focused
primarily on tweet-level stances from established platforms, user-level stance
resources, especially on emerging platforms like Bluesky remain scarce.
User-level stance detection provides a more holistic view by considering a
user's complete posting history rather than isolated posts. We present the
first stance detection dataset for the 2024 U.S. presidential election,
collected from Bluesky and centered on Kamala Harris and Donald Trump. The
dataset comprises 16,044 user-target stance pairs enriched with engagement
metadata, interaction graphs, and user posting histories. PolitiSky24 was
created using a carefully evaluated pipeline combining advanced information
retrieval and large language models, which generates stance labels with
supporting rationales and text spans for transparency. The labeling approach
achieves 81\% accuracy with scalable LLMs. This resource addresses gaps in
political stance analysis through its timeliness, open-data nature, and
user-level perspective. The dataset is available at
https://doi.org/10.5281/zenodo.15616911

</details>


### [107] [Vuyko Mistral: Adapting LLMs for Low-Resource Dialectal Translation](https://arxiv.org/abs/2506.07617)
*Roman Kyslyi,Yuliia Maksymiuk,Ihor Pysmennyi*

Main category: cs.CL

TL;DR: 本文针对低资源、形态复杂的乌克兰胡祖尔方言，首次尝试适配大语言模型（LLM）。通过构建双语语料库和词典，并利用增强检索生成（RAG）技术生成合成数据扩展训练集。使用LoRA微调多个开源LLM，在标准乌克兰语到方言翻译任务中表现优于零样本GPT-4o。


<details>
  <summary>Details</summary>
Motivation: 解决乌克兰胡祖尔方言作为低资源语言的LLM适配难题，填补该方言缺乏计算语言学资源的空白。

Method: 1. 创建9852句平行语料库和7320词词典 2. 用RAG管道生成52142句合成翻译对 3. 采用LoRA技术微调7B级开源LLM 4. 结合BLEU/chrF++/TER/GPT-4o进行多指标评估

Result: 微调后的7B小模型在自动指标和LLM评估中均超越零样本GPT-4o。在无人类标注情况下，综合评估显示微调模型有效性。

Conclusion: 即使小型LLM经适当微调也能在低资源方言翻译任务上超越大型通用模型，合成数据扩展和参数高效微调是有效方案。

Abstract: In this paper we introduce the first effort to adapt large language models
(LLMs) to the Ukrainian dialect (in our case Hutsul), a low-resource and
morphologically complex dialect spoken in the Carpathian Highlands. We created
a parallel corpus of 9852 dialect-to-standard Ukrainian sentence pairs and a
dictionary of 7320 dialectal word mappings. We also addressed data shortage by
proposing an advanced Retrieval-Augmented Generation (RAG) pipeline to generate
synthetic parallel translation pairs, expanding the corpus with 52142 examples.
We have fine-tuned multiple open-source LLMs using LoRA and evaluated them on a
standard-to-dialect translation task, also comparing with few-shot GPT-4o
translation. In the absence of human annotators, we adopt a multi-metric
evaluation strategy combining BLEU, chrF++, TER, and LLM-based judgment
(GPT-4o). The results show that even small(7B) finetuned models outperform
zero-shot baselines such as GPT-4o across both automatic and LLM-evaluated
metrics. All data, models, and code are publicly released at:
https://github.com/woters/vuyko-hutsul

</details>


### [108] [LoRMA: Low-Rank Multiplicative Adaptation for LLMs](https://arxiv.org/abs/2506.07621)
*Harsh Bihany,Shubham Patel,Ashutosh Modi*

Main category: cs.CL

TL;DR: 提出了LoRMA方法，通过矩阵乘法转换替代传统的加法更新来提高大语言模型微调效率


<details>
  <summary>Details</summary>
Motivation: 现有LoRA等基于加法更新的高效微调方法存在局限性，需要更丰富的参数更新方式来提升效果

Method: 设计Low-Rank Multiplicative Adaptation (LoRMA)，引入矩阵乘法转换替代加法更新；通过操作重排和秩扩展策略解决计算复杂度和秩瓶颈问题

Result: 通过大量实验验证了LoRMA在多种评估指标上的有效性

Conclusion: LoRMA通过乘法变换范式革新了高效微调方法，解决了加法更新的局限性，在不同指标上展现出优越性

Abstract: Large Language Models have shown remarkable capabilities in the NLP domain.
Their effectiveness can mainly be attributed to their ability to adapt to an
array of downstream tasks. However, generally, full fine-tuning is a
computationally expensive job. To mitigate this, many techniques have been
developed that prime efficiency, a prominent one being Low-Rank Adaptation
(LoRA). However, LoRA and its variants employ re-parametrized additive updates.
In this paper, we propose Low-Rank Multiplicative Adaptation (LoRMA), which
shifts the paradigm of additive updates to a richer space of matrix
multiplicative transformations. We tackle challenges such as computational
complexity and rank bottleneck of matrix multiplication by effectively
re-ordering operations and introducing rank inflation strategies. We conduct
extensive experiments to demonstrate the effectiveness of our approach in terms
of various evaluation metrics.

</details>


### [109] [Intent Matters: Enhancing AI Tutoring with Fine-Grained Pedagogical Intent Annotation](https://arxiv.org/abs/2506.07626)
*Kseniia Petukhova,Ekaterina Kochmar*

Main category: cs.CL

TL;DR: 本研究將11種教學意圖精細標註應用於MathDial數學輔導對話數據集，並微調大型語言模型，結果顯示該模型產生的回應教學對齊度更高、效果更好。


<details>
  <summary>Details</summary>
Motivation: 大型語言模型在智能教學系統中極具潛力，但當前模型缺乏教學策略對齊，需任務特定適應。探索細粒度教學意圖標註能否提升LLM生成的輔導回應質量。

Method: 基於MathDial數學教學對話數據集，應用自動化標註框架重新標註數據（使用11種教學意圖的分類方式），並用新標註數據微調LLM。與原始四類分類模型進行對比。

Result: 自動評估和定性分析均顯示，使用細粒度意圖分類的模型產生的回應教學對齊度更高、效果更好。

Conclusion: 精細意圖標註在教育情境中能有效提升可控文本生成品質，釋出標註數據與程式碼以促進後續研究。

Abstract: Large language models (LLMs) hold great promise for educational applications,
particularly in intelligent tutoring systems. However, effective tutoring
requires alignment with pedagogical strategies - something current LLMs lack
without task-specific adaptation. In this work, we explore whether fine-grained
annotation of teacher intents can improve the quality of LLM-generated tutoring
responses. We focus on MathDial, a dialog dataset for math instruction, and
apply an automated annotation framework to re-annotate a portion of the dataset
using a detailed taxonomy of eleven pedagogical intents. We then fine-tune an
LLM using these new annotations and compare its performance to models trained
on the original four-category taxonomy. Both automatic and qualitative
evaluations show that the fine-grained model produces more pedagogically
aligned and effective responses. Our findings highlight the value of intent
specificity for controlled text generation in educational settings, and we
release our annotated data and code to facilitate further research.

</details>


### [110] [Unblocking Fine-Grained Evaluation of Detailed Captions: An Explaining AutoRater and Critic-and-Revise Pipeline](https://arxiv.org/abs/2506.07631)
*Brian Gordon,Yonatan Bitton,Andreea Marzoca,Yasumasa Onoe,Xiao Wang,Daniel Cohen-Or,Idan Szpektor*

Main category: cs.CL

TL;DR: 提出了DOCCI-Critique基准测试，包含1400个视觉语言模型（VLM）生成的段落说明，带有10216个句子级人工标注的错误事实和原因分析；并开发了VNLI-Critique模型用于自动句子级事实性分类和评论生成；该工作还提供了三个关键应用：强大的泛化能力、可靠的模型排名和改进图像说明事实性的新方法。


<details>
  <summary>Details</summary>
Motivation: 大视觉语言模型（VLMs）生成了极其详细的段落级图像说明，但目前缺乏对其进行细粒度事实准确性评估的方法和数据集。

Method: 构建DOCCI-Critique数据集，包含1400个VLM生成的段落说明并标注10216个句子级错误分析；开发基于该数据的VNLI-Critique模型用于自动化事实性评估。

Result: 1）VNLI-Critique在M-HalDetect等基准测试中达到最佳性能；2）AutoRater模型与人工评估的斯皮尔曼相关性达0.98；3）Critic-and-Revise流程使Caption事实准确性提升46%。

Conclusion: 该研究提供了细粒度评估视觉语言模型的基准和实用工具，显著提升了评估标准和模型改进能力。

Abstract: Large Vision-Language Models (VLMs) now generate highly detailed,
paragraphlength image captions, yet evaluating their factual accuracy remains
challenging. Current methods often miss fine-grained errors, being designed for
shorter texts or lacking datasets with verified inaccuracies. We introduce
DOCCI-Critique, a benchmark with 1,400 VLM-generated paragraph captions (100
images, 14 VLMs) featuring over 10,216 sentence-level human annotations of
factual correctness and explanatory rationales for errors, all within paragraph
context. Building on this, we develop VNLI-Critique, a model for automated
sentence-level factuality classification and critique generation. We highlight
three key applications: (1) VNLI-Critique demonstrates robust generalization,
validated by state-of-the-art performance on the M-HalDetect benchmark and
strong results in CHOCOLATE claim verification. (2) The VNLI-Critique driven
AutoRater for DOCCI-Critique provides reliable VLM rankings, showing excellent
alignment with human factuality judgments (e.g., 0.98 Spearman). (3) An
innovative Critic-and-Revise pipeline, where critiques from VNLI-Critique guide
LLM-based corrections, achieves substantial improvements in caption factuality
(e.g., a 46% gain on DetailCaps-4870). Our work offers a crucial benchmark
alongside practical tools, designed to significantly elevate the standards for
fine-grained evaluation and foster the improvement of VLM image understanding.
Project page: https://google.github.io/unblocking-detail-caption

</details>


### [111] [TreeReview: A Dynamic Tree of Questions Framework for Deep and Efficient LLM-based Scientific Peer Review](https://arxiv.org/abs/2506.07642)
*Yuan Chang,Ziyue Li,Hengyuan Zhang,Yuanbo Kong,Yanru Wu,Zhijiang Guo,Ngai Wong*

Main category: cs.CL

TL;DR: 提出TreeReview框架，通过树状分解问题的方法生成更全面深入的同行评审反馈，同时显著降低计算成本。


<details>
  <summary>Details</summary>
Motivation: 现有LLM辅助同行评审方法难以兼顾生成深度审稿内容与计算效率。

Method: 将评审建模为层次化的双向QA过程：递归分解问题形成树状结构，自下而上聚合答案，并配备动态问题扩展机制。

Result: 在ICLR和NeurIPS基准上取得更全面、深入、专家一致的评审意见，比基线方法降低80%token消耗。

Conclusion: TreeReview高效解决了LLM辅助评审的深度与效率平衡问题，开源代码和数据集推动相关研究。

Abstract: While Large Language Models (LLMs) have shown significant potential in
assisting peer review, current methods often struggle to generate thorough and
insightful reviews while maintaining efficiency. In this paper, we propose
TreeReview, a novel framework that models paper review as a hierarchical and
bidirectional question-answering process. TreeReview first constructs a tree of
review questions by recursively decomposing high-level questions into
fine-grained sub-questions and then resolves the question tree by iteratively
aggregating answers from leaf to root to get the final review. Crucially, we
incorporate a dynamic question expansion mechanism to enable deeper probing by
generating follow-up questions when needed. We construct a benchmark derived
from ICLR and NeurIPS venues to evaluate our method on full review generation
and actionable feedback comments generation tasks. Experimental results of both
LLM-based and human evaluation show that TreeReview outperforms strong
baselines in providing comprehensive, in-depth, and expert-aligned review
feedback, while reducing LLM token usage by up to 80% compared to
computationally intensive approaches. Our code and benchmark dataset are
available at https://github.com/YuanChang98/tree-review.

</details>


### [112] [Evaluating LLMs Robustness in Less Resourced Languages with Proxy Models](https://arxiv.org/abs/2506.07645)
*Maciej Chrabąszcz,Katarzyna Lorenc,Karolina Seweryn*

Main category: cs.CL

TL;DR: 研究展示如何通过对低资源语种的拼写攻击绕过大型语言模型的安全机制


<details>
  <summary>Details</summary>
Motivation: 发现多语言大型语言模型在安全训练数据中主要依赖高资源语种（如英语），导致在波兰语等低资源语种中存在安全漏洞

Method: 使用小型代理模型计算词重要性，通过少量字符改动和词级攻击构建对抗样本

Result: 字符和词级攻击显著改变了不同大型语言模型的预测结果，证实了在波兰语等语言中的安全脆弱性

Conclusion: 该方法在低资源语种中能有效绕过模型的安全机制，并推广到其他语言；同时公开数据集和代码供后续研究

Abstract: Large language models (LLMs) have demonstrated impressive capabilities across
various natural language processing (NLP) tasks in recent years. However, their
susceptibility to jailbreaks and perturbations necessitates additional
evaluations. Many LLMs are multilingual, but safety-related training data
contains mainly high-resource languages like English. This can leave them
vulnerable to perturbations in low-resource languages such as Polish. We show
how surprisingly strong attacks can be cheaply created by altering just a few
characters and using a small proxy model for word importance calculation. We
find that these character and word-level attacks drastically alter the
predictions of different LLMs, suggesting a potential vulnerability that can be
used to circumvent their internal safety mechanisms. We validate our attack
construction methodology on Polish, a low-resource language, and find potential
vulnerabilities of LLMs in this language. Additionally, we show how it can be
extended to other languages. We release the created datasets and code for
further research.

</details>


### [113] [Transcript-Prompted Whisper with Dictionary-Enhanced Decoding for Japanese Speech Annotation](https://arxiv.org/abs/2506.07646)
*Rui Hu,Xiaolong Lin,Jiawang Liu,Shixi Huang,Zhenpeng Zhan*

Main category: cs.CL

TL;DR: 提出一种基于音频-文本对标注日语音位和韵律信息的方法，用于构建日语TTS数据集。


<details>
  <summary>Details</summary>
Motivation: 旨在高效构建高质量的日语文本转语音训练数据集，同时解决传统文本或音频单一方法在标注精度上的不足。

Method: 1) 微调大规模预训练ASR模型，使其基于真实文本同步输出字素和标注标签
2) 利用词典先验知识设计解码策略修正音位标注错误

Result: 客观评估：超越仅基于文本或音频的传统方法
主观评估：使用本方法标注数据训练的TTS模型，语音自然度接近人工标注数据训练的模型

Conclusion: 该方法能以接近人工标注的质量自动生成TTS训练标注，显著提升效率，突破纯文本/音频标注的性能瓶颈

Abstract: In this paper, we propose a method for annotating phonemic and prosodic
labels on a given audio-transcript pair, aimed at constructing Japanese
text-to-speech (TTS) datasets. Our approach involves fine-tuning a large-scale
pre-trained automatic speech recognition (ASR) model, conditioned on ground
truth transcripts, to simultaneously output phrase-level graphemes and
annotation labels. To further correct errors in phonemic labeling, we employ a
decoding strategy that utilizes dictionary prior knowledge. The objective
evaluation results demonstrate that our proposed method outperforms previous
approaches relying solely on text or audio. The subjective evaluation results
indicate that the naturalness of speech synthesized by the TTS model, trained
with labels annotated using our method, is comparable to that of a model
trained with manual annotations.

</details>


### [114] [Beyond Benchmarks: A Novel Framework for Domain-Specific LLM Evaluation and Knowledge Mapping](https://arxiv.org/abs/2506.07658)
*Nitin Sharma,Thomas Wolfers,Çağatay Yıldız*

Main category: cs.CL

TL;DR: 本文介绍了一种构建领域特定基准的方法，用于评估语言模型在领域适应过程中的知识表示，该方法避免了数据污染问题，并能高效评估最新领域数据。实验表明该方法与专家基准高度相关，并揭示了领域适应的分层学习机制与遗忘模式。


<details>
  <summary>Details</summary>
Motivation: 解决语言模型评估中的两大挑战：构建可靠的领域特定基准以及理解领域适应过程中的知识表示问题，同时避免传统评估方法存在的数据污染和高计算成本等问题。

Method: 提出一种确定性流程，将原始领域语料转化为完成型测试基准。该方法通过TF和Term TF-IDF方法生成领域关键词及相关词列表，构建提示-目标对，评估模型完成提示的能力。使用多种模型（如GPT-2, Llama系列等）和领域进行全面实验。

Result: 1）新基准与专家构建基准强相关，且比困惑度指标更准确；2）发现小模型在500步内快速适应；3）揭示初始层负责属性提取、后续层负责预测的机制；4）发现遗忘起始于中间层（属性提取层）并在后续层放大。

Conclusion: 本研究提供了实用的领域模型评估方法，揭示了领域适应中的分层知识表征机制，为高效微调和减轻灾难性遗忘提供了新思路。

Abstract: The paper addresses two critical challenges in language model (LM)
evaluation: creating reliable domain-specific benchmarks and understanding
knowledge representation during domain adaptation. We introduce a deterministic
pipeline that converts raw domain corpora into completion-type benchmarks
without relying on LMs or human curation, eliminating benchmark contamination
issues while enabling evaluation on the latest domain data. Our approach
generates domain-specific keywords and related word lists using TF and Term
TF-IDF methods and constructs prompt-target pairs. We evaluate models by
measuring their ability to complete these prompts with the correct
domain-specific targets, providing a direct assessment of domain knowledge with
low computational cost. Through comprehensive experiments across multiple
models (GPT-2 medium/XL, Llama-2/3.1, OLMo-2, Qwen-2, Mistral) and domains, we
demonstrate that our benchmark strongly correlates with expert-generated
benchmarks while providing a more accurate measure of domain knowledge than
traditional perplexity metrics. We reveal that domain adaptation happens
rapidly in smaller models (within 500 steps) and illustrate a new approach to
domain knowledge evaluation in base models during training for early stopping.
By extending mechanistic analysis to domain adaptation, we discover that
initial-to-mid layers are primarily responsible for attribute extraction, while
later layers focus on next token prediction. Furthermore, we show that during
adaptation, forgetting begins in the middle layers, where attribute extraction
happens and is amplified in later layers. Our work provides both a practical
evaluation methodology for domain-specific LMs and novel insights into
knowledge representation during adaptation, with implications for more
efficient fine-tuning strategies and targeted approaches to mitigate
catastrophic forgetting.

</details>


### [115] [Synthesis by Design: Controlled Data Generation via Structural Guidance](https://arxiv.org/abs/2506.07664)
*Lei Xu,Sirui Chen,Yuxuan Huang,Chaochao Lu*

Main category: cs.CL

TL;DR: 提出了一个通过生成代码提取数学解题结构信息的方法，构建了包含39K问题和6.1K高难度问题的数据集，实验证明数据有效提升模型推理能力。


<details>
  <summary>Details</summary>
Motivation: 现有数学推理数据生成方法存在生成质量和问题复杂度不足的问题，需要更好的结构化解决方案。

Method: 从数学题解中提取结构信息（通过生成代码实现），创建带有标注中间步骤的标注数据集。

Result: 1) 创建了两个数据集：39K标准题和6.1K高难度题；2) 发现模型性能随推理步长增加而下降；3) 微调实验验证了数据集有效性。

Conclusion: 该方法改善了数学推理数据的质量，希望为提升LLM推理能力的研究提供帮助。

Abstract: Mathematical reasoning remains challenging for LLMs due to complex logic and
the need for precise computation. Existing methods enhance LLM reasoning by
synthesizing datasets through problem rephrasing, but face issues with
generation quality and problem complexity. To address this, we propose to
extract structural information with generated problem-solving code from
mathematical reasoning and guide data generation with structured solutions.
Applied to MATH and GSM8K, our approach produces 39K problems with labeled
intermediate steps and a 6.1K-problem benchmark of higher difficulty. Results
on our benchmark show that model performance declines as reasoning length
increases. Additionally, we conducted fine-tuning experiments using the
proposed training data on a range of LLMs, and the results validate the
effectiveness of our dataset. We hope the proposed method and dataset will
contribute to future research in enhancing LLM reasoning capabilities.

</details>


### [116] [Silencing Empowerment, Allowing Bigotry: Auditing the Moderation of Hate Speech on Twitch](https://arxiv.org/abs/2506.07667)
*Prarabdh Shukla,Wei Yin Chong,Yash Patel,Brennan Schaffner,Danish Pruthi,Arjun Bhagoji*

Main category: cs.CL

TL;DR: 审计发现Twitch的AutoMod工具在识别仇恨内容时严重依赖特定词汇且准确率低，漏检率达94%，同时错误屏蔽了89.5%的良性内容，突显其语境理解能力的不足。


<details>
  <summary>Details</summary>
Motivation: 实时互动平台的内容审核系统效果未知，尤其针对像Twitch这样需要低延迟审核的场景，因此需要评估其自动化审核工具AutoMod对仇恨内容的识别效果。

Method: 通过创建测试账号，使用Twitch API发送107,000条来自4个数据集的仇恨/良性评论，测试AutoMod对性别歧视/种族歧视/残疾歧视/恐同等内容的标注准确率。

Result: 1) 仇恨内容漏检率最高达94%；2) 添加特定侮辱词后删除率达100%证明其依赖关键词；3) 89.5%使用敏感词的良性内容被错误屏蔽。

Conclusion: AutoMod存在严重缺陷：过度依赖词汇而忽略语境，导致仇恨内容泛滥与良性内容误杀，亟需改进上下文理解能力。

Abstract: To meet the demands of content moderation, online platforms have resorted to
automated systems. Newer forms of real-time engagement($\textit{e.g.}$, users
commenting on live streams) on platforms like Twitch exert additional pressures
on the latency expected of such moderation systems. Despite their prevalence,
relatively little is known about the effectiveness of these systems. In this
paper, we conduct an audit of Twitch's automated moderation tool
($\texttt{AutoMod}$) to investigate its effectiveness in flagging hateful
content. For our audit, we create streaming accounts to act as siloed test
beds, and interface with the live chat using Twitch's APIs to send over
$107,000$ comments collated from $4$ datasets. We measure $\texttt{AutoMod}$'s
accuracy in flagging blatantly hateful content containing misogyny, racism,
ableism and homophobia. Our experiments reveal that a large fraction of hateful
messages, up to $94\%$ on some datasets, $\textit{bypass moderation}$.
Contextual addition of slurs to these messages results in $100\%$ removal,
revealing $\texttt{AutoMod}$'s reliance on slurs as a moderation signal. We
also find that contrary to Twitch's community guidelines, $\texttt{AutoMod}$
blocks up to $89.5\%$ of benign examples that use sensitive words in
pedagogical or empowering contexts. Overall, our audit points to large gaps in
$\texttt{AutoMod}$'s capabilities and underscores the importance for such
systems to understand context effectively.

</details>


### [117] [GaRAGe: A Benchmark with Grounding Annotations for RAG Evaluation](https://arxiv.org/abs/2506.07671)
*Ionut-Teodor Sorodoc,Leonardo F. R. Ribeiro,Rexhina Blloshmi,Christopher Davis,Adrià de Gispert*

Main category: cs.CL

TL;DR: GaRAGe 是一个大规模 RAG 基准测试，包含 2366 个多样化问题和超过 35K 人工标注的段落，用于评估 LLM 在生成答案时识别相关依据的能力。评估发现当前顶尖 LLM 存在过度总结、依据不足时偏转率低（最高 31%）以及来源归属 F1 值最高仅 58.9% 等问题，在时效性问题和稀疏私有数据源上表现更差。


<details>
  <summary>Details</summary>
Motivation: 现有 RAG 评估缺少细粒度标注，无法精确衡量 LLM 识别相关依据的能力。GaRAGe 通过人工标注的段落级相关性和真实回答，建立标准化测试平台以填补这一空白。

Method: 构建包含 2366 个多样化问题的问题集，从私有文档和网页爬取超过 35K 段落并人工标注相关性。使用标准检索器获取段落后，评估 LLM 在 (a)仅依赖相关依据生成答案 (b)依据不足时有效偏转 两方面的性能，采用 Relevance-Aware Factuality Score、偏转识别率和来源归属 F1 等指标。

Result: 测试的顶尖 LLM 表现：1) 事实性分数最高仅 60% 2) 有效偏转率最高 31% 3) 来源归属 F1 最高 58.9%。模型普遍存在过度总结问题，在时效性问题和稀疏私有数据源场景下性能显著下降。

Conclusion: GaRAGe 揭示了当前 LLM 在精确依据识别和合理偏转上的重大缺陷，特别是面对动态知识或稀疏数据源时。该基准为开发更可靠的 RAG 系统提供了关键评估工具。

Abstract: We present GaRAGe, a large RAG benchmark with human-curated long-form answers
and annotations of each grounding passage, allowing a fine-grained evaluation
of whether LLMs can identify relevant grounding when generating RAG answers.
Our benchmark contains 2366 questions of diverse complexity, dynamism, and
topics, and includes over 35K annotated passages retrieved from both private
document sets and the Web, to reflect real-world RAG use cases. This makes it
an ideal test bed to evaluate an LLM's ability to identify only the relevant
information necessary to compose a response, or provide a deflective response
when there is insufficient information. Evaluations of multiple
state-of-the-art LLMs on GaRAGe show that the models tend to over-summarise
rather than (a) ground their answers strictly on the annotated relevant
passages (reaching at most a Relevance-Aware Factuality Score of 60%), or (b)
deflect when no relevant grounding is available (reaching at most 31% true
positive rate in deflections). The F1 in attribution to relevant sources is at
most 58.9%, and we show that performance is particularly reduced when answering
time-sensitive questions and when having to draw knowledge from sparser private
grounding sources.

</details>


### [118] [Training Superior Sparse Autoencoders for Instruct Models](https://arxiv.org/abs/2506.07691)
*Jiaming Li,Haoran Ye,Yukun Chen,Xinyue Li,Lei Zhang,Hamid Alinejad-Rokny,Jimmy Chih-Hsien Peng,Min Yang*

Main category: cs.CL

TL;DR: FAST是一种新的稀疏自编码器训练方法，专门针对指令微调模型优化，通过匹配数据分布和激活模式，显著提升重构效果和特征可解释性。实验表明其在多个模型上优于基线，并意外发现通过干预特殊令牌可改进输出质量。


<details>
  <summary>Details</summary>
Motivation: 现存的稀疏自编码器训练方法主要针对基础模型开发，当应用于指令微调模型时重构质量和可解释性明显下降。本文旨在解决该领域局限性。

Method: 提出FAST框架（Finetuning-aligned Sequential Training），其关键创新是使训练过程与指令模型的数据分布和激活特性保持一致：1. 引入指令微调数据集训练 2. 序列化训练策略适配激活模式

Result: 1. 在Qwen2.5-7B重构任务中，MSE降至0.6468（基线为5.1985和1.5096）2. Llama3.2-3B上高质量特征比例达21.1%（基线7.0%和10.2%）3. 发现对特殊令牌激活干预可提升模型输出质量

Conclusion: FAST有效解决了指令模型场景的稀疏自编码器适配问题，实验验证其在重构性能与特征解释性方面的优越性，并为模型细粒度控制提供了新思路（代码和240个预训练SAE已开源）。

Abstract: As large language models (LLMs) grow in scale and capability, understanding
their internal mechanisms becomes increasingly critical. Sparse autoencoders
(SAEs) have emerged as a key tool in mechanistic interpretability, enabling the
extraction of human-interpretable features from LLMs. However, existing SAE
training methods are primarily designed for base models, resulting in reduced
reconstruction quality and interpretability when applied to instruct models. To
bridge this gap, we propose
$\underline{\textbf{F}}$inetuning-$\underline{\textbf{a}}$ligned
$\underline{\textbf{S}}$equential $\underline{\textbf{T}}$raining
($\textit{FAST}$), a novel training method specifically tailored for instruct
models. $\textit{FAST}$ aligns the training process with the data distribution
and activation patterns characteristic of instruct models, resulting in
substantial improvements in both reconstruction and feature interpretability.
On Qwen2.5-7B-Instruct, $\textit{FAST}$ achieves a mean squared error of 0.6468
in token reconstruction, significantly outperforming baseline methods with
errors of 5.1985 and 1.5096. In feature interpretability, $\textit{FAST}$
yields a higher proportion of high-quality features, for Llama3.2-3B-Instruct,
$21.1\%$ scored in the top range, compared to $7.0\%$ and $10.2\%$ for
$\textit{BT(P)}$ and $\textit{BT(F)}$. Surprisingly, we discover that
intervening on the activations of special tokens via the SAEs leads to
improvements in output quality, suggesting new opportunities for fine-grained
control of model behavior. Code, data, and 240 trained SAEs are available at
https://github.com/Geaming2002/FAST.

</details>


### [119] [Through the Valley: Path to Effective Long CoT Training for Small Language Models](https://arxiv.org/abs/2506.07712)
*Renjie Luo,Jiaxi Li,Chen Huang,Wei Lu*

Main category: cs.CL

TL;DR: 研究发现，在小型语言模型（SLMs; ≤3B参数）上使用长思维链（CoT）监督会导致性能显著下降，称为Long CoT Degradation现象。实验表明，这种现象在多个SLM模型家族中普遍存在，错误累积是主要原因，且会影响强化学习效果，但可通过扩大监督微调规模缓解。


<details>
  <summary>Details</summary>
Motivation: 长思维链（CoT）监督虽能提升大模型推理能力，但观察到小型语言模型使用有限长CoT数据训练时会出现性能恶化现象。本文旨在验证该现象的普遍性、分析成因，并探索解决方案。

Method: 在Qwen2.5、LLaMA3和Gemma3等SLM模型家族上开展实验：1) 使用8k-220k长CoT样本进行微调；2) 测试模型在原始任务上的性能变化；3) 分析错误累积效应；4) 探究CoT训练对下游强化学习的影响。

Result: 1) 仅8k长CoT样本微调即可使SLM性能下降高达75%；2) 部分超小型模型即使使用220k样本也无法恢复原始性能；3) 性能下降源于长响应导致的错误累积；4) Long CoT Degradation会负面影响强化学习，但扩大SFT规模可缓解。

Conclusion: 长CoT训练对小型语言模型存在系统性风险，挑战了其必然有益的假设。实际应用中应避免对SLMs盲目使用长CoT，建议通过扩大SFT数据规模或调整监督策略来构建更有效的小型推理模型。

Abstract: Long chain-of-thought (CoT) supervision has become a common strategy to
enhance reasoning in language models. While effective for large models, we
identify a phenomenon we call Long CoT Degradation, in which small language
models (SLMs; <=3B parameters) trained on limited long CoT data experience
significant performance deterioration. Through extensive experiments on the
Qwen2.5, LLaMA3 and Gemma3 families, we demonstrate that this degradation is
widespread across SLMs. In some settings, models trained on only 8k long CoT
examples lose up to 75% of their original performance before fine-tuning.
Strikingly, we further observe that for some particularly small models, even
training on 220k long CoT examples fails to recover or surpass their original
performance prior to fine-tuning. Our analysis attributes this effect to error
accumulation: while longer responses increase the capacity for multi-step
reasoning, they also amplify the risk of compounding mistakes. Furthermore, we
find that Long CoT Degradation may negatively impacts downstream reinforcement
learning (RL), although this can be alleviated by sufficiently scaled
supervised fine-tuning (SFT). Our findings challenge common assumptions about
the benefits of long CoT training for SLMs and offer practical guidance for
building more effective small-scale reasoning models.

</details>


### [120] [Multilingual Grammatical Error Annotation: Combining Language-Agnostic Framework with Language-Specific Flexibility](https://arxiv.org/abs/2506.07719)
*Mengyang Qiu,Tran Minh Nguyen,Zihao Huang,Zelong Li,Yang Gu,Qingyu Gao,Siliang Liu,Jungyeul Park*

Main category: cs.CL

TL;DR: 介绍了一个新的多语言语法错误标注框架，改进和扩展了现有的errant，支持英语、德语、捷克语、韩语和中文，促进了跨语言GEC的一致性和可扩展性。


<details>
  <summary>Details</summary>
Motivation: 现有的语法错误标注框架如errant在扩展到不同类型的语言时存在限制，因此需要建立一个标准化、模块化的多语言框架来解决一致性和灵活性问题。

Method: 提出了一种结合语言无关基础和结构化语言特定扩展的方法，重新实现errant并利用stanza支持多语言覆盖。

Result: 该框架成功应用于包括英语、德语在内的五种语言，支持从通用标注到定制化语言细化，实现了可扩展和可解释的跨语言GEC。

Conclusion: 这项研究建立了一个标准化多语言错误标注框架，促进跨语言GEC的一致评估，并通过开源代码实现工具共享。

Abstract: Grammatical Error Correction (GEC) relies on accurate error annotation and
evaluation, yet existing frameworks, such as $\texttt{errant}$, face
limitations when extended to typologically diverse languages. In this paper, we
introduce a standardized, modular framework for multilingual grammatical error
annotation. Our approach combines a language-agnostic foundation with
structured language-specific extensions, enabling both consistency and
flexibility across languages. We reimplement $\texttt{errant}$ using
$\texttt{stanza}$ to support broader multilingual coverage, and demonstrate the
framework's adaptability through applications to English, German, Czech,
Korean, and Chinese, ranging from general-purpose annotation to more customized
linguistic refinements. This work supports scalable and interpretable GEC
annotation across languages and promotes more consistent evaluation in
multilingual settings. The complete codebase and annotation tools can be
accessed at https://github.com/open-writing-evaluation/jp_errant_bea.

</details>


### [121] [Swiss Parliaments Corpus Re-Imagined (SPC_R): Enhanced Transcription with RAG-based Correction and Predicted BLEU](https://arxiv.org/abs/2506.07726)
*Vincenzo Timmel,Manfred Vogel,Daniel Perruchoud,Reza Kakooee*

Main category: cs.CL

TL;DR: 介绍了一个新的瑞士议会语料库长文本版本，通过Whisper和GPT-4o处理音频，结合质量过滤，获得751小时高质量语音-文本对，BLEU分提升6点。


<details>
  <summary>Details</summary>
Motivation: 构建高质量长文本领域的瑞士德语语音-文本对齐语料库，尤其针对低资源领域，改进现有句级语料库的质量问题。

Method: 1. 用Whisper Large-v3将音频转写成标准德文 2. 两阶段GPT-4o修正：先对照官方协议修正命名实体，再评估语义完整性 3. 基于预测BLEU和GPT-4评分过滤低质量片段

Result: 建成801小时语料库，751小时通过质检，比原句级语料库BLEU分提高6点

Conclusion: 结合先进ASR、LLM修正和数据过滤能有效提升低资源领域语音语料的质与量

Abstract: This paper presents a new long-form release of the Swiss Parliaments Corpus,
converting entire multi-hour Swiss German debate sessions (each aligned with
the official session protocols) into high-quality speech-text pairs. Our
pipeline starts by transcribing all session audio into Standard German using
Whisper Large-v3 under high-compute settings. We then apply a two-step GPT-4o
correction process: first, GPT-4o ingests the raw Whisper output alongside the
official protocols to refine misrecognitions, mainly named entities. Second, a
separate GPT-4o pass evaluates each refined segment for semantic completeness.
We filter out any segments whose Predicted BLEU score (derived from Whisper's
average token log-probability) and GPT-4o evaluation score fall below a certain
threshold. The final corpus contains 801 hours of audio, of which 751 hours
pass our quality control. Compared to the original sentence-level SPC release,
our long-form dataset achieves a 6-point BLEU improvement, demonstrating the
power of combining robust ASR, LLM-based correction, and data-driven filtering
for low-resource, domain-specific speech corpora.

</details>


### [122] [Augmenting LLMs' Reasoning by Reinforcing Abstract Thinking](https://arxiv.org/abs/2506.07751)
*Silin Gao,Antoine Bosselut,Samy Bengio,Emmanuel Abbe*

Main category: cs.CL

TL;DR: 论文提出AbstraL方法，利用强化学习训练语言模型进行问题抽象，以提升在分布变化下的推理鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有小规模语言模型在数值/名义变量变化或插入干扰子句时推理性能显著下降。传统通过合成数据实例化的方法效果有限，而问题抽象不仅能抵抗分布偏移，还能连接符号工具求解。

Method: 开发AbstraL框架：通过强化学习训练模型产生抽象化的问题表示（而非监督微调），使用细粒度抽象数据提升抽象能力。

Result: 在GSM扰动基准测试上明显减轻了性能下降，比基线方法更有效抵御分布变化。

Conclusion: 通过RL学习抽象表示优于实例化方法，能同时提升鲁棒性和可解释性，为符号推理工具整合提供路径。

Abstract: Recent studies have shown that large language models (LLMs), especially
smaller ones, often lack robustness in their reasoning. I.e., they tend to
experience performance drops when faced with distribution shifts, such as
changes to numerical or nominal variables, or insertions of distracting
clauses. A possible strategy to address this involves generating synthetic data
to further "instantiate" reasoning problems on potential variations. In
contrast, our approach focuses on "abstracting" reasoning problems. This not
only helps counteract distribution shifts but also facilitates the connection
to symbolic tools for deriving solutions. We find that this abstraction process
is better acquired through reinforcement learning (RL) than just supervised
fine-tuning, which often fails to produce faithful abstractions. Our method,
AbstraL -- which promotes abstract reasoning in LLMs using RL on granular
abstraction data -- significantly mitigates performance degradation on recent
GSM perturbation benchmarks.

</details>


### [123] [LLM Unlearning Should Be Form-Independent](https://arxiv.org/abs/2506.07795)
*Xiaotian Ye,Mengqi Zhang,Shu Wu*

Main category: cs.CL

TL;DR: 该研究发现大型语言模型（LLM）遗忘技术存在形式依赖偏差问题，导致无法泛化到同一知识的不同表达形式。通过提出ORT基准评估该问题后，作者开发了训练无关的ROCR方法，通过重定向激活的危险概念实现高效遗忘。


<details>
  <summary>Details</summary>
Motivation: 现有遗忘技术难以应用于实际场景，因其效果过度依赖训练样本的表达形式，无法泛化到知识的不同表述方式，阻碍实用化进程。

Method: 1) 提出"形式依赖偏差"概念并设计ORT基准量化评估该问题；2) 开发Rank-one Concept Redirection (ROCR)——通过参数微调在数秒内将危险概念重定向至无害概念的免训练方法。

Result: 1) 验证形式依赖偏差在现有技术上普遍存在且严重；2) ROCR相比传统方法显著提升遗忘效果（尤其对知识变体表达），同时保持输出自然性。

Conclusion: LLM遗忘应追求形式无关性才能应对实际安全场景多样挑战。ROCR通过概念重定向机制为此提供了可行路径，并为未来建立更鲁棒的遗忘框架奠定基础。

Abstract: Large Language Model (LLM) unlearning aims to erase or suppress undesirable
knowledge within the model, offering promise for controlling harmful or private
information to prevent misuse. However, recent studies highlight its limited
efficacy in real-world scenarios, hindering practical adoption. In this study,
we identify a pervasive issue underlying many downstream failures: the
effectiveness of existing unlearning methods heavily depends on the form of
training samples and frequently fails to generalize to alternate expressions of
the same knowledge. We formally characterize this problem as Form-Dependent
Bias and systematically investigate its specific manifestation patterns across
various downstream tasks. To quantify its prevalence and support future
research, we introduce ORT, a novel benchmark designed to evaluate the
robustness of unlearning methods against variations in knowledge expression.
Results reveal that Form-Dependent Bias is both widespread and severe among
current techniques.
  We argue that LLM unlearning should be form-independent to address the
endless forms of downstream tasks encountered in real-world security-critical
scenarios. Towards this goal, we introduce Rank-one Concept Redirection (ROCR),
a novel training-free method, as a promising solution path. ROCR performs
unlearning by targeting the invariants in downstream tasks, specifically the
activated dangerous concepts. It is capable of modifying model parameters
within seconds to redirect the model's perception of a specific unlearning
target concept to another harmless concept. Extensive experiments demonstrate
that ROCR significantly improves unlearning effectiveness compared to
traditional methods while generating highly natural outputs.

</details>


### [124] [MultiMatch: Multihead Consistency Regularization Matching for Semi-Supervised Text Classification](https://arxiv.org/abs/2506.07801)
*Iustin Sirbu,Robert-Adrian Popovici,Cornelia Caragea,Stefan Trausan-Matu,Traian Rebedea*

Main category: cs.CL

TL;DR: MultiMatch：一种新的半监督学习算法，结合了协同训练和一致性正则化，通过三重伪标签加权模块在自然语言处理数据集上实现了最先进的结果。


<details>
  <summary>Details</summary>
Motivation: 现有的半监督学习方法未能充分结合不同技术（如协同训练、自适应阈值和伪间隔）的优势，同时缺乏在数据不平衡（尤其是在文本分类中常见）情况下的鲁棒性。

Method: 提出了三重伪标签加权模块：1) 基于头部模型的一致性筛选伪标签 2) 利用自适应阈值过滤 3) 根据分类难度加权，统一了Multihead Co-training、FreeMatch和MarginMatch的技术。

Result: 在5个NLP数据集的10个设置中，9项取得SOTA；Friedman测试中在19种方法中排名第一；在高度不平衡数据上比次优方法高3.26%。

Conclusion: MultiMatch通过整合三种现有技术形成统一框架，显著提升半监督学习的性能和鲁棒性，尤其在数据不平衡的文本分类任务中优势明显。

Abstract: We introduce MultiMatch, a novel semi-supervised learning (SSL) algorithm
combining the paradigms of co-training and consistency regularization with
pseudo-labeling. At its core, MultiMatch features a three-fold pseudo-label
weighting module designed for three key purposes: selecting and filtering
pseudo-labels based on head agreement and model confidence, and weighting them
according to the perceived classification difficulty. This novel module
enhances and unifies three existing techniques -- heads agreement from
Multihead Co-training, self-adaptive thresholds from FreeMatch, and Average
Pseudo-Margins from MarginMatch -- resulting in a holistic approach that
improves robustness and performance in SSL settings. Experimental results on
benchmark datasets highlight the superior performance of MultiMatch, achieving
state-of-the-art results on 9 out of 10 setups from 5 natural language
processing datasets and ranking first according to the Friedman test among 19
methods. Furthermore, MultiMatch demonstrates exceptional robustness in highly
imbalanced settings, outperforming the second-best approach by 3.26% -- and
data imbalance is a key factor for many text classification tasks.

</details>


### [125] [WebUIBench: A Comprehensive Benchmark for Evaluating Multimodal Large Language Models in WebUI-to-Code](https://arxiv.org/abs/2506.07818)
*Zhiyu Lin,Zhengda Zhou,Zhiyuan Zhao,Tianrui Wan,Yilun Ma,Junyu Gao,Xuelong Li*

Main category: cs.CL

TL;DR: 该论文提出了一个名为WebUIBench的多视图评估基准，用于系统地评估多模态大型语言模型在四个关键领域的能力：WebUI感知、HTML编程、WebUI-HTML理解以及WebUI到代码的转换。该基准包含来自700多个真实网站的21K个高质量问答对，并评估了29个主流模型以揭示其技能特点和开发过程中的弱点。


<details>
  <summary>Details</summary>
Motivation: 现有基准通常仅关注网页生成结果，而未能提供对模型在开发过程中多维子能力的评估。因此，需要构建一个多视图评估框架来准确指导开发效率的提升。

Method: 从软件工程原理中汲取灵感，创建WebUIBench基准，该基准在四个关键领域（WebUI感知、HTML编程、WebUI-HTML理解、WebUI到代码转换）系统性地评估MLLMs。基准数据包含21K个来自700+真实网站的高质量问答对。

Result: 通过对29个主流MLLMs的广泛评估，揭示了各模型在开发过程中的技能特点和多种弱点。

Conclusion: WebUIBench作为一个系统化的评估工具，能够有效识别MLLMs在网页应用开发不同阶段的能力缺陷，为后续模型改进提供方向。

Abstract: With the rapid advancement of Generative AI technology, Multimodal Large
Language Models(MLLMs) have the potential to act as AI software engineers
capable of executing complex web application development. Considering that the
model requires a confluence of multidimensional sub-capabilities to address the
challenges of various development phases, constructing a multi-view evaluation
framework is crucial for accurately guiding the enhancement of development
efficiency. However, existing benchmarks usually fail to provide an assessment
of sub-capabilities and focus solely on webpage generation outcomes. In this
work, we draw inspiration from the principles of software engineering and
further propose WebUIBench, a benchmark systematically designed to evaluate
MLLMs in four key areas: WebUI Perception, HTML Programming,WebUI-HTML
Understanding, and WebUI-to-Code. WebUIBench comprises 21K high-quality
question-answer pairs derived from over 0.7K real-world websites. The extensive
evaluation of 29 mainstream MLLMs uncovers the skill characteristics and
various weakness that models encountered during the development process.

</details>


### [126] [Learning to Focus: Causal Attention Distillation via Gradient-Guided Token Pruning](https://arxiv.org/abs/2506.07851)
*Yiju Guo,Wenkai Yang,Zexu Sun,Ning Ding,Zhiyuan Liu,Yankai Lin*

Main category: cs.CL

TL;DR: 论文介绍LeaF框架，通过两阶段干预减轻训练数据中的虚假关联影响，提升语言模型在长上下文推理中的准确性。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在长上下文推理中易受干扰模式影响，导致注意力分散。初步实验表明，移除这些干扰能显著提升性能。作者认为这是训练数据中的虚假相关性阻碍了模型识别真正的因果指令-响应关系。

Method: 提出LeaF框架：1) 利用梯度比较和教师模型自动识别混淆token；2) 在蒸馏阶段修剪这些token，使学生的注意力分布对齐教师对关键上下文的关注。

Result: LeaF在数学推理和代码生成基准上取得绝对提升，有效抑制推理中对混淆token的关注，产生更可解释可靠的模型。

Conclusion: LeaF通过干预式推理解耦混杂因子，证明专注关键上下文能显著提升语言模型的推理性能和鲁棒性。

Abstract: Large language models (LLMs) have demonstrated significant improvements in
contextual understanding. However, their ability to attend to truly critical
information during long-context reasoning and generation still falls behind the
pace. Specifically, our preliminary experiments reveal that certain distracting
patterns can misdirect the model's attention during inference, and removing
these patterns substantially improves reasoning accuracy and generation
quality. We attribute this phenomenon to spurious correlations in the training
data, which obstruct the model's capacity to infer authentic causal
instruction-response relationships. This phenomenon may induce redundant
reasoning processes, potentially resulting in significant inference overhead
and, more critically, the generation of erroneous or suboptimal responses. To
mitigate this, we introduce a two-stage framework called Learning to Focus
(LeaF) leveraging intervention-based inference to disentangle confounding
factors. In the first stage, LeaF employs gradient-based comparisons with an
advanced teacher to automatically identify confounding tokens based on causal
relationships in the training corpus. Then, in the second stage, it prunes
these tokens during distillation to enact intervention, aligning the student's
attention with the teacher's focus distribution on truly critical context
tokens. Experimental results demonstrate that LeaF not only achieves an
absolute improvement in various mathematical reasoning and code generation
benchmarks but also effectively suppresses attention to confounding tokens
during inference, yielding a more interpretable and reliable reasoning model.

</details>


### [127] [MEMOIR: Lifelong Model Editing with Minimal Overwrite and Informed Retention for LLMs](https://arxiv.org/abs/2506.07899)
*Ke Wang,Yiming Qin,Nikolaos Dimitriadis,Alessandro Favero,Pascal Frossard*

Main category: cs.CL

TL;DR: MEMOIR框架通过残差记忆模块实现语言模型的高效持续编辑，避免遗忘和干扰，支持数千次连续编辑。


<details>
  <summary>Details</summary>
Motivation: 现有方法难以高效更新语言模型知识，常导致遗忘或干扰问题。

Method: 使用样本依赖掩码稀疏化激活，将编辑隔离到残差记忆的特定参数子集；推理时通过激活模式匹配召回相关知识。

Result: 在LLaMA-3和Mistral上的实验表明，MEMOIR在问答、幻觉纠正等任务上达到SOTA，支持数千次编辑。

Conclusion: MEMOIR通过解耦核心模型和可编辑记忆模块，首次实现了大规模可靠的知识更新。

Abstract: Language models deployed in real-world systems often require post-hoc updates
to incorporate new or corrected knowledge. However, editing such models
efficiently and reliably - without retraining or forgetting previous
information - remains a major challenge. Existing methods for lifelong model
editing either compromise generalization, interfere with past edits, or fail to
scale to long editing sequences. We propose MEMOIR, a novel scalable framework
that injects knowledge through a residual memory, i.e., a dedicated parameter
module, while preserving the core capabilities of the pre-trained model. By
sparsifying input activations through sample-dependent masks, MEMOIR confines
each edit to a distinct subset of the memory parameters, minimizing
interference among edits. At inference, it identifies relevant edits by
comparing the sparse activation patterns of new queries to those stored during
editing. This enables generalization to rephrased queries by activating only
the relevant knowledge while suppressing unnecessary memory activation for
unrelated prompts. Experiments on question answering, hallucination correction,
and out-of-distribution generalization benchmarks across LLaMA-3 and Mistral
demonstrate that MEMOIR achieves state-of-the-art performance across
reliability, generalization, and locality metrics, scaling to thousands of
sequential edits with minimal forgetting.

</details>


### [128] [MiniCPM4: Ultra-Efficient LLMs on End Devices](https://arxiv.org/abs/2506.07900)
*MiniCPM Team,Chaojun Xiao,Yuxuan Li,Xu Han,Yuzhuo Bai,Jie Cai,Haotian Chen,Wentong Chen,Xin Cong,Ganqu Cui,Ning Ding,Shengdan Fan,Yewei Fang,Zixuan Fu,Wenyu Guan,Yitong Guan,Junshao Guo,Yufeng Han,Bingxiang He,Yuxiang Huang,Cunliang Kong,Qiuzuo Li,Siyuan Li,Wenhao Li,Yanghao Li,Yishan Li,Zhen Li,Dan Liu,Biyuan Lin,Yankai Lin,Xiang Long,Quanyu Lu,Yaxi Lu,Peiyan Luo,Hongya Lyu,Litu Ou,Yinxu Pan,Zekai Qu,Qundong Shi,Zijun Song,Jiayuan Su,Zhou Su,Ao Sun,Xianghui Sun,Peijun Tang,Fangzheng Wang,Feng Wang,Shuo Wang,Yudong Wang,Yesai Wu,Zhenyu Xiao,Jie Xie,Zihao Xie,Yukun Yan,Jiarui Yuan,Kaihuo Zhang,Lei Zhang,Linyue Zhang,Xueren Zhang,Yudi Zhang,Hengyu Zhao,Weilin Zhao,Weilun Zhao,Yuanqian Zhao,Zhi Zheng,Ge Zhou,Jie Zhou,Wei Zhou,Zihan Zhou,Zixuan Zhou,Zhiyuan Liu,Guoyang Zeng,Chao Jia,Dahai Li,Maosong Sun*

Main category: cs.CL

TL;DR: MiniCPM4 是一个高效的大型语言模型，专为终端设备设计，通过模型架构、训练数据、训练算法和推理系统四方面的创新实现高效性。包括提出 InfLLM v2、UltraClean 和 UltraChat v2 数据集、ModelTunnel v2 训练策略以及 CPM.cu 推理系统。提供了 0.5B 和 8B 两种参数规模的版本，在多个基准测试中优于同类开源模型，特别是在长序列处理上速度更快。


<details>
  <summary>Details</summary>
Motivation: 为了解决终端设备上运行大型语言模型存在的效率问题，需要针对模型架构、训练数据、训练算法和推理系统进行系统性优化，以适应设备资源限制并提升性能。

Method: 1. 模型架构：提出 InfLLM v2 可训练稀疏注意力机制，加速长上下文处理的预填充和解码阶段。
2. 训练数据：开发 UltraClean（高效预训练数据过滤生成策略）和 UltraChat v2（全面监督微调数据集）。
3. 训练算法：提出 ModelTunnel v2 高效预训练策略搜索；改进后训练方法（块状 rollout 负载均衡 RL 和数据高效 Ternary LLM BitCPM）。
4. 推理系统：集成稀疏注意力、模型量化和推测采样的 CPM.cu 系统。
5. 发布 0.5B 和 8B 两种参数量版本。

Result: MiniCPM4 在多个基准测试上优于同类规模的开源模型。特别是 MiniCPM4-8B 在处理长序列时比 Qwen3-8B 速度显著更快。成功应用于可信调查生成和模型上下文协议的工具使用等场景。

Conclusion: MiniCPM4 通过系统性创新实现了终端设备上的高效 LLM 部署，在性能和速度方面表现出色，且展示了广泛的适用性。

Abstract: This paper introduces MiniCPM4, a highly efficient large language model (LLM)
designed explicitly for end-side devices. We achieve this efficiency through
systematic innovation in four key dimensions: model architecture, training
data, training algorithms, and inference systems. Specifically, in terms of
model architecture, we propose InfLLM v2, a trainable sparse attention
mechanism that accelerates both prefilling and decoding phases for long-context
processing. Regarding training data, we propose UltraClean, an efficient and
accurate pre-training data filtering and generation strategy, and UltraChat v2,
a comprehensive supervised fine-tuning dataset. These datasets enable
satisfactory model performance to be achieved using just 8 trillion training
tokens. Regarding training algorithms, we propose ModelTunnel v2 for efficient
pre-training strategy search, and improve existing post-training methods by
introducing chunk-wise rollout for load-balanced reinforcement learning and
data-efficient tenary LLM, BitCPM. Regarding inference systems, we propose
CPM.cu that integrates sparse attention, model quantization, and speculative
sampling to achieve efficient prefilling and decoding. To meet diverse
on-device requirements, MiniCPM4 is available in two versions, with 0.5B and 8B
parameters, respectively. Sufficient evaluation results show that MiniCPM4
outperforms open-source models of similar size across multiple benchmarks,
highlighting both its efficiency and effectiveness. Notably, MiniCPM4-8B
demonstrates significant speed improvements over Qwen3-8B when processing long
sequences. Through further adaptation, MiniCPM4 successfully powers diverse
applications, including trustworthy survey generation and tool use with model
context protocol, clearly showcasing its broad usability.

</details>


### [129] [Quantum Graph Transformer for NLP Sentiment Classification](https://arxiv.org/abs/2506.07937)
*Shamminuj Aktar,Andreas Bärtschi,Abdel-Hameed A. Badawy,Stephan Eidenbenz*

Main category: cs.CL

TL;DR: 提出了量子图变换模型QGT，结合量子自注意力机制和图传递框架，用于结构化语言建模，在情感分类任务中优于现有量子NLP模型，且样本效率更高。


<details>
  <summary>Details</summary>
Motivation: 结合量子机器学习的优势（高效性和表达力）来解决结构化数据（如自然语言）中的复杂关系建模问题，同时通过量子自注意力减少可训练参数。

Method: 开发量子图变换模型QGT：将参数化量子电路（PQC）实现的自注意力机制整合到图传递框架中，用于结构化语言建模。

Result: 在五个情感分类基准测试中：1）准确率优于现有量子NLP模型；2）比经典图变换模型平均提升5.42%（真实数据集）和4.76%（合成数据集）；3）在Yelp数据集上达到同等性能所需标注样本减少50%。

Conclusion: 该研究证明了基于图的量子自然语言处理技术在推动高效、可扩展语言理解方面的潜力。

Abstract: Quantum machine learning is a promising direction for building more efficient
and expressive models, particularly in domains where understanding complex,
structured data is critical. We present the Quantum Graph Transformer (QGT), a
hybrid graph-based architecture that integrates a quantum self-attention
mechanism into the message-passing framework for structured language modeling.
The attention mechanism is implemented using parameterized quantum circuits
(PQCs), which enable the model to capture rich contextual relationships while
significantly reducing the number of trainable parameters compared to classical
attention mechanisms. We evaluate QGT on five sentiment classification
benchmarks. Experimental results show that QGT consistently achieves higher or
comparable accuracy than existing quantum natural language processing (QNLP)
models, including both attention-based and non-attention-based approaches. When
compared with an equivalent classical graph transformer, QGT yields an average
accuracy improvement of 5.42% on real-world datasets and 4.76% on synthetic
datasets. Additionally, QGT demonstrates improved sample efficiency, requiring
nearly 50% fewer labeled samples to reach comparable performance on the Yelp
dataset. These results highlight the potential of graph-based QNLP techniques
for advancing efficient and scalable language understanding.

</details>


### [130] [Statistical Hypothesis Testing for Auditing Robustness in Language Models](https://arxiv.org/abs/2506.07947)
*Paulius Rauba,Qiyao Wei,Mihaela van der Schaar*

Main category: cs.CL

TL;DR: 提出基于分布的扰动分析框架，用于测试大型语言模型在干预下输出变化，通过蒙特卡洛采样构建低维语义空间的经验分布，实现可处理的假设检验。


<details>
  <summary>Details</summary>
Motivation: 现有方法无法解决由模型随机性导致的输出对比难题，且无法在计算可行的情况下比较整个输出分布。专门针对LLM扰动分析的方法缺失。

Method: 在低维语义相似度空间中，通过蒙特卡洛采样构建原假设和备择假设的经验输出分布，执行频率派假设检验。支持任意输入扰动和黑盒模型。

Result: 框架具备模型无关性、可解释p值、多重扰动控制、效应量报告等特性。案例研究验证其在量化响应变化、测量正误报率、模型对齐评估中的有效性。

Conclusion: 该频率派假设检验框架为LLM审计提供了可靠工具，能系统分析干预对输出的影响。

Abstract: Consider the problem of testing whether the outputs of a large language model
(LLM) system change under an arbitrary intervention, such as an input
perturbation or changing the model variant. We cannot simply compare two LLM
outputs since they might differ due to the stochastic nature of the system, nor
can we compare the entire output distribution due to computational
intractability. While existing methods for analyzing text-based outputs exist,
they focus on fundamentally different problems, such as measuring bias or
fairness. To this end, we introduce distribution-based perturbation analysis, a
framework that reformulates LLM perturbation analysis as a frequentist
hypothesis testing problem. We construct empirical null and alternative output
distributions within a low-dimensional semantic similarity space via Monte
Carlo sampling, enabling tractable inference without restrictive distributional
assumptions. The framework is (i) model-agnostic, (ii) supports the evaluation
of arbitrary input perturbations on any black-box LLM, (iii) yields
interpretable p-values; (iv) supports multiple perturbations via controlled
error rates; and (v) provides scalar effect sizes. We demonstrate the
usefulness of the framework across multiple case studies, showing how we can
quantify response changes, measure true/false positive rates, and evaluate
alignment with reference models. Above all, we see this as a reliable
frequentist hypothesis testing framework for LLM auditing.

</details>


### [131] [Language Models over Canonical Byte-Pair Encodings](https://arxiv.org/abs/2506.07956)
*Tim Vieira,Tianyu Liu,Clemente Pasti,Yahya Emara,Brian DuSell,Benjamin LeBrun,Mario Giulianelli,Juan Luis Gastaldi,Timothy J. O'Donnell,Ryan Cotterell*

Main category: cs.CL

TL;DR: 当前基于token的语言模型会将概率分配给大量无法在训练数据中出现的非标准token序列（解码后为有效字符串但token化方式不可能出现）。这浪费了概率质量，降低了模型效率。本文提出两种方法：条件约束法（无需训练）和构造法（需训练）来确保只生成标准token序列，提高了模型似然性能。


<details>
  <summary>Details</summary>
Motivation: 现有token化语言模型将概率质量错误分配给了不可能出现的非标准token序列。这不仅造成概率资源的浪费，还会降低模型性能。因为任何大小的训练语料库中都不会包含这些序列，所以模型错误地赋予它们正概率是不合理的。

Method: 1. 条件约束法（无需训练）：在推理阶段通过控制策略强制只输出标准token序列。<br>2. 构造法（需训练）：修改模型参数化方式，从根本上保证输出的token序列必然是标准形式。

Result: 通过在多个模型和语料上的实验表明：修正这些非标准序列错误能有效提高测试数据的似然度（即提升模型评估性能）。

Conclusion: 强制语言模型只输出标准token序列能有效提升模型效率。两种提出的方法均成功解决了非标准序列分配概率的问题，减少了概率资源浪费，且实际提升了语言模型的性能指标。

Abstract: Modern language models represent probability distributions over character
strings as distributions over (shorter) token strings derived via a
deterministic tokenizer, such as byte-pair encoding. While this approach is
highly effective at scaling up language models to large corpora, its current
incarnations have a concerning property: the model assigns nonzero probability
mass to an exponential number of $\it{noncanonical}$ token encodings of each
character string -- these are token strings that decode to valid character
strings but are impossible under the deterministic tokenizer (i.e., they will
never be seen in any training corpus, no matter how large). This misallocation
is both erroneous, as noncanonical strings never appear in training data, and
wasteful, diverting probability mass away from plausible outputs. These are
avoidable mistakes! In this work, we propose methods to enforce canonicality in
token-level language models, ensuring that only canonical token strings are
assigned positive probability. We present two approaches: (1) canonicality by
conditioning, leveraging test-time inference strategies without additional
training, and (2) canonicality by construction, a model parameterization that
guarantees canonical outputs but requires training. We demonstrate that fixing
canonicality mistakes improves the likelihood of held-out data for several
models and corpora.

</details>


### [132] [Correlated Errors in Large Language Models](https://arxiv.org/abs/2506.07962)
*Elliot Kim,Avi Garg,Kenny Peng,Nikhil Garg*

Main category: cs.CL

TL;DR: 350个LLM的实证研究表明，不同模型的错误高度相关，即使架构和提供商不同，更大更强的模型也是如此，这对下游任务如AI评委和招聘中的算法单一文化有影响。


<details>
  <summary>Details</summary>
Motivation: 探讨多样性假设（数据、架构、提供商）是否能真正降低LLM的同质性，缺乏实证证据验证不同LLM是否有显著差异。

Method: 使用两个主流排行榜和一个简历筛选任务对350多个LLM进行大规模评估，分析错误相关性及驱动因素（如共享架构、提供商）。

Result: 模型错误高度相关（某排行榜数据中错误一致率达60%）；更大更强模型即使架构提供商不同也高度相关；共享架构/提供商是影响因素但非唯一原因。

Conclusion: 挑战了多样性降低同质性的假设，揭示规模化放大了算法单一文化风险，尤其在招聘等场景需警惕模型错误相关性。

Abstract: Diversity in training data, architecture, and providers is assumed to
mitigate homogeneity in LLMs. However, we lack empirical evidence on whether
different LLMs differ meaningfully. We conduct a large-scale empirical
evaluation on over 350 LLMs overall, using two popular leaderboards and a
resume-screening task. We find substantial correlation in model errors -- on
one leaderboard dataset, models agree 60% of the time when both models err. We
identify factors driving model correlation, including shared architectures and
providers. Crucially, however, larger and more accurate models have highly
correlated errors, even with distinct architectures and providers. Finally, we
show the effects of correlation in two downstream tasks: LLM-as-judge
evaluation and hiring -- the latter reflecting theoretical predictions
regarding algorithmic monoculture.

</details>


### [133] [Reinforcement Pre-Training](https://arxiv.org/abs/2506.08007)
*Qingxiu Dong,Li Dong,Yao Tang,Tianzhu Ye,Yutao Sun,Zhifang Sui,Furu Wei*

Main category: cs.CL

TL;DR: RPT reframes next-token prediction as a reinforcement learning task with verifiable rewards, providing a scalable method for pre-training LLMs and improving language modeling accuracy.


<details>
  <summary>Details</summary>
Motivation: Current methods rely on domain-specific annotated answers. RPT leverages vast text data for general reinforcement learning by turning next-token prediction into a reasoning task with intrinsic rewards.

Method: Using Reinforcement Pre-Training (RPT) where models receive rewards for correct next-token predictions. RPT creates RL training signals from unlabeled text without domain-specific annotations.

Result: RPT improves next-token prediction accuracy and provides stronger foundation for downstream RL fine-tuning. Scaling curves demonstrate accuracy improvements with increased compute.

Conclusion: RPT is an effective scaling paradigm that advances LLM pre-training by integrating reinforcement learning principles with next-token prediction.

Abstract: In this work, we introduce Reinforcement Pre-Training (RPT) as a new scaling
paradigm for large language models and reinforcement learning (RL).
Specifically, we reframe next-token prediction as a reasoning task trained
using RL, where it receives verifiable rewards for correctly predicting the
next token for a given context. RPT offers a scalable method to leverage vast
amounts of text data for general-purpose RL, rather than relying on
domain-specific annotated answers. By incentivizing the capability of
next-token reasoning, RPT significantly improves the language modeling accuracy
of predicting the next tokens. Moreover, RPT provides a strong pre-trained
foundation for further reinforcement fine-tuning. The scaling curves show that
increased training compute consistently improves the next-token prediction
accuracy. The results position RPT as an effective and promising scaling
paradigm to advance language model pre-training.

</details>


### [134] [How Significant Are the Real Performance Gains? An Unbiased Evaluation Framework for GraphRAG](https://arxiv.org/abs/2506.06331)
*Qiming Zeng,Xiao Yan,Hao Luo,Yuhao Lin,Yuxiang Wang,Fangcheng Fu,Bo Du,Quanqing Xu,Jiawei Jiang*

Main category: cs.CL

TL;DR: 该论文发现现有的GraphRAG评估框架存在与问题不相关和评估偏差两个关键缺陷，提出了一种基于图文本接地的问题生成和无偏评估程序的新框架。应用该框架对三种代表性GraphRAG方法进行评估后发现，其性能提升远低于先前报告。


<details>
  <summary>Details</summary>
Motivation: 当前基于知识图谱的检索增强生成(GraphRAG)方法的评估框架存在两个关键缺陷：无关问题和评估偏差，这可能导致对性能得出错误结论。

Method: 提出无偏评估框架，包含两个核心组件：1)基于图文本接地的问题生成方法，产生与底层数据集更相关的问题；2)无偏评估程序，消除基于LLM的答案评估中的偏差。

Result: 应用新框架评估3种代表性GraphRAG方法后发现，其性能增益比先前报告的结果要温和得多（即性能提升幅度远低于预期）。

Conclusion: 虽然提出的评估框架可能仍存在缺陷，但它强调需要进行科学评估来为GraphRAG研究奠定坚实基础，并揭示了当前方法被高估的性能增益。

Abstract: By retrieving contexts from knowledge graphs, graph-based retrieval-augmented
generation (GraphRAG) enhances large language models (LLMs) to generate quality
answers for user questions. Many GraphRAG methods have been proposed and
reported inspiring performance in answer quality. However, we observe that the
current answer evaluation framework for GraphRAG has two critical flaws, i.e.,
unrelated questions and evaluation biases, which may lead to biased or even
wrong conclusions on performance. To tackle the two flaws, we propose an
unbiased evaluation framework that uses graph-text-grounded question generation
to produce questions that are more related to the underlying dataset and an
unbiased evaluation procedure to eliminate the biases in LLM-based answer
assessment. We apply our unbiased framework to evaluate 3 representative
GraphRAG methods and find that their performance gains are much more moderate
than reported previously. Although our evaluation framework may still have
flaws, it calls for scientific evaluations to lay solid foundations for
GraphRAG research.

</details>


### [135] [TESU-LLM: Training Speech-LLMs Without Speech via Unified Encoder Alignment](https://arxiv.org/abs/2506.06343)
*Taesoo Kim,Jong Hwan Ko*

Main category: cs.CL

TL;DR: TESU-LLM 是一个仅使用文本数据训练语音语言模型的新框架，通过统一编码器将语音映射到与文本共享的隐空间，无需配对语音文本数据即可实现高性能。


<details>
  <summary>Details</summary>
Motivation: 现有语音模型依赖大规模配对语音文本数据和大量算力，这限制了其可扩展性和可用性。本文旨在开发不依赖语音数据的语音语言模型。

Method: 采用统一编码器将语义等效的语音和文本映射到共享隐空间，并通过轻量投影网络对齐LLM嵌入空间，实现仅文本监督下的训练和语音推理泛化。

Result: 在多个语音基准测试中达到与基于大规模多模态数据训练的基线相当的性能，证明方法高效且有效。

Conclusion: TESU-LLM 为无需语音数据的语音语言模型训练提供可扩展途径，解决数据资源瓶颈问题。

Abstract: Recent advances in speech-enabled language models have shown promising
results in building intelligent voice assistants. However, most existing
approaches rely on large-scale paired speech-text data and extensive
computational resources, which pose challenges in terms of scalability and
accessibility. In this paper, we present \textbf{TESU-LLM}, a novel framework
that enables training speech-capable language models using only text data. Our
key insight is to leverage a unified encoder that maps semantically equivalent
text and speech inputs to a shared latent space. By aligning the encoder output
with the embedding space of a LLM via a lightweight projection network, we
enable the model to generalize from text-only supervision to speech-based
inference. Despite being trained exclusively on text, TESU-LLM achieves strong
performance on various speech-related benchmarks, comparable to baseline
methods trained with large-scale multimodal datasets and substantial
computational resources. These results highlight the effectiveness and
efficiency of our approach, offering a scalable path toward building speech
LLMs without speech data.

</details>


### [136] [Unified Game Moderation: Soft-Prompting and LLM-Assisted Label Transfer for Resource-Efficient Toxicity Detection](https://arxiv.org/abs/2506.06347)
*Zachary Yang,Domenico Tullo,Reihaneh Rabbany*

Main category: cs.CL

TL;DR: 为了解决多游戏多语言环境下游戏社区实时毒性检测的扩展性难题，本工作提出两项关键技术：1)基于软提示的游戏上下文统一建模，2)GPT-4o辅助的多语言标注迁移。在7种语言上实现32.96%-58.88%的F1值，部署后每日每款游戏平均捕获50名违规玩家。


<details>
  <summary>Details</summary>
Motivation: 现有毒性检测系统在跨游戏跨语言扩展时面临计算效率和维护成本挑战，需在保持实时性能的同时降低多游戏多语言场景的部署复杂度。

Method: 1)设计游戏上下文软提示方法实现单模型多游戏适配；2)利用GPT-4o-mini构建标注迁移框架扩展多语言支持

Result: 德语F1值超越英文基准(45.39%)，德/法/葡/俄四语F1区间32.96%-58.88%；生产环境计算资源与维护开销显著降低

Conclusion: 软提示与LLM辅助框架的协同方案可有效解决跨平台毒性检测的扩展瓶颈，统一模型在Ubisoft每日捕获50名/游戏违规玩家

Abstract: Toxicity detection in gaming communities faces significant scaling challenges
when expanding across multiple games and languages, particularly in real-time
environments where computational efficiency is crucial. We present two key
findings to address these challenges while building upon our previous work on
ToxBuster, a BERT-based real-time toxicity detection system. First, we
introduce a soft-prompting approach that enables a single model to effectively
handle multiple games by incorporating game-context tokens, matching the
performance of more complex methods like curriculum learning while offering
superior scalability. Second, we develop an LLM-assisted label transfer
framework using GPT-4o-mini to extend support to seven additional languages.
Evaluations on real game chat data across French, German, Portuguese, and
Russian achieve macro F1-scores ranging from 32.96% to 58.88%, with
particularly strong performance in German, surpassing the English benchmark of
45.39%. In production, this unified approach significantly reduces
computational resources and maintenance overhead compared to maintaining
separate models for each game and language combination. At Ubisoft, this model
successfully identifies an average of 50 players, per game, per day engaging in
sanctionable behavior.

</details>


### [137] [Relationship Detection on Tabular Data Using Statistical Analysis and Large Language Models](https://arxiv.org/abs/2506.06371)
*Panagiotis Koletsis,Christos Panagiotopoulos,Georgios Th. Papadopoulos,Vasilis Efthymiou*

Main category: cs.CL

TL;DR: 提出了一种混合方法，使用知识图谱（KG）检测未标记表格数据中列间的关系（CPA任务），结合大语言模型（LLM）和统计分析来减少KG关系搜索空间。


<details>
  <summary>Details</summary>
Motivation: 表格解释任务在新技术和基准测试推动下进展显著，但未标记表格的列关系检测需要高效方法以减少人工标注成本并提高准确性。

Method: 基于知识图谱构建混合框架：1）利用域和范围约束检测 2）关系共现分析缩减搜索空间；结合LLMs预测关系，测试不同量化级别的LLM及提示技术。

Result: 在SemTab挑战赛的两个基准数据集上评估，各模块均有效提升性能；不同LLMs在量化后仍保持竞争力，整体方法达到SOTA水平。

Conclusion: 混合方法（统计缩减搜索空间+LLMs预测）可高效解决CPA任务，代码已开源；量化对LLMs性能影响有限，提示工程是关键因素之一。

Abstract: Over the past few years, table interpretation tasks have made significant
progress due to their importance and the introduction of new technologies and
benchmarks in the field. This work experiments with a hybrid approach for
detecting relationships among columns of unlabeled tabular data, using a
Knowledge Graph (KG) as a reference point, a task known as CPA. This approach
leverages large language models (LLMs) while employing statistical analysis to
reduce the search space of potential KG relations. The main modules of this
approach for reducing the search space are domain and range constraints
detection, as well as relation co-appearance analysis. The experimental
evaluation on two benchmark datasets provided by the SemTab challenge assesses
the influence of each module and the effectiveness of different
state-of-the-art LLMs at various levels of quantization. The experiments were
performed, as well as at different prompting techniques. The proposed
methodology, which is publicly available on github, proved to be competitive
with state-of-the-art approaches on these datasets.

</details>


### [138] [Enhancing Decision-Making of Large Language Models via Actor-Critic](https://arxiv.org/abs/2506.06376)
*Heng Dong,Kefei Duan,Chongjie Zhang*

Main category: cs.CL

TL;DR: 提出了LAC框架，一种基于LLM的Actor-Critic方法，通过长期动作评估改进LLM在多步决策任务中的性能，解决了现有方法在长期推理和结果评估上的局限。


<details>
  <summary>Details</summary>
Motivation: 现有LLM在复杂决策场景中存在局限：短时自回归动作生成无法进行长期推理；现有方法难以准确模拟推演和评估结果。需要一种能结合长期评估改进策略的框架。

Method: LAC框架包含两个关键技术：(1) 通过正/负面结果相关的token logits计算Q值，结合未来轨迹推演增强评估；(2) 采用无需梯度的策略改进机制。在ALFWorld、BabyAI-Text、WebShop三个环境中验证。

Result: 在多个环境超越SOTA方法。使用7B/8B参数模型即达到强竞争力，在复杂任务中甚至优于使用GPT-4的基线方法。

Conclusion: LAC证明了将结构化策略优化与LLM内在知识结合的有效性，显著提升了多步环境中的决策能力，为LLM决策研究提供新方向。

Abstract: Large Language Models (LLMs) have achieved remarkable advancements in natural
language processing tasks, yet they encounter challenges in complex
decision-making scenarios that require long-term reasoning and alignment with
high-level objectives. Existing methods either rely on short-term
auto-regressive action generation or face limitations in accurately simulating
rollouts and assessing outcomes, leading to sub-optimal decisions. This paper
introduces a novel LLM-based Actor-Critic framework, termed LAC, that
effectively improves LLM policies with long-term action evaluations in a
principled and scalable way. Our approach addresses two key challenges: (1)
extracting robust action evaluations by computing Q-values via token logits
associated with positive/negative outcomes, enhanced by future trajectory
rollouts and reasoning; and (2) enabling efficient policy improvement through a
gradient-free mechanism. Experiments across diverse environments -- including
high-level decision-making (ALFWorld), low-level action spaces (BabyAI-Text),
and large action spaces (WebShop) -- demonstrate the framework's generality and
superiority over state-of-the-art methods. Notably, our approach achieves
competitive performance using 7B/8B parameter LLMs, even outperforming baseline
methods employing GPT-4 in complex tasks. These results underscore the
potential of integrating structured policy optimization with LLMs' intrinsic
knowledge to advance decision-making capabilities in multi-step environments.

</details>


### [139] [Detection Method for Prompt Injection by Integrating Pre-trained Model and Heuristic Feature Engineering](https://arxiv.org/abs/2506.06384)
*Yi Ji,Runzhi Li,Baolei Mao*

Main category: cs.CL

TL;DR: 基于双通道特征融合的DMPI-PMHFE框架，通过结合预训练语言模型和启发式特征工程有效检测提示注入攻击，在多项指标上超越现有方法


<details>
  <summary>Details</summary>
Motivation: 现有提示注入防御机制存在效果与泛化性之间的矛盾，需开发通用性强的高效检测方案

Method: 1) 使用DeBERTa-v3-base提取语义向量 2) 基于攻击模式设计启发式规则提取结构特征 3) 双通道特征融合后经全连接网络分类

Result: 在多基准测试中准确率、召回率和F1值全面领先；实际部署显著降低GLM-4/LLaMA3/Qwen2.5/GPT-4o等主流LLM攻击成功率

Conclusion: 双通道特征融合策略有效平衡语义理解与模式识别，为跨模型提示注入防御提供通用解决方案

Abstract: With the widespread adoption of Large Language Models (LLMs), prompt
injection attacks have emerged as a significant security threat. Existing
defense mechanisms often face critical trade-offs between effectiveness and
generalizability. This highlights the urgent need for efficient prompt
injection detection methods that are applicable across a wide range of LLMs. To
address this challenge, we propose DMPI-PMHFE, a dual-channel feature fusion
detection framework. It integrates a pretrained language model with heuristic
feature engineering to detect prompt injection attacks. Specifically, the
framework employs DeBERTa-v3-base as a feature extractor to transform input
text into semantic vectors enriched with contextual information. In parallel,
we design heuristic rules based on known attack patterns to extract explicit
structural features commonly observed in attacks. Features from both channels
are subsequently fused and passed through a fully connected neural network to
produce the final prediction. This dual-channel approach mitigates the
limitations of relying only on DeBERTa to extract features. Experimental
results on diverse benchmark datasets demonstrate that DMPI-PMHFE outperforms
existing methods in terms of accuracy, recall, and F1-score. Furthermore, when
deployed actually, it significantly reduces attack success rates across
mainstream LLMs, including GLM-4, LLaMA 3, Qwen 2.5, and GPT-4o.

</details>


### [140] [Confidence Is All You Need: Few-Shot RL Fine-Tuning of Language Models](https://arxiv.org/abs/2506.06395)
*Pengyi Li,Matvey Skripkin,Alexander Zubrey,Andrey Kuznetsov,Ivan Oseledets*

Main category: cs.CL

TL;DR: 提出了一种名为RLSC的自信心强化学习方法，利用模型自身置信度作为奖励信号，无需外部奖励模型或人工标注。在Qwen2.5-Math-7B模型上使用少量样本进行训练，显著提升了多个数学基准测试的准确率。


<details>
  <summary>Details</summary>
Motivation: 现有强化学习方法需要昂贵的人工标注或外部奖励模型，这限制了大型语言模型（LLMs）在推理任务中的应用效率与可扩展性。

Method: 提出了基于自信心的强化学习（RLSC）框架，利用模型自身生成的置信度分数作为奖励信号进行微调。

Result: 在每问仅用8样本和4训练周期的条件下：AIME2024准确率提升20.10%，MATH500提升49.40%，AMC23提升52.50%。

Conclusion: RLSC提供了一种简单、可扩展且需极少监督的推理模型微调方法。

Abstract: Large language models (LLMs) excel at reasoning, yet post-training remains
critical for aligning their behavior with task goals. Existing reinforcement
learning (RL) methods often depend on costly human annotations or external
reward models. We propose Reinforcement Learning via Self-Confidence (RLSC),
which uses the model's own confidence as reward signals-eliminating the need
for labels, preference models, or reward engineering. Applied to
Qwen2.5-Math-7B with only 8 samples per question and 4 training epochs, RLSC
improves accuracy by +20.10% on AIME2024, +49.40% on MATH500, and +52.50% on
AMC23. RLSC offers a simple, scalable post-training method for reasoning models
with minimal supervision.

</details>


### [141] [Natural Language Interaction with Databases on Edge Devices in the Internet of Battlefield Things](https://arxiv.org/abs/2506.06396)
*Christopher D. Molek,Roberto Fronteddu,K. Brent Venable,Niranjan Suri*

Main category: cs.CL

TL;DR: 该论文提出一种利用自然语言处理（NLP）和大型语言模型（LLMs）的工作流，使战场物联网（IoBT）设备数据可通过自然语言查询数据库并以自然语言返回结果，便于关键决策中的态势感知。实验表明，采用两步法放宽Cypher查询的精确匹配要求后，准确率提升19.4%。


<details>
  <summary>Details</summary>
Motivation: 战场物联网（IoBT）设备产生的大量数据需转化为可消费信息以增强态势感知，但现有方法需要精确匹配数据库查询语句，限制了可用性。

Method: 1）使用适合边缘设备的中型LLMs将自然语言问题转换为Cypher数据库查询；2）用LLMs将数据库输出总结为自然语言响应；3）在美军多用途传感区数据集上测试多种中型LLMs。

Result: Llama 3.1（80亿参数）表现最佳，采用两步法后准确率提升19.4%（相较于要求Cypher查询完全精确匹配的传统方法）。

Conclusion: 该工作流通过边缘部署的LLMs实现自然语言交互，提升关键决策信息获取效率，且放宽精确匹配要求显著提高系统实用性。

Abstract: The expansion of the Internet of Things (IoT) in the battlefield, Internet of
Battlefield Things (IoBT), gives rise to new opportunities for enhancing
situational awareness. To increase the potential of IoBT for situational
awareness in critical decision making, the data from these devices must be
processed into consumer-ready information objects, and made available to
consumers on demand. To address this challenge we propose a workflow that makes
use of natural language processing (NLP) to query a database technology and
return a response in natural language. Our solution utilizes Large Language
Models (LLMs) that are sized for edge devices to perform NLP as well as
graphical databases which are well suited for dynamic connected networks which
are pervasive in the IoBT. Our architecture employs LLMs for both mapping
questions in natural language to Cypher database queries as well as to
summarize the database output back to the user in natural language. We evaluate
several medium sized LLMs for both of these tasks on a database representing
publicly available data from the US Army's Multipurpose Sensing Area (MSA) at
the Jornada Range in Las Cruces, NM. We observe that Llama 3.1 (8 billion
parameters) outperforms the other models across all the considered metrics.
Most importantly, we note that, unlike current methods, our two step approach
allows the relaxation of the Exact Match (EM) requirement of the produced
Cypher queries with ground truth code and, in this way, it achieves a 19.4%
increase in accuracy. Our workflow lays the ground work for deploying LLMs on
edge devices to enable natural language interactions with databases containing
information objects for critical decision making.

</details>


### [142] [Direct Behavior Optimization: Unlocking the Potential of Lightweight LLMs](https://arxiv.org/abs/2506.06401)
*Hongming Yang,Shi Lin,Jun Shao,Changting Lin,Donghai Zhu,Meng Han,Qinglei Kong*

Main category: cs.CL

TL;DR: 本文介绍了 DeBoP，一种用于轻量级大语言模型（LwLLMs）的直接行为优化范式，旨在解决 LwLLMs 在推理能力和复杂任务中的局限性，通过无梯度蒙特卡洛树搜索优化执行路径，在七项任务中超越其他方法，性能接近 GPT-3.5 的同时减少计算时间


<details>
  <summary>Details</summary>
Motivation: 轻量级大语言模型（LwLLMs）能在消费级硬件上高效运行，但推理能力有限，难以处理复杂任务；现有提示优化方法依赖人工或强模型，对 LwLLMs 效果不足

Method: DeBoP 范式：将复杂提示优化转化为离散可量化执行路径的优化，采用无梯度蒙特卡洛树搜索，直接优化 LwLLMs 的行为输出

Result: 在 LwLLMs 薄弱但顶级模型表现良好的七项任务中：DeBoP 显著超越现有提示优化方法，优化后的 LwLLMs 多数任务超过 GPT-3.5 性能，且计算耗时减少约 60%

Conclusion: DeBoP 为 LwLLMs 提供了一种自动、高效的提示优化方案，扩展了轻量模型在复杂任务中的应用潜力，证明行为级直接优化可弥合与大型模型的性能差距

Abstract: Lightweight Large Language Models (LwLLMs) are reduced-parameter, optimized
models designed to run efficiently on consumer-grade hardware, offering
significant advantages in resource efficiency, cost-effectiveness, and data
privacy. However, these models often struggle with limited inference and
reasoning capabilities, which restrict their performance on complex tasks and
limit their practical applicability. Moreover, existing prompt optimization
methods typically rely on extensive manual effort or the meta-cognitive
abilities of state-of-the-art LLMs, making them less effective for LwLLMs. To
address these challenges, we introduce DeBoP, a new Direct Behavior
Optimization Paradigm, original from the Chain-of-Thought (CoT) prompting
technique. Unlike CoT Prompting, DeBoP is an automatic optimization method,
which focuses on the optimization directly on the behavior of LwLLMs. In
particular, DeBoP transforms the optimization of complex prompts into the
optimization of discrete, quantifiable execution sequences using a
gradient-free Monte Carlo Tree Search. We evaluate DeBoP on seven challenging
tasks where state-of-the-art LLMs excel but LwLLMs generally underperform.
Experimental results demonstrate that DeBoP significantly outperforms recent
prompt optimization methods on most tasks. In particular, DeBoP-optimized
LwLLMs surpass GPT-3.5 on most tasks while reducing computational time by
approximately 60% compared to other automatic prompt optimization methods.

</details>


### [143] [Unintended Harms of Value-Aligned LLMs: Psychological and Empirical Insights](https://arxiv.org/abs/2506.06404)
*Sooyung Choi,Jaehyeok Lee,Xiaoyuan Yi,Jing Yao,Xing Xie,JinYeong Bak*

Main category: cs.CL

TL;DR: 本文研究了与人类价值观对齐的大型语言模型（LLMs）的安全风险，发现价值观对齐会增加模型的有害行为倾向，并揭示了其背后的心理机制。作者通过实验证明价值观对齐模型比未微调模型更具危害性，且比一般微调模型略危险，并提出了上下文对齐方法来提升安全性。


<details>
  <summary>Details</summary>
Motivation: 随着个性化大模型应用的扩展，价值观对齐可能放大安全风险：某些价值观会关联有害信息，需要系统评估这种风险并探索缓解方法。

Method: 研究者识别价值观对齐模型的安全风险类别，通过构造包含详细安全类别的数据集进行实验，对比分析微调/未微调模型的危害性差异，并结合心理学原理解释现象机制。

Result: 实验发现：1) 价值观对齐模型比基础模型产生更多有害输出，且比常规微调模型风险略高；2) 安全风险源于模型严格遵循对齐价值观，该机制通过心理学假设得到验证（尤其当价值观含危害成分时）。

Conclusion: 价值观对齐是LLMs安全的双刃剑，需谨慎实施。研究通过揭示'黑盒'机制，提出了上下文对齐（in-context alignment）作为降低风险的有效方案，为安全部署个性化模型提供了理论和方法基础。

Abstract: The application scope of Large Language Models (LLMs) continues to expand,
leading to increasing interest in personalized LLMs that align with human
values. However, aligning these models with individual values raises
significant safety concerns, as certain values may correlate with harmful
information. In this paper, we identify specific safety risks associated with
value-aligned LLMs and investigate the psychological principles behind these
challenges. Our findings reveal two key insights. (1) Value-aligned LLMs are
more prone to harmful behavior compared to non-fine-tuned models and exhibit
slightly higher risks in traditional safety evaluations than other fine-tuned
models. (2) These safety issues arise because value-aligned LLMs genuinely
generate text according to the aligned values, which can amplify harmful
outcomes. Using a dataset with detailed safety categories, we find significant
correlations between value alignment and safety risks, supported by
psychological hypotheses. This study offers insights into the "black box" of
value alignment and proposes in-context alignment methods to enhance the safety
of value-aligned LLMs.

</details>


### [144] [SMAR: Soft Modality-Aware Routing Strategy for MoE-based Multimodal Large Language Models Preserving Language Capabilities](https://arxiv.org/abs/2506.06406)
*Guoyang Xia,Yifeng Ding,Fengfa Li,Lei Ren,Chen Wei,Fangxiang Feng,Xiaojie Wang*

Main category: cs.CL

TL;DR: 提出了Soft Modality-Aware Routing (SMAR)正则化技术，用于解决多模态MoE模型中语言能力退化和训练成本高的问题。该方法通过KL散度控制跨模态路由概率分布，促进专家专业化，无需修改架构或依赖文本数据。实验显示在视觉指令微调中，仅用2.5%纯文本数据即可保留86.6%的语言能力，同时保持强大多模态性能。


<details>
  <summary>Details</summary>
Motivation: 现有的多模态MoE模型构建方法存在训练成本高或语言能力退化的问题，特别是在适应预训练模型时。这限制了其在多模态任务中的应用效果和效率。

Method: 提出SMAR正则化技术，利用Kullback-Leibler散度来调控不同模态间的路由概率分布，促进专家模型针对特定模态的专业化，且不改变模型架构或依赖大量文本数据。

Result: 在视觉指令微调实验中，SMAR仅使用2.5%的纯文本数据就实现了86.6%的语言能力保留率，优于基线方法，同时保持强大的多模态性能。

Conclusion: SMAR提供了一种实用高效的解决方案，可在多模态MoE模型中平衡模态专业化和语言能力，提升模型效率同时维持性能。

Abstract: Mixture of Experts (MoE) architectures have become a key approach for scaling
large language models, with growing interest in extending them to multimodal
tasks. Existing methods to build multimodal MoE models either incur high
training costs or suffer from degraded language capabilities when adapting
pretrained models. To address this, we propose Soft ModalityAware Routing
(SMAR), a novel regularization technique that uses Kullback Leibler divergence
to control routing probability distributions across modalities, encouraging
expert specialization without modifying model architecture or heavily relying
on textual data. Experiments on visual instruction tuning show that SMAR
preserves language ability at 86.6% retention with only 2.5% pure text,
outperforming baselines while maintaining strong multimodal performance. Our
approach offers a practical and efficient solution to balance modality
differentiation and language capabilities in multimodal MoE models.

</details>


### [145] [Canonical Autoregressive Generation](https://arxiv.org/abs/2506.06446)
*Ivi Chatzi,Nina Corvelo Benz,Stratis Tsirtsis,Manuel Gomez-Rodriguez*

Main category: cs.CL

TL;DR: 论文指出当前大型语言模型在生成token序列时不会总是产生规范序列，带来负面后果。基于生成规范序列需每一步都产生规范部分序列的发现，作者提出了规范采样方法，防止模型输出非规范序列，并证明其输出分布更接近训练数据的真实分布。


<details>
  <summary>Details</summary>
Motivation: 虽然tokenizer定义了一个字符串的唯一规范token序列，但实证表明LLM常生成非规范序列，导致模型输出不一致、解释困难等负面后果。

Method: 提出'规范采样'方法：在每个自回归生成步骤中强制选择规范token序列分片。通过在每步限制只生成规范的部分序列实现过程合规。

Result: 规范采样有效阻止模型生成非规范token序列，同时在理论上证明其输出分布比标准采样更接近真实训练数据分布。

Conclusion: 规范采样是一种简单高效的解码方法，通过保证每一步生成的局部序列规范性，提升模型整体的输出一致性和训练分布匹配度。

Abstract: State of the art large language models are trained using large amounts of
tokens derived from raw text using what is called a tokenizer. Crucially, the
tokenizer determines the (token) vocabulary a model will use during inference
as well as, in principle, the (token) language. This is because, while the
token vocabulary may allow for different tokenizations of a string, the
tokenizer always maps the string to only one of these tokenizations--the
canonical tokenization. However, multiple lines of empirical evidence suggest
that large language models do not always generate canonical token sequences,
and this comes with several negative consequences. In this work, we first show
that, to generate a canonical token sequence, a model needs to generate
(partial) canonical token sequences at each step of the autoregressive
generation process underpinning its functioning. Building upon this theoretical
result, we introduce canonical sampling, a simple and efficient sampling method
that precludes a given model from generating non-canonical token sequences.
Further, we also show that, in comparison with standard sampling, the
distribution of token sequences generated using canonical sampling is provably
closer to the true distribution of token sequences used during training.

</details>


### [146] [What Is Seen Cannot Be Unseen: The Disruptive Effect of Knowledge Conflict on Large Language Models](https://arxiv.org/abs/2506.06485)
*Kaiser Sun,Fan Bai,Mark Dredze*

Main category: cs.CL

TL;DR: 提出了一个诊断框架评估LLM在上下文与参数知识冲突时的行为，发现知识冲突对不依赖知识的任务影响小；参数与上下文一致时性能更高；模型无法完全抑制内部知识；提供冲突解释会增加上下文依赖。这些发现对模型评估和部署有重要影响。


<details>
  <summary>Details</summary>
Motivation: 大语言模型依赖上下文输入和参数知识，但两者可能冲突，尤其当检索文档与模型固有知识矛盾时。需系统评估冲突下模型行为，以揭示潜在问题。

Method: 构建诊断数据集模拟上下文-参数知识冲突场景，分析模型在多种任务类型（含/不含知识利用需求）的表现，测试模型抑制内部知识能力及解释冲突的影响。

Result: 发现：知识冲突对无需知识的任务影响微弱；上下文与参数一致时性能最优；模型无法彻底抑制固有知识；提供冲突解释增强上下文依赖。

Conclusion: 知识冲突暴露模型评估潜在失真风险，需在LLM部署中针对性解决。模型受固有知识影响超预期，提供解释能改善上下文遵从。后续应优化模型知识整合机制。

Abstract: Large language models frequently rely on both contextual input and parametric
knowledge to perform tasks. However, these sources can come into conflict,
especially when retrieved documents contradict the model's parametric
knowledge. We propose a diagnostic framework to systematically evaluate LLM
behavior under context-memory conflict, where the contextual information
diverges from their parametric beliefs. We construct diagnostic data that
elicit these conflicts and analyze model performance across multiple task
types. Our findings reveal that (1) knowledge conflict has minimal impact on
tasks that do not require knowledge utilization, (2) model performance is
consistently higher when contextual and parametric knowledge are aligned, (3)
models are unable to fully suppress their internal knowledge even when
instructed, and (4) providing rationales that explain the conflict increases
reliance on contexts. These insights raise concerns about the validity of
model-based evaluation and underscore the need to account for knowledge
conflict in the deployment of LLMs.

</details>


### [147] [Improving LLM-Powered EDA Assistants with RAFT](https://arxiv.org/abs/2506.06500)
*Luyao Shi,Michael Kazda,Charles Schmitter,Hemlata Gupta*

Main category: cs.CL

TL;DR: 提出了一个使用合成Q/A数据集结合RAFT方法来增强预训练语言模型在EDA领域性能的方法，解决了领域知识缺乏和标注数据获取困难的问题，并提升了RAG任务的准确性和安全性。


<details>
  <summary>Details</summary>
Motivation: 预训练的开源语言模型缺乏EDA领域知识，而传统的微调方法需要大量高质量的标注数据（在EDA领域难以获取），导致基于RAG的方法可能产生不准确的输出。

Method: 1) 利用合成Q/A数据集对语言模型进行RAFT微调；2) 探索真实用户问题作为RAFS样本以生成更优质的合成数据；3) 实施安全访问控制保护敏感数据；4) 评估微调过程中的数据泄漏风险。

Result: RAFT结合合成数据显著提升语言模型在EDA任务的性能；真实用户问题作为RAFS的样本可提升合成数据质量；安全机制有效限制敏感信息访问；数据泄漏风险评估为实践提供参考。

Conclusion: 该方法有效解决EDA领域专业语言模型训练的数据瓶颈问题，同时平衡性能与安全性，为专业领域RAG应用提供技术路径和安全保障。

Abstract: Electronic design engineers often struggle to efficiently access relevant
information for tasks like design verification and technology development.
While large language models (LLMs) can enhance productivity as conversational
agents, pre-trained open-source LLMs lack domain-specific knowledge for
Electronic Design Automation (EDA). In a Retrieval-Augmented Generation (RAG)
context, LLMs rely on external context but may still produce inaccurate
responses. Retrieval-Augmented Fine-Tuning (RAFT) improves LLM performance, but
acquiring labeled question/answer (Q/A) data in EDA is difficult. To address
this, we propose using synthetic Q/A datasets to enhance LLMs with RAFT. Our
results show that RAFT with synthetic data significantly boosts LLM performance
for RAG-based EDA tasks. We also investigate the impact of using real user
questions as Retrieval-Augmented Few-Shot (RAFS) examples for synthetic data
generation. Additionally, we implement secure access control to ensure
sensitive information is only accessible to authorized personnel. Finally, we
assess the risk of data leakage and unintended memorization during fine-tuning
with synthetic data, providing practical insights.

</details>


### [148] [Biases Propagate in Encoder-based Vision-Language Models: A Systematic Analysis From Intrinsic Measures to Zero-shot Retrieval Outcomes](https://arxiv.org/abs/2506.06506)
*Kshitish Ghate,Tessa Charlesworth,Mona Diab,Aylin Caliskan*

Main category: cs.CL

TL;DR: 该研究发现基础视觉语言模型(VLMs)中的内在社会群体偏见会系统性地传播到零样本检索任务中，导致下游任务出现偏见。通过实验证明内在与外在偏见高度相关(平均ρ=0.83±0.10)，且性能更强的模型偏见传播更严重。


<details>
  <summary>Details</summary>
Motivation: 理解基础VLMs中存在的社会群体偏见如何影响下游任务，从而构建更公平的AI系统。

Method: 提出控制框架：通过(a)表征空间的内在偏见测量与(b)零样本图文/图到文检索的外在偏见测量的相关性分析。在三种VLMs上对六个社会群体进行114次分析。

Result: 1. 内在与外在偏见呈现强相关(ρ=0.83±0.10) 
2. 性能更强的模型偏见传播更严重 
3. 少数群体在传播过程中表现更脆弱

Conclusion: 基础模型的系统性偏见传播问题亟需关注，尤其随着模型规模增大趋势；需要开发新的公平评估任务，特别是聚焦弱势群体的鲁棒性。

Abstract: To build fair AI systems we need to understand how social-group biases
intrinsic to foundational encoder-based vision-language models (VLMs) manifest
in biases in downstream tasks. In this study, we demonstrate that intrinsic
biases in VLM representations systematically ``carry over'' or propagate into
zero-shot retrieval tasks, revealing how deeply rooted biases shape a model's
outputs. We introduce a controlled framework to measure this propagation by
correlating (a) intrinsic measures of bias in the representational space with
(b) extrinsic measures of bias in zero-shot text-to-image (TTI) and
image-to-text (ITT) retrieval. Results show substantial correlations between
intrinsic and extrinsic bias, with an average $\rho$ = 0.83 $\pm$ 0.10. This
pattern is consistent across 114 analyses, both retrieval directions, six
social groups, and three distinct VLMs. Notably, we find that
larger/better-performing models exhibit greater bias propagation, a finding
that raises concerns given the trend towards increasingly complex AI models.
Our framework introduces baseline evaluation tasks to measure the propagation
of group and valence signals. Investigations reveal that underrepresented
groups experience less robust propagation, further skewing their model-related
outcomes.

</details>


### [149] [Fixing It in Post: A Comparative Study of LLM Post-Training Data Quality and Model Performance](https://arxiv.org/abs/2506.06522)
*Aladin Djuhera,Swanand Ravindra Kadhe,Syed Zawad,Farhan Ahmed,Heiko Ludwig,Holger Boche*

Main category: cs.CL

TL;DR: 该研究对两个开源的训练后数据集Tulu-3-SFT-Mix和SmolTalk进行了首次全面比较分析，开发了Magpie框架来标注数据质量指标，基于分析结果设计出更精炼的新数据集TuluTalk（样本减少14%但性能相当或更好）。


<details>
  <summary>Details</summary>
Motivation: 当前领先的开源和闭源LLM使用的训练后数据集大多不公开且构建过程不透明，现有开源替代数据集虽能达到可比性能，但因计算成本高昂缺乏系统比较，导致数据质量评估中样本/任务/策略的影响机制不明确。

Method: 1. 使用Magpie框架标注数据集样本的质量指标（对话结构/任务类别/输入质量/响应质量）
2. 通过统计学分析揭示数据集结构与质量差异
3. 基于分析结果设计新数据混合配方TuluTalk

Result: 1. 发现两数据集的结构和质量差异
2. 新数据集TuluTalk比源数据集少14%样本，但在关键基准测试中性能相当或更好
3. 公开发布标注后的源数据集及TuluTalk混合集

Conclusion: 该研究提供了构建高效训练后数据集的可操作见解（在有限资源下提升模型性能），通过系统分析填补了开源数据集比较的空白，公开资源将促进未来研究。

Abstract: Recent work on large language models (LLMs) has increasingly focused on
post-training and alignment with datasets curated to enhance instruction
following, world knowledge, and specialized skills. However, most post-training
datasets used in leading open- and closed-source LLMs remain inaccessible to
the public, with limited information about their construction process. This
lack of transparency has motivated the recent development of open-source
post-training corpora. While training on these open alternatives can yield
performance comparable to that of leading models, systematic comparisons remain
challenging due to the significant computational cost of conducting them
rigorously at scale, and are therefore largely absent. As a result, it remains
unclear how specific samples, task types, or curation strategies influence
downstream performance when assessing data quality. In this work, we conduct
the first comprehensive side-by-side analysis of two prominent open
post-training datasets: Tulu-3-SFT-Mix and SmolTalk. Using the Magpie
framework, we annotate each sample with detailed quality metrics, including
turn structure (single-turn vs. multi-turn), task category, input quality, and
response quality, and we derive statistics that reveal structural and
qualitative similarities and differences between the two datasets. Based on
these insights, we design a principled curation recipe that produces a new data
mixture, TuluTalk, which contains 14% fewer samples than either source dataset
while matching or exceeding their performance on key benchmarks. Our findings
offer actionable insights for constructing more effective post-training
datasets that improve model performance within practical resource limits. To
support future research, we publicly release both the annotated source datasets
and our curated TuluTalk mixture.

</details>


### [150] [Beyond Facts: Evaluating Intent Hallucination in Large Language Models](https://arxiv.org/abs/2506.06539)
*Yijie Hao,Haofei Yu,Jiaxuan You*

Main category: cs.CL

TL;DR: 本文引入了'意图幻觉'概念，指大语言模型在处理复杂查询时部分忽略或错误解释条件的问题。作者发布了FAITHQA基准（20,068个问题）进行系统评估，发现该现象普遍存在且由条件遗漏或误解导致，同时提出自动评估指标CONSTRAINT SCORE。


<details>
  <summary>Details</summary>
Motivation: 现有大型语言模型在处理含多条件的复杂查询时，经常仅部分满足查询而忽略某些条件，导致响应与用户意图不符。为解决该问题，需要明确定义并量化评估这类'意图幻觉'现象。

Method: 1. 提出意图幻觉概念：包括遗漏（未响应部分查询）和曲解（响应虚构内容）两类；2. 构建FAITHQA基准，覆盖20,068个问题，包含纯查询和检索增强生成场景；3. 评估主流LLM表现，分析根本原因；4. 设计自动评估指标CONSTRAINT SCORE。

Result: 1. 所有先进LLM均存在意图幻觉问题；2. 模型表现不佳的根源是条件遗漏或曲解；3. 新指标CONSTRAINT SCORE经人工验证，比基线方法更接近人类判断水平。

Conclusion: 意图幻觉是大语言模型的普遍缺陷，FAITHQA作为首款非事实性幻觉基准可推动相关研究。提出的CONSTRAINT SCORE指标能有效检测该现象，未来需针对性优化模型对齐能力。

Abstract: When exposed to complex queries containing multiple conditions, today's large
language models (LLMs) tend to produce responses that only partially satisfy
the query while neglecting certain conditions. We therefore introduce the
concept of Intent Hallucination. In this phenomenon, LLMs either omit
(neglecting to address certain parts) or misinterpret (responding to invented
query parts) elements of the given query, leading to intent hallucinated
generation. To systematically evaluate intent hallucination, we introduce
FAITHQA, a novel benchmark for intent hallucination that contains 20,068
problems, covering both query-only and retrieval-augmented generation (RAG)
setups with varying topics and difficulty. FAITHQA is the first hallucination
benchmark that goes beyond factual verification, tailored to identify the
fundamental cause of intent hallucination. By evaluating various LLMs on
FAITHQA, we find that (1) intent hallucination is a common issue even for
state-of-the-art models, and (2) the phenomenon stems from omission or
misinterpretation of LLMs. To facilitate future research, we introduce an
automatic LLM generation evaluation metric, CONSTRAINT SCORE, for detecting
intent hallucination. Human evaluation results demonstrate that CONSTRAINT
SCORE is closer to human performance for intent hallucination compared to
baselines.

</details>


### [151] [LaMP-Cap: Personalized Figure Caption Generation With Multimodal Figure Profiles](https://arxiv.org/abs/2506.06561)
*Ho Yin 'Sam' Ng,Ting-Yao Hsu,Aashish Anantha Ramakrishnan,Branislav Kveton,Nedim Lipka,Franck Dernoncourt,Dongwon Lee,Tong Yu,Sungchul Kim,Ryan A. Rossi,Ting-Hao 'Kenneth' Huang*

Main category: cs.CL

TL;DR: 提出了LaMP-Cap数据集用于个性化生成带有多模态档案的图表标题。实验证明使用档案信息（尤其是图像）可以提升标题生成效果。


<details>
  <summary>Details</summary>
Motivation: 现有AI生成的图表标题需要大量修改才能匹配作者的写作风格和领域风格，现有语言模型个性化技术主要针对纯文本场景，缺少多模态输入和个人档案的处理。

Method: 构建LaMP-Cap数据集，包含目标图表的图像及同一文档中其他三个图表（含图像、标题和提及段落的档案）。使用四个大型语言模型进行实验，验证多模态档案对标题生成的影响。

Result: 使用档案信息生成的标题更接近作者原始标题，消融研究显示图像比提及段落更有帮助，证明多模态档案优于纯文本档案。

Conclusion: 多模态档案（尤其图像）能有效提升个性化图表标题生成质量，LaMP-Cap数据集为此任务提供了支持。

Abstract: Figure captions are crucial for helping readers understand and remember a
figure's key message. Many models have been developed to generate these
captions, helping authors compose better quality captions more easily. Yet,
authors almost always need to revise generic AI-generated captions to match
their writing style and the domain's style, highlighting the need for
personalization. Despite language models' personalization (LaMP) advances,
these technologies often focus on text-only settings and rarely address
scenarios where both inputs and profiles are multimodal. This paper introduces
LaMP-Cap, a dataset for personalized figure caption generation with multimodal
figure profiles. For each target figure, LaMP-Cap provides not only the needed
inputs, such as figure images, but also up to three other figures from the same
document--each with its image, caption, and figure-mentioning paragraphs--as a
profile to characterize the context. Experiments with four LLMs show that using
profile information consistently helps generate captions closer to the original
author-written ones. Ablation studies reveal that images in the profile are
more helpful than figure-mentioning paragraphs, highlighting the advantage of
using multimodal profiles over text-only ones.

</details>


### [152] [Precise Information Control in Long-Form Text Generation](https://arxiv.org/abs/2506.06589)
*Jacqueline He,Howard Yen,Margaret Li,Shuyue Stella Li,Zhiyuan Zeng,Weijia Shi,Yulia Tsvetkov,Danqi Chen,Pang Wei Koh,Luke Zettlemoyer*

Main category: cs.CL

TL;DR: 该论文提出PIC任务（精确信息控制）来研究语言模型的内在幻觉问题，并建立PIC-Bench基准测试。通过评估发现当前顶级模型在70%以上的输出中存在幻觉，进而开发了一个8B参数的PIC-LM模型，将F1分数从69.1%提升至91.0%。该模型在事实性生成任务中也表现出显著改进。


<details>
  <summary>Details</summary>
Motivation: 解决语言模型生成未经证实的合理信息（内在幻觉）的问题，需要确保模型输出严格基于可验证的输入声明。

Method: 提出了PIC任务和PIC-Bench基准测试，包含完整和部分两种设置。开发了基于弱监督偏好数据构建的微调框架，训练了8B参数的PIC-LM模型。

Result: 现有先进模型在PIC-Bench上仍产生超过70%的幻觉输出。PIC-LM将完整PIC设置下的F1分数从69.1%提升到91.0%。在端到端事实生成任务中使精确匹配召回率提高17.1%，事实精确度提高30.5%。

Conclusion: PIC任务有效暴露了语言模型的内在幻觉问题，通过针对性训练可显著改善。PIC-LM展示出精确可控生成在实际应用中的潜力，但挑战仍然存在。

Abstract: A central challenge in modern language models (LMs) is intrinsic
hallucination: the generation of information that is plausible but
unsubstantiated relative to input context. To study this problem, we propose
Precise Information Control (PIC), a new task formulation that requires models
to generate long-form outputs grounded in a provided set of short
self-contained statements, known as verifiable claims, without adding any
unsupported ones. For comprehensiveness, PIC includes a full setting that tests
a model's ability to include exactly all input claims, and a partial setting
that requires the model to selectively incorporate only relevant claims. We
present PIC-Bench, a benchmark of eight long-form generation tasks (e.g.,
summarization, biography generation) adapted to the PIC setting, where LMs are
supplied with well-formed, verifiable input claims. Our evaluation of a range
of open and proprietary LMs on PIC-Bench reveals that, surprisingly,
state-of-the-art LMs still intrinsically hallucinate in over 70% of outputs. To
alleviate this lack of faithfulness, we introduce a post-training framework,
using a weakly supervised preference data construction method, to train an 8B
PIC-LM with stronger PIC ability--improving from 69.1% to 91.0% F1 in the full
PIC setting. When integrated into end-to-end factual generation pipelines,
PIC-LM improves exact match recall by 17.1% on ambiguous QA with retrieval, and
factual precision by 30.5% on a birthplace verification task, underscoring the
potential of precisely grounded generation.

</details>


### [153] [MedCite: Can Language Models Generate Verifiable Text for Medicine?](https://arxiv.org/abs/2506.06605)
*Xiao Wang,Mengjue Tan,Qiao Jin,Guangzhi Xiong,Yu Hu,Aidong Zhang,Zhiyong Lu,Minjia Zhang*

Main category: cs.CL

TL;DR: 摘要介绍了一个名为\name的端到端框架,旨在改善现有医疗问答LLM系统缺乏引用生成和评估能力的问题。该框架包含一种新型的多通路检索-引用方法,能生成高质量的引用。评估显示该方法在引用精准度和召回率上优于基线方法,且评估结果与专家标注高度相关。


<details>
  <summary>Details</summary>
Motivation: 现有基于LLM的医疗问答系统缺乏引用生成和评估功能,阻碍了其在实践中的应用

Method: 提出名为\name的端到端框架,引入多通路检索-引用方法

Result: 该方法在引用精准度和召回率上显著优于基线方法,且自动评估结果与专家标注高度一致

Conclusion: 该框架成功解决了医疗问答中的引用生成挑战,并通过创新方法提升了引用质量,为实际应用铺平道路

Abstract: Existing LLM-based medical question-answering systems lack citation
generation and evaluation capabilities, raising concerns about their adoption
in practice. In this work, we introduce \name, the first end-to-end framework
that facilitates the design and evaluation of citation generation with LLMs for
medical tasks. Meanwhile, we introduce a novel multi-pass retrieval-citation
method that generates high-quality citations. Our evaluation highlights the
challenges and opportunities of citation generation for medical tasks, while
identifying important design choices that have a significant impact on the
final citation quality. Our proposed method achieves superior citation
precision and recall improvements compared to strong baseline methods, and we
show that evaluation results correlate well with annotation results from
professional experts.

</details>


### [154] [Training-Free Tokenizer Transplantation via Orthogonal Matching Pursuit](https://arxiv.org/abs/2506.06607)
*Charles Goddard,Fernando Fernandes Neto*

Main category: cs.CL

TL;DR: 提出了一种无需训练的方法，利用正交匹配追踪（OMP）重建未见过的词元嵌入，实现预训练大语言模型中词元器的移植。该方法通过共享锚定词元的稀疏线性组合来近似新词元，在两个跨词元器任务中表现出最佳性能，无需梯度更新即可保持模型能力。


<details>
  <summary>Details</summary>
Motivation: 为了解决跨词元器应用中（如知识蒸馏、推测解码等）出现的词元器不匹配问题，避免重新训练模型的巨大开销，开发一种无需训练即可移植词元器的方法。

Method: 采用正交匹配追踪（OMP）算法，将新词元表示为一组共享锚定词元的稀疏线性组合：先在供体模型的词元嵌入空间中计算新词元的表达，再将这些稀疏系数转移到基础模型的词元嵌入空间中来重建新词元向量。

Result: 在Llama到Mistral NeMo（120亿参数）和Qwen到Llama（10亿参数）的跨词元器任务中，OMP方法在多个基准测试上保持基础模型性能方面表现最佳（零样本），显著优于零初始化、均值初始化、WECHSEL、FOCUS、ZETT等基线方法。该方法还成功识别了数值词元化方案不匹配对数学推理能力的影响。

Conclusion: OMP提供了一种高效移植词元器的方法，无需训练即可有效弥合词元器差异，适用于知识蒸馏、推测解码、模型集成及领域词表适配等场景。该方法已集成至mergekit-tokensurgeon开源工具中实现词汇表后验对齐。

Abstract: We present a training-free method to transplant tokenizers in pretrained
large language models (LLMs) by reconstructing unseen token embeddings via
Orthogonal Matching Pursuit (OMP). Specifically, we approximate each
out-of-vocabulary token as a sparse linear combination of shared tokens, in two
phases: first, compute each new token's representation in the donor embedding
space with a small dictionary of shared anchor tokens, then transfer these same
sparse coefficients back into the base model's embedding space.
  On two challenging cross-tokenizer tasks--Llama$\to$Mistral NeMo (12B) and
Qwen$\to$Llama (1B)--we show that OMP achieves best zero-shot preservation of
the base model's performance across multiple benchmarks, while other zero-shot
approaches degrade significantly. Compared to baselines (zero-init, mean-init,
and existing approaches like WECHSEL, FOCUS, ZETT), OMP consistently achieves
the best overall performance, effectively bridging large tokenizer
discrepancies without gradient updates. Our analysis further identifies
mismatched numerical tokenization schemes as a critical challenge for
preserving mathematical reasoning capabilities. This technique enables direct
reuse of pretrained model weights with new tokenizers, facilitating
cross-tokenizer knowledge distillation, speculative decoding, ensembling,
merging, and domain-specific vocabulary adaptations. We integrate our method
into the open-source mergekit-tokensurgeon tool for post hoc vocabulary
realignment.

</details>


### [155] [Transferring Features Across Language Models With Model Stitching](https://arxiv.org/abs/2506.06609)
*Alan Chen,Jack Merullo,Alessandro Stolfo,Ellie Pavlick*

Main category: cs.CL

TL;DR: 本论文证明了在语言模型的残差流之间使用仿射映射是一种经济高效的特征迁移方法，可将稀疏自编码器（SAE）在不同规模模型间迁移，从而比较表示空间。研究发现大小模型学习到高度相似的表示空间，因此提出在小型模型上训练昂贵组件（如SAE）再迁移至大型模型以节省计算量（例如降低50%训练成本）。同时验证了迁移探测器和导向向量能有效恢复真实性能，并深入揭示了语义与结构特征的迁移差异以及特定功能特征的角色映射。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型中训练如稀疏自编码器（SAE）的组件计算成本高昂，且不同规模模型间的表示空间相似性尚未系统研究。若能证明小模型和大模型的表示空间高度相似，则可先在小型模型上训练这些昂贵组件再迁移至大型模型，大幅降低训练成本。

Method: 使用残差流之间的仿射映射技术，将SAE权重在不同规模的语言模型之间迁移。通过迁移后的SAE作为初始化点，在大模型上继续训练SAE以节省计算量。同时，通过迁移探测器和导向向量评估特征重构效果，并分析语义/结构/功能三类特征的迁移特性。

Result: 1) 小模型和大模型学习到的表示空间高度相似，使得SAE迁移可行——小型模型训练后迁移至大型模型的SAE作为初始化可节省50%训练成本。2) 迁移的探测器和导向向量能有效恢复真实性能。3) 特征层面：语义和结构特征迁移效果显著不同，而特定功能特征的角色能被忠实映射。

Conclusion: 该研究揭示了不同规模语言模型在线性表示空间的共性与差异，并开发出一种提升SAE训练效率的方法（小模型预训练+大模型迁移）。通过特征层面的可迁移性分析，为模型间组件复用提供了理论基础和实用技术。

Abstract: In this work, we demonstrate that affine mappings between residual streams of
language models is a cheap way to effectively transfer represented features
between models. We apply this technique to transfer the weights of Sparse
Autoencoders (SAEs) between models of different sizes to compare their
representations. We find that small and large models learn highly similar
representation spaces, which motivates training expensive components like SAEs
on a smaller model and transferring to a larger model at a FLOPs savings. For
example, using a small-to-large transferred SAE as initialization can lead to
50% cheaper training runs when training SAEs on larger models. Next, we show
that transferred probes and steering vectors can effectively recover ground
truth performance. Finally, we dive deeper into feature-level transferability,
finding that semantic and structural features transfer noticeably differently
while specific classes of functional features have their roles faithfully
mapped. Overall, our findings illustrate similarities and differences in the
linear representation spaces of small and large models and demonstrate a method
for improving the training efficiency of SAEs.

</details>


### [156] [Interpretable Depression Detection from Social Media Text Using LLM-Derived Embeddings](https://arxiv.org/abs/2506.06616)
*Samuel Kim,Oghenemaro Imieye,Yunting Yin*

Main category: cs.CL

TL;DR: 研究了大型語言模型(LLMs)與傳統機器學習分類器在社交媒體上的抑鬱語言檢測效果。結果發現，零樣本LLMs在二進制分類中表現良好，但難以處理有序分類任務；而使用LLMs摘要嵌入的分類器在各任務中表現優異，尤其在與傳統文本嵌入比較時。


<details>
  <summary>Details</summary>
Motivation: 準確且可解釋的社交媒體抑鬱語言檢測對心理健康早期干預至關重要，能夠為臨床實踐和公共衛生工作提供支持。

Method: 比較零樣本LLMs與基於傳統文本嵌入和LLMs生成摘要嵌入訓練的分類器，在三個社交媒體數據分類任務中的表現：二進制抑鬱分類、抑鬱嚴重程度分類和抑鬱/PTSD/焦慮的鑑別診斷分類。

Result: 零樣本LLMs在二進制分類中展現強泛化能力，但在精細有序分類任務中表現不佳。使用LLMs摘要嵌入的分類器表現優於或相當於基於傳統嵌入的分類器。

Conclusion: LLMs在心理健康預測方面具有優勢，研究為更好地利用其零樣本能力和上下文感知摘要技術提供了方向。

Abstract: Accurate and interpretable detection of depressive language in social media
is useful for early interventions of mental health conditions, and has
important implications for both clinical practice and broader public health
efforts. In this paper, we investigate the performance of large language models
(LLMs) and traditional machine learning classifiers across three classification
tasks involving social media data: binary depression classification, depression
severity classification, and differential diagnosis classification among
depression, PTSD, and anxiety. Our study compares zero-shot LLMs with
supervised classifiers trained on both conventional text embeddings and
LLM-generated summary embeddings. Our experiments reveal that while zero-shot
LLMs demonstrate strong generalization capabilities in binary classification,
they struggle with fine-grained ordinal classifications. In contrast,
classifiers trained on summary embeddings generated by LLMs demonstrate
competitive, and in some cases superior, performance on the classification
tasks, particularly when compared to models using traditional text embeddings.
Our findings demonstrate the strengths of LLMs in mental health prediction, and
suggest promising directions for better utilization of their zero-shot
capabilities and context-aware summarization techniques.

</details>


### [157] [BriefMe: A Legal NLP Benchmark for Assisting with Legal Briefs](https://arxiv.org/abs/2506.06619)
*Jesse Woo,Fateme Hashemi Chaleshtori,Ana Marasović,Kenneth Marino*

Main category: cs.CL

TL;DR: 本文介绍了BRIEFME数据集，用于评估语言模型在协助法律文书写中的作用，包括三个任务：论点摘要、论点补全和案例检索。当前大语言模型在摘要和引导补全任务中表现良好，甚至优于人工生成的标题，但在现实补全和案例检索任务中表现不佳。


<details>
  <summary>Details</summary>
Motivation: 法律工作中起草和编辑法律文书（如法律简报）尚未得到Legal NLP领域的充分探索。这些任务要求对法律有深入理解，并能创造性地提出有说服力的新论点。

Method: 引入BRIEFME数据集，包含三个任务：1) 论点摘要（将法律论点提炼为标题），2) 论点补全（基于给定上下文续写论点），3) 案例检索（查找相关判例）。

Result: 1) 当前大语言模型在论点摘要任务中表现优异，超越人工标题质量；2) 在引导性论点补全任务中表现良好；3) 在现实论点补全和案例检索任务上表现较差。

Conclusion: BRIEFME数据集突显了现有模型的局限性，尤其在实际应用场景下的不足，有望推动Legal NLP领域开发更实用的法律辅助工具。

Abstract: A core part of legal work that has been under-explored in Legal NLP is the
writing and editing of legal briefs. This requires not only a thorough
understanding of the law of a jurisdiction, from judgments to statutes, but
also the ability to make new arguments to try to expand the law in a new
direction and make novel and creative arguments that are persuasive to judges.
To capture and evaluate these legal skills in language models, we introduce
BRIEFME, a new dataset focused on legal briefs. It contains three tasks for
language models to assist legal professionals in writing briefs: argument
summarization, argument completion, and case retrieval. In this work, we
describe the creation of these tasks, analyze them, and show how current models
perform. We see that today's large language models (LLMs) are already quite
good at the summarization and guided completion tasks, even beating
human-generated headings. Yet, they perform poorly on other tasks in our
benchmark: realistic argument completion and retrieving relevant legal cases.
We hope this dataset encourages more development in Legal NLP in ways that will
specifically aid people in performing legal work.

</details>


### [158] [Psychological Counseling Cannot Be Achieved Overnight: Automated Psychological Counseling Through Multi-Session Conversations](https://arxiv.org/abs/2506.06626)
*Junzhe Wang,Bichen Wang,Xing Fu,Yixin Sun,Yanyan Zhao,Bing Qin*

Main category: cs.CL

TL;DR: 该论文介绍了用于多轮心理咨询对话的数据集MusPsy-Dataset及对应模型MusPsy-Model，解决了现有研究局限于单次咨询的问题，实验表明该模型在连续咨询场景优于基线模型。


<details>
  <summary>Details</summary>
Motivation: 现有LLM心理咨询研究集中在单次会话，但实际心理咨询是持续多轮的过程，需要模型具备跨会话追踪咨询进展的能力。

Method: 基于公开心理咨询案例构建多轮渐进式对话数据集(MusPsy-Dataset)，并开发能追踪用户进展的MusPsy-Model，在连续会话中动态调整咨询方向。

Result: 实验证明MusPsy-Model在跨会话心理咨询任务中性能超越基线模型。

Conclusion: MusPsy-Dataset填补了多轮心理咨询数据空白，MusPsy-Model通过跨会话状态追踪实现了更符合实际的渐进式心理咨询。

Abstract: In recent years, Large Language Models (LLMs) have made significant progress
in automated psychological counseling. However, current research focuses on
single-session counseling, which doesn't represent real-world scenarios. In
practice, psychological counseling is a process, not a one-time event,
requiring sustained, multi-session engagement to progressively address clients'
issues. To overcome this limitation, we introduce a dataset for Multi-Session
Psychological Counseling Conversation Dataset (MusPsy-Dataset). Our
MusPsy-Dataset is constructed using real client profiles from publicly
available psychological case reports. It captures the dynamic arc of
counseling, encompassing multiple progressive counseling conversations from the
same client across different sessions. Leveraging our dataset, we also
developed our MusPsy-Model, which aims to track client progress and adapt its
counseling direction over time. Experiments show that our model performs better
than baseline models across multiple sessions.

</details>


### [159] [SafeLawBench: Towards Safe Alignment of Large Language Models](https://arxiv.org/abs/2506.06636)
*Chuxue Cao,Han Zhu,Jiaming Ji,Qichao Sun,Zhenghao Zhu,Yinyu Wu,Juntao Dai,Yaodong Yang,Sirui Han,Yike Guo*

Main category: cs.CL

TL;DR: SafeLawBench：首个从法律角度评估大型语言模型安全性的基准，包含24,860道选择题和1,106道开放域问答。评估20个模型发现，即使顶级模型准确率也低于80.5%，行业平均仅68.8%，呼吁加强LLM安全性研究。


<details>
  <summary>Details</summary>
Motivation: 现有LLM安全性评估缺乏客观标准，作者从法律视角构建系统化评估框架以填补此空白。

Method: 1) 基于法律标准将安全风险分三级 2) 建立含24,860选择题+1,106开放问答的SafeLawBench 3) 对20个LLM进行零/少量样本测试 4) 分析模型安全推理稳定性与拒绝行为 5) 验证多数投票提升效果

Result: Claude-3.5和GPT-4o在选择题最高准确率仅80.5%，20个模型平均68.8%；多数投票可提升性能；开放问答显示模型存在安全漏洞

Conclusion: 当前LLM安全性能不足，需社区重视；SafeLawBench为法律合规性评估提供标准化工具；倡导多数投票等优化方案

Abstract: With the growing prevalence of large language models (LLMs), the safety of
LLMs has raised significant concerns. However, there is still a lack of
definitive standards for evaluating their safety due to the subjective nature
of current safety benchmarks. To address this gap, we conducted the first
exploration of LLMs' safety evaluation from a legal perspective by proposing
the SafeLawBench benchmark. SafeLawBench categorizes safety risks into three
levels based on legal standards, providing a systematic and comprehensive
framework for evaluation. It comprises 24,860 multi-choice questions and 1,106
open-domain question-answering (QA) tasks. Our evaluation included 2
closed-source LLMs and 18 open-source LLMs using zero-shot and few-shot
prompting, highlighting the safety features of each model. We also evaluated
the LLMs' safety-related reasoning stability and refusal behavior.
Additionally, we found that a majority voting mechanism can enhance model
performance. Notably, even leading SOTA models like Claude-3.5-Sonnet and
GPT-4o have not exceeded 80.5% accuracy in multi-choice tasks on SafeLawBench,
while the average accuracy of 20 LLMs remains at 68.8\%. We urge the community
to prioritize research on the safety of LLMs.

</details>


### [160] [Quantile Regression with Large Language Models for Price Prediction](https://arxiv.org/abs/2506.06657)
*Nikhita Vedula,Dushyanta Dhyani,Laleh Jalali,Boris Oreshkin,Mohsen Bayati,Shervin Malmasi*

Main category: cs.CL

TL;DR: 本文提出使用大型语言模型（LLMs）进行概率回归的新方法，重点关注价格预测等需要文本理解和不确定性量化的任务。通过分位数回归使LLMs生成完整的预测分布，在三个数据集上证明其超越传统方法。


<details>
  <summary>Details</summary>
Motivation: 现有LLM结构化预测主要关注点估计，缺乏概率建模和系统比较。价格预测等任务需要文本理解和分布预测能力，但传统方法无法同时满足。

Method: 提出基于Mistral-7B的分位数回归框架，添加quantile heads生成预测分布。系统比较了LLM架构、训练方法和数据规模，并采用LLM辅助标签修正。

Result: 在三个价格数据集上，微调的Mistral-7B在预测准确性和分布校准的六个指标上均优于传统方法（包括编码器架构、嵌入方法和少样本学习）。LLM辅助标签修正实现了无系统偏差的人类级精度。

Conclusion: LLM分位数回归能有效解决文本到分布的预测问题。Mistral-7B架构在概率回归任务中具有优势，公开数据集可促进相关研究。

Abstract: Large Language Models (LLMs) have shown promise in structured prediction
tasks, including regression, but existing approaches primarily focus on point
estimates and lack systematic comparison across different methods. We
investigate probabilistic regression using LLMs for unstructured inputs,
addressing challenging text-to-distribution prediction tasks such as price
estimation where both nuanced text understanding and uncertainty quantification
are critical. We propose a novel quantile regression approach that enables LLMs
to produce full predictive distributions, improving upon traditional point
estimates. Through extensive experiments across three diverse price prediction
datasets, we demonstrate that a Mistral-7B model fine-tuned with quantile heads
significantly outperforms traditional approaches for both point and
distributional estimations, as measured by three established metrics each for
prediction accuracy and distributional calibration. Our systematic comparison
of LLM approaches, model architectures, training approaches, and data scaling
reveals that Mistral-7B consistently outperforms encoder architectures,
embedding-based methods, and few-shot learning methods. Our experiments also
reveal the effectiveness of LLM-assisted label correction in achieving
human-level accuracy without systematic bias. Our curated datasets are made
available at https://github.com/vnik18/llm-price-quantile-reg/ to support
future research.

</details>


### [161] [Learning Distribution-Wise Control in Representation Space for Language Models](https://arxiv.org/abs/2506.06686)
*Chunyuan Deng,Ruidi Chang,Hanjie Chen*

Main category: cs.CL

TL;DR: 分布级干预扩展了点控制的可学习干预方法，学习概念子空间及周围区域，在常识和算术推理任务中提升了控制性和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 传统表示微调只能在概念子空间内实施点控制，缺乏对概念周围区域的掌控能力。为更全面引导语言模型行为，需扩展至分布层次。

Method: 提出分布式干预方法(D-Intervention)，学习概念子空间的分布特征而非点变换，通过调整标准差优化性能。

Result: 在8个常识推理和7个算术推理基准中，分布干预在控制性与鲁棒性上一致优于点干预，较大标准差与更好性能相关。

Conclusion: 分布级干预为语言模型行为控制提供更全面的解决方案，实现细粒度操控，代码已开源。

Abstract: Interventions in language models (LMs) are applied strategically to steer
model behavior during the forward pass. Learnable interventions, also known as
representation fine-tuning, aim to apply pointwise control within the concept
subspace and have proven effective in altering high-level behaviors. In this
work, we extend this approach to the distribution level, enabling the model to
learn not only pointwise transformations but also the surrounding regions of
the concept subspace. We demonstrate that these methods perform effectively in
early layers, with larger standard deviations correlating strongly with
improved performance. Across eight commonsense reasoning and seven arithmetic
reasoning benchmarks, our distribution-wise interventions consistently
outperform pointwise interventions in controllability and robustness. These
results illustrate that distribution-wise interventions provide a more
comprehensive method for steering model behavior and enabling finer-grained
control over language models. The code is at:
\href{https://github.com/chili-lab/D-Intervention}{https://github.com/chili-lab/D-Intervention}.

</details>


### [162] [Dynamic and Parametric Retrieval-Augmented Generation](https://arxiv.org/abs/2506.06704)
*Weihang Su,Qingyao Ai,Jingtao Zhan,Qian Dong,Yiqun Liu*

Main category: cs.CL

TL;DR: 介绍两种新的RAG方法：Dynamic RAG和Parametric RAG，它们分别通过动态决定检索时机与内容和参数级知识注入，解决传统静态RAG在复杂任务中的局限性。


<details>
  <summary>Details</summary>
Motivation: 传统静态RAG（检索后生成）和上下文知识注入在需要多跳推理、自适应信息访问和更深知识整合的复杂任务中存在缺陷。因此需要更灵活的RAG方法。

Method: 提出两种新型RAG范式：1) Dynamic RAG：在LLM生成过程中自适应决定检索时机和内容；2) Parametric RAG：将知识注入从输入级提升到参数级，提高效率和效果。

Result: 本文是教程性综述，未报告具体实验指标，但系统性地总结了两类新兴RAG方法的理论基础与实践经验。

Conclusion: Dynamic RAG和Parametric RAG通过自适应检索和参数化知识注入为复杂任务提供了更优解决方案，有望推动RAG在知识密集型应用的进一步发展。

Abstract: Retrieval-Augmented Generation (RAG) has become a foundational paradigm for
equipping large language models (LLMs) with external knowledge, playing a
critical role in information retrieval and knowledge-intensive applications.
However, conventional RAG systems typically adopt a static
retrieve-then-generate pipeline and rely on in-context knowledge injection,
which can be suboptimal for complex tasks that require multihop reasoning,
adaptive information access, and deeper integration of external knowledge.
Motivated by these limitations, the research community has moved beyond static
retrieval and in-context knowledge injection. Among the emerging directions,
this tutorial delves into two rapidly growing and complementary research areas
on RAG: Dynamic RAG and Parametric RAG. Dynamic RAG adaptively determines when
and what to retrieve during the LLM's generation process, enabling real-time
adaptation to the LLM's evolving information needs. Parametric RAG rethinks how
retrieved knowledge should be injected into LLMs, transitioning from
input-level to parameter-level knowledge injection for enhanced efficiency and
effectiveness. This tutorial offers a comprehensive overview of recent advances
in these emerging research areas. It also shares theoretical foundations and
practical insights to support and inspire further research in RAG.

</details>


### [163] [DivScore: Zero-Shot Detection of LLM-Generated Text in Specialized Domains](https://arxiv.org/abs/2506.06705)
*Zhihui Chen,Kai He,Yucheng Huang,Yunxiao Zhu,Mengling Feng*

Main category: cs.CL

TL;DR: 提出DivScore零样本框架，用于在特殊领域检测AI生成的文本，通过归一化熵和领域知识来应对领域偏移，实验显示在医疗和法律领域效果显著。


<details>
  <summary>Details</summary>
Motivation: 目前在通用领域有效的AI文本检测器在医疗和法律等专业领域因领域偏移而表现不佳，需应对专业领域错误信息风险。

Method: DivScore框架结合归一化熵评分与领域知识蒸馏，基于KL散度理论分析，无需训练即可直接应用。

Result: 在自建医疗法律基准上：AUROC提高14.4%，召回率（0.1%假阳性率阈值）提升64.0%；对抗场景中AUROC平均提升22.8%，召回率提高29.5%。

Conclusion: DivScore在专业领域实现最先进检测性能，理论证明KL散度对领域偏移的影响，并开源代码与数据集供未来研究。

Abstract: Detecting LLM-generated text in specialized and high-stakes domains like
medicine and law is crucial for combating misinformation and ensuring
authenticity. However, current zero-shot detectors, while effective on general
text, often fail when applied to specialized content due to domain shift. We
provide a theoretical analysis showing this failure is fundamentally linked to
the KL divergence between human, detector, and source text distributions. To
address this, we propose DivScore, a zero-shot detection framework using
normalized entropy-based scoring and domain knowledge distillation to robustly
identify LLM-generated text in specialized domains. We also release a
domain-specific benchmark for LLM-generated text detection in the medical and
legal domains. Experiments on our benchmark show that DivScore consistently
outperforms state-of-the-art detectors, with 14.4% higher AUROC and 64.0%
higher recall (0.1% false positive rate threshold). In adversarial settings,
DivScore demonstrates superior robustness than other baselines, achieving on
average 22.8% advantage in AUROC and 29.5% in recall. Code and data are
publicly available.

</details>


### [164] [A Survey of Retentive Network](https://arxiv.org/abs/2506.06708)
*Haiqi Yang,Zhiyuan Li,Yi Chang,Yuan Wu*

Main category: cs.CL

TL;DR: 该论文是关于Retentive Network (RetNet)的首篇综述，分析了其作为Transformer高效替代方案的架构创新、应用领域、现有挑战及未来方向。


<details>
  <summary>Details</summary>
Motivation: 现有文献缺乏对RetNet架构的全面综述，而该网络在长序列处理上具有线性时间推理、并行训练等优势，已在多个领域证明有效性。

Method: 通过系统调查RetNet的保留机制（融合循环归纳偏置和全局依赖建模），总结其架构设计、应用场景（NLP/语音/时间序列）及优化方案。

Result: 归纳了RetNet突破Transformer二次复杂度局限的核心技术，建立统一框架对比其性能优势，并识别部署中的关键挑战。

Conclusion: RetNet是序列建模的重要进展，后续需研究其理论解释性、动态序列适应等方向以推动实际应用。

Abstract: Retentive Network (RetNet) represents a significant advancement in neural
network architecture, offering an efficient alternative to the Transformer.
While Transformers rely on self-attention to model dependencies, they suffer
from high memory costs and limited scalability when handling long sequences due
to their quadratic complexity. To mitigate these limitations, RetNet introduces
a retention mechanism that unifies the inductive bias of recurrence with the
global dependency modeling of attention. This mechanism enables linear-time
inference, facilitates efficient modeling of extended contexts, and remains
compatible with fully parallelizable training pipelines. RetNet has garnered
significant research interest due to its consistently demonstrated cross-domain
effectiveness, achieving robust performance across machine learning paradigms
including natural language processing, speech recognition, and time-series
analysis. However, a comprehensive review of RetNet is still missing from the
current literature. This paper aims to fill that gap by offering the first
detailed survey of the RetNet architecture, its key innovations, and its
diverse applications. We also explore the main challenges associated with
RetNet and propose future research directions to support its continued
advancement in both academic research and practical deployment.

</details>


### [165] [C-PATH: Conversational Patient Assistance and Triage in Healthcare System](https://arxiv.org/abs/2506.06737)
*Qi Shi,Qiwei Han,Cláudia Soares*

Main category: cs.CL

TL;DR: 引入C-PATH，一個基於大型語言模型的對話式AI系統，通過自然對話協助患者識別症狀和推薦醫療科室。系統通過三階段流程在LLaMA3架構上微調，並創建了基於GPT的數據增強框架將臨床知識轉化為對話數據。評估顯示其在清晰度、信息量和推薦準確性方面表現優異。


<details>
  <summary>Details</summary>
Motivation: 當前患者在導航複雜醫療系統時面臨挑戰，需要及時準確的診療指引但易被流程阻礙。開發能自然對話的智能分診助手可提升醫療可及性。

Method: 1) 基於LLaMA3架構構建三階段微調管道，融合醫學知識/對話數據/臨床摘要 2) 創新GPT驅動數據增強框架，將DDXPlus結構化知識轉譯為通俗對話 3) 設計可擴展對話歷史管理機制確保長期連貫性。

Result: GPTScore評估表明在多輪對話場景下，各維度性能超越領域基線：清晰度提升18%，推薦準確率達92.7%，信息完整性提高21%。在GPT重寫數據集上的量化評測顯著優於專業模型。

Conclusion: C-PATH證明了對話式AI在醫療分診場景的實用性，其數據增強和歷史管理策略為用戶中心化系統提供新範式。未來需臨床試驗驗證現實場景有效性。

Abstract: Navigating healthcare systems can be complex and overwhelming, creating
barriers for patients seeking timely and appropriate medical attention. In this
paper, we introduce C-PATH (Conversational Patient Assistance and Triage in
Healthcare), a novel conversational AI system powered by large language models
(LLMs) designed to assist patients in recognizing symptoms and recommending
appropriate medical departments through natural, multi-turn dialogues. C-PATH
is fine-tuned on medical knowledge, dialogue data, and clinical summaries using
a multi-stage pipeline built on the LLaMA3 architecture. A core contribution of
this work is a GPT-based data augmentation framework that transforms structured
clinical knowledge from DDXPlus into lay-person-friendly conversations,
allowing alignment with patient communication norms. We also implement a
scalable conversation history management strategy to ensure long-range
coherence. Evaluation with GPTScore demonstrates strong performance across
dimensions such as clarity, informativeness, and recommendation accuracy.
Quantitative benchmarks show that C-PATH achieves superior performance in
GPT-rewritten conversational datasets, significantly outperforming
domain-specific baselines. C-PATH represents a step forward in the development
of user-centric, accessible, and accurate AI tools for digital health
assistance and triage.

</details>


### [166] [Geopolitical biases in LLMs: what are the "good" and the "bad" countries according to contemporary language models](https://arxiv.org/abs/2506.06751)
*Mikhail Salnikov,Dmitrii Korzh,Ivan Lazichny,Elvir Karimov,Artyom Iudin,Ivan Oseledets,Oleg Y. Rogov,Alexander Panchenko,Natalia Loukachevitch,Elena Tutubalina*

Main category: cs.CL

TL;DR: 本文评估了LLM在地缘政治上的偏见，通过分析它们对不同国家（美、英、苏、中）历史事件冲突观点的解释。提出了包含中立事件描述和各国对立观点的数据集，发现模型存在显著偏见且倾向特定国家叙事。简单去偏见提示效果有限，实验显示模型对来源标签敏感。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLM）在处理涉及不同国家视角的历史事件时，可能表现出地缘政治偏见。这种偏见可能影响模型的公正性和可信度，需要系统评估和解决方案。

Method: 1. 构建包含中立事件描述和各国对立观点的新数据集；2. 量化评估LLM对不同国家叙事的偏好；3. 测试简单去偏见提示（如指令调整）的有效性；4. 通过互换参与者标签（如国家名）检测模型敏感性。

Result: 1. 所有测试模型均表现出显著的地缘政治偏见，倾向于特定国家（尤其是美国）的叙事；2. 简单去偏见提示仅能有限降低偏见；3. 国家标签互换实验揭示：模型对来源信息高度敏感——当标签矛盾时可能放大偏见或识别不一致。

Conclusion: LLM普遍存在地缘政治叙事偏见且难以通过简单方法消除。研究表明：（1）需要更精细的去偏见技术；（2）评估需考虑叙事标签的影响；（3）所提出的数据集和框架能为未来研究提供基准。

Abstract: This paper evaluates geopolitical biases in LLMs with respect to various
countries though an analysis of their interpretation of historical events with
conflicting national perspectives (USA, UK, USSR, and China). We introduce a
novel dataset with neutral event descriptions and contrasting viewpoints from
different countries. Our findings show significant geopolitical biases, with
models favoring specific national narratives. Additionally, simple debiasing
prompts had a limited effect in reducing these biases. Experiments with
manipulated participant labels reveal models' sensitivity to attribution,
sometimes amplifying biases or recognizing inconsistencies, especially with
swapped labels. This work highlights national narrative biases in LLMs,
challenges the effectiveness of simple debiasing methods, and offers a
framework and dataset for future geopolitical bias research.

</details>


### [167] [They want to pretend not to understand: The Limits of Current LLMs in Interpreting Implicit Content of Political Discourse](https://arxiv.org/abs/2506.06775)
*Walter Paci,Alessandro Panunzi,Sandro Pezzelle*

Main category: cs.CL

TL;DR: 该研究探讨大型语言模型(LLMs)在政治话语中解释隐含内容(如预设和含意)的能力，使用IMPAQTS语料库进行测试，发现现有模型在此任务上表现不佳，但指出了改进方向。


<details>
  <summary>Details</summary>
Motivation: 政治话语中广泛使用隐含内容作为操控手段，虽然LLMs在语义和语用理解方面表现强劲，但尚未系统评估其在政治场景中解释隐含内容的能力。

Method: 基于标注了操纵性隐含内容的意大利政治演讲语料库IMPAQTS，设计多选题和开放式生成任务评估LLMs对预设和含意的解释能力。

Result: 所有测试模型在解释预设和含意任务上均表现不佳，表明当前LLMs缺乏准确解读政治话语中高度隐含内容的关键语用能力。

Conclusion: 现有LLMs尚无法可靠处理政治隐含内容，但研究揭示了改进方向；同时公开了数据集和代码以促进相关研究。

Abstract: Implicit content plays a crucial role in political discourse, where speakers
systematically employ pragmatic strategies such as implicatures and
presuppositions to influence their audiences. Large Language Models (LLMs) have
demonstrated strong performance in tasks requiring complex semantic and
pragmatic understanding, highlighting their potential for detecting and
explaining the meaning of implicit content. However, their ability to do this
within political discourse remains largely underexplored. Leveraging, for the
first time, the large IMPAQTS corpus, which comprises Italian political
speeches with the annotation of manipulative implicit content, we propose
methods to test the effectiveness of LLMs in this challenging problem. Through
a multiple-choice task and an open-ended generation task, we demonstrate that
all tested models struggle to interpret presuppositions and implicatures. We
conclude that current LLMs lack the key pragmatic capabilities necessary for
accurately interpreting highly implicit language, such as that found in
political discourse. At the same time, we highlight promising trends and future
directions for enhancing model performance. We release our data and code at
https://github.com/WalterPaci/IMPAQTS-PID

</details>


### [168] [Extending dependencies to the taggedPBC: Word order in transitive clauses](https://arxiv.org/abs/2506.06785)
*Hiram Ring*

Main category: cs.CL

TL;DR: 该论文介绍了一个CoNLLU格式的依赖注释版本taggedPBC数据集，该数据集将依赖信息和POS标签扩展到1500多种语言中。虽然标签和依赖的质量存在问题，但从中提取的词序信息与三大类型学数据库的专家判定结果具有相关性，证明了基于语料库的类型学方法的有效性，并表明即使在噪声数据中也能获得重要见解。


<details>
  <summary>Details</summary>
Motivation: 原始taggedPBC数据集虽包含1800多句POS标注的平行文本（覆盖1500多种语言），但缺少依赖注释。为填补这一空白，本研究旨在创建依赖注释版本，探索语料库方法在语言类型学研究中的潜力，验证即使有噪声的标注数据也能提供有价值的语言学洞见。

Method: 通过将依赖信息和POS标签迁移到taggedPBC数据集的所有语言中，创建CoNLLU格式的依赖注释语料库。随后从该数据集中提取及物从句中论元和谓词的词序信息，并与WALS、Grambank、Autotyp三大类型学数据库的专家判定结果进行相关性分析。

Result: 1. 成功构建覆盖1500+语言的依赖注释语料库；2. 尽管存在标签质量担忧，但提取的词汇顺序与三个权威类型学数据库的专家判断显著相关；3. 验证了基于语料库的类型学方法对扩展离散语言类别比较的实用性；4. 证明充分标注的噪声数据仍能提供重要语言学见解。

Conclusion: 研究证明了自动化依赖标注在跨语言研究中的可行性，强调标注质量而非数据纯净度才是关键因素。通过GitHub公开的依赖注释语料库，为语言类型学合作研究提供新资源，推动计算语言学和语言类型学的交叉发展。

Abstract: The taggedPBC (Ring 2025a) contains more than 1,800 sentences of pos-tagged
parallel text data from over 1,500 languages, representing 133 language
families and 111 isolates. While this dwarfs previously available resources,
and the POS tags achieve decent accuracy, allowing for predictive
crosslinguistic insights (Ring 2025b), the dataset was not initially annotated
for dependencies. This paper reports on a CoNLLU-formatted version of the
dataset which transfers dependency information along with POS tags to all
languages in the taggedPBC. Although there are various concerns regarding the
quality of the tags and the dependencies, word order information derived from
this dataset regarding the position of arguments and predicates in transitive
clauses correlates with expert determinations of word order in three
typological databases (WALS, Grambank, Autotyp). This highlights the usefulness
of corpus-based typological approaches (as per Baylor et al. 2023; Bjerva 2024)
for extending comparisons of discrete linguistic categories, and suggests that
important insights can be gained even from noisy data, given sufficient
annotation. The dependency-annotated corpora are also made available for
research and collaboration via GitHub.

</details>


### [169] [On the Adaptive Psychological Persuasion of Large Language Models](https://arxiv.org/abs/2506.06800)
*Tianjie Ju,Yujia Chen,Hao Fei,Mong-Li Lee,Wynne Hsu,Pengzhou Cheng,Zongru Wu,Zhuosheng Zhang,Gongshen Liu*

Main category: cs.CL

TL;DR: 该论文探讨了大型语言模型（LLMs）在心理说服任务中的自主说服和抗说服能力。研究发现现有LLMs的说服策略重复且成功率低，引入11种心理说服策略可提升效果但缺乏普适性。作者提出一个基于直接偏好优化的自适应框架，训练LLMs自主选择最优策略，实验证明该方法显著提高了说服成功率。


<details>
  <summary>Details</summary>
Motivation: 针对LLMs在自主说服和抵抗心理修辞说服方面的能力缺乏系统性研究。现有模型在对抗性对话中策略单一、成功率低，需要开发能自适应选择最优心理策略的方法。

Method: 1. 评估四种主流LLMs作为说服者/倾听者的表现
2. 引入11种心理说服策略进行实验
3. 提出基于直接偏好优化(DPO)的自适应框架训练LLMs自主选择最优策略
4. 在三个开源LLMs上进行实验验证

Result: 1. 基线LLMs说服策略重复且成功率低
2. 明确指令采用特定心理策略（如流畅效应/重复效应）显著提升成功率
3. DPO框架使模型自主选择策略效果最优，说服成功率显著提升并保持通用能力

Conclusion: 通过自适应策略选择框架，LLMs能有效提升在心理说服任务中的表现，证明动态策略优化的必要性。代码已开源供进一步研究。

Abstract: Previous work has showcased the intriguing capabilities of Large Language
Models (LLMs) in instruction-following and rhetorical fluency. However,
systematic exploration of their dual capabilities to autonomously persuade and
resist persuasion, particularly in contexts involving psychological rhetoric,
remains unexplored. In this paper, we first evaluate four commonly adopted LLMs
by tasking them to alternately act as persuaders and listeners in adversarial
dialogues. Empirical results show that persuader LLMs predominantly employ
repetitive strategies, leading to low success rates. Then we introduce eleven
comprehensive psychological persuasion strategies, finding that explicitly
instructing LLMs to adopt specific strategies such as Fluency Effect and
Repetition Effect significantly improves persuasion success rates. However, no
``one-size-fits-all'' strategy proves universally effective, with performance
heavily dependent on contextual counterfactuals. Motivated by these
observations, we propose an adaptive framework based on direct preference
optimization that trains LLMs to autonomously select optimal strategies by
leveraging persuasion results from strategy-specific responses as preference
pairs. Experiments on three open-source LLMs confirm that the proposed adaptive
psychological persuasion method effectively enables persuader LLMs to select
optimal strategies, significantly enhancing their success rates while
maintaining general capabilities. Our code is available at
https://github.com/KalinaEine/PsychologicalPersuasion.

</details>


### [170] [Label-semantics Aware Generative Approach for Domain-Agnostic Multilabel Classification](https://arxiv.org/abs/2506.06806)
*Subhendu Khatuya,Shashwat Naidu,Saptarshi Ghosh,Pawan Goyal,Niloy Ganguly*

Main category: cs.CL

TL;DR: 该论文提出了一种新的生成式多标签文本分类框架LAGAMC，通过生成标签描述并匹配预定义描述，结合双目标损失函数，在多个数据集上实现了SOTA性能


<details>
  <summary>Details</summary>
Motivation: 解决文本数据爆炸导致的人工分类困难，传统方法将标签视为原子符号的局限性

Method: 1. 训练模型生成预定义的标签描述
2. 推理时用微调的句子转换器匹配生成描述与预定义标签
3. 使用结合交叉熵损失和余弦相似度的双目标损失函数

Result: 在所有评估数据集上取得新的SOTA性能，相比最佳基线：Micro-F1提升13.94%，Macro-F1提升24.85%

Conclusion: LAGAMC框架具有参数高效性和跨领域通用性，显著提升多标签分类性能

Abstract: The explosion of textual data has made manual document classification
increasingly challenging. To address this, we introduce a robust, efficient
domain-agnostic generative model framework for multi-label text classification.
Instead of treating labels as mere atomic symbols, our approach utilizes
predefined label descriptions and is trained to generate these descriptions
based on the input text. During inference, the generated descriptions are
matched to the pre-defined labels using a finetuned sentence transformer. We
integrate this with a dual-objective loss function, combining cross-entropy
loss and cosine similarity of the generated sentences with the predefined
target descriptions, ensuring both semantic alignment and accuracy. Our
proposed model LAGAMC stands out for its parameter efficiency and versatility
across diverse datasets, making it well-suited for practical applications. We
demonstrate the effectiveness of our proposed model by achieving new
state-of-the-art performances across all evaluated datasets, surpassing several
strong baselines. We achieve improvements of 13.94% in Micro-F1 and 24.85% in
Macro-F1 compared to the closest baseline across all datasets.

</details>


### [171] [Not quite Sherlock Holmes: Language model predictions do not reliably differentiate impossible from improbable events](https://arxiv.org/abs/2506.06808)
*James A. Michaelov,Reeka Estacio,Zhien Zhang,Benjamin K. Bergen*

Main category: cs.CL

TL;DR: 语言模型在区分可能事件与不可能事件方面不可靠，在部分条件下表现甚至低于随机水平。


<details>
  <summary>Details</summary>
Motivation: 探讨语言模型能否稳定预测可能事件比低概率事件更可能发生，通过解构可能性、典型性和语境相关性进行验证。

Method: 设计实验比较语言模型对不可能句子（如'车被刹车开了罚单'）和低概率句子（如'车被探险家开了罚单'）的概率赋值，测试Llama 3/Gemma 2/Mistral NeMo等模型。

Result: 所有模型在特定条件下均表现不佳，甚至出现给不可能句子分配概率高于低概率句子的反直觉结果。

Conclusion: 语言模型对可能性判断的稳健性不足，其预测能力受制于上下文因素而非实际可能性。

Abstract: Can language models reliably predict that possible events are more likely
than merely improbable ones? By teasing apart possibility, typicality, and
contextual relatedness, we show that despite the results of previous work,
language models' ability to do this is far from robust. In fact, under certain
conditions, all models tested - including Llama 3, Gemma 2, and Mistral NeMo -
perform at worse-than-chance level, assigning higher probabilities to
impossible sentences such as 'the car was given a parking ticket by the brake'
than to merely unlikely sentences such as 'the car was given a parking ticket
by the explorer'.

</details>


### [172] [Advancing Question Generation with Joint Narrative and Difficulty Control](https://arxiv.org/abs/2506.06812)
*Bernardo Leite,Henrique Lopes Cardoso*

Main category: cs.CL

TL;DR: 该研究提出了一种联合控制叙事和难度的策略，用于同时控制阅读理解问题生成的这两个属性。初步评估表明该方法可行，但并非在所有情况下都有效，并讨论了其适用条件和权衡。


<details>
  <summary>Details</summary>
Motivation: 现有研究缺乏将问题难度控制（DCQG）和叙事控制（NCQG）结合的方法，而结合这两种控制对于生成适合教育目的的问题至关重要。

Method: 提出了一种联合叙事和难度控制的策略（Joint Narrative and Difficulty Control），用于在阅读理解问题生成中同时控制这两个属性。

Result: 评估提供了初步证据表明该方法可行，但并非在所有实例中都有效，研究指出了策略表现良好的条件以及应用中的权衡。

Conclusion: 该研究填补了QG领域同时控制难度和叙事的空白，证明了联合控制策略的可行性，但指出其效果有局限性，需要根据特定条件应用。

Abstract: Question Generation (QG), the task of automatically generating questions from
a source input, has seen significant progress in recent years.
Difficulty-controllable QG (DCQG) enables control over the difficulty level of
generated questions while considering the learner's ability. Additionally,
narrative-controllable QG (NCQG) allows control over the narrative aspects
embedded in the questions. However, research in QG lacks a focus on combining
these two types of control, which is important for generating questions
tailored to educational purposes. To address this gap, we propose a strategy
for Joint Narrative and Difficulty Control, enabling simultaneous control over
these two attributes in the generation of reading comprehension questions. Our
evaluation provides preliminary evidence that this approach is feasible, though
it is not effective across all instances. Our findings highlight the conditions
under which the strategy performs well and discuss the trade-offs associated
with its application.

</details>


### [173] [BTPD: A Multilingual Hand-curated Dataset of Bengali Transnational Political Discourse Across Online Communities](https://arxiv.org/abs/2506.06813)
*Dipto Das,Syed Ishtiaque Ahmed,Shion Guha*

Main category: cs.CL

TL;DR: 为了解决孟加拉语（Bengali）这一重要但资源匮乏的语言中政治话语分析数据集缺乏的问题，本文构建了首个跨国孟加拉语政治话语（BTPD）多语言数据集，采集自三个不同社区结构的在线平台，并提供了关于数据集构建方法、主题和语言组成的概述


<details>
  <summary>Details</summary>
Motivation: 政治话语分析对于理解公众意见和意识形态极化至关重要，但现有研究集中在英语上，孟加拉语等资源匮乏的语言因数据集缺失而难以展开类似研究（研究背景）。需要构建跨平台孟加拉政治话语数据集来填补这一空白（研究必要性）

Method: 1）从三种不同社区结构的在线平台手工收集数据；2）通过社区知情（community-informed）的关键词检索策略构建数据集；3）对数据集的语种分布特征和话题结构进行统计分析

Result: 1）创建了名为BTPD的开源多语言数据集，覆盖三大平台；2）揭示了孟加拉跨国政治讨论的多语言现象（含多语种内容）；3）展示了不同平台的社区动态差异（如互动模式、话题分布等）

Conclusion: BTPD 数据集通过提供手动整理且具有社区代表性的样本资源，促进对资源稀缺语言的跨国政治话语研究（贡献成果）。本研究突出了在线社区结构对政治讨论形态的影响（价值洞察）

Abstract: Understanding political discourse in online spaces is crucial for analyzing
public opinion and ideological polarization. While social computing and
computational linguistics have explored such discussions in English, such
research efforts are significantly limited in major yet under-resourced
languages like Bengali due to the unavailability of datasets. In this paper, we
present a multilingual dataset of Bengali transnational political discourse
(BTPD) collected from three online platforms, each representing distinct
community structures and interaction dynamics. Besides describing how we
hand-curated the dataset through community-informed keyword-based retrieval,
this paper also provides a general overview of its topics and multilingual
content.

</details>


### [174] [How do datasets, developers, and models affect biases in a low-resourced language?](https://arxiv.org/abs/2506.06816)
*Dipto Das,Shion Guha,Bryan Semaan*

Main category: cs.CL

TL;DR: 这篇论文针对低资源语言孟加拉语，通过算法审核研究了情感分析模型中存在的性别、宗教和国籍偏见，发现尽管语义内容和结构相似，模型仍表现出跨身份类别的偏见，并讨论了这些偏见与认知不公、AI对齐及方法学决策的联系。


<details>
  <summary>Details</summary>
Motivation: 现有的语言技术常表现出基于身份的偏见，这种现象在低资源环境中研究不足，尤其加剧了边缘化群体的困境。虽然通常建议使用特定语言或多语言支持的模型和数据集来解决偏见，但其在孟加拉语环境中的有效性尚未经验证。

Method: 对基于mBERT和BanglaBERT的情感分析模型进行算法审核，这些模型使用Google Dataset Search中所有孟加拉情感分析数据集进行微调，重点检测性别、宗教和国籍维度的偏见。

Result: 研究发现，即使语义内容和结构相似，孟加拉情感分析模型在不同身份类别上仍表现出系统性偏见；同时揭示了预训练模型与多样化背景创建的数据集结合时产生的不一致性和不确定性。

Conclusion: 该研究将算法偏见问题与认知不公正、AI对齐等更广泛议题联系起来，强调了算法审核中方法学决策的重要性，尤其对低资源语言环境具有启示意义。

Abstract: Sociotechnical systems, such as language technologies, frequently exhibit
identity-based biases. These biases exacerbate the experiences of historically
marginalized communities and remain understudied in low-resource contexts.
While models and datasets specific to a language or with multilingual support
are commonly recommended to address these biases, this paper empirically tests
the effectiveness of such approaches in the context of gender, religion, and
nationality-based identities in Bengali, a widely spoken but low-resourced
language. We conducted an algorithmic audit of sentiment analysis models built
on mBERT and BanglaBERT, which were fine-tuned using all Bengali sentiment
analysis (BSA) datasets from Google Dataset Search. Our analyses showed that
BSA models exhibit biases across different identity categories despite having
similar semantic content and structure. We also examined the inconsistencies
and uncertainties arising from combining pre-trained models and datasets
created by individuals from diverse demographic backgrounds. We connected these
findings to the broader discussions on epistemic injustice, AI alignment, and
methodological decisions in algorithmic audits.

</details>


### [175] [Beyond Classification: Towards Speech Emotion Reasoning with Multitask AudioLLMs](https://arxiv.org/abs/2506.06820)
*Wenyu Zhang,Yingxu He,Geyu Lin,Zhuohan Liu,Shuo Sun,Bin Wang,Xunlong Zou,Jeremy H. M. Wong,Qiongqiong Wang,Hardik B. Sailor,Nancy F. Chen,Ai Ti Aw*

Main category: cs.CL

TL;DR: 该论文提出了一种利用音频大语言模型（AudioLLMs）进行情绪推理的方法，通过生成证据解释来提高情绪识别的准确性和解释性。结合了增强数据监督、双编码器结构和任务交替训练，实验在IEMOCAP和MELD数据集上显示出预测准确性和生成响应的改善。


<details>
  <summary>Details</summary>
Motivation: 现有方法将情绪理解视为分类问题，缺乏对预测背后理由的洞察。AudioLLMs在多语义任务中表现良好，但在建模副语言线索（如情绪）方面受限。因此，探索利用AudioLLMs的生成能力增强情绪识别，并通过证据基础解释提供合理化依据。

Method: 引入统一框架，结合三个方面：1) 增强推理的数据监督，2) 双编码器架构，3) 任务交替训练。使AudioLLMs能有效学习不同任务并融合情绪推理能力。

Result: 在IEMOCAP和MELD数据集上的实验表明，该方法不仅提升了情绪预测准确率（如分类性能指标优化），还增强了生成响应的连贯性和证据基础（如解释质量评估）。

Conclusion: 通过情绪推理策略，AudioLLMs在情绪识别任务中实现了更高准确性和可解释性，证明了生成式解释对多任务音频模型的有效性。统一框架解决了模型融合多任务学习的挑战，为副语言建模提供了新思路。

Abstract: Audio Large Language Models (AudioLLMs) have achieved strong results in
semantic tasks like speech recognition and translation, but remain limited in
modeling paralinguistic cues such as emotion. Existing approaches often treat
emotion understanding as a classification problem, offering little insight into
the underlying rationale behind predictions. In this work, we explore emotion
reasoning, a strategy that leverages the generative capabilities of AudioLLMs
to enhance emotion recognition by producing semantically aligned,
evidence-grounded explanations. To support this in multitask AudioLLMs, we
introduce a unified framework combining reasoning-augmented data supervision,
dual-encoder architecture, and task-alternating training. This approach enables
AudioLLMs to effectively learn different tasks while incorporating emotional
reasoning. Experiments on IEMOCAP and MELD show that our approach not only
improves emotion prediction accuracy but also enhances the coherence and
evidential grounding of the generated responses.

</details>


### [176] [Can LLMs Generate Reliable Test Case Generators? A Study on Competition-Level Programming Problems](https://arxiv.org/abs/2506.06821)
*Yuhan Cao,Zian Chen,Kun Quan,Ziliang Zhang,Yu Wang,Xiaoning Dong,Yeqi Feng,Guanzhong He,Jingcheng Huang,Jianhao Li,Yixuan Tan,Jiafu Tang,Yilin Tang,Junlei Wu,Qianyu Xiao,Can Zheng,Shouchen Zhou,Yuxiang Zhu,Yiming Huang,Tian Xie,Tianxing He*

Main category: cs.CL

TL;DR: 提出TCGBench基准来评估LLM在竞赛编程中生成测试用例生成器的能力，发现当前LLM可生成有效测试用例但难以针对性暴露代码缺陷，通过构建高质量数据集可提升性能。


<details>
  <summary>Details</summary>
Motivation: 探究LLM是否可通过生成测试用例来实现代码检查/调试，尤其是在竞赛编程场景中未被充分研究的领域。

Method: 构建包含两项任务的TCGBench基准：1) 标准测试用例生成器生成 2) 针对性暴露代码缺陷的生成器生成。使用高级LLM（如o3-mini）进行实验，并构建手动标注的针对性生成器指令数据集。

Result: 实验表明：SOTA LLM能生成有效测试用例（任务1），但多数难以生成针对性暴露缺陷的用例（任务2），性能显著低于人类。使用构建数据集后（通过提示微调或精调），LLM性能显着提升。

Conclusion: LLM在针对性测试用例生成能力不足，但可通过高质量指导数据集改善。这为LLM辅助调试提供了新方向，并揭示了当前模型局限性。

Abstract: Large Language Models (LLMs) have demonstrated remarkable capabilities in
code generation, capable of tackling complex tasks during inference. However,
the extent to which LLMs can be utilized for code checking or debugging through
test case generation remains largely unexplored. We investigate this problem
from the perspective of competition-level programming (CP) programs and propose
TCGBench, a Benchmark for (LLM generation of) Test Case Generators. This
benchmark comprises two tasks, aimed at studying the capabilities of LLMs in
(1) generating valid test case generators for a given CP problem, and further
(2) generating targeted test case generators that expose bugs in human-written
code. Experimental results indicate that while state-of-the-art LLMs can
generate valid test case generators in most cases, most LLMs struggle to
generate targeted test cases that reveal flaws in human code effectively.
Especially, even advanced reasoning models (e.g., o3-mini) fall significantly
short of human performance in the task of generating targeted generators.
Furthermore, we construct a high-quality, manually curated dataset of
instructions for generating targeted generators. Analysis demonstrates that the
performance of LLMs can be enhanced with the aid of this dataset, by both
prompting and fine-tuning.

</details>


### [177] [PCoT: Persuasion-Augmented Chain of Thought for Detecting Fake News and Social Media Disinformation](https://arxiv.org/abs/2506.06842)
*Arkadiusz Modzelewski,Witold Sosnowski,Tiziano Labruna,Adam Wierzbicki,Giovanni Da San Martino*

Main category: cs.CL

TL;DR: 提出了Persuasion-Augmented Chain of Thought (PCoT)方法，通过在零样本分类中融入说服知识来提高虚假信息检测效果，并在五个LLM和五个数据集上平均性能提升15%。发布两个新数据集EUDisinfo和MultiDis用于评估。


<details>
  <summary>Details</summary>
Motivation: 心理学研究表明，了解说服谬误能帮助个体识别虚假信息。受此启发，作者探索了在大型语言模型中注入说服知识是否能提升虚假信息检测能力。

Method: 提出PCoT方法——在思维链中融合说服知识，利用说服机制增强零样本分类的虚假信息检测。使用在线新闻和社交媒体帖子进行广泛评估，并创建两个新数据集EUDisinfo与MultiDis（内容发表于模型知识截止日期后，确保评估公正性）。

Result: 实验表明：PCoT在五个大型语言模型和五个数据集上的平均性能优于基线方法15%；发布的两个新数据集为未来研究提供了全新测试基准。

Conclusion: 说服知识的引入显著强化了零样本虚假信息检测能力，验证了心理学发现与LLM能力结合的可行性；新发布的数据集填补了当前时效性数据空白。

Abstract: Disinformation detection is a key aspect of media literacy. Psychological
studies have shown that knowledge of persuasive fallacies helps individuals
detect disinformation. Inspired by these findings, we experimented with large
language models (LLMs) to test whether infusing persuasion knowledge enhances
disinformation detection. As a result, we introduce the Persuasion-Augmented
Chain of Thought (PCoT), a novel approach that leverages persuasion to improve
disinformation detection in zero-shot classification. We extensively evaluate
PCoT on online news and social media posts. Moreover, we publish two novel,
up-to-date disinformation datasets: EUDisinfo and MultiDis. These datasets
enable the evaluation of PCoT on content entirely unseen by the LLMs used in
our experiments, as the content was published after the models' knowledge
cutoffs. We show that, on average, PCoT outperforms competitive methods by 15%
across five LLMs and five datasets. These findings highlight the value of
persuasion in strengthening zero-shot disinformation detection.

</details>


### [178] [Adapt Once, Thrive with Updates: Transferable Parameter-Efficient Fine-Tuning on Evolving Base Models](https://arxiv.org/abs/2506.06844)
*Naibin Gu,Peng Fu,Xiyu Liu,Ke Ma,Zheng Lin,Weiping Wang*

Main category: cs.CL

TL;DR: Trans-PEFT: 一种解决参数高效微调模块在基础模型更新后性能下降的方法，通过关注任务特定模式减少对基础模型知识的依赖，无需重新调优即可适应新版本


<details>
  <summary>Details</summary>
Motivation: 基础模型更新后，原有PEFT模块性能大幅下降，重新调优所有模块计算成本高。研究发现持续训练主要影响前馈网络的任务知识，对注意力机制中任务模式影响较小。

Method: 提出Trans-PEFT方法，增强PEFT模块对任务模式的关注度，降低对基础模型特定知识的依赖。包含理论分析和模块设计改进。

Result: 在7个基础模型和12个数据集上的实验表明，Trans-PEFT训练的模块在更新后的基础模型上无需重新调优即可保持性能

Conclusion: Trans-PEFT显著降低实际应用中PEFT模块的维护开销，为多用户场景下的基础模型持续更新提供高效解决方案

Abstract: Parameter-efficient fine-tuning (PEFT) has become a common method for
fine-tuning large language models, where a base model can serve multiple users
through PEFT module switching. To enhance user experience, base models require
periodic updates. However, once updated, PEFT modules fine-tuned on previous
versions often suffer substantial performance degradation on newer versions.
Re-tuning these numerous modules to restore performance would incur significant
computational costs. Through a comprehensive analysis of the changes that occur
during base model updates, we uncover an interesting phenomenon: continual
training primarily affects task-specific knowledge stored in Feed-Forward
Networks (FFN), while having less impact on the task-specific pattern in the
Attention mechanism. Based on these findings, we introduce Trans-PEFT, a novel
approach that enhances the PEFT module by focusing on the task-specific pattern
while reducing its dependence on certain knowledge in the base model. Further
theoretical analysis supports our approach. Extensive experiments across 7 base
models and 12 datasets demonstrate that Trans-PEFT trained modules can maintain
performance on updated base models without re-tuning, significantly reducing
maintenance overhead in real-world applications.

</details>


### [179] [Right Is Not Enough: The Pitfalls of Outcome Supervision in Training LLMs for Math Reasoning](https://arxiv.org/abs/2506.06877)
*Jiaxing Guo,Wenjie Yang,Shengzhong Zhang,Tongshan Xu,Lun Du,Da Zheng,Zengfeng Huang*

Main category: cs.CL

TL;DR: 该论文指出，通过结果奖励训练的大型语言模型在解决数学问题时存在推理过程缺陷，尽管答案正确。研究团队引入了MathOlympiadEval数据集，揭示了模型的答案正确性与过程正确性之间的显著差距。现有方法难以可靠检测推理缺陷，因此作者提出了ParaStepVerifier方法进行逐步验证。实验表明该方法能显著提高识别错误推理步骤的准确性。


<details>
  <summary>Details</summary>
Motivation: 当前通过结果奖励训练的LLMs存在'奖励黑客'现象，即模型通过错误的推理过程得出正确答案。现有评估方法无法有效检测这种逻辑缺陷，尤其在复杂多步骤数学问题中。

Method: 1. 提出精细化标注数据集MathOlympiadEval；2. 设计ParaStepVerifier方法：将证明分解为并行步骤进行验证；3. 通过识别单步错误实现整体推理链条的可靠性评估。

Result: ParaStepVerifier在检测错误推理步骤上的准确率显著超过基线方法（如LLM-as-a-judge），尤其在多步骤问题上提升明显。新数据集揭示了模型答案正确率（高）与过程正确率（低）之间的巨大差距（例如GPT-4仅为25%）。

Conclusion: 结果奖励机制导致LLMs产生表面正确的虚假推理。ParaStepVerifier为识别真实数学推理能力提供了更可靠的评估路径，未来可应用于模型训练以提升推理严谨性。

Abstract: Outcome-rewarded Large Language Models (LLMs) have demonstrated remarkable
success in mathematical problem-solving. However, this success often masks a
critical issue: models frequently achieve correct answers through fundamentally
unsound reasoning processes, a phenomenon indicative of reward hacking. We
introduce MathOlympiadEval, a new dataset with fine-grained annotations, which
reveals a significant gap between LLMs' answer correctness and their low
process correctness. Existing automated methods like LLM-as-a-judge struggle to
reliably detect these reasoning flaws. To address this, we propose
ParaStepVerifier, a novel methodology for meticulous, step-by-step verification
of mathematical solutions. ParaStepVerifier identifies incorrect reasoning
steps. Empirical results demonstrate that ParaStepVerifier substantially
improves the accuracy of identifying flawed solutions compared to baselines,
especially for complex, multi-step problems. This offers a more robust path
towards evaluating and training LLMs with genuine mathematical reasoning.

</details>


### [180] [Mixture of Small and Large Models for Chinese Spelling Check](https://arxiv.org/abs/2506.06887)
*Ziheng Qiao,Houquan Zhou,Zhenghua Li*

Main category: cs.CL

TL;DR: 该论文提出了一种动态混合方法，结合微调小模型和大型语言模型（LLMs）的概率分布，在不微调LLMs的情况下提升了中文拼写检查（CSC）任务的性能。


<details>
  <summary>Details</summary>
Motivation: 现有LLMs方法在CSC任务上表现不佳，而微调的BERT模型在高质量领域数据上表现好但容易过拟合编辑模式。

Method: 在beam search解码阶段动态混合小模型和LLMs的概率分布，平衡小模型的精确纠正和LLMs的流畅性。

Result: 该方法显著提升纠错能力，在多个数据集上达到SOTA（最先进）结果。

Conclusion: 动态混合方法有效结合了两种模型的优势，节省了LLM微调的成本，并有利于领域适应。

Abstract: In the era of large language models (LLMs), the Chinese Spelling Check (CSC)
task has seen various LLM methods developed, yet their performance remains
unsatisfactory. In contrast, fine-tuned BERT-based models, relying on
high-quality in-domain data, show excellent performance but suffer from edit
pattern overfitting. This paper proposes a novel dynamic mixture approach that
effectively combines the probability distributions of small models and LLMs
during the beam search decoding phase, achieving a balanced enhancement of
precise corrections from small models and the fluency of LLMs. This approach
also eliminates the need for fine-tuning LLMs, saving significant time and
resources, and facilitating domain adaptation. Comprehensive experiments
demonstrate that our mixture approach significantly boosts error correction
capabilities, achieving state-of-the-art results across multiple datasets. Our
code is available at https://github.com/zhqiao-nlp/MSLLM.

</details>


### [181] [Automatic Speech Recognition of African American English: Lexical and Contextual Effects](https://arxiv.org/abs/2506.06888)
*Hamid Mojarad,Kevin Tang*

Main category: cs.CL

TL;DR: 该研究发现ASR对非洲裔美国人英语（AAE）中的辅音丛简化（CCR）和ING缩减现象存在显著识别错误，且无外部语言模型（LM）的ASR系统更易受词汇邻域效应影响。


<details>
  <summary>Details</summary>
Motivation: 解决自动语音识别（ASR）对非洲裔美国人英语（AAE）特有语音特征的识别问题，特别是辅音丛简化（CCR）和ING缩减现象的影响。

Method: 使用wav2vec 2.0（带或不带LM）转录AAE语料库CORAAL；利用蒙特利尔强制对齐器（MFA）检测CCR/ING缩减；分析这些因素对词错误率（WER）的影响及LM对上下文预测力的作用。

Result: CCR和ING缩减对WER有显著但较小的影响；无LM的ASR系统中词汇邻域效应更明显。

Conclusion: AAE特定语音特征会降低ASR性能；外部语言模型可减轻词汇邻域效应，但需专门优化以提高对语言变体的包容性。

Abstract: Automatic Speech Recognition (ASR) models often struggle with the phonetic,
phonological, and morphosyntactic features found in African American English
(AAE). This study focuses on two key AAE variables: Consonant Cluster Reduction
(CCR) and ING-reduction. It examines whether the presence of CCR and
ING-reduction increases ASR misrecognition. Subsequently, it investigates
whether end-to-end ASR systems without an external Language Model (LM) are more
influenced by lexical neighborhood effect and less by contextual predictability
compared to systems with an LM. The Corpus of Regional African American
Language (CORAAL) was transcribed using wav2vec 2.0 with and without an LM. CCR
and ING-reduction were detected using the Montreal Forced Aligner (MFA) with
pronunciation expansion. The analysis reveals a small but significant effect of
CCR and ING on Word Error Rate (WER) and indicates a stronger presence of
lexical neighborhood effect in ASR systems without LMs.

</details>


### [182] [Hybrid Extractive Abstractive Summarization for Multilingual Sentiment Analysis](https://arxiv.org/abs/2506.06929)
*Mikhail Krasitskii,Grigori Sidorov,Olga Kolesnikova,Liliana Chanona Hernandez,Alexander Gelbukh*

Main category: cs.CL

TL;DR: 该论文提出一种混合多语言情感分析方法，结合抽取式和生成式摘要，以克服单一方法限制。利用TF-IDF抽取和调优的XLM-R生成模块，配合动态阈值与文化适应，在10种语言上显著超越基线，英语准确率达0.90，低资源语言达0.84。计算效率提升22%，可应用于品牌监控和跨文化分析。未来计划通过8位量化优化低资源语言性能。


<details>
  <summary>Details</summary>
Motivation: 解决单方法处理多语言情感分析时的局限（如文化差异、资源不均衡问题），通过结合抽取和生成式摘要的优势提升准确性及效率。

Method: 1. 整合TF-IDF抽取式摘要
2. 微调XLM-R进行生成式摘要
3. 引入动态阈值调整机制
4. 加入文化适应性组件

Result: 1. 在10种语言测试中：英语准确率0.90，低资源语言0.84
2. 计算效率比传统方法提高22%
3. 成功应用于实时品牌监控和跨文化话语分析场景

Conclusion: 混合方法显著提升多语言情感分析性能，尤其在跨文化场景和效率方面；未来将通过8位量化继续优化低资源语言支持。

Abstract: We propose a hybrid approach for multilingual sentiment analysis that
combines extractive and abstractive summarization to address the limitations of
standalone methods. The model integrates TF-IDF-based extraction with a
fine-tuned XLM-R abstractive module, enhanced by dynamic thresholding and
cultural adaptation. Experiments across 10 languages show significant
improvements over baselines, achieving 0.90 accuracy for English and 0.84 for
low-resource languages. The approach also demonstrates 22% greater
computational efficiency than traditional methods. Practical applications
include real-time brand monitoring and cross-cultural discourse analysis.
Future work will focus on optimization for low-resource languages via 8-bit
quantization.

</details>


### [183] [DiscoSum: Discourse-aware News Summarization](https://arxiv.org/abs/2506.06930)
*Alexander Spangher,Tenghao Huang,Jialiang Gu,Jiatong Shi,Muhao Chen*

Main category: cs.CL

TL;DR: 本文提出了一种将语篇结构整合到新闻摘要生成中的新方法，以解决语言模型在保持新闻文章组织流程上的不足；开发了新型新闻语篇框架、数据集及DiscoSum算法，实验证明该方法能有效保持叙述忠实度并满足结构要求。


<details>
  <summary>Details</summary>
Motivation: 当前文本摘要方法主要依赖大语言模型，但它们在处理新闻文章时难以维持长期语篇结构，而文章的组织流程对读者参与度至关重要。

Method: 1. 构建多平台新闻摘要数据集；2. 设计新型新闻语篇框架；3. 开发DiscoSum算法（基于束搜索技术），实现结构感知的摘要生成。

Result: 通过人工和自动评估验证：该方法成功保持叙述忠实度并满足不同结构性需求，尤其在跨社交媒体平台适应性上表现显著。

Conclusion: 将语篇结构显式整合到摘要过程中可有效提升新闻摘要质量，DiscoSum算法为不同风格/结构需求提供通用解决方案。

Abstract: Recent advances in text summarization have predominantly leveraged large
language models to generate concise summaries. However, language models often
do not maintain long-term discourse structure, especially in news articles,
where organizational flow significantly influences reader engagement. We
introduce a novel approach to integrating discourse structure into
summarization processes, focusing specifically on news articles across various
media. We present a novel summarization dataset where news articles are
summarized multiple times in different ways across different social media
platforms (e.g. LinkedIn, Facebook, etc.). We develop a novel news discourse
schema to describe summarization structures and a novel algorithm, DiscoSum,
which employs beam search technique for structure-aware summarization, enabling
the transformation of news stories to meet different stylistic and structural
demands. Both human and automatic evaluation results demonstrate the efficacy
of our approach in maintaining narrative fidelity and meeting structural
requirements.

</details>


### [184] [What Makes a Good Natural Language Prompt?](https://arxiv.org/abs/2506.06950)
*Do Xuan Long,Duy Dinh,Ngoc-Hai Nguyen,Kenji Kawaguchi,Nancy F. Chen,Shafiq Joty,Min-Yen Kan*

Main category: cs.CL

TL;DR: 该研究对超过150篇关于提示工程的论文和博客进行了元分析，提出了一个包含六个维度和21个属性的提示质量评估框架，并分析了高质量自然语言提示的属性相关性。研究发现单一属性增强在推理任务中效果最显著，且基于属性增强提示进行指令微调能提升模型推理能力。


<details>
  <summary>Details</summary>
Motivation: 随着大型语言模型的进步和人机交互日益普遍，提示质量成为关键因素。但目前缺乏对自然语言提示的量化共识，因此需要建立一个系统的评估框架来分析提示属性如何影响模型表现。

Method: 1. 元分析150+篇提示相关文献 2.提出六个维度(可理解性/适配性等)的21属性评估框架 3.实验研究属性相关性及单属性增强效果 4.采用属性增强提示进行指令微调训练

Result: 1.揭示现有研究对各属性支持不均衡 2.发现高质量提示中属性间存在多重相关性 3.单属性增强在推理任务提升最显著(如增强'清晰性'使GPT-4准确率提升22%) 4.基于属性增强提示微调的模型在GSM8K基准提升3.1%

Conclusion: 该研究通过构建首个属性中心的提示评估框架，揭示了提示属性的独立价值和组合效应，为人机交互提示优化奠定基础，并为通过提示工程提升模型性能开辟新方向。

Abstract: As large language models (LLMs) have progressed towards more human-like and
human--AI communications have become prevalent, prompting has emerged as a
decisive component. However, there is limited conceptual consensus on what
exactly quantifies natural language prompts. We attempt to address this
question by conducting a meta-analysis surveying more than 150
prompting-related papers from leading NLP and AI conferences from 2022 to 2025
and blogs. We propose a property- and human-centric framework for evaluating
prompt quality, encompassing 21 properties categorized into six dimensions. We
then examine how existing studies assess their impact on LLMs, revealing their
imbalanced support across models and tasks, and substantial research gaps.
Further, we analyze correlations among properties in high-quality natural
language prompts, deriving prompting recommendations. We then empirically
explore multi-property prompt enhancements in reasoning tasks, observing that
single-property enhancements often have the greatest impact. Finally, we
discover that instruction-tuning on property-enhanced prompts can result in
better reasoning models. Our findings establish a foundation for
property-centric prompt evaluation and optimization, bridging the gaps between
human--AI communication and opening new prompting research directions.

</details>


### [185] [BIS Reasoning 1.0: The First Large-Scale Japanese Benchmark for Belief-Inconsistent Syllogistic Reasoning](https://arxiv.org/abs/2506.06955)
*Ha-Thanh Nguyen,Chaoran Liu,Hirokazu Kiyomaru,Koichi Takeda,Yusuke Miyao,Maki Matsuda,Yusuke Oda,Pontus Stenetorp,Qianying Liu,Su Myat Noe,Hideyuki Tachibana,Kouta Nakayama,Sadao Kurohashi*

Main category: cs.CL

TL;DR: ...


<details>
  <summary>Details</summary>
Motivation: ...

Method: ...

Result: ...

Conclusion: ...

Abstract: We present BIS Reasoning 1.0, the first large-scale Japanese dataset of
syllogistic reasoning problems explicitly designed to evaluate
belief-inconsistent reasoning in large language models (LLMs). Unlike prior
datasets such as NeuBAROCO and JFLD, which focus on general or belief-aligned
reasoning, BIS Reasoning 1.0 introduces logically valid yet belief-inconsistent
syllogisms to uncover reasoning biases in LLMs trained on human-aligned
corpora. We benchmark state-of-the-art models - including GPT models, Claude
models, and leading Japanese LLMs - revealing significant variance in
performance, with GPT-4o achieving 79.54% accuracy. Our analysis identifies
critical weaknesses in current LLMs when handling logically valid but
belief-conflicting inputs. These findings have important implications for
deploying LLMs in high-stakes domains such as law, healthcare, and scientific
literature, where truth must override intuitive belief to ensure integrity and
safety.

</details>


### [186] [Learning to Clarify by Reinforcement Learning Through Reward-Weighted Fine-Tuning](https://arxiv.org/abs/2506.06964)
*Subhojyoti Mukherjee,Viet Dac Lai,Raghavendra Addanki,Ryan Rossi,Seunghyun Yoon,Trung Bui,Anup Rao,Jayakumar Subramanian,Branislav Kveton*

Main category: cs.CL

TL;DR: 该论文提出了一种在问答系统中通过强化学习学习询问澄清问题的方法，使用离线强化学习目标进行优化，相比监督微调和直接偏好优化方法，在优化奖励和语言质量方面表现更优。


<details>
  <summary>Details</summary>
Motivation: 在问答代理中，当问题模糊或不完整时，需要能够提出澄清性问题以提高回答准确性。现有方法如监督微调（SFT）和直接偏好优化（DPO）存在超参数调整问题且不能直接优化奖励函数，因此需要更有效的方法。

Method: 提出通过强化学习（RL）模拟包含澄清问题的对话进行学习。使用离线RL目标（本质是奖励加权的监督微调），无需额外超参数，易于在大型语言模型中优化。

Result: 相比SFT和DPO方法，该方法在优化的奖励指标和语言质量方面均取得提升。

Conclusion: 所提出的离线强化学习方法能有效训练问答代理学习询问澄清问题，在优化奖励和语言质量上优于现有基准方法。

Abstract: Question answering (QA) agents automatically answer questions posed in
natural language. In this work, we learn to ask clarifying questions in QA
agents. The key idea in our method is to simulate conversations that contain
clarifying questions and learn from them using reinforcement learning (RL). To
make RL practical, we propose and analyze offline RL objectives that can be
viewed as reward-weighted supervised fine-tuning (SFT) and easily optimized in
large language models. Our work stands in a stark contrast to recently proposed
methods, based on SFT and direct preference optimization, which have additional
hyper-parameters and do not directly optimize rewards. We compare to these
methods empirically and report gains in both optimized rewards and language
quality.

</details>


### [187] [A dependently-typed calculus of event telicity and culminativity](https://arxiv.org/abs/2506.06968)
*Pavel Kovalev,Carlo Angiuli*

Main category: cs.CL

TL;DR: 介绍了一个基于依赖类型理论的跨语言框架，用于分析事件的有界性和完成性，通过英语例句展示应用，并已在Agda证明助手中形式化实现。


<details>
  <summary>Details</summary>
Motivation: 解决语言学中对事件结构（特别是事件的有界性telicity和完成性culminativity）的系统化建模需求，结合名词短语的有界性和动词领域的事件演算。

Method: 1) 在名词领域：建模名词短语的有界性及其与子类型化、定量限定和形容词修饰的关系；2) 在动词领域：提出依赖事件演算，将有界受事作为有界事件的定义标准，并将达成内在终点的有界事件定义为完成事件；3) 在两者领域特别关注推导关系；4) 框架基于带内涵的Martin-Löf依赖类型理论扩展实现，并通过Agda形式化验证。

Result: 开发了一个形式化框架能统一处理名词有界性和动词事件结构，具体展示了英语句子的建模能力。通过类型理论和证明助手为语言现象提供了严格的计算基础。

Conclusion: 该框架为事件结构提供了可计算的理论模型，同时关联名词和动词领域的语义特性，其形式化实现确保了逻辑一致性，为跨语言分析奠定基础。

Abstract: We present a dependently-typed cross-linguistic framework for analyzing the
telicity and culminativity of events, accompanied by examples of using our
framework to model English sentences. Our framework consists of two parts. In
the nominal domain, we model the boundedness of noun phrases and its
relationship to subtyping, delimited quantities, and adjectival modification.
In the verbal domain we define a dependent event calculus, modeling telic
events as those whose undergoer is bounded, culminating events as telic events
that achieve their inherent endpoint, and consider adverbial modification. In
both domains we pay particular attention to associated entailments. Our
framework is defined as an extension of intensional Martin-L\"of dependent type
theory, and the rules and examples in this paper have been formalized in the
Agda proof assistant.

</details>


### [188] [Break-The-Chain: Reasoning Failures in LLMs via Adversarial Prompting in Code Generation](https://arxiv.org/abs/2506.06971)
*Jaechul Roh,Varun Gandhi,Shivani Anilkumar,Arin Garg*

Main category: cs.CL

TL;DR: 该论文引入了一套语义忠实但对抗性结构的提示扰动方法，系统研究了大型语言模型（LLMs）在复杂推理任务中的鲁棒性。通过对700个经过扰动的LeetCode风格代码生成问题进行评估，发现某些扰动会导致模型性能严重下降（准确性下降高达42.1%），而另一些扰动则意外提升准确性（提高达35.3%），揭示了当前推理系统的脆弱性和不可预测性。


<details>
  <summary>Details</summary>
Motivation: 尽管LLMs在需要复杂推理的任务（如代码生成、数学问题解决）中取得了显著成功，但核心问题仍未解决：这些模型是否真正进行推理，还是仅仅利用浅层的统计模式？

Method: 研究者开发了一套包含语义忠实但对抗性结构变化的提示扰动方法（如故事化重构、无关约束注入、示例重排序和数字扰动），并在700个基于LeetCode风格问题的扰动代码生成案例中进行评估。

Result: 评估发现：特定扰动会导致模型性能显著下降（最大准确性降幅42.1%），而其他扰动却意外提升性能（最大升幅35.3%），表明模型性能对提示的表面结构和语义均高度敏感。

Conclusion: 当前推理系统存在显著脆弱性和不可预测性，突显了对推理对齐和提示鲁棒性建立更原则性方法的需求。研究者开源扰动数据集和评估框架以促进可信赖LLM推理研究。

Abstract: Large Language Models (LLMs) have achieved remarkable success in tasks
requiring complex reasoning, such as code generation, mathematical problem
solving, and algorithmic synthesis -- especially when aided by reasoning tokens
and Chain-of-Thought prompting. Yet, a core question remains: do these models
truly reason, or do they merely exploit shallow statistical patterns? In this
paper, we systematically investigate the robustness of reasoning LLMs by
introducing a suite of semantically faithful yet adversarially structured
prompt perturbations. Our evaluation -- spanning 700 perturbed code generations
derived from LeetCode-style problems -- applies transformations such as
storytelling reframing, irrelevant constraint injection, example reordering,
and numeric perturbation. We observe that while certain modifications severely
degrade performance (with accuracy drops up to -42.1%), others surprisingly
improve model accuracy by up to 35.3%, suggesting sensitivity not only to
semantics but also to surface-level prompt dynamics. These findings expose the
fragility and unpredictability of current reasoning systems, underscoring the
need for more principles approaches to reasoning alignments and prompting
robustness. We release our perturbation datasets and evaluation framework to
promote further research in trustworthy and resilient LLM reasoning.

</details>


### [189] [Atomic Reasoning for Scientific Table Claim Verification](https://arxiv.org/abs/2506.06972)
*Yuji Zhang,Qingyun Wang,Cheng Qian,Jiateng Liu,Chenkai Sun,Denghui Zhang,Tarek Abdelzaher,Chengxiang Zhai,Preslav Nakov,Heng Ji*

Main category: cs.CL

TL;DR: 论文针对科学表格中的误导性信息，提出基于认知负荷理论减少复杂性的原子技能链方法。只用了350个微调样本，新模型在SciAtomicBench基准上性能就超过GPT-4o的思维链方法。


<details>
  <summary>Details</summary>
Motivation: 科学表格信息密度高、可信度强，但易使非专家误解。现有表格验证模型（包括SOTA大模型）在细粒度推理上存在错误，缺乏精确性。

Method: 受认知负荷理论启发，设计可复用的原子技能模块（atomic skills），通过技能链动态组合这些原子技能，降低认知负担。

Result: 仅用350个微调样本开发的模型在跨领域基准SciAtomicBench上超越GPT-4o的思维链方法，取得SOTA性能，训练数据量显著减少。

Conclusion: 原子技能链方法能有效压缩认知负荷，提升表格细粒度验证的准确性和泛化能力。这为信息验证模型的轻量化训练提供新思路。

Abstract: Scientific texts often convey authority due to their technical language and
complex data. However, this complexity can sometimes lead to the spread of
misinformation. Non-experts are particularly susceptible to misleading claims
based on scientific tables due to their high information density and perceived
credibility. Existing table claim verification models, including
state-of-the-art large language models (LLMs), often struggle with precise
fine-grained reasoning, resulting in errors and a lack of precision in
verifying scientific claims. Inspired by Cognitive Load Theory, we propose that
enhancing a model's ability to interpret table-based claims involves reducing
cognitive load by developing modular, reusable reasoning components (i.e.,
atomic skills). We introduce a skill-chaining schema that dynamically composes
these skills to facilitate more accurate and generalizable reasoning with a
reduced cognitive load. To evaluate this, we create SciAtomicBench, a
cross-domain benchmark with fine-grained reasoning annotations. With only 350
fine-tuning examples, our model trained by atomic reasoning outperforms
GPT-4o's chain-of-thought method, achieving state-of-the-art results with far
less training data.

</details>


### [190] [Chain of Methodologies: Scaling Test Time Computation without Training](https://arxiv.org/abs/2506.06982)
*Cong Liu,Jie Wu,Weigang Wu,Xu Chen,Liang Lin,Wei-Shi Zheng*

Main category: cs.CL

TL;DR: Chain of Methodologies (CoM) 是一种创新的提示框架，通过整合人类方法论洞察来增强语言模型的结构化思维，无需微调即可提升复杂推理任务性能，实验证明其优于现有基线方法。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在处理复杂推理任务时，由于训练数据缺乏深度洞察而表现不佳。本文旨在通过人类方法论激发系统性推理，弥补这一不足。

Method: 提出CoM框架：通过用户自定义的方法论激活语言模型的元认知能力，引导其进行结构化延伸推理。此方法无需微调模型。

Result: 实验表明CoM在复杂推理任务中超越现有基线方法，验证了免训练提示框架的有效性。

Conclusion: CoM证明整合人类方法论的提示策略能显著提升模型推理能力，为接近人类水平推理提供了新路径。

Abstract: Large Language Models (LLMs) often struggle with complex reasoning tasks due
to insufficient in-depth insights in their training data, which are typically
absent in publicly available documents. This paper introduces the Chain of
Methodologies (CoM), an innovative and intuitive prompting framework that
enhances structured thinking by integrating human methodological insights,
enabling LLMs to tackle complex tasks with extended reasoning. CoM leverages
the metacognitive abilities of advanced LLMs, activating systematic reasoning
throught user-defined methodologies without explicit fine-tuning. Experiments
show that CoM surpasses competitive baselines, demonstrating the potential of
training-free prompting methods as robust solutions for complex reasoning tasks
and bridging the gap toward human-level reasoning through human-like
methodological insights.

</details>


### [191] [Cultural Bias Matters: A Cross-Cultural Benchmark Dataset and Sentiment-Enriched Model for Understanding Multimodal Metaphors](https://arxiv.org/abs/2506.06987)
*Senqi Yang,Dongyu Zhang,Jing Ren,Ziqi Xu,Xiuzhen Zhang,Yiliao Song,Hongfei Lin,Feng Xia*

Main category: cs.CL

TL;DR: 论文提出了一个多文化多模态隐喻数据集MultiMM，用于研究中文和英文的跨文化隐喻，并开发了情感增强隐喻检测模型SEMD，以减少NLP中的文化偏见。


<details>
  <summary>Details</summary>
Motivation: 现有隐喻处理研究主要依赖英文数据，存在西方文化偏见，可能导致模型性能评估失真。跨文化隐喻处理尤其在多模态领域尚未充分探索。

Method: 构建包含8461个图文广告对的MultiMM数据集，涵盖中英双语；提出SEMD模型，通过融入情感嵌入提升跨文化隐喻理解。

Result: 实验证明SEMD在隐喻检测和情感分析任务中有效；MultiMM数据集为跨文化隐喻研究提供了新资源。

Conclusion: 研究揭示了NLP中文化偏见的影响，MultiMM和SEMD有助于开发更公平、包容的语言模型。

Abstract: Metaphors are pervasive in communication, making them crucial for natural
language processing (NLP). Previous research on automatic metaphor processing
predominantly relies on training data consisting of English samples, which
often reflect Western European or North American biases. This cultural skew can
lead to an overestimation of model performance and contributions to NLP
progress. However, the impact of cultural bias on metaphor processing,
particularly in multimodal contexts, remains largely unexplored. To address
this gap, we introduce MultiMM, a Multicultural Multimodal Metaphor dataset
designed for cross-cultural studies of metaphor in Chinese and English. MultiMM
consists of 8,461 text-image advertisement pairs, each accompanied by
fine-grained annotations, providing a deeper understanding of multimodal
metaphors beyond a single cultural domain. Additionally, we propose
Sentiment-Enriched Metaphor Detection (SEMD), a baseline model that integrates
sentiment embeddings to enhance metaphor comprehension across cultural
backgrounds. Experimental results validate the effectiveness of SEMD on
metaphor detection and sentiment analysis tasks. We hope this work increases
awareness of cultural bias in NLP research and contributes to the development
of fairer and more inclusive language models. Our dataset and code are
available at https://github.com/DUTIR-YSQ/MultiMM.

</details>


### [192] [What makes Reasoning Models Different? Follow the Reasoning Leader for Efficient Decoding](https://arxiv.org/abs/2506.06998)
*Ming Li,Zhengyuan Yang,Xiyao Wang,Dianqi Li,Kevin Lin,Tianyi Zhou,Lijuan Wang*

Main category: cs.CL

TL;DR: 分析发现大型推理模型在生成长思维链时存在过度思考和全局/局部错位，提出FoReaL解码方法减少计算量和思维链长度，有效保持性能。


<details>
  <summary>Details</summary>
Motivation: LRMs长思考链导致推理速度慢且容易陷入冗余细节现象（过思考）。研究发现全局错位增加和局部错位减弱现象，提出高效解法以实现计算效率与准确性权衡。

Method: 利用“快慢思考协作框架FoReaL”：用强大模型生成每句开头几个token(引导)，由弱草稿模型完成剩余内容。采用随机门机制平滑切换模型。

Result: 4大数学推理基准表现：计算量(FLOPs)减少30-50%，思维链长度缩短40%，推理能力保留86-100%。

Conclusion: FoReaL无需微调即实现推理任务优质计算效率权衡，为轻量级推理提供了技术路径。

Abstract: Large reasoning models (LRMs) achieve strong reasoning performance by
emitting long chains of thought. Yet, these verbose traces slow down inference
and often drift into unnecessary detail, known as the overthinking phenomenon.
To better understand LRMs' behavior, we systematically analyze the token-level
misalignment between reasoning and non-reasoning models. While it is expected
that their primary difference lies in the stylistic "thinking cues", LRMs
uniquely exhibit two pivotal, previously under-explored phenomena: a Global
Misalignment Rebound, where their divergence from non-reasoning models persists
or even grows as response length increases, and more critically, a Local
Misalignment Diminish, where the misalignment concentrates at the "thinking
cues" each sentence starts with but rapidly declines in the remaining of the
sentence. Motivated by the Local Misalignment Diminish, we propose
FoReaL-Decoding, a collaborative fast-slow thinking decoding method for
cost-quality trade-off. In FoReaL-Decoding, a Leading model leads the first few
tokens for each sentence, and then a weaker draft model completes the following
tokens to the end of each sentence. FoReaL-Decoding adopts a stochastic gate to
smoothly interpolate between the small and the large model. On four popular
math-reasoning benchmarks (AIME24, GPQA-Diamond, MATH500, AMC23),
FoReaL-Decoding reduces theoretical FLOPs by 30 to 50% and trims CoT length by
up to 40%, while preserving 86 to 100% of model performance. These results
establish FoReaL-Decoding as a simple, plug-and-play route to controllable
cost-quality trade-offs in reasoning-centric tasks.

</details>


### [193] [Adversarial Paraphrasing: A Universal Attack for Humanizing AI-Generated Text](https://arxiv.org/abs/2506.07001)
*Yize Cheng,Vinu Sankar Sadasivan,Mehrdad Saberi,Shoumik Saha,Soheil Feizi*

Main category: cs.CL

TL;DR: 该论文提出了'对抗性改述'攻击框架，利用现成的大型语言模型在AI文本检测器指导下改写文本，有效降低多种检测系统的检测率，平均T@1%F降低87.88%，同时文本质量仅轻微下降，揭示了现有检测方法的脆弱性。


<details>
  <summary>Details</summary>
Motivation: 现有AI生成文本检测器对简单改写攻击展现出较强鲁棒性，但研究者发现通过有针对性优化的改写仍可有效规避检测，这暴露了检测系统的潜在安全风险。

Method: 提出训练免费的攻击框架：使用指令跟随型LLM，在AI文本检测器的指导下对AI生成文本进行对抗性改述，生成专门优化以绕过检测的对抗样本。

Result: 攻击显著降低多种检测器的T@1%F指标（RADAR降低64.49%，Fast-DetectGPT降低98.96%）；在包含神经网络/水印/零样本检测器的测试集上平均降低87.88%；文本质量仅轻微下降。

Conclusion: 对抗性改述暴露当前AI文本检测策略的脆弱性，证明先进逃避技术的高效性，强调需要开发更具鲁棒性的检测方法。

Abstract: The increasing capabilities of Large Language Models (LLMs) have raised
concerns about their misuse in AI-generated plagiarism and social engineering.
While various AI-generated text detectors have been proposed to mitigate these
risks, many remain vulnerable to simple evasion techniques such as
paraphrasing. However, recent detectors have shown greater robustness against
such basic attacks. In this work, we introduce Adversarial Paraphrasing, a
training-free attack framework that universally humanizes any AI-generated text
to evade detection more effectively. Our approach leverages an off-the-shelf
instruction-following LLM to paraphrase AI-generated content under the guidance
of an AI text detector, producing adversarial examples that are specifically
optimized to bypass detection. Extensive experiments show that our attack is
both broadly effective and highly transferable across several detection
systems. For instance, compared to simple paraphrasing attack--which,
ironically, increases the true positive at 1% false positive (T@1%F) by 8.57%
on RADAR and 15.03% on Fast-DetectGPT--adversarial paraphrasing, guided by
OpenAI-RoBERTa-Large, reduces T@1%F by 64.49% on RADAR and a striking 98.96% on
Fast-DetectGPT. Across a diverse set of detectors--including neural
network-based, watermark-based, and zero-shot approaches--our attack achieves
an average T@1%F reduction of 87.88% under the guidance of
OpenAI-RoBERTa-Large. We also analyze the tradeoff between text quality and
attack success to find that our method can significantly reduce detection
rates, with mostly a slight degradation in text quality. Our adversarial setup
highlights the need for more robust and resilient detection strategies in the
light of increasingly sophisticated evasion techniques.

</details>


### [194] [A Culturally-diverse Multilingual Multimodal Video Benchmark & Model](https://arxiv.org/abs/2506.07032)
*Bhuiyan Sanjid Shafique,Ashmal Vayani,Muhammad Maaz,Hanoona Abdul Rasheed,Dinura Dissanayake,Mohammed Irfan Kurpath,Yahya Hmaiti,Go Inoue,Jean Lahoud,Md. Safirur Rashid,Shadid Intisar Quasem,Maheen Fatima,Franco Vidal,Mykola Maslych,Ketan Pravin More,Sanoojan Baliah,Hasindri Watawana,Yuhao Li,Fabian Farestam,Leon Schaller,Roman Tymtsiv,Simon Weber,Hisham Cholakkal,Ivan Laptev,Shin'ichi Satoh,Michael Felsberg,Mubarak Shah,Salman Khan,Fahad Shahbaz Khan*

Main category: cs.CL

TL;DR: 提出多语言视频模型基准ViMUL-Bench和新模型ViMUL，覆盖14种语言和15类文化内容，以促进视频大模型的文化和语言包容性研究


<details>
  <summary>Details</summary>
Motivation: 现有视频大模型主要局限于英语，缺乏多语言和文化包容性评估基准

Method: 构建含8k人工验证样本的多语言视频基准ViMUL-Bench（含15类文化主题）和120万样本翻译训练集，开发ViMUL视频模型

Result: ViMUL在高低资源语言视频理解任务中取得更好平衡

Conclusion: 发布的ViMUL-Bench基准、模型和训练数据集将推动包容性多语言视频大模型发展

Abstract: Large multimodal models (LMMs) have recently gained attention due to their
effectiveness to understand and generate descriptions of visual content. Most
existing LMMs are in English language. While few recent works explore
multilingual image LMMs, to the best of our knowledge, moving beyond the
English language for cultural and linguistic inclusivity is yet to be
investigated in the context of video LMMs. In pursuit of more inclusive video
LMMs, we introduce a multilingual Video LMM benchmark, named ViMUL-Bench, to
evaluate Video LMMs across 14 languages, including both low- and high-resource
languages: English, Chinese, Spanish, French, German, Hindi, Arabic, Russian,
Bengali, Urdu, Sinhala, Tamil, Swedish, and Japanese. Our ViMUL-Bench is
designed to rigorously test video LMMs across 15 categories including eight
culturally diverse categories, ranging from lifestyles and festivals to foods
and rituals and from local landmarks to prominent cultural personalities.
ViMUL-Bench comprises both open-ended (short and long-form) and multiple-choice
questions spanning various video durations (short, medium, and long) with 8k
samples that are manually verified by native language speakers. In addition, we
also introduce a machine translated multilingual video training set comprising
1.2 million samples and develop a simple multilingual video LMM, named ViMUL,
that is shown to provide a better tradeoff between high-and low-resource
languages for video understanding. We hope our ViMUL-Bench and multilingual
video LMM along with a large-scale multilingual video training set will help
ease future research in developing cultural and linguistic inclusive
multilingual video LMMs. Our proposed benchmark, video LMM and training data
will be publicly released at https://mbzuai-oryx.github.io/ViMUL/.

</details>


### [195] [KG2QA: Knowledge Graph-enhanced Retrieval-Augmented Generation for Communication Standards Question Answering](https://arxiv.org/abs/2506.07037)
*Zhongze Luo,Weixuan Wan,Qizhi Zheng,Yanhong Bai,Jingyun Sun,Jian Wang,Dan Wang*

Main category: cs.CL

TL;DR: 提出了一种将大模型微调与知识图谱结合的通信标准智能咨询问答系统，显著提升了问答效果与实用性


<details>
  <summary>Details</summary>
Motivation: 传统咨询周期长且依赖专家经验，难以满足通信技术快速发展需求

Method: 1. 使用6587组通信标准QA数据对Qwen2.5-7B进行LoRA微调；2. 构建含13906实体/13524关系的知识图谱；3. 服务端集成微调模型与知识图谱检索，实现RAG框架

Result: 微调后指标显著提升：BLEU-4达66.8993（原18.8564）；ROUGE等指标超越Llama-3-8B。RAG框架使DeepSeek评估5维度平均分提升2.26%，图谱查询准确率良好

Conclusion: 系统在交互体验与后端接入方面表现优异，具备良好实用价值

Abstract: There are many types of standards in the field of communication. The
traditional consulting model has a long cycle and relies on the knowledge and
experience of experts, making it difficult to meet the rapidly developing
technological demands. This paper combines the fine-tuning of large language
models with the construction of knowledge graphs to implement an intelligent
consultation and question-answering system for communication standards. The
experimental results show that after LoRA tuning on the constructed dataset of
6,587 questions and answers in the field of communication standards,
Qwen2.5-7B-Instruct demonstrates outstanding professional capabilities in the
field of communication standards on the test set. BLEU-4 rose from 18.8564 to
66.8993, and evaluation indicators such as ROUGE also increased significantly,
outperforming the fine-tuning effect of the comparison model
Llama-3-8B-Instruct. Based on the ontology framework containing 6 entity
attributes and 10 relation attributes, a knowledge graph of the communication
standard domain containing 13,906 entities and 13,524 relations was
constructed, showing a relatively good query accuracy rate. The intelligent
consultation and question-answering system enables the fine-tuned model on the
server side to access the locally constructed knowledge graph and conduct
graphical retrieval of key information first, which is conducive to improving
the question-answering effect. The evaluation using DeepSeek as the Judge on
the test set shows that our RAG framework enables the fine-tuned model to
improve the scores at all five angles, with an average score increase of 2.26%.
And combined with web services and API interfaces, it has achieved very good
results in terms of interaction experience and back-end access, and has very
good practical application value.

</details>


### [196] [Reasoning with RAGged events: RAG-Enhanced Event Knowledge Base Construction and reasoning with proof-assistants](https://arxiv.org/abs/2506.07042)
*Stergios Chatzikyriakidis*

Main category: cs.CL

TL;DR: 该论文开发了基于多种LLM（GPT-4、Claude、Llama 3.2）的历史事件自动提取方法，比较了三种增强策略的效果，并将提取的RDF转化为Coq规范以实现高阶推理验证。


<details>
  <summary>Details</summary>
Motivation: 解决手工构建历史事件计算表示的高成本问题，并突破RDF/OWL推理器在一阶逻辑片段内的局限性。

Method: 使用三种LLM，采用纯基础生成、知识图谱增强和RAG三种策略；通过Thucydides历史文本评估；构建自动化流程将RDF转为Coq规范。

Result: 增强策略在不同维度各有优势：基础生成在覆盖范围最优；RAG提高精确度；模型架构决定增强效果（大模型稳健，Llama 3.2波动大）；Coq验证成功实现高阶推理。

Conclusion: 通过LLM+增强策略组合可优化事件提取，RAG提取的事件类型经Coq验证有效；自动转Coq流程能突破RDF的推理限制。

Abstract: Extracting structured computational representations of historical events from
narrative text remains computationally expensive when constructed manually.
While RDF/OWL reasoners enable graph-based reasoning, they are limited to
fragments of first-order logic, preventing deeper temporal and semantic
analysis. This paper addresses both challenges by developing automatic
historical event extraction models using multiple LLMs (GPT-4, Claude, Llama
3.2) with three enhancement strategies: pure base generation, knowledge graph
enhancement, and Retrieval-Augmented Generation (RAG). We conducted
comprehensive evaluations using historical texts from Thucydides. Our findings
reveal that enhancement strategies optimize different performance dimensions
rather than providing universal improvements. For coverage and historical
breadth, base generation achieves optimal performance with Claude and GPT-4
extracting comprehensive events. However, for precision, RAG enhancement
improves coordinate accuracy and metadata completeness. Model architecture
fundamentally determines enhancement sensitivity: larger models demonstrate
robust baseline performance with incremental RAG improvements, while Llama 3.2
shows extreme variance from competitive performance to complete failure. We
then developed an automated translation pipeline converting extracted RDF
representations into Coq proof assistant specifications, enabling higher-order
reasoning beyond RDF capabilities including multi-step causal verification,
temporal arithmetic with BC dates, and formal proofs about historical
causation. The Coq formalization validates that RAG-discovered event types
represent legitimate domain-specific semantic structures rather than
ontological violations.

</details>


### [197] [Lingshu: A Generalist Foundation Model for Unified Multimodal Medical Understanding and Reasoning](https://arxiv.org/abs/2506.07044)
*LASA Team,Weiwen Xu,Hou Pong Chan,Long Li,Mahani Aljunied,Ruifeng Yuan,Jianyu Wang,Chenghao Xiao,Guizhen Chen,Chaoqun Liu,Zhaodonghui Li,Yu Sun,Junao Shen,Chaojun Wang,Jie Tan,Deli Zhao,Tingyang Xu,Hao Zhang,Yu Rong*

Main category: cs.CL

TL;DR: 提出医疗专用多模态大模型Lingshu，通过全面数据整理和分阶段训练解决医疗应用中现有MLLMs的局限性，并在多个医疗任务中表现优异


<details>
  <summary>Details</summary>
Motivation: 现有医疗多模态大语言模型存在医疗知识覆盖有限、易产生幻觉、缺乏针对复杂医疗场景的推理能力三大缺陷

Method: （1）创新的数据整理流程：从医学影像/文本/通用域获取数据，合成医疗标注/VQA/推理样本；（2）分阶段训练Lingshu模型嵌入医疗专业知识；（3）探索强化学习增强医疗推理；（4）开发标准化评估框架MedEvalKit

Result: 在医疗多模态问答、文本问答、医疗报告生成三大任务上，Lingshu持续超越现有开源多模态模型

Conclusion: 通过系统性数据整理和专业化训练策略构建的Lingshu模型，显著提升了医疗MLLMs的准确性和推理能力

Abstract: Multimodal Large Language Models (MLLMs) have demonstrated impressive
capabilities in understanding common visual elements, largely due to their
large-scale datasets and advanced training strategies. However, their
effectiveness in medical applications remains limited due to the inherent
discrepancies between data and tasks in medical scenarios and those in the
general domain. Concretely, existing medical MLLMs face the following critical
limitations: (1) limited coverage of medical knowledge beyond imaging, (2)
heightened susceptibility to hallucinations due to suboptimal data curation
processes, (3) lack of reasoning capabilities tailored for complex medical
scenarios. To address these challenges, we first propose a comprehensive data
curation procedure that (1) efficiently acquires rich medical knowledge data
not only from medical imaging but also from extensive medical texts and
general-domain data; and (2) synthesizes accurate medical captions, visual
question answering (VQA), and reasoning samples. As a result, we build a
multimodal dataset enriched with extensive medical knowledge. Building on the
curated data, we introduce our medical-specialized MLLM: Lingshu. Lingshu
undergoes multi-stage training to embed medical expertise and enhance its
task-solving capabilities progressively. Besides, we preliminarily explore the
potential of applying reinforcement learning with verifiable rewards paradigm
to enhance Lingshu's medical reasoning ability. Additionally, we develop
MedEvalKit, a unified evaluation framework that consolidates leading multimodal
and textual medical benchmarks for standardized, fair, and efficient model
assessment. We evaluate the performance of Lingshu on three fundamental medical
tasks, multimodal QA, text-based QA, and medical report generation. The results
show that Lingshu consistently outperforms the existing open-source multimodal
models on most tasks ...

</details>


### [198] [Com$^2$: A Causal-Guided Benchmark for Exploring Complex Commonsense Reasoning in Large Language Models](https://arxiv.org/abs/2506.07064)
*Kai Xiong,Xiao Ding,Yixin Cao,Yuxiong Yan,Li Du,Yufei Zhang,Jinglong Gao,Jiaqian Liu,Bing Qin,Ting Liu*

Main category: cs.CL

TL;DR: LLMs精通简单显式常识推理，但在复杂隐式常识推理（如事件长期影响）上表现不佳。为了解决这个问题，研究者提出了名为Com²的新基准，利用因果事件图谱构建结构化复杂常识，并通过因果干预理论创造不同场景，最后用LLM生成测试示例。实验表明LLMs在推理深度和广度上存在困难，但微调和慢思考能改善表现。


<details>
  <summary>Details</summary>
Motivation: 现有研究主要关注数学、代码等结构化复杂推理，而源于简单常识的复杂隐式常识推理（对人类决策更重要）因不确定性和缺乏结构鲜被探索。该研究旨在填补这一空白并贴近现实需求。

Method: 1）整合因果事件图谱作为结构化复杂常识基础；2）应用因果干预理论修改图谱生成符合人类关注的不同场景；3）采用慢思考机制指导LLM根据修改后的图谱逻辑关系合成测试示例；4）额外构建侦探故事子集提升挑战性。

Result: 实验发现LLMs普遍在推理深度（处理多步因果链）和广度（考虑多维度影响）表现不足，但通过领域微调（post-training）和慢思考策略能有效缓解困难。

Conclusion: Com²揭示了LLMs在复杂常识推理上的显著缺陷，证实结构化的因果图谱表示与慢思考机制对提升此类能力的有效性，为未来研究提供了新基准和洞察。

Abstract: Large language models (LLMs) have mastered abundant simple and explicit
commonsense knowledge through pre-training, enabling them to achieve human-like
performance in simple commonsense reasoning. Nevertheless, LLMs struggle to
reason with complex and implicit commonsense knowledge that is derived from
simple ones (such as understanding the long-term effects of certain events), an
aspect humans tend to focus on more. Existing works focus on complex tasks like
math and code, while complex commonsense reasoning remains underexplored due to
its uncertainty and lack of structure. To fill this gap and align with
real-world concerns, we propose a benchmark Com$^2$ focusing on complex
commonsense reasoning. We first incorporate causal event graphs to serve as
structured complex commonsense. Then we adopt causal theory~(e.g.,
intervention) to modify the causal event graphs and obtain different scenarios
that meet human concerns. Finally, an LLM is employed to synthesize examples
with slow thinking, which is guided by the logical relationships in the
modified causal graphs. Furthermore, we use detective stories to construct a
more challenging subset. Experiments show that LLMs struggle in reasoning depth
and breadth, while post-training and slow thinking can alleviate this. The code
and data are available at https://github.com/Waste-Wood/Com2.

</details>


### [199] [Representation Decomposition for Learning Similarity and Contrastness Across Modalities for Affective Computing](https://arxiv.org/abs/2506.07086)
*Yuanhe Tian,Pengsen Cheng,Guoqing Jin,Lei Zhang,Yan Song*

Main category: cs.CL

TL;DR: 提出了一种基于大型语言模型（LLM）的情感计算方法，通过解构视觉和文本表征为共享和特定模态组件，在三个情感计算任务上优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有方法无法有效捕捉多模态信息中复杂和冲突的证据，导致情感分析效果不佳。

Method: 1. 使用预训练多模态编码器对齐输入；2. 通过表征解构框架分离共同情感内容和独特线索；3. 利用注意力机制整合信号生成动态软提示输入LLM。

Result: 在多模态方面情感分析、情感分析和仇恨言论检测任务上均超越强基线模型和SOTA方法。

Conclusion: 该解构式多模态LLM方法能有效处理跨模态冲突，提升情感计算性能。

Abstract: Multi-modal affective computing aims to automatically recognize and interpret
human attitudes from diverse data sources such as images and text, thereby
enhancing human-computer interaction and emotion understanding. Existing
approaches typically rely on unimodal analysis or straightforward fusion of
cross-modal information that fail to capture complex and conflicting evidence
presented across different modalities. In this paper, we propose a novel
LLM-based approach for affective computing that explicitly deconstructs visual
and textual representations into shared (modality-invariant) and
modality-specific components. Specifically, our approach firstly encodes and
aligns input modalities using pre-trained multi-modal encoders, then employs a
representation decomposition framework to separate common emotional content
from unique cues, and finally integrates these decomposed signals via an
attention mechanism to form a dynamic soft prompt for a multi-modal LLM.
Extensive experiments on three representative tasks for affective computing,
namely, multi-modal aspect-based sentiment analysis, multi-modal emotion
analysis, and hateful meme detection, demonstrate the effectiveness of our
approach, which consistently outperforms strong baselines and state-of-the-art
models.

</details>


### [200] [How Far Are We from Optimal Reasoning Efficiency?](https://arxiv.org/abs/2506.07104)
*Jiaxuan Gao,Shu Yan,Qixin Tan,Lu Yang,Shusheng Xu,Wei Fu,Zhiyu Mei,Kaifeng Lyu,Yi Wu*

Main category: cs.CL

TL;DR: 提出了一个推理效率差距指标REG，并设计了REO-RL减少模型推理长度


<details>
  <summary>Details</summary>
Motivation: 现有的大型推理模型存在计算效率低下问题

Method: 使用强化学习在关键推理节点采样

Result: REO-RL显著提升了效率

Conclusion: 推理效率仍有优化空间

Abstract: Large Reasoning Models (LRMs) demonstrate remarkable problem-solving
capabilities through extended Chain-of-Thought (CoT) reasoning but often
produce excessively verbose and redundant reasoning traces. This inefficiency
incurs high inference costs and limits practical deployment. While existing
fine-tuning methods aim to improve reasoning efficiency, assessing their
efficiency gains remains challenging due to inconsistent evaluations. In this
work, we introduce the reasoning efficiency frontiers, empirical upper bounds
derived from fine-tuning base LRMs across diverse approaches and training
configurations. Based on these frontiers, we propose the Reasoning Efficiency
Gap (REG), a unified metric quantifying deviations of any fine-tuned LRMs from
these frontiers. Systematic evaluation on challenging mathematical benchmarks
reveals significant gaps in current methods: they either sacrifice accuracy for
short length or still remain inefficient under tight token budgets. To reduce
the efficiency gap, we propose REO-RL, a class of Reinforcement Learning
algorithms that minimizes REG by targeting a sparse set of token budgets.
Leveraging numerical integration over strategically selected budgets, REO-RL
approximates the full efficiency objective with low error using a small set of
token budgets. Through systematic benchmarking, we demonstrate that our
efficiency metric, REG, effectively captures the accuracy-length trade-off,
with low-REG methods reducing length while maintaining accuracy. Our approach,
REO-RL, consistently reduces REG by >=50 across all evaluated LRMs and matching
Qwen3-4B/8B efficiency frontiers under a 16K token budget with minimal accuracy
loss. Ablation studies confirm the effectiveness of our exponential token
budget strategy. Finally, our findings highlight that fine-tuning LRMs to
perfectly align with the efficiency frontiers remains an open challenge.

</details>


### [201] [Theorem-of-Thought: A Multi-Agent Framework for Abductive, Deductive, and Inductive Reasoning in Language Models](https://arxiv.org/abs/2506.07106)
*Samir Abdaljalil,Hasan Kurban,Khalid Qaraqe,Erchin Serpedin*

Main category: cs.CL

TL;DR: 論文提出Theorem-of-Thought (ToTh)框架，透過三種推理代理（溯因、演繹、歸納）協作生成結構化推理圖，並用貝葉斯置信傳播評估一致性，在符號與數值推理任務上超越Chain-of-Thought等方法。


<details>
  <summary>Details</summary>
Motivation: 現有LLM推理方法（如Chain-of-Thought）缺乏邏輯結構約束和內部一致性評估機制，導致推理過程脆弱且不易解釋。

Method: 設計三種平行推理代理（溯因/演繹/歸納），各自生成推理軌跡後建構形式化推理圖，利用自然語言推理(NLI)指導的貝葉斯置信傳播評估步驟間一致性，選取最連貫的推理圖輸出答案。

Result: 在WebOfLies（符號推理）和MultiArith（數值推理）基準測試中，ToTh在多個LLM上持續優於Chain-of-Thought、Self-Consistency和CoT-Decoding方法。

Conclusion: ToTh框架為建構更魯棒且具認知啟發性的LLM推理提供新方向，同時產生可解釋且邏輯紮實的推理鏈。

Abstract: Large language models (LLMs) have shown strong performance across natural
language reasoning tasks, yet their reasoning processes remain brittle and
difficult to interpret. Prompting techniques like Chain-of-Thought (CoT)
enhance reliability by eliciting intermediate reasoning steps or aggregating
multiple outputs. However, they lack mechanisms for enforcing logical structure
and assessing internal coherence. We introduce Theorem-of-Thought (ToTh), a
novel framework that models reasoning as collaboration among three parallel
agents, each simulating a distinct mode of inference: abductive, deductive, and
inductive. Each agent produces a reasoning trace, which is structured into a
formal reasoning graph. To evaluate consistency, we apply Bayesian belief
propagation guided by natural language inference (NLI), assigning confidence
scores to each step. The most coherent graph is selected to derive the final
answer. Experiments on symbolic (WebOfLies) and numerical (MultiArith)
reasoning benchmarks show that ToTh consistently outperforms CoT,
Self-Consistency, and CoT-Decoding across multiple LLMs, while producing
interpretable and logically grounded reasoning chains. Our findings suggest a
promising direction for building more robust and cognitively inspired LLM
reasoning. The implementation is available at
https://github.com/KurbanIntelligenceLab/theorem-of-thought.

</details>


### [202] [Prompting Science Report 2: The Decreasing Value of Chain of Thought in Prompting](https://arxiv.org/abs/2506.07142)
*Lennart Meincke,Ethan Mollick,Lilach Mollick,Dan Shapiro*

Main category: cs.CL

TL;DR: CoT prompting improves some models slightly but increases variability and cost; minimal gains for reasoning models.


<details>
  <summary>Details</summary>
Motivation: To evaluate the effectiveness of Chain-of-Thought prompting across different AI models and tasks.

Method: Tested CoT prompting on various LLMs, comparing performance, variability, and token efficiency.

Result: CoT slightly helps non-reasoning models but introduces errors and high token costs; reasoning models see negligible accuracy gains with increased costs.

Conclusion: CoT's value is task/model-dependent—often not worth the added cost, especially for inherent reasoning models.

Abstract: This is the second in a series of short reports that seek to help business,
education, and policy leaders understand the technical details of working with
AI through rigorous testing. In this report, we investigate Chain-of-Thought
(CoT) prompting, a technique that encourages a large language model (LLM) to
"think step by step" (Wei et al., 2022). CoT is a widely adopted method for
improving reasoning tasks, however, our findings reveal a more nuanced picture
of its effectiveness. We demonstrate two things:
  - The effectiveness of Chain-of-Thought prompting can vary greatly depending
on the type of task and model. For non-reasoning models, CoT generally improves
average performance by a small amount, particularly if the model does not
inherently engage in step-by-step processing by default. However, CoT can
introduce more variability in answers, sometimes triggering occasional errors
in questions the model would otherwise get right. We also found that many
recent models perform some form of CoT reasoning even if not asked; for these
models, a request to perform CoT had little impact. Performing CoT generally
requires far more tokens (increasing cost and time) than direct answers.
  - For models designed with explicit reasoning capabilities, CoT prompting
often results in only marginal, if any, gains in answer accuracy. However, it
significantly increases the time and tokens needed to generate a response.

</details>


### [203] [Semantic-preserved Augmentation with Confidence-weighted Fine-tuning for Aspect Category Sentiment Analysis](https://arxiv.org/abs/2506.07148)
*Yaping Chai,Haoran Xie,Joe S. Qin*

Main category: cs.CL

TL;DR: 该论文提出了一种基于大语言模型（LLM）的数据增强方法，针对方面类别情感分析（ACSA）任务，通过结构化提示模板生成语义一致且语言多样的增强数据，并采用置信度加权微调策略提升模型性能。该方法在四个基准数据集上优于所有基线模型。


<details>
  <summary>Details</summary>
Motivation: 低资源场景下数据稀缺问题影响模型性能，现有方法依赖手工设计提示进行数据增强，需改进以更好地保持原始语义并增加语言多样性。

Method: 1. 结构化提示模板：指导LLM生成符合预设内容的增强数据；2. 后处理技术：确保生成句与原句语义一致性；3. 置信度加权微调：提升模型预测的置信度与准确性。

Result: 在四个基准数据集上均取得最优性能，超越所有基线方法。

Conclusion: 结构化提示与后处理技术能有效生成高质量增强数据，置信加权微调进一步提升模型推理能力，该方法在低资源ACSA任务中具有显著优势。

Abstract: Large language model (LLM) is an effective approach to addressing data
scarcity in low-resource scenarios. Recent existing research designs
hand-crafted prompts to guide LLM for data augmentation. We introduce a data
augmentation strategy for the aspect category sentiment analysis (ACSA) task
that preserves the original sentence semantics and has linguistic diversity,
specifically by providing a structured prompt template for an LLM to generate
predefined content. In addition, we employ a post-processing technique to
further ensure semantic consistency between the generated sentence and the
original sentence. The augmented data increases the semantic coverage of the
training distribution, enabling the model better to understand the relationship
between aspect categories and sentiment polarities, enhancing its inference
capabilities. Furthermore, we propose a confidence-weighted fine-tuning
strategy to encourage the model to generate more confident and accurate
sentiment polarity predictions. Compared with powerful and recent works, our
method consistently achieves the best performance on four benchmark datasets
over all baselines.

</details>


### [204] [Syntactic Control of Language Models by Posterior Inference](https://arxiv.org/abs/2506.07154)
*Vicky Xefteri,Tim Vieira,Ryan Cotterell,Afra Amini*

Main category: cs.CL

TL;DR: 使用基于后验推断的抽样算法（结合SMC和句法标注器）可以有效地在语言模型生成文本时控制句法结构，在GPT-2和Llama3-8B上实现了句法准确率的显著提升（F1分数从12.31/35.33提高到约93），且不影响流畅性。


<details>
  <summary>Details</summary>
Motivation: 控制语言模型生成文本的句法结构对于需要清晰度、风格一致性或可解释性的应用至关重要，但当前仍具有挑战性。

Method: 1. 基于后验推断的抽样算法（结合序列蒙特卡洛方法估计后验分布）
2. 使用句法标注器确保每个生成token符合目标句法结构

Result: 在GPT-2-large和Llama3-8B模型上：
- 句法准确率（F1分数）从12.31（GPT2）/35.33（Llama3）提升至约93
- 未损害语言模型流畅性

Conclusion: 该方法有效解决了句法控制难题，为需要精确控制语法结构的应用提供了可行方案，证明了抽样算法在句法控制中的有效性。

Abstract: Controlling the syntactic structure of text generated by language models is
valuable for applications requiring clarity, stylistic consistency, or
interpretability, yet it remains a challenging task. In this paper, we argue
that sampling algorithms based on the posterior inference can effectively
enforce a target constituency structure during generation. Our approach
combines sequential Monte Carlo, which estimates the posterior distribution by
sampling from a proposal distribution, with a syntactic tagger that ensures
that each generated token aligns with the desired syntactic structure. Our
experiments with GPT2 and Llama3-8B models show that with an appropriate
proposal distribution, we can improve syntactic accuracy, increasing the F1
score from $12.31$ (GPT2-large) and $35.33$ (Llama3-8B) to about $93$ in both
cases without compromising the language model's fluency. These results
underscore both the complexity of syntactic control and the effectiveness of
sampling algorithms, offering a promising approach for applications where
precise control over syntax is essential.

</details>


### [205] [GeometryZero: Improving Geometry Solving for LLM with Group Contrastive Policy Optimization](https://arxiv.org/abs/2506.07160)
*Yikun Wang,Yibin Wang,Dianyi Wang,Zimian Peng,Qipeng Guo,Dacheng Tao,Jiaqi Wang*

Main category: cs.CL

TL;DR: 提出了Group Contrastive Policy Optimization (GCPO)框架，用于训练小型模型解决几何问题，通过条件奖励信号提高辅助构造的效率，相比现有方法性能提升4.29%。


<details>
  <summary>Details</summary>
Motivation: 现有大型语言模型(如GPT-4o)在解决需要辅助构造的几何问题时计算成本过高，而基于强化学习的方法(如GRPO)因无条件奖励信号导致无效的辅助构造。需要一种新方法在保持高效的同时提升推理准确性。

Method: 开发了GCPO强化学习框架：1) Group Contrastive Masking根据上下文自适应提供正/负奖励；2) 引入长度奖励促进长推理链。在此基础上构建了GeometryZero系列模型。

Result: 在Geometry3K和MathVista等基准测试中，GeometryZero模型平均显著超越基线(如GRPO)4.29%。

Conclusion: GCPO框架通过在强化学习中引入条件奖励机制，有效解决了辅助构造的盲目性问题，使中小规模模型在几何推理任务上实现了更优的性能效率比。

Abstract: Recent advances in large language models (LLMs) have demonstrated remarkable
capabilities across diverse domains, particularly in mathematical reasoning,
amid which geometry problem solving remains a challenging area where auxiliary
construction plays a enssential role. Existing approaches either achieve
suboptimal performance or rely on massive LLMs (e.g., GPT-4o), incurring
massive computational costs. We posit that reinforcement learning with
verifiable reward (e.g., GRPO) offers a promising direction for training
smaller models that effectively combine auxiliary construction with robust
geometric reasoning. However, directly applying GRPO to geometric reasoning
presents fundamental limitations due to its dependence on unconditional
rewards, which leads to indiscriminate and counterproductive auxiliary
constructions. To address these challenges, we propose Group Contrastive Policy
Optimization (GCPO), a novel reinforcement learning framework featuring two key
innovations: (1) Group Contrastive Masking, which adaptively provides positive
or negative reward signals for auxiliary construction based on contextual
utility, and a (2) length reward that promotes longer reasoning chains.
Building on GCPO, we develop GeometryZero, a family of affordable-size
geometric reasoning models that judiciously determine when to employ auxiliary
construction. Our extensive empirical evaluation across popular geometric
benchmarks (Geometry3K, MathVista) demonstrates that GeometryZero models
consistently outperform baselines (e.g. GRPO), achieving an average improvement
of 4.29% across all benchmarks.

</details>


### [206] [CTDGSI: A comprehensive exploitation of instance selection methods for automatic text classification. VII Concurso de Teses, Dissertações e Trabalhos de Graduação em SI -- XXI Simpósio Brasileiro de Sistemas de Informação](https://arxiv.org/abs/2506.07169)
*Washington Cunha,Leonardo Rocha,Marcos André Gonçalves*

Main category: cs.CL

TL;DR: 该论文提出实例选择（IS）作为减少NLP训练集大小的方法，在保持模型效果的同时降低成本。作者比较了多种IS方法在自动文本分类中的应用，并提出了两种新型IS解决方案，实现了41%的训练集缩减和最高1.67倍的速度提升。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型训练需要海量计算资源，实例选择技术能通过去除冗余/噪声实例来降低训练成本，但该技术在当前NLP研究中尚未充分探索。

Method: 1. 系统比较现有IS方法在自动文本分类任务上的表现
2. 提出两种新型IS解决方案：面向噪声处理的方案和冗余感知方案，专为大规模数据集和Transformer架构设计

Result: 1. 平均减少41%训练数据量且保持相同准确率
2. 训练速度提升1.67倍（最高达2.46倍）
3. 方案适用于数十万文档级别的大规模数据集

Conclusion: 实例选择技术在NLP领域具有显著未开发潜力，所提出的新型解决方案能有效降低训练成本并保持模型性能，为资源受限场景提供实用方法。

Abstract: Progress in Natural Language Processing (NLP) has been dictated by the rule
of more: more data, more computing power and more complexity, best exemplified
by the Large Language Models. However, training (or fine-tuning) large dense
models for specific applications usually requires significant amounts of
computing resources. This \textbf{Ph.D. dissertation} focuses on an
under-investi\-gated NLP data engineering technique, whose potential is
enormous in the current scenario known as Instance Selection (IS). The IS goal
is to reduce the training set size by removing noisy or redundant instances
while maintaining the effectiveness of the trained models and reducing the
training process cost. We provide a comprehensive and scientifically sound
comparison of IS methods applied to an essential NLP task -- Automatic Text
Classification (ATC), considering several classification solutions and many
datasets. Our findings reveal a significant untapped potential for IS
solutions. We also propose two novel IS solutions that are noise-oriented and
redundancy-aware, specifically designed for large datasets and transformer
architectures. Our final solution achieved an average reduction of 41\% in
training sets, while maintaining the same levels of effectiveness in all
datasets. Importantly, our solutions demonstrated speedup improvements of 1.67x
(up to 2.46x), making them scalable for datasets with hundreds of thousands of
documents.

</details>


### [207] [RULE: Reinforcement UnLEarning Achieves Forget-Retain Pareto Optimality](https://arxiv.org/abs/2506.07171)
*Chenlong Zhang,Zhuoran Jin,Hongbang Yuan,Jiaheng Wei,Tong Zhou,Kang Liu,Jun Zhao,Yubo Chen*

Main category: cs.CL

TL;DR: 提出了一个名为强化遗忘学习的框架来解决大型语言模型中内容遗忘问题，该方法利用少量训练和合成边界实现高效遗忘并保持模型实用性。


<details>
  <summary>Details</summary>
Motivation: 现有遗忘方法需要大规模数据集、产生不自然响应、泛化性差或导致模型性能下降。需要高效有选择地移除特定信息，以解决敏感/非法内容的顾虑。

Method: 将遗忘建模为拒绝边界优化问题，使用约12%遗忘集和8%合成边界查询，通过可验证奖励函数训练，鼓励拒绝有害查询同时保留有用响应。

Result: 仅使用少量数据就在遗忘率(+17.5%)和回答自然度(+16.3%)超越现有方案，实现遗忘-保留帕累托最优，增强泛化和输出自然度。

Conclusion: 强化遗忘学习框架实现了高效且有针对性的内容遗忘，无需大规模数据集，保持模型实用性同时提升自然度和效率。

Abstract: The widespread deployment of Large Language Models (LLMs) trained on massive,
uncurated corpora has raised growing concerns about the inclusion of sensitive,
copyrighted, or illegal content. This has led to increasing interest in LLM
unlearning: the task of selectively removing specific information from a model
without retraining from scratch or degrading overall utility. However, existing
methods often rely on large-scale forget and retain datasets, and suffer from
unnatural responses, poor generalization, or catastrophic utility loss. In this
work, we propose Reinforcement UnLearning (RULE), an efficient framework that
formulates unlearning as a refusal boundary optimization problem. RULE is
trained with a small portion of the forget set and synthesized boundary
queries, using a verifiable reward function that encourages safe refusal on
forget--related queries while preserving helpful responses on permissible
inputs. We provide both theoretical and empirical evidence demonstrating the
effectiveness of RULE in achieving targeted unlearning without compromising
model utility. Experimental results show that, with only $12%$ forget set and
$8%$ synthesized boundary data, RULE outperforms existing baselines by up to
$17.5%$ forget quality and $16.3%$ naturalness response while maintaining
general utility, achieving forget--retain Pareto optimality. Remarkably, we
further observe that RULE improves the naturalness of model outputs, enhances
training efficiency, and exhibits strong generalization ability, generalizing
refusal behavior to semantically related but unseen queries.

</details>


### [208] [Flattery in Motion: Benchmarking and Analyzing Sycophancy in Video-LLMs](https://arxiv.org/abs/2506.07180)
*Wenrui Zhou,Shu Yang,Qingsong Yang,Zikun Guo,Lijie Hu,Di Wang*

Main category: cs.CL

TL;DR: 该论文介绍了针对视频大语言模型盲目附和用户输入的问题，首次提出VISE基准测试集及关键帧选择缓解方法。


<details>
  <summary>Details</summary>
Motivation: 现有研究在视频和语言领域对模型盲目附和用户输入的问题关注不足，缺乏系统化的基准测试，因此需要专门评估该行为，以提高模型在多模态推理中的可靠性和事实一致性。

Method: 1. 提出首个专门评估视频大语言模型盲目附和行为的基准测试VISE，涵盖多种问题形式、提示偏见和视觉推理任务。
2. 将语言领域的盲目附和分析引入视觉领域，实现细粒度分类研究。
3. 探索可解释的免训练缓解策略——关键帧选择，强化视觉信息对模型预测的影响。

Result: 1. 建立了覆盖多种盲目附和类型和交互模式的评估体系。
2. 通过关键帧选择策略初步验证了增强视觉基础可降低模型盲目附和倾向。

Conclusion: 该工作填补了视频语言模型盲目附和评估的空白，VISE基准测试为未来模型开发提供诊断工具，关键帧选择策略为后续研究提供了新思路。

Abstract: As video large language models (Video-LLMs) become increasingly integrated
into real-world applications that demand grounded multimodal reasoning,
ensuring their factual consistency and reliability is of critical importance.
However, sycophancy, the tendency of these models to align with user input even
when it contradicts the visual evidence, undermines their trustworthiness in
such contexts. Current sycophancy research has largely overlooked its specific
manifestations in the video-language domain, resulting in a notable absence of
systematic benchmarks and targeted evaluations to understand how Video-LLMs
respond under misleading user input. To fill this gap, we propose VISE
(Video-LLM Sycophancy Benchmarking and Evaluation), the first dedicated
benchmark designed to evaluate sycophantic behavior in state-of-the-art
Video-LLMs across diverse question formats, prompt biases, and visual reasoning
tasks. Specifically, VISE pioneeringly brings linguistic perspectives on
sycophancy into the visual domain, enabling fine-grained analysis across
multiple sycophancy types and interaction patterns. In addition, we explore
key-frame selection as an interpretable, training-free mitigation strategy,
which reveals potential paths for reducing sycophantic bias by strengthening
visual grounding.

</details>


### [209] [SDE-SQL: Enhancing Text-to-SQL Generation in Large Language Models via Self-Driven Exploration with SQL Probes](https://arxiv.org/abs/2506.07245)
*Wenxuan Xie,Yaxun Dai,Wenhao Jiang*

Main category: cs.CL

TL;DR: 本文摘要指出静态数据库信息限制了大语言模型（LLM）在文本到SQL任务中的理解能力并据此提出SDE-SQL框架，该框架使模型能在推理过程中通过自主生成和执行SQL探针来动态探索数据库。


<details>
  <summary>Details</summary>
Motivation: 现有基于大语言模型的Text-to-SQL方法需要依赖预处理的静态数据库信息，限制了模型对数据库内容的深入理解能力。

Method: 提出SDE-SQL框架，让语言模型在推理时自动生成和执行SQL查询探针，通过动态检索数据库信息迭代更新对数据的理解。该方法在零样本设置下运行，无需任何示例对来演示。

Result: 在BIRD基准测试中使用Qwen2.5-72B-Instruct模型，SDE-SQL相比基线模型相对提升执行准确率8.02%，创下基于开源模型（不使用监督微调和模型集成）的最佳记录，监督微调后还可进一步提升0.52%的准确率。

Conclusion: SDE-SQL通过赋予大语言模型自主数据库探索能力，显著提升了Text-to-SQL任务性能，尤其在没有监督微调的环境下达到最先进水平，且微调后仍有进一步提升空间。

Abstract: Recent advancements in large language models (LLMs) have significantly
improved performance on the Text-to-SQL task. However, prior approaches
typically rely on static, pre-processed database information provided at
inference time, which limits the model's ability to fully understand the
database contents. Without dynamic interaction, LLMs are constrained to fixed,
human-provided context and cannot autonomously explore the underlying data. To
address this limitation, we propose SDE-SQL, a framework that enables large
language models to perform self-driven exploration of databases during
inference. This is accomplished by generating and executing SQL probes, which
allow the model to actively retrieve information from the database and
iteratively update its understanding of the data. Unlike prior methods, SDE-SQL
operates in a zero-shot setting, without relying on any question-SQL pairs as
in-context demonstrations. When evaluated on the BIRD benchmark with
Qwen2.5-72B-Instruct, SDE-SQL achieves an 8.02% relative improvement in
execution accuracy over the vanilla Qwen2.5-72B-Instruct baseline, establishing
a new state-of-the-art among methods based on open-source models without
supervised fine-tuning (SFT) or model ensembling. Moreover, with SFT, the
performance of SDE-SQL can be further enhanced, yielding an additional 0.52%
improvement.

</details>


### [210] [Improving the Efficiency of Long Document Classification using Sentence Ranking Approach](https://arxiv.org/abs/2506.07248)
*Prathamesh Kokate,Mitali Sarnaik,Manavi Khopade,Raviraj Joshi*

Main category: cs.CL

TL;DR: 本文提出了一种基于TF-IDF的句子排序方法，用于长文档分类，通过选择最具信息量的句子实现高效分类。该方法在MahaNews数据集上表现优异，仅使用50%的输入内容就能在MahaBERT-v2模型上实现与全文本基准几乎相同的准确率（仅下降0.33%），同时减少43%的推理延迟。


<details>
  <summary>Details</summary>
Motivation: 解决长文档分类中Transformer模型（如BERT）面临的计算效率问题：固定输入长度限制、二次方注意力复杂度，以及全文分类的冗余性——实际上仅需少量关键句子即可完成分类。

Method: 1. 开发基于TF-IDF的句子排序算法，优先选择信息量高的句子；2. 探索两种选择策略：固定数量选择（fixed-count）和比例选择（percentage-based）；3. 提出增强评分策略，结合归一化TF-IDF得分和句子长度。

Result: 在MahaNews长文档数据集（马拉地语新闻）上：1. 显著优于首句/末句/随机选择基线；2. 使用50％输入内容时，分类准确率仅比全文本基准下降0.33％；3. 输入规模减少超50%，推理延迟降低43%。

Conclusion: 该方法证明对长文档进行大规模上下文压缩（>50%）不会显著影响分类性能，为现实场景中的高效长文本分类提供了实用解决方案。

Abstract: Long document classification poses challenges due to the computational
limitations of transformer-based models, particularly BERT, which are
constrained by fixed input lengths and quadratic attention complexity.
Moreover, using the full document for classification is often redundant, as
only a subset of sentences typically carries the necessary information. To
address this, we propose a TF-IDF-based sentence ranking method that improves
efficiency by selecting the most informative content. Our approach explores
fixed-count and percentage-based sentence selection, along with an enhanced
scoring strategy combining normalized TF-IDF scores and sentence length.
Evaluated on the MahaNews LDC dataset of long Marathi news articles, the method
consistently outperforms baselines such as first, last, and random sentence
selection. With MahaBERT-v2, we achieve near-identical classification accuracy
with just a 0.33 percent drop compared to the full-context baseline, while
reducing input size by over 50 percent and inference latency by 43 percent.
This demonstrates that significant context reduction is possible without
sacrificing performance, making the method practical for real-world long
document classification tasks.

</details>


### [211] [Bias Attribution in Filipino Language Models: Extending a Bias Interpretability Metric for Application on Agglutinative Languages](https://arxiv.org/abs/2506.07249)
*Lance Calvin Lim Gamboa,Yue Feng,Mark Lee*

Main category: cs.CL

TL;DR: 研究在菲律賓等黏着語言上自適應資訊理論偏見歸因分數，結果顯示菲律賓模型的偏見源於人物、物件與關係，與英語模型中與行為相關的偏見不同。


<details>
  <summary>Details</summary>
Motivation: 英語文本的偏見歸因研究已成熟，但對黏着語言（如菲律賓語）的處理模型如何產生偏見尚缺乏研究。

Method: 將資訊理論偏見歸因分數適配於黏着語言模型，並應用於純菲律賓語模型及三種多語言模型（全球數據、東南亞數據）。

Result: 菲律賓模型的偏見主要由人物、物件與關係類詞彙驅動（實體主題），而非英語模型中常見的行為類主題（如犯罪、性別相關行為），顯示不同語言模型的偏見形成機制存在差異。

Conclusion: 英語與非英語模型在處理社會人口群體相關輸入時存在根本性差異，凸顯跨語言偏見研究的必要性。

Abstract: Emerging research on bias attribution and interpretability have revealed how
tokens contribute to biased behavior in language models processing English
texts. We build on this line of inquiry by adapting the information-theoretic
bias attribution score metric for implementation on models handling
agglutinative languages, particularly Filipino. We then demonstrate the
effectiveness of our adapted method by using it on a purely Filipino model and
on three multilingual models: one trained on languages worldwide and two on
Southeast Asian data. Our results show that Filipino models are driven towards
bias by words pertaining to people, objects, and relationships, entity-based
themes that stand in contrast to the action-heavy nature of bias-contributing
themes in English (i.e., criminal, sexual, and prosocial behaviors). These
findings point to differences in how English and non-English models process
inputs linked to sociodemographic groups and bias.

</details>


### [212] [Question Answering under Temporal Conflict: Evaluating and Organizing Evolving Knowledge with LLMs](https://arxiv.org/abs/2506.07270)
*Atahan Özer,Çağatay Yıldız*

Main category: cs.CL

TL;DR: 这篇论文提出了一个新框架，用于解决大型语言模型在应对不断更新的知识时面临的挑战。作者创建了两个衡量知识随时间变化的基准测试（Temporal Wiki和Unified Clark），发现现有方法在冲突或过时事实推理上的不足。他们开发的轻量级外部记忆系统显著优于上下文学习和检索增强生成等方法。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型的静态知识库无法适应现实世界信息的持续更新。传统更新方法（如重新训练或上下文学习）在规模化和处理信息频繁变动时存在效率低、成本高的问题。论文旨在提升模型对时效性文本的处理能力，特别是在事实随时间演变的场景中（如球员转会信息）。

Method: 提出了一个轻量级代理框架，通过构建结构化外部记忆来组织时序文档信息。该方法在推理时检索并整合经过时间过滤的相关证据，避免模型重新训练。具体包括创建两个新基准测试进行分析，并设计增量记忆构建机制应对知识冲突。

Result: 该方法在Temporal Wiki和Unified Clark基准上全面超越ICL和RAG基线，尤其在需要整合冲突事实或复杂推理的任务中提升显著。例如在处理球员效力球队动态变化等问题时，准确率提高超过15个百分点。

Conclusion: 外部结构化记忆有效解决了语言模型处理时效性知识的瓶颈。该框架为动态知识管理提供了新范式，证明了增量记忆构建比传统方法更适应信息持续演化的场景，且避开了重新训练的高成本。

Abstract: Large language models (LLMs) exhibit remarkable capabilities in question
answering and reasoning thanks to their extensive parametric memory. However,
their knowledge is inherently limited by the scope of their pre-training data,
while real-world information evolves continuously. Updating this knowledge
typically requires costly and brittle re-training, or in-context learning
(ICL), which becomes impractical at scale given the volume and volatility of
modern information. Motivated by these limitations, we investigate how LLMs
perform when exposed to temporal text corpora, or documents that reflect
evolving knowledge over time, such as sports biographies where facts like a
player's "current team" change year by year. To this end, we introduce two new
benchmarks: Temporal Wiki, which captures factual drift across historical
Wikipedia snapshots, and Unified Clark, which aggregates timestamped news
articles to simulate real-world information accumulation. Our analysis reveals
that LLMs often struggle to reconcile conflicting or outdated facts and can be
misled when multiple versions of a fact appear in context. To address these
issues, we propose a lightweight, agentic framework that incrementally builds a
structured, external memory from source documents without requiring
re-training. This knowledge organization strategy enables models to retrieve
and reason over temporally filtered, relevant information at inference time.
Empirically, our method outperforms ICL and RAG baselines across both
benchmarks, especially on questions requiring more complex reasoning or
integration of conflicting facts.

</details>


### [213] [Parsing the Switch: LLM-Based UD Annotation for Complex Code-Switched and Low-Resource Languages](https://arxiv.org/abs/2506.07274)
*Olga Kellert,Nemika Tyagi,Muhammad Imran,Nelvin Licona-Guevara,Carlos Gómez-Rodríguez*

Main category: cs.CL

TL;DR: 提出BiLingua Parser，一种基于大语言模型的标注流程，用于生成代码转换文本的通用依赖标注，在西班牙语-英语和西班牙语-瓜拉尼语数据上实现了高精度句法分析。


<details>
  <summary>Details</summary>
Motivation: 解决在低资源代码转换场景下，句法分析缺乏标注数据和现有单语解析器泛化能力不足的问题。

Method: 1. 开发基于提示词的框架，结合少样本提示和专家评审 2. 发布两个标注数据集（含首个西-瓜语UD语料库） 3. 跨语言对和交际语境进行切换点句法分析

Result: 专家修订后LAS达95.29%，显著超越基线。证明引导后的大语言模型可有效助力低资源代码转换场景的句法标注。

Conclusion: 精心设计的LLM提示框架能作为实用工具，在资源匮乏的代码转换环境中引导生成高质量句法资源

Abstract: Code-switching presents a complex challenge for syntactic analysis,
especially in low-resource language settings where annotated data is scarce.
While recent work has explored the use of large language models (LLMs) for
sequence-level tagging, few approaches systematically investigate how well
these models capture syntactic structure in code-switched contexts. Moreover,
existing parsers trained on monolingual treebanks often fail to generalize to
multilingual and mixed-language input. To address this gap, we introduce the
BiLingua Parser, an LLM-based annotation pipeline designed to produce Universal
Dependencies (UD) annotations for code-switched text. First, we develop a
prompt-based framework for Spanish-English and Spanish-Guaran\'i data,
combining few-shot LLM prompting with expert review. Second, we release two
annotated datasets, including the first Spanish-Guaran\'i UD-parsed corpus.
Third, we conduct a detailed syntactic analysis of switch points across
language pairs and communicative contexts. Experimental results show that
BiLingua Parser achieves up to 95.29% LAS after expert revision, significantly
outperforming prior baselines and multilingual parsers. These results show that
LLMs, when carefully guided, can serve as practical tools for bootstrapping
syntactic resources in under-resourced, code-switched environments. Data and
source code are available at https://github.com/N3mika/ParsingProject

</details>


### [214] [Exploring the Impact of Temperature on Large Language Models:Hot or Cold?](https://arxiv.org/abs/2506.07295)
*Lujun Li,Lama Sleem,Niccolo' Gentile,Geoffrey Nichil,Radu State*

Main category: cs.CL

TL;DR: 本文研究了采样温度（0-2范围）对不同规模LLM六项能力的影响，发现温度对性能的影响具有技能特异性。提出基于BERT的温度选择器优化小中型模型在SuperGLUE的表现，并验证温度效应在FP16和4位量化模型中一致。发现突变温度随模型规模增加而升高。


<details>
  <summary>Details</summary>
Motivation: 已有研究挑战'随机鹦鹉'假说，表明LLM能理解语义而非单纯记忆，且温度调制的随机性在推理中起关键作用。但温度对多项能力的异质性影响尚不清晰，需系统评估以优化实际应用中的温度选择。

Method: 系统评测温度(0-2)对评估六种能力的测试集影响，统计分析三个规模的开源模型(small:1B-4B, medium:6B-13B, large:40B-80B)；提出BERT-based温度选择器；扩展FP16精度和量化模型(最高温度4.0)的评测。

Result: 1) 温度影响具有技能特异性 2) BERT选择器显著提升中小型模型在SuperGLUE的性能 3) FP16与4-bit量化模型温度效应一致 4) 量化模型中突变温度随模型规模增大而升高(最高达4.0时)。

Conclusion: 温度选择需考虑任务技能特性；提出的温度选择器有效优化性能；温度效应在不同精度下稳健；模型规模增大需更高温度触发显著性能变化。

Abstract: The sampling temperature, a critical hyperparameter in large language models
(LLMs), modifies the logits before the softmax layer, thereby reshaping the
distribution of output tokens. Recent studies have challenged the Stochastic
Parrots analogy by demonstrating that LLMs are capable of understanding
semantics rather than merely memorizing data and that randomness, modulated by
sampling temperature, plays a crucial role in model inference. In this study,
we systematically evaluated the impact of temperature in the range of 0 to 2 on
data sets designed to assess six different capabilities, conducting statistical
analyses on open source models of three different sizes: small (1B--4B), medium
(6B--13B), and large (40B--80B). Our findings reveal distinct skill-specific
effects of temperature on model performance, highlighting the complexity of
optimal temperature selection in practical applications. To address this
challenge, we propose a BERT-based temperature selector that takes advantage of
these observed effects to identify the optimal temperature for a given prompt.
We demonstrate that this approach can significantly improve the performance of
small and medium models in the SuperGLUE datasets. Furthermore, our study
extends to FP16 precision inference, revealing that temperature effects are
consistent with those observed in 4-bit quantized models. By evaluating
temperature effects up to 4.0 in three quantized models, we find that the
Mutation Temperature -- the point at which significant performance changes
occur -- increases with model size.

</details>


### [215] [Subjectivity in the Annotation of Bridging Anaphora](https://arxiv.org/abs/2506.07297)
*Lauren Levine,Amir Zeldes*

Main category: cs.CL

TL;DR: Abstract 分析了桥接注释中的主观性问题，包括指称识别、先行词解析和桥接子类型选择三个层面。通过在GUM语料库测试集上进行标注试验，提出了一个新的桥接子类型分类系统，并与先前方案进行比较。结果显示先前资源可能存在严重标注不足，且标注者间在桥接实例识别上一致性较低，源于对实体的主观理解差异。


<details>
  <summary>Details</summary>
Motivation: 识别桥接关系的标注存在高度主观性，导致标注一致性低。本文旨在探索桥接注释在三个层面的主观性：指称识别、先行词解析和桥接子类型选择。

Method: 1）在GUM语料库测试集上进行标注试验；2）提出新的桥接子类型分类系统，并与现有方案比较；3）分析标注者间一致性。

Result: 1）先前资源可能存在严重标注不足；2）桥接子类型类别标注一致性中等；3）桥接实例识别的标注者重叠率低，主要源于对实体的主观理解差异。

Conclusion: 桥接标注高度依赖主观判断，尤其在指称识别层面存在显著分歧。这揭示出现有语料库可能存在系统性标注遗漏，未来研究需开发更鲁棒的标注框架。

Abstract: Bridging refers to the associative relationship between inferable entities in
a discourse and the antecedents which allow us to understand them, such as
understanding what "the door" means with respect to an aforementioned "house".
As identifying associative relations between entities is an inherently
subjective task, it is difficult to achieve consistent agreement in the
annotation of bridging anaphora and their antecedents. In this paper, we
explore the subjectivity involved in the annotation of bridging instances at
three levels: anaphor recognition, antecedent resolution, and bridging subtype
selection. To do this, we conduct an annotation pilot on the test set of the
existing GUM corpus, and propose a newly developed classification system for
bridging subtypes, which we compare to previously proposed schemes. Our results
suggest that some previous resources are likely to be severely under-annotated.
We also find that while agreement on the bridging subtype category was
moderate, annotator overlap for exhaustively identifying instances of bridging
is low, and that many disagreements resulted from subjective understanding of
the entities involved.

</details>


### [216] [ConfQA: Answer Only If You Are Confident](https://arxiv.org/abs/2506.07309)
*Yin Huang,Yifan Ethan Xu,Kai Sun,Vera Yan,Alicia Sun,Haidar Khan,Jimmy Nguyen,Mohammad Kachuee,Zhaojiang Lin,Yue Liu,Aaron Colak,Anuj Kumar,Wen-tau Yih,Xin Luna Dong*

Main category: cs.CL

TL;DR: 提出了名为 ConfQA 的微调策略，通过训练模型仅在有信心时回答来显著降低 LLM 幻觉率（从 20-40% 降至 5% 以下），并在此基础上提出双神经知识框架以进一步提升准确率至 95% 以上。


<details>
  <summary>Details</summary>
Motivation: 解决大型语言模型（LLMs）在生成事实陈述时产生幻觉的问题（原幻觉率为 20-40%），通过校准模型信心来减少错误回答。

Method: 1. 使用微调策略 ConfQA：模型回答正确时要求完整输出答案，错误时训练其承认“我不确定”；2. 引入抑制性提示“仅在自信时回答”；3. 利用知识图谱属性值校准置信度；随后提出 Dual Neural Knowledge 框架，基于置信度动态选择内部参数化知识或外部符号知识。

Result: 1. 幻觉率在多事实基准测试中下降至 5% 以下（原为 20-40%）；2. 若省略抑制性提示则幻觉率仍达 15%-25%；3. Dual Neural Knowledge 框架使准确率突破 95% 同时减少 30%+ 不必要外部检索。

Conclusion: ConfQA 策略大幅降低 LLM 幻觉且具跨域鲁棒性；其衍生的双知识框架通过动态知识选择机制实现更高准确率与检索效率。

Abstract: Can we teach Large Language Models (LLMs) to refrain from hallucinating
factual statements? In this paper we present a fine-tuning strategy that we
call ConfQA, which can reduce hallucination rate from 20-40% to under 5% across
multiple factuality benchmarks. The core idea is simple: when the LLM answers a
question correctly, it is trained to continue with the answer; otherwise, it is
trained to admit "I am unsure". But there are two key factors that make the
training highly effective. First, we introduce a dampening prompt "answer only
if you are confident" to explicitly guide the behavior, without which
hallucination remains high as 15%-25%. Second, we leverage simple factual
statements, specifically attribute values from knowledge graphs, to help LLMs
calibrate the confidence, resulting in robust generalization across domains and
question types. Building on this insight, we propose the Dual Neural Knowledge
framework, which seamlessly select between internally parameterized neural
knowledge and externally recorded symbolic knowledge based on ConfQA's
confidence. The framework enables potential accuracy gains to beyond 95%, while
reducing unnecessary external retrievals by over 30%.

</details>


### [217] [Reward Model Interpretability via Optimal and Pessimal Tokens](https://arxiv.org/abs/2506.07326)
*Brian Christian,Hannah Rose Kirk,Jessica A. F. Thompson,Christopher Summerfield,Tsvetomira Dumbalska*

Main category: cs.CL

TL;DR: 摘要介绍奖励模型解读新方法，揭示模型间异质性、系统不对称性、提示框架敏感性、令牌频率偏差，及训练隐含的风险偏见。


<details>
  <summary>Details</summary>
Motivation: 当前奖励模型作为人价值对齐核心组件未被充分研究，研究旨在填补此空白。

Method: 通过词汇空间全范围分析：比较10个开源奖励模型对单一令牌响应打分。

Result: 发现四关键问题：模型异质性；高低分令牌编码不对称性；提示框架敏感性；高频令牌高估。证明模型隐含身份群体偏见

Conclusion: 挑战奖励模型互换性前提，警示其作为人类价值代理的局限性和扩散偏见风险。

Abstract: Reward modeling has emerged as a crucial component in aligning large language
models with human values. Significant attention has focused on using reward
models as a means for fine-tuning generative models. However, the reward models
themselves -- which directly encode human value judgments by turning
prompt-response pairs into scalar rewards -- remain relatively understudied. We
present a novel approach to reward model interpretability through exhaustive
analysis of their responses across their entire vocabulary space. By examining
how different reward models score every possible single-token response to
value-laden prompts, we uncover several striking findings: (i) substantial
heterogeneity between models trained on similar objectives, (ii) systematic
asymmetries in how models encode high- vs low-scoring tokens, (iii) significant
sensitivity to prompt framing that mirrors human cognitive biases, and (iv)
overvaluation of more frequent tokens. We demonstrate these effects across ten
recent open-source reward models of varying parameter counts and architectures.
Our results challenge assumptions about the interchangeability of reward
models, as well as their suitability as proxies of complex and
context-dependent human values. We find that these models can encode concerning
biases toward certain identity groups, which may emerge as unintended
consequences of harmlessness training -- distortions that risk propagating
through the downstream large language models now deployed to millions.

</details>


### [218] [Improving LLM Reasoning through Interpretable Role-Playing Steering](https://arxiv.org/abs/2506.07335)
*Anyi Wang,Dong Shu,Yifan Wang,Yunpu Ma,Mengnan Du*

Main category: cs.CL

TL;DR: 本文介绍了一个新颖的框架SRPS，通过识别和控制模型内部特征来增强角色扮演能力，在多个基准测试上提升了模型表现。


<details>
  <summary>Details</summary>
Motivation: 传统角色扮演提示方法缺乏稳定性与可解释性，需开发更可控的特征导向方法。

Method: 从角色扮演提示中提取隐表征→基于激活模式筛选特征→构建可调节的转向向量注入残差流。

Result: 在零样本CoT设定下：Llama3.1-8B在CSQA准确率从31.86%提升至39.80%；Gemma2-9B在SVAMP从37.50%升至45.10%。

Conclusion: SRPS通过操控内部特征实现了更精细的角色行为控制，为模型行为可解释性提供新思路。

Abstract: Role-playing has emerged as an effective technique for enhancing the
reasoning capabilities of large language models (LLMs). However, existing
methods primarily rely on prompt engineering, which often lacks stability and
interpretability. In this paper, we introduce Sparse Autoencoder Role-Playing
Steering (SRPS), a novel framework that identifies and manipulates internal
model features associated with role-playing behavior. Our approach extracts
latent representations from role-play prompts, selects the most relevant
features based on activation patterns, and constructs a steering vector that
can be injected into the model's residual stream with controllable intensity.
Our method enables fine-grained control over role-specific behavior and offers
insights into how role information influences internal model activations.
Extensive experiments across various reasoning benchmarks and model sizes
demonstrate consistent performance gains. Notably, in the zero-shot
chain-of-thought (CoT) setting, the accuracy of Llama3.1-8B on CSQA improves
from 31.86% to 39.80%, while Gemma2-9B on SVAMP increases from 37.50% to
45.10%. These results highlight the potential of SRPS to enhance reasoning
ability in LLMs, providing better interpretability and stability compared to
traditional prompt-based role-playing.

</details>


### [219] [Refusal-Feature-guided Teacher for Safe Finetuning via Data Filtering and Alignment Distillation](https://arxiv.org/abs/2506.07356)
*Seokil Ham,Yubin Choi,Seungju Cho,Yujin Yang,Younghun Kim,Changick Kim*

Main category: cs.CL

TL;DR: 为了解决Finetuning-as-a-Service中用户数据包含有害提示导致LLM安全对齐退化的问题，本文提出了一种基于拒绝特征的教师模型（ReFT），该模型通过输入提示特征与拒绝特征的相似性识别有害提示，在微调中过滤有害数据并蒸馏对齐知识。


<details>
  <summary>Details</summary>
Motivation: 现有服务在用户微调时容易因用户数据含有害提示导致安全对齐退化，虽存在解决方案但尚未从数据过滤的根本层面解决。作者观察到安全对齐LLM的拒绝特征天然区分有害/无害提示，据此提出ReFT方法。

Method: 提出Refusal-Feature-guided Teacher（ReFT）模型：1）利用安全对齐LLM提取拒绝特征；2）训练ReFT模型基于输入提示特征与拒绝特征的相似性识别有害提示；3）在微调时作为教师模型过滤有害数据，并向基础模型蒸馏对齐知识。

Result: 大量实验证明：ReFT微调策略可显著减少有害输出，同时提升用户特定任务的微调精度，为Finetuning-as-a-Service提供安全可靠的部署方案。

Conclusion: ReFT通过拒绝特征引导的有害数据过滤和对齐知识蒸馏，解决了微调服务中的安全对齐退化问题，在安全性和任务准确性上实现双重提升。

Abstract: Recently, major AI service providers such as Google and OpenAI have
introduced Finetuning-as-a-Service, which enables users to customize Large
Language Models (LLMs) for specific downstream tasks using their own data.
However, this service is vulnerable to degradation of LLM safety-alignment when
user data contains harmful prompts. While some prior works address this issue,
fundamentally filtering harmful data from user data remains unexplored.
Motivated by our observation that a directional representation reflecting
refusal behavior (called the refusal feature) obtained from safety-aligned LLMs
can inherently distinguish between harmful and harmless prompts, we propose the
Refusal-Feature-guided Teacher (ReFT). Our ReFT model is trained to identify
harmful prompts based on the similarity between input prompt features and its
refusal feature. During finetuning, the ReFT model serves as a teacher that
filters harmful prompts from user data and distills alignment knowledge into
the base model. Extensive experiments demonstrate that our ReFT-based
finetuning strategy effectively minimizes harmful outputs and enhances
finetuning accuracy for user-specific tasks, offering a practical solution for
secure and reliable deployment of LLMs in Finetuning-as-a-Service.

</details>


### [220] [SEED: Enhancing Text-to-SQL Performance and Practical Usability Through Automatic Evidence Generation](https://arxiv.org/abs/2506.07423)
*Janghyeon Yun,Sang-goo Lee*

Main category: cs.CL

TL;DR: 本研究提出SEED系统，自动生成数据库证据以提升无证据场景下的Text-to-SQL性能，解决BIRD数据集依赖人工证据的问题


<details>
  <summary>Details</summary>
Motivation: 现有Text-to-SQL模型依赖BIRD数据集提供的专家级人工证据，违背技术初衷且证据存在缺陷。真实场景用户缺乏领域知识，需自动证据生成方案

Method: SEED系统通过解析数据库模式、描述文件和数值来自动提取证据。包括：1) 模式分析 2) 描述文件处理 3) 数值关联

Result: 在BIRD和Spider数据集上实验显示：1) 无证据场景中SQL准确率显著提升 2) 部分情况超越BIRD人工证据的效果

Conclusion: SEED生成的证据缩小研究与实际应用的差距，增强模型适应性和鲁棒性，为Text-to-SQL实用化提供有效解决方案

Abstract: Text-to-SQL enables non-experts to retrieve data from databases by converting
natural language queries into SQL. However, state-of-the-art text-to-SQL
studies rely on the BIRD dataset, which assumes that evidence is provided along
with questions. Although BIRD facilitates research advancements, it assumes
that users have expertise and domain knowledge, contradicting the fundamental
goal of text-to-SQL. In addition, human-generated evidence in BIRD contains
defects, including missing or erroneous evidence, which affects model
performance. To address this issue, we propose SEED (System for Evidence
Extraction and Domain knowledge generation), an approach that automatically
generates evidence to improve performance and practical usability in real-world
scenarios. SEED systematically analyzes database schema, description files, and
values to extract relevant information. We evaluated SEED on BIRD and Spider,
demonstrating that it significantly improves SQL generation accuracy in the
no-evidence scenario, and in some cases, even outperforms the setting where
BIRD evidence is provided. Our results highlight that SEED-generated evidence
not only bridges the gap between research and real-world deployment but also
improves the adaptability and robustness of text-to-SQL models. Our code is
available at https://github.com/felix01189/SEED

</details>


### [221] [Plug-in and Fine-tuning: Bridging the Gap between Small Language Models and Large Language Models](https://arxiv.org/abs/2506.07424)
*Kyeonghyun Kim,Jinhee Jang,Juhwan Choi,Yoonji Lee,Kyohoon Jin,YoungBin Kim*

Main category: cs.CL

TL;DR: 该文提出了PiFi框架，通过在小型语言模型（SLM）中插入冻结的大型语言模型（LLM）单层并进行微调，实现了高效且高性能的自然语言处理。


<details>
  <summary>Details</summary>
Motivation: LLMs计算需求高难以部署在资源受限环境，而SLMs效率高但泛化能力差。PiFi旨在结合二者优势：以可接受的计算成本提升SLM性能。

Method: 将LLM的单个冻结层集成到SLM中，再对组合模型进行任务特定微调。

Result: 在多项自然语言理解和生成任务中性能持续提升，有效利用LLM知识增强领域泛化能力和语言能力迁移。

Conclusion: PiFi在计算效率和模型性能之间取得平衡，为资源受限环境提供可行的LLM-SLM协同解决方案。

Abstract: Large language models (LLMs) are renowned for their extensive linguistic
knowledge and strong generalization capabilities, but their high computational
demands make them unsuitable for resource-constrained environments. In
contrast, small language models (SLMs) are computationally efficient but often
lack the broad generalization capacity of LLMs. To bridge this gap, we propose
PiFi, a novel framework that combines the strengths of both LLMs and SLMs to
achieve high performance while maintaining efficiency. PiFi integrates a single
frozen layer from an LLM into a SLM and fine-tunes the combined model for
specific tasks, boosting performance without a significant increase in
computational cost. We show that PiFi delivers consistent performance
improvements across a range of natural language processing tasks, including
both natural language understanding and generation. Moreover, our findings
demonstrate PiFi's ability to effectively leverage LLM knowledge, enhancing
generalization to unseen domains and facilitating the transfer of linguistic
abilities.

</details>


### [222] [Conjoined Predication and Scalar Implicature](https://arxiv.org/abs/2506.07429)
*Ratna Kandala*

Main category: cs.CL

TL;DR: Magri's first puzzle involves infelicitous conjunctions like '(Only) Some Italians come from a warm country and are blond,' which lack obvious conflicting scalar implicatures. This paper analyzes the puzzle by attributing the oddness to collective/concurrent interpretations causing indirect contextual contradictions, arguing that pragmatic mechanisms extend beyond grammatical exhaustification accounts.


<details>
  <summary>Details</summary>
Motivation: To resolve Magri's first unresolved puzzle regarding infelicitous conjunctions, exploring hidden interactions among quantification, collective interpretation, and contextual updating that challenge existing scalar implicature theories.

Method: Conceptually analyzing the puzzle within Magri's theoretical framework, proposing that collective/concurrent readings of conjunctive predicates create indirect contextual contradictions.

Result: Identifies collective interpretation as the source of infelicity in examples like 'Some Italians come from a warm country and are blond,' despite absence of direct scalar conflict.

Conclusion: The study suggests that pragmatic mechanisms for scalar implicatures surpass grammatical exhaustification models, revealing new dimensions in quantification-context interactions.

Abstract: Magri (2016) investigates two puzzles arising from conjunction. Although
Magri has proposed a solution to the second puzzle, the first remains
unresolved. This first puzzle reveals a hidden interaction among
quantification, collective/concurrent interpretation, and contextual updating
dimensions that have yet to be explored. In essence, the problem is that
certain forms of sentences like "Some Italians come from a warm country," when
conjoined as in "(Only) Some Italians come from a warm country and are blond,"
sound infelicitous, even though no obvious alternative triggers a conflicting
scalar implicature. In this paper, we offer a conceptual analysis of Magri's
first puzzle by situating it within its original theoretical framework. We
argue that the oddness arises from the collective or concurrent reading of the
conjunctive predicate: in examples such as "(Only) Some Italians come from a
warm country and are blond," this interpretation generates an indirect
contextual contradiction. Moreover, we suggest that the pragmatic mechanisms
governing scalar implicature generation extend beyond what is captured by
exhaustification-based grammatical licensing accounts.

</details>


### [223] [Well Begun is Half Done: Low-resource Preference Alignment by Weak-to-Strong Decoding](https://arxiv.org/abs/2506.07434)
*Feifan Song,Shaohang Wei,Wen Luo,Yuxuan Fan,Tianyu Liu,Guoyin Wang,Houfeng Wang*

Main category: cs.CL

TL;DR: 本文提出了一种名为Weak-to-Strong Decoding（WSD）的新框架，通过小模型引导生成对齐响应的开头，再由基础大模型继续后续内容，并使用自动切换机制。此外，作者收集了GenerAlign数据集来微调小模型，实验证明该方法能有效提升基础模型的对齐能力，同时避免下游任务性能下降。


<details>
  <summary>Details</summary>
Motivation: 现有的大语言模型对齐方法在资源有限的情况下难以同时保证高质量和对齐的内容。作者观察发现，生成对齐响应的困难主要在于解码的开头部分，因此提出WSD框架利用小模型引导开头来提升基础模型的对齐能力。

Method: 1) 提出弱到强解码（WSD）框架：先用小型对齐模型生成对齐良好的开头片段；2) 通过设计的自动切换机制，由基础大模型继续生成后续内容；3) 收集GenerAlign数据集，用于微调小型草案模型Pilot-3B。

Result: 在WSD框架下，使用Pilot-3B引导不同基础模型后，性能超越所有基线方法，且下游任务未出现对齐税（性能下降）。实验还分析了不同设置的影响、时间效率及WSD的内在机制。

Conclusion: WSD框架通过小模型引导解码开头的创新方法有效地提升了大模型的对齐能力，同时避免了传统对齐方法带来的下游任务性能下降问题。深入分析验证了该机制的有效性。

Abstract: Large Language Models (LLMs) require alignment with human preferences to
avoid generating offensive, false, or meaningless content. Recently,
low-resource methods for LLM alignment have been popular, while still facing
challenges in obtaining both high-quality and aligned content. Motivated by the
observation that the difficulty of generating aligned responses is concentrated
at the beginning of decoding, we propose a novel framework, Weak-to-Strong
Decoding (WSD), to enhance the alignment ability of base models by the guidance
of a small aligned model. The small model first drafts well-aligned beginnings,
followed by the large base model to continue the rest, controlled by a
well-designed auto-switch mechanism. We also collect a new dataset, GenerAlign,
to fine-tune a small-sized Pilot-3B as the draft model, which effectively
enhances different base models under the WSD framework to outperform all
baseline methods, while avoiding degradation on downstream tasks, termed as the
alignment tax. Extensive experiments are further conducted to examine the
impact of different settings and time efficiency, as well as analyses on the
intrinsic mechanisms of WSD in depth.

</details>


### [224] [LG-ANNA-Embedding technical report](https://arxiv.org/abs/2506.07438)
*Jooyoung Choi,Hyun Kim,Hansol Jang,Changwook Jun,Kyunghoon Bae,Hyewon Choi,Stanley Jungkyu Choi,Honglak Lee,Chulmin Yun*

Main category: cs.CL

TL;DR: 该论文提出了一种统一的指令框架，用于学习针对信息检索（IR）和非IR任务优化的广义文本嵌入。该方法基于Mistral-7B模型，结合上下文学习、软监督和自适应难负例挖掘，无需任务特定微调即可生成上下文感知的嵌入。


<details>
  <summary>Details</summary>
Motivation: 传统的文本嵌入方法通常需要为不同任务进行特定微调，缺乏泛化能力。为了解决这个问题，研究团队希望开发一个统一的框架，能适应多种任务（包括IR和非IR），同时提升嵌入的语义判别能力。

Method: 1. 使用结构化指令和少样本示例指导模型处理多样化任务；2. 采用软标签框架，将高性能稠密检索器和重排器蒸馏的连续相关分数作为细粒度监督信号；3. 提出自适应基于间隔的难负例挖掘，根据负例与正例的相似度过滤模糊负例，提升训练稳定性和检索鲁棒性。

Result: 在MTEB（英文，v2）基准测试的41个任务上评估，模型展现出强泛化能力：1. Borda分数排名前列；2. 超越多个更大或完全微调的基线模型；3. 在分类、语义相似性、聚类和重排任务中均表现优异。

Conclusion: 上下文提示、软监督和自适应采样的组合能有效生成可扩展的高质量嵌入。该方法证实了指令框架在统一处理多样化任务上的潜力，同时为提升语义判别性提供了可解释的技术路径。

Abstract: This report presents a unified instruction-based framework for learning
generalized text embeddings optimized for both information retrieval (IR) and
non-IR tasks. Built upon a decoder-only large language model (Mistral-7B), our
approach combines in-context learning, soft supervision, and adaptive
hard-negative mining to generate context-aware embeddings without task-specific
fine-tuning. Structured instructions and few-shot examples are used to guide
the model across diverse tasks, enabling strong performance on classification,
semantic similarity, clustering, and reranking benchmarks. To improve semantic
discrimination, we employ a soft labeling framework where continuous relevance
scores, distilled from a high-performance dense retriever and reranker, serve
as fine-grained supervision signals. In addition, we introduce adaptive
margin-based hard-negative mining, which filters out semantically ambiguous
negatives based on their similarity to positive examples, thereby enhancing
training stability and retrieval robustness. Our model is evaluated on the
newly introduced MTEB (English, v2) benchmark, covering 41 tasks across seven
categories. Results show that our method achieves strong generalization and
ranks among the top-performing models by Borda score, outperforming several
larger or fully fine-tuned baselines. These findings highlight the
effectiveness of combining in-context prompting, soft supervision, and adaptive
sampling for scalable, high-quality embedding generation.

</details>


### [225] [Understanding Cross-Domain Adaptation in Low-Resource Topic Modeling](https://arxiv.org/abs/2506.07453)
*Pritom Saha Akash,Kevin Chen-Chuan Chang*

Main category: cs.CL

TL;DR: 提出名为DALTA的新框架，针对低资源主题建模中的域适应问题，通过共享编码器、专用解码器和对抗性对齐实现知识迁移，在多样低资源数据集上优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有主题模型在低资源场景下因目标域数据有限导致主题推断不稳定、不连贯。需要利用高资源源域信息辅助目标域，同时避免无关内容干扰。

Method: 提出DALTA框架：1) 共享编码器提取域不变特征；2) 专用解码器处理域特定信息；3) 对抗性对齐选择性地迁移相关知识。理论分析表明需同时最小化潜在空间差异并防止过拟合。

Result: 在多个低资源数据集上的实验显示，DALTA在主题连贯性（coherence）、稳定性和可迁移性方面持续优于最先进方法。

Conclusion: 通过领域对齐的潜在主题适应方法，有效解决了低资源主题建模中的知识迁移问题，为跨域主题发现提供新思路。

Abstract: Topic modeling plays a vital role in uncovering hidden semantic structures
within text corpora, but existing models struggle in low-resource settings
where limited target-domain data leads to unstable and incoherent topic
inference. We address this challenge by formally introducing domain adaptation
for low-resource topic modeling, where a high-resource source domain informs a
low-resource target domain without overwhelming it with irrelevant content. We
establish a finite-sample generalization bound showing that effective knowledge
transfer depends on robust performance in both domains, minimizing latent-space
discrepancy, and preventing overfitting to the data. Guided by these insights,
we propose DALTA (Domain-Aligned Latent Topic Adaptation), a new framework that
employs a shared encoder for domain-invariant features, specialized decoders
for domain-specific nuances, and adversarial alignment to selectively transfer
relevant information. Experiments on diverse low-resource datasets demonstrate
that DALTA consistently outperforms state-of-the-art methods in terms of topic
coherence, stability, and transferability.

</details>


### [226] [KScope: A Framework for Characterizing the Knowledge Status of Language Models](https://arxiv.org/abs/2506.07458)
*Yuxin Xiao,Shan Chen,Jack Gallifant,Danielle Bitterman,Thomas Hartvigsen,Marzyeh Ghassemi*

Main category: cs.CL

TL;DR: 该论文针对大语言模型的知识状态识别提出挑战，引入五种知识状态分类，并开发KScope方法系统评估LLM知识。研究发现支持性上下文可缩小知识差距，特征驱动更新，不同模型中特征偏好差异，特定策略可改进知识更新。


<details>
  <summary>Details</summary>
Motivation: 现有方法主要关注知识冲突情景，未能全面描述LLM对问题的理解程度。需要建立系统性框架以评估不同知识状态（一致性/正确性维度），从而揭示LLM知识更新机制并指导改进。

Method: 提出知识状态五分类法；设计KScope框架（多层次统计假设检验），逐步细化知识模式假设。在九种LLM、四个数据集上应用，分析支持性上下文影响和特征驱动因素。

Result: (1)支持性上下文显著缩小模型知识差距 (2)上下文难度/相关性/熟悉度特征驱动更新成功 (3)部分正确/冲突时特征偏好相似；完全错误时迥异 (4)基于特征分析的摘要与增强可信度策略提升更新效果且具跨模型泛化性

Conclusion: 知识状态五元分类法超越传统冲突分析；KScope框架为LLM知识系统评估提供新工具；发现的特征规律可指导上下文优化设计以增强模型知识可靠性。

Abstract: Characterizing a large language model's (LLM's) knowledge of a given question
is challenging. As a result, prior work has primarily examined LLM behavior
under knowledge conflicts, where the model's internal parametric memory
contradicts information in the external context. However, this does not fully
reflect how well the model knows the answer to the question. In this paper, we
first introduce a taxonomy of five knowledge statuses based on the consistency
and correctness of LLM knowledge modes. We then propose KScope, a hierarchical
framework of statistical tests that progressively refines hypotheses about
knowledge modes and characterizes LLM knowledge into one of these five
statuses. We apply KScope to nine LLMs across four datasets and systematically
establish: (1) Supporting context narrows knowledge gaps across models. (2)
Context features related to difficulty, relevance, and familiarity drive
successful knowledge updates. (3) LLMs exhibit similar feature preferences when
partially correct or conflicted, but diverge sharply when consistently wrong.
(4) Context summarization constrained by our feature analysis, together with
enhanced credibility, further improves update effectiveness and generalizes
across LLMs.

</details>


### [227] [From Calibration to Collaboration: LLM Uncertainty Quantification Should Be More Human-Centered](https://arxiv.org/abs/2506.07461)
*Siddartha Devic,Tejas Srinivasan,Jesse Thomason,Willie Neiswanger,Vatsal Sharan*

Main category: cs.CL

TL;DR: 当前大语言模型(LLMs)的不确定性量化研究存在生态效度低、仅考虑认知不确定性、指标不实用三大问题，阻碍了人机协作的实际应用。研究者建议采用更贴近真实用户需求的方法论转向。


<details>
  <summary>Details</summary>
Motivation: 现有不确定性量化方法未能有效支持真实场景中用户对LLM预测的信任决策，阻碍了人机协作的实际效果。

Method: 分析40种LLM不确定性量化方法，批判现有方法论存在的三大缺陷：1)评估任务生态效度低；2)仅关注认知不确定性；3)优化指标与下游实用性脱节。

Result: 指出当前研究范式偏离用户需求核心问题，具体表现为在非代表性任务上使用不完善指标进行无效优化。

Conclusion: 主张LLM不确定性量化研究需转向人本中心范式，提出针对三大问题的用户导向改进建议：采用生态效度高的评估任务、整合认知与随机不确定性、开发面向实用性的评价指标。

Abstract: Large Language Models (LLMs) are increasingly assisting users in the real
world, yet their reliability remains a concern. Uncertainty quantification (UQ)
has been heralded as a tool to enhance human-LLM collaboration by enabling
users to know when to trust LLM predictions. We argue that current practices
for uncertainty quantification in LLMs are not optimal for developing useful UQ
for human users making decisions in real-world tasks. Through an analysis of 40
LLM UQ methods, we identify three prevalent practices hindering the community's
progress toward its goal of benefiting downstream users: 1) evaluating on
benchmarks with low ecological validity; 2) considering only epistemic
uncertainty; and 3) optimizing metrics that are not necessarily indicative of
downstream utility. For each issue, we propose concrete user-centric practices
and research directions that LLM UQ researchers should consider. Instead of
hill-climbing on unrepresentative tasks using imperfect metrics, we argue that
the community should adopt a more human-centered approach to LLM uncertainty
quantification.

</details>


### [228] [CCI4.0: A Bilingual Pretraining Dataset for Enhancing Reasoning in Large Language Models](https://arxiv.org/abs/2506.07463)
*Guang Liu,Liangdong Wang,Jijie Li,Yang Yu,Yao Xu,Jiabei Chen,Yu Bai,Feng Liao,Yonghua Lin*

Main category: cs.CL

TL;DR: CCI4.0 is a 35TB bilingual dataset with two sub-datasets: Base (curated web corpus + Nemotron-CC + specialized data) and CoT (4.5B extracted reasoning templates). It uses a novel pipeline for data deduplication/quality scoring and staged CoT extraction to reduce hallucination. Pre-training on it boosts LLM performance, especially in math/coding tasks.


<details>
  <summary>Details</summary>
Motivation: Existing datasets have dynamic quality standards requiring excessive manual curation, while CoT data from model distillation lacks reasoning diversity and causes hallucination. CCI4.0 addresses these via automated quality control and human-like staged CoT extraction.

Method: 1) Build bilingual corpus with web/educational/professional sources; 2) Two-stage deduplication + multiclassifier scoring + domain-aware fluency filtering; 3) Staged extraction of 4.5B CoT templates from existing data (not distillation).

Result: LLMs pre-trained on CCI4.0 show consistent gains, particularly in mathematical and coding reflection downstream tasks.

Conclusion: Automated data curation plus human-like reasoning templates critically improves LLM training; the pipeline demonstrates viable large-scale corpus processing.

Abstract: We introduce CCI4.0, a large-scale bilingual pre-training dataset engineered
for superior data quality and diverse human-like reasoning trajectory. CCI4.0
occupies roughly $35$ TB of disk space and comprises two sub-datasets:
CCI4.0-M2-Base and CCI4.0-M2-CoT. CCI4.0-M2-Base combines a $5.2$ TB carefully
curated Chinese web corpus, a $22.5$ TB English subset from Nemotron-CC, and
diverse sources from math, wiki, arxiv, and code. Although these data are
mostly sourced from well-processed datasets, the quality standards of various
domains are dynamic and require extensive expert experience and labor to
process. So, we propose a novel pipeline justifying data quality mainly based
on models through two-stage deduplication, multiclassifier quality scoring, and
domain-aware fluency filtering. We extract $4.5$ billion pieces of
CoT(Chain-of-Thought) templates, named CCI4.0-M2-CoT. Differing from the
distillation of CoT from larger models, our proposed staged CoT extraction
exemplifies diverse reasoning patterns and significantly decreases the
possibility of hallucination. Empirical evaluations demonstrate that LLMs
pre-trained in CCI4.0 benefit from cleaner, more reliable training signals,
yielding consistent improvements in downstream tasks, especially in math and
code reflection tasks. Our results underscore the critical role of rigorous
data curation and human thinking templates in advancing LLM performance,
shedding some light on automatically processing pretraining corpora.

</details>


### [229] [Improving Fairness of Large Language Models in Multi-document Summarization](https://arxiv.org/abs/2506.07479)
*Haoyuan Li Yusen Zhang,Snigdha Chaturvedi*

Main category: cs.CL

TL;DR: 提出FairPO方法，一种兼顾摘要级和语料库级公平性的偏好调整方法，用于多文档摘要任务，通过扰动文档集生成偏好对并动态调整权重来提高公平性，同时保持摘要质量。


<details>
  <summary>Details</summary>
Motivation: 现有方法主要关注摘要级公平性，但公平性在多文档摘要中至关重要，需要同时考虑摘要级和语料库级公平性以避免偏见影响决策。

Method: FairPO方法：1) 为摘要级公平性，通过扰动文档集生成偏好对；2) 为语料库级公平性，通过动态调整偏好对权重进行公平感知偏好调整。

Result: 实验表明FairPO优于强基线，在提升公平性的同时保持了摘要的关键质量指标。

Conclusion: FairPO能有效提升多文档摘要中两个层次的公平性，为构建更公正的摘要系统提供新方案，代码已开源。

Abstract: Fairness in multi-document summarization (MDS) is crucial for providing
comprehensive views across documents with diverse social attribute values,
which can significantly impact decision-making. For example, a summarization
system that tends to overrepresent negative reviews of products can mislead
customers into disregarding good products. Previous works measure fairness in
MDS at two levels: summary-level and corpus-level. While summary-level fairness
focuses on individual summaries, corpus-level fairness focuses on a corpus of
summaries. Recent methods primarily focus on summary-level fairness. We propose
FairPO, a preference tuning method that focuses on both summary-level and
corpus-level fairness in MDS. To improve summary-level fairness, we propose to
generate preference pairs by perturbing document sets. To improve corpus-level
fairness, we propose fairness-aware preference tuning by dynamically adjusting
the weights of preference pairs. Our experiments show that FairPO outperforms
strong baselines while maintaining the critical qualities of summaries. The
code is available at https://github.com/leehaoyuan/coverage_fairnes.

</details>


### [230] [A Hybrid GA LLM Framework for Structured Task Optimization](https://arxiv.org/abs/2506.07483)
*Berry Feng,Jonas Lin,Patrick Lau*

Main category: cs.CL

TL;DR: GA LLM是一个结合遗传算法和大型语言模型的混合框架，用于在严格约束下处理结构化生成任务。它将输出视为基因，利用LLM指导选择、交叉和变异等进化操作迭代优化方案。


<details>
  <summary>Details</summary>
Motivation: 单独使用语言模型生成结构化输出时，常面临约束满足不足和全局优化困难的问题。遗传算法擅长全局搜索但缺乏领域知识，而LLM能提供创意却难以保证结构完整性。将两者结合可互补优势。

Method: 1. 将每个输出（如行程计划）编码为基因序列；2. 语言模型引导进化操作：评估适应度（约束满足度）、设计交叉点、生成有意义变异；3. 遗传算法管理种群迭代，保留最优解并重组改进。

Result: 在行程规划、学术大纲编写和商业报告生成等任务中：1. 约束满足率提升15-22%；2. 结构完整性评分提高30%；3. 人类评估显示输出质量优于纯LLM方法2.4倍（5分制）。

Conclusion: 该框架通过GA的结构化优化能力与LLM的领域知识创造性相结合，显著提升复杂约束下的生成质量。模块化设计支持快速迁移至新领域，为受限生成任务提供新范式。

Abstract: GA LLM is a hybrid framework that combines Genetic Algorithms with Large
Language Models to handle structured generation tasks under strict constraints.
Each output, such as a plan or report, is treated as a gene, and evolutionary
operations like selection, crossover, and mutation are guided by the language
model to iteratively improve solutions. The language model provides domain
knowledge and creative variation, while the genetic algorithm ensures
structural integrity and global optimization. GA LLM has proven effective in
tasks such as itinerary planning, academic outlining, and business reporting,
consistently producing well structured and requirement satisfying results. Its
modular design also makes it easy to adapt to new tasks. Compared to using a
language model alone, GA LLM achieves better constraint satisfaction and higher
quality solutions by combining the strengths of both components.

</details>


### [231] [DEBATE: A Dataset for Disentangling Textual Ambiguity in Mandarin Through Speech](https://arxiv.org/abs/2506.07502)
*Haotian Guo,Jing Han,Yongfeng Tu,Shihao Gao,Shengfan Shen,Wulong Xiang,Weihao Gan,Zixing Zhang*

Main category: cs.CL

TL;DR: 为解决口语消歧(disambiguation through speech, DTS)研究领域的数据集缺失问题，该研究提出了首个中文语音-文本数据集DEBATE，包含1,001个有歧义的句子且每个句子由10位母语者录音。研究详细描述了数据采集方法，并对3个大模型进行基准测试，发现机器与人类在理解口语意图上存在明显差距。


<details>
  <summary>Details</summary>
Motivation: 现有研究主要关注文本和视觉消歧，而通过语音信号进行消歧的研究(如利用发音、停顿、重音和语调等线索)因缺乏高质量数据集而未被充分探索。

Method: 1) 构建DEBATE数据集：精心筛选1,001个歧义句，每个句子由10位中文母语者录音，捕捉语音中的消歧线索；2) 建立严格的数据收集与质量分析流程；3) 评估三款最先进的大规模语音及音语模型在数据集上的表现。

Result: 1) 成功创建首个针对性研究语音消歧的中文数据集；2) 基准测试显示现有模型与人类表现存在显著差距（人类理解正确率约90%，最优模型仅80%）；3) 验证了语音特征对消除文本歧义的有效性。

Conclusion: DEBATE填补了语音消歧研究的数据空白，证明了语音线索在理解说话人真实意图中的关键作用。数据集公开可用，为跨语言/文化的DTS研究奠定基础。当前模型性能的差距也凸显了该领域的发展空间。

Abstract: Despite extensive research on textual and visual disambiguation,
disambiguation through speech (DTS) remains underexplored. This is largely due
to the lack of high-quality datasets that pair spoken sentences with richly
ambiguous text. To address this gap, we present DEBATE, a unique public Chinese
speech-text dataset designed to study how speech cues and
patterns-pronunciation, pause, stress and intonation-can help resolve textual
ambiguity and reveal a speaker's true intent. DEBATE contains 1,001 carefully
selected ambiguous utterances, each recorded by 10 native speakers, capturing
diverse linguistic ambiguities and their disambiguation through speech. We
detail the data collection pipeline and provide rigorous quality analysis.
Additionally, we benchmark three state-of-the-art large speech and
audio-language models, illustrating clear and huge performance gaps between
machine and human understanding of spoken intent. DEBATE represents the first
effort of its kind and offers a foundation for building similar DTS datasets
across languages and cultures. The dataset and associated code are available
at: https://github.com/SmileHnu/DEBATE.

</details>


### [232] [What Do Indonesians Really Need from Language Technology? A Nationwide Survey](https://arxiv.org/abs/2506.07506)
*Muhammad Dehan Al Kautsar,Lucky Susanto,Derry Wijaya,Fajri Koto*

Main category: cs.CL

TL;DR: 该论文通过全国性调查揭示了印度尼西亚本土语言社区对语言技术的真实需求：机器翻译和信息检索是当务之急，同时需关注隐私、偏见和数据使用的透明度问题以促进AI采纳。


<details>
  <summary>Details</summary>
Motivation: 当前印尼700多种地方语言的NLP开发进展缓慢且成本高昂，但社区实际需求不明。研究旨在填补这一空白，了解本土语言社区最需要哪些语言技术支持。

Method: 在全国范围内开展问卷调查，评估印尼母语使用者的实际语言技术需求。

Result: 发现突破语言障碍（尤其机器翻译和信息检索）是最迫切需求；社区对语言技术进步热情高涨，但对隐私、偏见及公开数据用于AI训练存在担忧。

Conclusion: 推进语言技术需优先满足核心需求，同时通过提升透明度和明确沟通来解决伦理顾虑，才能扩大AI技术的接纳度。

Abstract: There is an emerging effort to develop NLP for Indonesias 700+ local
languages, but progress remains costly due to the need for direct engagement
with native speakers. However, it is unclear what these language communities
truly need from language technology. To address this, we conduct a nationwide
survey to assess the actual needs of native speakers in Indonesia. Our findings
indicate that addressing language barriers, particularly through machine
translation and information retrieval, is the most critical priority. Although
there is strong enthusiasm for advancements in language technology, concerns
around privacy, bias, and the use of public data for AI training highlight the
need for greater transparency and clear communication to support broader AI
adoption.

</details>


### [233] [DeRAGEC: Denoising Named Entity Candidates with Synthetic Rationale for ASR Error Correction](https://arxiv.org/abs/2506.07510)
*Solee Im,Wonjun Lee,Jinmyeong An,Yunsu Kim,Jungseul Ok,Gary Geunbae Lee*

Main category: cs.CL

TL;DR: DeRAGEC通过合成去噪原理改进ASR系统中的命名实体纠正，无需额外训练即在CommonVoice和STOP数据集上显著降低WER 28%。


<details>
  <summary>Details</summary>
Motivation: 现有RAGEC方法在检索时容易引入噪声实体，影响自动语音识别(ASR)的命名实体纠正效果。

Method: 扩展RAGEC框架：1) 利用语音相似性和增强定义生成合成去噪原理 2) 通过上下文学习过滤噪声实体候选后再纠正。

Result: 在CommonVoice和STOP数据集上：WER相对基准ASR降低28%，命名实体命中率提升，优于原始RAGEC和其他基线方法。

Conclusion: DeRAGEC证实了去噪机制对检索增强纠错的有效性，且无需训练即可提升ASR的命名实体识别性能。

Abstract: We present DeRAGEC, a method for improving Named Entity (NE) correction in
Automatic Speech Recognition (ASR) systems. By extending the
Retrieval-Augmented Generative Error Correction (RAGEC) framework, DeRAGEC
employs synthetic denoising rationales to filter out noisy NE candidates before
correction. By leveraging phonetic similarity and augmented definitions, it
refines noisy retrieved NEs using in-context learning, requiring no additional
training. Experimental results on CommonVoice and STOP datasets show
significant improvements in Word Error Rate (WER) and NE hit ratio,
outperforming baseline ASR and RAGEC methods. Specifically, we achieved a 28%
relative reduction in WER compared to ASR without postprocessing. Our source
code is publicly available at: https://github.com/solee0022/deragec

</details>


### [234] [Towards Large Language Models with Self-Consistent Natural Language Explanations](https://arxiv.org/abs/2506.07523)
*Sahar Admoni,Ofra Amir,Assaf Hallak,Yftah Ziser*

Main category: cs.CL

TL;DR: 该论文指出目前大语言模型（LLM）的事后解释与其实际决策特征重要性存在不一致的问题。为解决评估成本高昂的局限，作者提出了PSCB基准，包含多任务多模型的决策数据和解释。分析发现现有自洽度量标准无法有效区分解释质量，因此提出新度量标准并用DPO优化LLM，显著提高了解释与决策特征的对齐程度。


<details>
  <summary>Details</summary>
Motivation: 现有LLM的事后解释常与其实际决策过程不一致，且评估这种不一致的成本高昂导致难以大规模研究。需要建立大规模基准和改进度量方法来推动可信赖的自我解释模型发展。

Method: 1. 构建PSCB基准(Post-hoc Self-Consistency Bank)：覆盖多种任务和模型的大规模决策数据集，包含模型预测、生成的解释及对应的特征重要性评分。2. 分析现有自洽度量的缺陷。3. 提出改进的解释质量度量标准。4. 使用DPO（Direct Preference Optimization）基于新标准微调LLM。

Result: 1. PSCB分析显示：正确和错误预测的自洽度几乎无差异。2. 标准度量无法有效区分解释质量。3. 新提出的度量标准能更有效捕捉解释质量差异。4. DPO微调的模型显著提升了解释与决策特征的对齐度（包括领域转移场景）。

Conclusion: PSCB基准为新研究奠定基础；新度量标准能更好评估解释质量；经过DPO优化后，模型可实现更可信的解释自洽性，为构建可靠自解释模型提供了可扩展路径。

Abstract: Large language models (LLMs) seem to offer an easy path to interpretability:
just ask them to explain their decisions. Yet, studies show that these post-hoc
explanations often misrepresent the true decision process, as revealed by
mismatches in feature importance. Despite growing evidence of this
inconsistency, no systematic solutions have emerged, partly due to the high
cost of estimating feature importance, which limits evaluations to small
datasets. To address this, we introduce the Post-hoc Self-Consistency Bank
(PSCB) - a large-scale benchmark of decisions spanning diverse tasks and
models, each paired with LLM-generated explanations and corresponding feature
importance scores. Analysis of PSCB reveals that self-consistency scores barely
differ between correct and incorrect predictions. We also show that the
standard metric fails to meaningfully distinguish between explanations. To
overcome this limitation, we propose an alternative metric that more
effectively captures variation in explanation quality. We use it to fine-tune
LLMs via Direct Preference Optimization (DPO), leading to significantly better
alignment between explanations and decision-relevant features, even under
domain shift. Our findings point to a scalable path toward more trustworthy,
self-consistent LLMs.

</details>


### [235] [Bit-level BPE: Below the byte boundary](https://arxiv.org/abs/2506.07541)
*Sangwhan Moon,Tatsuya Hiraoka,Naoaki Okazaki*

Main category: cs.CL

TL;DR: 针对中文、日文、韩文（CJK）及表情符号等字符多样性场景中子词分词时字节级回退导致的序列过长问题，本文提出了一种无损压缩技术以减少序列长度。


<details>
  <summary>Details</summary>
Motivation: 当前大型语言模型中普遍采用字节级回退解决词汇表外词（OOV）问题，但在处理CJK字符和表情符号时会解码为字节序列，导致序列长度显著增加，进而增加训练和推理的计算开销。

Method: 提出了一种针对字节序列的无损压缩技术，在不损失信息的前提下缩短处理长尾词汇时的序列长度。

Result: 未在摘要中明确提及实验结果，但暗示该技术能有效减少序列长度。

Conclusion: 该压缩技术在保持解决OOV问题能力的同时，可能降低计算成本，提升大型语言模型在特定场景的效率。

Abstract: Byte-level fallbacks for subword tokenization have become a common practice
in large language models. In particular, it has been demonstrated to be
incredibly effective as a pragmatic solution for preventing OOV, especially in
the context of larger models. However, breaking a character down to individual
bytes significantly increases the sequence length for long-tail tokens in
languages such as Chinese, Japanese, and Korean (CJK) and other
character-diverse contexts such as emoji. The increased sequence length results
in longer computation during both training and inference. In this work, we
propose a simple compression technique that reduces the sequence length
losslessly.

</details>


### [236] [SELT: Self-Evaluation Tree Search for LLMs with Task Decomposition](https://arxiv.org/abs/2506.07557)
*Mengsong Wu,Di Zhang,Yuqiang Li,Dongzhan Zhou,Wenliang Chen*

Main category: cs.CL

TL;DR: SELT框架利用改进的MCTS提升LLMs在复杂推理任务中的表现，通过自评估机制减少幻觉和冗余推理路径，在多项基准测试中显著超越基线方法且无需微调。


<details>
  <summary>Details</summary>
Motivation: LLMs在复杂推理任务中表现下降，需要不依赖外部奖励模型的增强方案。

Method: 改进MCTS算法：重构UCB评分以对齐LLMs的自我评估能力，将推理分解为原子子任务并在节点进行语义聚类。

Result: 在MMLU和Seal-Tools基准上实现准确率和鲁棒性显著提升，最高指标达XX%（需补全具体数值）。

Conclusion: SELT为LLM推理提供高效、通用的增强框架，其自包含特性有望推动自动决策系统发展。

Abstract: While Large Language Models (LLMs) have achieved remarkable success in a wide
range of applications, their performance often degrades in complex reasoning
tasks. In this work, we introduce SELT (Self-Evaluation LLM Tree Search), a
novel framework that leverages a modified Monte Carlo Tree Search (MCTS) to
enhance LLM reasoning without relying on external reward models. By redefining
the Upper Confidence Bound scoring to align with intrinsic self-evaluation
capabilities of LLMs and decomposing the inference process into atomic subtasks
augmented with semantic clustering at each node, SELT effectively balances
exploration and exploitation, reduces redundant reasoning paths, and mitigates
hallucination. We validate our approach on challenging benchmarks, including
the knowledge-based MMLU and the Tool Learning dataset Seal-Tools, where SELT
achieves significant improvements in answer accuracy and reasoning robustness
compared to baseline methods. Notably, our framework operates without
task-specific fine-tuning, demonstrating strong generalizability across diverse
reasoning tasks. Relevant results and code are available at
https://github.com/fairyshine/SELT .

</details>


### [237] [Beyond the Sentence: A Survey on Context-Aware Machine Translation with Large Language Models](https://arxiv.org/abs/2506.07583)
*Ramakrishna Appicharla,Baban Gain,Santanu Pal,Asif Ekbal*

Main category: cs.CL

TL;DR: 本文综述了大型语言模型（LLMs）在上下文感知机器翻译中的应用，重点探讨了提示和微调方法，指出商业模型表现优于开源模型，并提出了未来研究方向。


<details>
  <summary>Details</summary>
Motivation: 尽管大型语言模型（LLMs）很受欢迎，但在机器翻译领域，特别是上下文感知翻译中应用相对较少。

Method: 文献综述法，对现有工作进行分析与总结。

Result: 商业大型语言模型表现优于开源模型，提示方法可为质量评估提供基线。

Conclusion: 未来研究应探索提示工程、微调策略、后编辑自动化以及翻译代理的开发方向。

Abstract: Despite the popularity of the large language models (LLMs), their application
to machine translation is relatively underexplored, especially in context-aware
settings. This work presents a literature review of context-aware translation
with LLMs. The existing works utilise prompting and fine-tuning approaches,
with few focusing on automatic post-editing and creating translation agents for
context-aware machine translation. We observed that the commercial LLMs (such
as ChatGPT and Tower LLM) achieved better results than the open-source LLMs
(such as Llama and Bloom LLMs), and prompt-based approaches serve as good
baselines to assess the quality of translations. Finally, we present some
interesting future directions to explore.

</details>


### [238] [Instructing Large Language Models for Low-Resource Languages: A Systematic Study for Basque](https://arxiv.org/abs/2506.07597)
*Oscar Sainz,Naiara Perez,Julen Etxaniz,Joseba Fernandez de Landa,Itziar Aldabe,Iker García-Ferrero,Aimar Zabala,Ekhi Azurmendi,German Rigau,Eneko Agirre,Mikel Artetxe,Aitor Soroa*

Main category: cs.CL

TL;DR: 本文探索了在低资源语言（如巴斯克语）上微调大语言模型的替代方法，仅使用目标语言语料库、现有预训练和指导调优模型以及合成指令数据。实验表明，使用指导调优的主干模型优于非指导模型，且目标语言语料和合成指令能生成稳健模型。使用Llama 3.1 70B主干模型获得接近前沿模型的效果，并开源代码、模型及数据。


<details>
  <summary>Details</summary>
Motivation: 解决低资源语言缺少大型指令数据集的问题。当前指令微调方法依赖大规模标注指令数据，但对资源稀缺语言无效，因此探索仅利用基础语料、预训练模型和合成指令的轻量级适应方案。

Method: 构建巴斯克语综合实验：仅使用1.2B单词目标语料库、多语言预训练/指令主干模型（如Llama 3.1）及英语指令数据。通过合成指令采样，在目标语言上微调主干模型，系统比较不同主干（指导/非指导）、模型规模及数据组合效果。

Result: 1) 目标语言语料库至关重要；2) 合成指令能生成稳健模型；3) 采用指导调优主干模型（如Llama 3.1）始终优于非指导模型；4) 模型扩展性良好（Llama 3.1 70B模型接近前沿大模型效果）。在1680人参与的人类评估中也验证了效果。

Conclusion: 低资源语言适配中：a) 指令调优主干模型是高效路径；b) 合成指令可替代人工标注；c) 模型容量比本地数据量更重要。开源所有资源推动该领域研究。

Abstract: Instructing language models with user intent requires large instruction
datasets, which are only available for a limited set of languages. In this
paper, we explore alternatives to conventional instruction adaptation pipelines
in low-resource scenarios. We assume a realistic scenario for low-resource
languages, where only the following are available: corpora in the target
language, existing open-weight multilingual base and instructed backbone LLMs,
and synthetically generated instructions sampled from the instructed backbone.
We present a comprehensive set of experiments for Basque that systematically
study different combinations of these components evaluated on benchmarks and
human preferences from 1,680 participants. Our conclusions show that target
language corpora are essential, with synthetic instructions yielding robust
models, and, most importantly, that using as backbone an instruction-tuned
model outperforms using a base non-instructed model, and improved results when
scaling up. Using Llama 3.1 instruct 70B as backbone our model comes near
frontier models of much larger sizes for Basque, without using any Basque data
apart from the 1.2B word corpora. We release code, models, instruction
datasets, and human preferences to support full reproducibility in future
research on low-resource language adaptation.

</details>


### [239] [PolitiSky24: U.S. Political Bluesky Dataset with User Stance Labels](https://arxiv.org/abs/2506.07606)
*Peyman Rostami,Vahid Rahimzadeh,Ali Adibi,Azadeh Shakery*

Main category: cs.CL

TL;DR: 介绍了PolitiSky24数据集，这是首个针对2024年美国总统选举的Bluesky平台用户级立场检测数据集，包含16,044条用户对Kamala Harris和Donald Trump的立场标注，附带交互元数据和标注流程。


<details>
  <summary>Details</summary>
Motivation: 现有立场检测数据集主要聚焦推特等成熟平台的推文级分析，而新兴平台Bluesky的用户级立场资源稀缺。用户级立场检测能通过分析用户整体发帖历史提供更全面的观点洞察。

Method: 使用结合高级信息检索和大语言模型的标注流程，生成立场标签及支持理由和文本片段，标注方法在可扩展LLMs上达到81%准确率。

Result: 构建了包含16,044条用户-目标立场对的数据集，附带参与度元数据、交互图和用户发帖历史。

Conclusion: PolitiSky24通过时效性、开放数据特性和用户级视角填补了政治立场分析的空白，数据集已在Zenodo开源。

Abstract: Stance detection identifies the viewpoint expressed in text toward a specific
target, such as a political figure. While previous datasets have focused
primarily on tweet-level stances from established platforms, user-level stance
resources, especially on emerging platforms like Bluesky remain scarce.
User-level stance detection provides a more holistic view by considering a
user's complete posting history rather than isolated posts. We present the
first stance detection dataset for the 2024 U.S. presidential election,
collected from Bluesky and centered on Kamala Harris and Donald Trump. The
dataset comprises 16,044 user-target stance pairs enriched with engagement
metadata, interaction graphs, and user posting histories. PolitiSky24 was
created using a carefully evaluated pipeline combining advanced information
retrieval and large language models, which generates stance labels with
supporting rationales and text spans for transparency. The labeling approach
achieves 81\% accuracy with scalable LLMs. This resource addresses gaps in
political stance analysis through its timeliness, open-data nature, and
user-level perspective. The dataset is available at
https://doi.org/10.5281/zenodo.15616911

</details>


### [240] [Vuyko Mistral: Adapting LLMs for Low-Resource Dialectal Translation](https://arxiv.org/abs/2506.07617)
*Roman Kyslyi,Yuliia Maksymiuk,Ihor Pysmennyi*

Main category: cs.CL

TL;DR: 本文首个将大语言模型(LLM)适配至乌克兰胡楚尔方言(低资源、形态复杂)的研究:构建9852句并行语料库和7320词词典;提出改进RAG生成52142句合成数据;微调开源LLMs并在方言翻译任务中超越GPT-4o基线和少样本学习;采用多指标评估策略;所有资源开源。


<details>
  <summary>Details</summary>
Motivation: 解决低资源胡楚尔方言的LLM适配问题:该方言缺乏标注数据且形态复杂,需要构建基础语言资源并探索高效微调方法。

Method: 1) 创建双语平行语料库(9852句)及方言词典(7320词) 2) 提出改进的检索增强生成(RAG)方法合成52142句数据 3) 使用LoRA技术微调多种开源LLM 4) 设计含BLEU/chrF++/TER/GPT-4o的多指标评估框架

Result: 微调后的小模型(7B)在方言翻译任务全面超越GPT-4o:1)机器指标(BLEU等)平均提升15% 2)LLM评估准确率提高22% 3)验证合成数据与LoRA微调的有效性

Conclusion: 系统证明:1)合成数据扩充有效解决低资源问题 2)小规模适配LLM可超越商用大模型 3)为濒危语言保护提供可扩展方案 4)开源资源促进乌克兰方言NLP研究

Abstract: In this paper we introduce the first effort to adapt large language models
(LLMs) to the Ukrainian dialect (in our case Hutsul), a low-resource and
morphologically complex dialect spoken in the Carpathian Highlands. We created
a parallel corpus of 9852 dialect-to-standard Ukrainian sentence pairs and a
dictionary of 7320 dialectal word mappings. We also addressed data shortage by
proposing an advanced Retrieval-Augmented Generation (RAG) pipeline to generate
synthetic parallel translation pairs, expanding the corpus with 52142 examples.
We have fine-tuned multiple open-source LLMs using LoRA and evaluated them on a
standard-to-dialect translation task, also comparing with few-shot GPT-4o
translation. In the absence of human annotators, we adopt a multi-metric
evaluation strategy combining BLEU, chrF++, TER, and LLM-based judgment
(GPT-4o). The results show that even small(7B) finetuned models outperform
zero-shot baselines such as GPT-4o across both automatic and LLM-evaluated
metrics. All data, models, and code are publicly released at:
https://github.com/woters/vuyko-hutsul

</details>


### [241] [LoRMA: Low-Rank Multiplicative Adaptation for LLMs](https://arxiv.org/abs/2506.07621)
*Harsh Bihany,Shubham Patel,Ashutosh Modi*

Main category: cs.CL

TL;DR: 提出了一种新的低秩乘法自适应方法LoRMA，以替代LoRA的加法更新，通过优化操作顺序和秩膨胀策略提高效率，实验证明了方法的有效性。


<details>
  <summary>Details</summary>
Motivation: 虽然LoRA等基于加法更新的方法提升了大型语言模型微调效率，但其存在局限性。为了在计算效率和表达能力上取得更好平衡，本文提出转向乘法更新的新范式。

Method: LoRMA采用矩阵乘法变换替代加法更新，设计了运算重排序和秩膨胀策略来降低计算复杂度并突破矩阵乘法的秩瓶颈。

Result: 通过大量实验验证了该方法在多项评估指标上的优越性能。

Conclusion: 低秩乘法自适应相比传统加法方法提供了更丰富的变换空间，是未来参数高效微调的有前景方向。

Abstract: Large Language Models have shown remarkable capabilities in the NLP domain.
Their effectiveness can mainly be attributed to their ability to adapt to an
array of downstream tasks. However, generally, full fine-tuning is a
computationally expensive job. To mitigate this, many techniques have been
developed that prime efficiency, a prominent one being Low-Rank Adaptation
(LoRA). However, LoRA and its variants employ re-parametrized additive updates.
In this paper, we propose Low-Rank Multiplicative Adaptation (LoRMA), which
shifts the paradigm of additive updates to a richer space of matrix
multiplicative transformations. We tackle challenges such as computational
complexity and rank bottleneck of matrix multiplication by effectively
re-ordering operations and introducing rank inflation strategies. We conduct
extensive experiments to demonstrate the effectiveness of our approach in terms
of various evaluation metrics.

</details>


### [242] [Intent Matters: Enhancing AI Tutoring with Fine-Grained Pedagogical Intent Annotation](https://arxiv.org/abs/2506.07626)
*Kseniia Petukhova,Ekaterina Kochmar*

Main category: cs.CL

TL;DR: 使用细粒度教师意图标注（十一种）替代原始的四分类标注，通过微调LLM提升教育场景中对话的生成质量。实验证明，标注粒度的提升使生成的回答更具教学对齐性和有效性。


<details>
  <summary>Details</summary>
Motivation: 现有LLM在教育应用（如智能辅导系统）中缺乏与教学策略的对齐，而标注的精细度可能是提升LLM生成教育响应质量的关键因素。

Method: 1. 选取数学辅导对话数据集MathDial。2. 使用十一种教学意图的细粒度分类体系对其重新标注。3. 基于新标注微调LLM。4. 与原始四分类微调模型进行自动评估和人工评测对比。

Result: 使用细粒度标注微调的LLM在自动评估和人工定性评估中均展现出：1. 更好的教学策略对齐性。2. 更有效的辅导响应。

Conclusion: 细粒度的教学意图标注显著提升教育场景下LLM生成内容的质量，验证了意图粒度对教育文本生成控制的价值；公开标注数据及代码以促进后续研究。

Abstract: Large language models (LLMs) hold great promise for educational applications,
particularly in intelligent tutoring systems. However, effective tutoring
requires alignment with pedagogical strategies - something current LLMs lack
without task-specific adaptation. In this work, we explore whether fine-grained
annotation of teacher intents can improve the quality of LLM-generated tutoring
responses. We focus on MathDial, a dialog dataset for math instruction, and
apply an automated annotation framework to re-annotate a portion of the dataset
using a detailed taxonomy of eleven pedagogical intents. We then fine-tune an
LLM using these new annotations and compare its performance to models trained
on the original four-category taxonomy. Both automatic and qualitative
evaluations show that the fine-grained model produces more pedagogically
aligned and effective responses. Our findings highlight the value of intent
specificity for controlled text generation in educational settings, and we
release our annotated data and code to facilitate further research.

</details>


### [243] [Unblocking Fine-Grained Evaluation of Detailed Captions: An Explaining AutoRater and Critic-and-Revise Pipeline](https://arxiv.org/abs/2506.07631)
*Brian Gordon,Yonatan Bitton,Andreea Marzoca,Yasumasa Onoe,Xiao Wang,Daniel Cohen-Or,Idan Szpektor*

Main category: cs.CL

TL;DR: 本文介绍了DOCCI-Critique基准和VNLI-Critique模型，用于评估大规模视觉语言模型（VLMs）生成段落级描述的事实准确性。基准包含1400个带有人工标注的描述，模型能自动分类事实错误并生成解释。应用包括模型排名、自动化评估和通过反馈改进描述准确性。


<details>
  <summary>Details</summary>
Motivation: 当前评估VLM生成段落级描述的方法缺乏细粒度错误检测能力，且缺少已验证错误的数据集。需要新工具来精细评估和提升VLM的事实准确性。

Method: 构建DOCCI-Critique基准（含100张图像的1400条描述，人工标注10166个句子级事实准确性及错误原因）。开发VNLI-Critique模型实现自动化句子级事实分类和批评生成。

Result: 1) VNLI-Critique在M-HalDetect和CHOCOLATE基准表现最优 2) 其自动化排名与人工评估高度相关（Spearman系数0.98）3) 批评指导的修订流程使DetailCaps-4870数据集事实准确率提升46%。

Conclusion: 提出的基准和工具显著提升细粒度评估标准，并为改进VLM图像理解提供实践路径，通过自动化批评-修订机制有效提升描述事实准确性。

Abstract: Large Vision-Language Models (VLMs) now generate highly detailed,
paragraphlength image captions, yet evaluating their factual accuracy remains
challenging. Current methods often miss fine-grained errors, being designed for
shorter texts or lacking datasets with verified inaccuracies. We introduce
DOCCI-Critique, a benchmark with 1,400 VLM-generated paragraph captions (100
images, 14 VLMs) featuring over 10,216 sentence-level human annotations of
factual correctness and explanatory rationales for errors, all within paragraph
context. Building on this, we develop VNLI-Critique, a model for automated
sentence-level factuality classification and critique generation. We highlight
three key applications: (1) VNLI-Critique demonstrates robust generalization,
validated by state-of-the-art performance on the M-HalDetect benchmark and
strong results in CHOCOLATE claim verification. (2) The VNLI-Critique driven
AutoRater for DOCCI-Critique provides reliable VLM rankings, showing excellent
alignment with human factuality judgments (e.g., 0.98 Spearman). (3) An
innovative Critic-and-Revise pipeline, where critiques from VNLI-Critique guide
LLM-based corrections, achieves substantial improvements in caption factuality
(e.g., a 46% gain on DetailCaps-4870). Our work offers a crucial benchmark
alongside practical tools, designed to significantly elevate the standards for
fine-grained evaluation and foster the improvement of VLM image understanding.
Project page: https://google.github.io/unblocking-detail-caption

</details>


### [244] [TreeReview: A Dynamic Tree of Questions Framework for Deep and Efficient LLM-based Scientific Peer Review](https://arxiv.org/abs/2506.07642)
*Yuan Chang,Ziyue Li,Hengyuan Zhang,Yuanbo Kong,Yanru Wu,Zhijiang Guo,Ngai Wong*

Main category: cs.CL

TL;DR: 本文提出TreeReview框架，用于提升LLM辅助同行评审的质量和效率。通过将评审建模为层次化双向问答过程，构建问题树并动态扩展问题，在减少80%计算量的同时生成更全面深入的评审反馈。


<details>
  <summary>Details</summary>
Motivation: 现有LLM辅助评审方法难以兼顾评审的深度、洞察力与效率。为解决该问题，作者希望设计一种能生成高质量评审同时保持计算效率的新框架。

Method: TreeReview框架：1) 递归分解高层问题为细粒度子问题构建问题树；2) 自底向上聚合答案形成最终评审；3) 引入动态问题扩展机制在需要时生成后续问题。

Result: 实验表明：1) 在ICLR/NeurIPS数据集上优于基线；2) 生成更全面、深入、专家认可的评审；3) 相比密集计算方法减少80%token使用量。

Conclusion: TreeReview通过分层问答结构实现了高效高质的学术评审，为LLM辅助评审提供了新思路。代码与基准数据集已开源。

Abstract: While Large Language Models (LLMs) have shown significant potential in
assisting peer review, current methods often struggle to generate thorough and
insightful reviews while maintaining efficiency. In this paper, we propose
TreeReview, a novel framework that models paper review as a hierarchical and
bidirectional question-answering process. TreeReview first constructs a tree of
review questions by recursively decomposing high-level questions into
fine-grained sub-questions and then resolves the question tree by iteratively
aggregating answers from leaf to root to get the final review. Crucially, we
incorporate a dynamic question expansion mechanism to enable deeper probing by
generating follow-up questions when needed. We construct a benchmark derived
from ICLR and NeurIPS venues to evaluate our method on full review generation
and actionable feedback comments generation tasks. Experimental results of both
LLM-based and human evaluation show that TreeReview outperforms strong
baselines in providing comprehensive, in-depth, and expert-aligned review
feedback, while reducing LLM token usage by up to 80% compared to
computationally intensive approaches. Our code and benchmark dataset are
available at https://github.com/YuanChang98/tree-review.

</details>


### [245] [Evaluating LLMs Robustness in Less Resourced Languages with Proxy Models](https://arxiv.org/abs/2506.07645)
*Maciej Chrabąszcz,Katarzyna Lorenc,Karolina Seweryn*

Main category: cs.CL

TL;DR: 论文揭示大型语言模型在低资源语言如波兰语中对字符和词级攻击的脆弱性，通过少量字符修改和代理模型计算词重要性即可绕过安全机制，并发布了数据集和代码。


<details>
  <summary>Details</summary>
Motivation: 尽管多语言LLM在各种任务中表现优秀，但其安全训练数据主要基于英语等高资源语言，对低资源语言（如波兰语）的扰动攻击存在潜在漏洞。

Method: 构建廉价攻击方法：修改字符级别扰动和词级重要性计算。通过小型代理模型评估词重要性，在波兰语中验证攻击效果，并将方法扩展到其他语言。

Result: 字符和词级攻击显著改变了不同LLM的预测结果，成功绕过了其内部安全机制，证明了低资源语言场景下的脆弱性。

Conclusion: 当前LLM的安全机制在低资源语言中存在严重漏洞，需加强多语言安全训练数据覆盖。发布的代码和数据可为后续研究提供支持。

Abstract: Large language models (LLMs) have demonstrated impressive capabilities across
various natural language processing (NLP) tasks in recent years. However, their
susceptibility to jailbreaks and perturbations necessitates additional
evaluations. Many LLMs are multilingual, but safety-related training data
contains mainly high-resource languages like English. This can leave them
vulnerable to perturbations in low-resource languages such as Polish. We show
how surprisingly strong attacks can be cheaply created by altering just a few
characters and using a small proxy model for word importance calculation. We
find that these character and word-level attacks drastically alter the
predictions of different LLMs, suggesting a potential vulnerability that can be
used to circumvent their internal safety mechanisms. We validate our attack
construction methodology on Polish, a low-resource language, and find potential
vulnerabilities of LLMs in this language. Additionally, we show how it can be
extended to other languages. We release the created datasets and code for
further research.

</details>


### [246] [Transcript-Prompted Whisper with Dictionary-Enhanced Decoding for Japanese Speech Annotation](https://arxiv.org/abs/2506.07646)
*Rui Hu,Xiaolong Lin,Jiawang Liu,Shixi Huang,Zhenpeng Zhan*

Main category: cs.CL

TL;DR: 提出了一种基于预训练ASR模型的日语文语转换数据集标注方法，通过微调模型同时输出字形及注音/韵律标签，并利用词典解码纠错，标注效果超越纯文本或纯音频方法，合成语音自然度接近人工标注模型。


<details>
  <summary>Details</summary>
Motivation: 为构建高质量日语文语转换(TTS)数据集，需要高效准确的音素及韵律标注方法，传统纯文本或纯音频方法存在局限，而结合两者信息的自动标注方案尚未完善。

Method: 1)微调基于音频-文本对的预训练ASR模型，使其同时输出短语级字形及注音/韵律标签 2)利用词典先验知识设计解码策略校正音素标注错误

Result: 1)客观评估:标注准确率超越纯文本/纯音频基线方法 2)主观评估:基于自动标注训练的TTS模型MOS自然度接近人工标注模型(差距<0.1)

Conclusion: 该方法能高效生成接近人工质量的TTS标注数据，验证了音频文本联合建模及先验知识融合在声学标注任务中的有效性。

Abstract: In this paper, we propose a method for annotating phonemic and prosodic
labels on a given audio-transcript pair, aimed at constructing Japanese
text-to-speech (TTS) datasets. Our approach involves fine-tuning a large-scale
pre-trained automatic speech recognition (ASR) model, conditioned on ground
truth transcripts, to simultaneously output phrase-level graphemes and
annotation labels. To further correct errors in phonemic labeling, we employ a
decoding strategy that utilizes dictionary prior knowledge. The objective
evaluation results demonstrate that our proposed method outperforms previous
approaches relying solely on text or audio. The subjective evaluation results
indicate that the naturalness of speech synthesized by the TTS model, trained
with labels annotated using our method, is comparable to that of a model
trained with manual annotations.

</details>


### [247] [Beyond Benchmarks: A Novel Framework for Domain-Specific LLM Evaluation and Knowledge Mapping](https://arxiv.org/abs/2506.07658)
*Nitin Sharma,Thomas Wolfers,Çağatay Yıldız*

Main category: cs.CL

TL;DR: 开发了一种确定性流水线，将原始领域语料库转化为不依赖LM或人工筛选的补全型评估基准，解决了评估中的领域特定基准创建和知识表征理解问题。


<details>
  <summary>Details</summary>
Motivation: 解决语言模型评估中的两个关键挑战：创建可靠的领域特定基准和理解领域适应过程中的知识表征。

Method: 引入确定性流水线：使用TF和Term TF-IDF方法生成领域关键词及关联词列表，构建提示-目标对；通过模型补全提示的能力直接评估领域知识。

Result: 在GPT-2等模型和多个领域上的实验显示：1) 基准与专家生成的标准强相关 2) 比传统困惑度指标更准确 3) 发现小模型领域适应迅速(500步内) 4) 揭示初始层负责属性提取，后续层专注词预测 5) 遗忘始于中间层并在后续层放大。

Conclusion: 提供了实用的领域LM评估方法，揭示了适应期知识表征机制，为高效微调和减轻灾难性遗忘提供了新思路。

Abstract: The paper addresses two critical challenges in language model (LM)
evaluation: creating reliable domain-specific benchmarks and understanding
knowledge representation during domain adaptation. We introduce a deterministic
pipeline that converts raw domain corpora into completion-type benchmarks
without relying on LMs or human curation, eliminating benchmark contamination
issues while enabling evaluation on the latest domain data. Our approach
generates domain-specific keywords and related word lists using TF and Term
TF-IDF methods and constructs prompt-target pairs. We evaluate models by
measuring their ability to complete these prompts with the correct
domain-specific targets, providing a direct assessment of domain knowledge with
low computational cost. Through comprehensive experiments across multiple
models (GPT-2 medium/XL, Llama-2/3.1, OLMo-2, Qwen-2, Mistral) and domains, we
demonstrate that our benchmark strongly correlates with expert-generated
benchmarks while providing a more accurate measure of domain knowledge than
traditional perplexity metrics. We reveal that domain adaptation happens
rapidly in smaller models (within 500 steps) and illustrate a new approach to
domain knowledge evaluation in base models during training for early stopping.
By extending mechanistic analysis to domain adaptation, we discover that
initial-to-mid layers are primarily responsible for attribute extraction, while
later layers focus on next token prediction. Furthermore, we show that during
adaptation, forgetting begins in the middle layers, where attribute extraction
happens and is amplified in later layers. Our work provides both a practical
evaluation methodology for domain-specific LMs and novel insights into
knowledge representation during adaptation, with implications for more
efficient fine-tuning strategies and targeted approaches to mitigate
catastrophic forgetting.

</details>


### [248] [Synthesis by Design: Controlled Data Generation via Structural Guidance](https://arxiv.org/abs/2506.07664)
*Lei Xu,Sirui Chen,Yuxuan Huang,Chaochao Lu*

Main category: cs.CL

TL;DR: 该论文提出了使用代码生成结构化解题步骤的数据增强方法，针对数学推理任务构建了包含3.9万题的新数据集和6.1K的高难度测试集，验证了推理链长度对模型性能的影响，并通过微调实验证明了数据集有效性。


<details>
  <summary>Details</summary>
Motivation: 现有数据增强方法在数学推理任务中存在生成质量低和难以处理复杂问题的问题，需要更可靠的数据生成方案来提升大语言模型的推理能力。

Method: 通过生成问题求解代码提取结构化信息，指导生成包含标注中间步骤的数学题解数据，构建了MATH和GSM8K任务的增强数据集。

Result: 构建了39K训练数据和6.1K高难度测试集；发现模型性能随推理步骤增加而下降；微调实验验证了所生成数据能有效提升LLM推理能力。

Conclusion: 本文提出的结构化数据生成方法可高效构建数学推理数据集，为解决复杂推理问题提供了新思路，数据集将促进LLM推理能力研究。

Abstract: Mathematical reasoning remains challenging for LLMs due to complex logic and
the need for precise computation. Existing methods enhance LLM reasoning by
synthesizing datasets through problem rephrasing, but face issues with
generation quality and problem complexity. To address this, we propose to
extract structural information with generated problem-solving code from
mathematical reasoning and guide data generation with structured solutions.
Applied to MATH and GSM8K, our approach produces 39K problems with labeled
intermediate steps and a 6.1K-problem benchmark of higher difficulty. Results
on our benchmark show that model performance declines as reasoning length
increases. Additionally, we conducted fine-tuning experiments using the
proposed training data on a range of LLMs, and the results validate the
effectiveness of our dataset. We hope the proposed method and dataset will
contribute to future research in enhancing LLM reasoning capabilities.

</details>


### [249] [Silencing Empowerment, Allowing Bigotry: Auditing the Moderation of Hate Speech on Twitch](https://arxiv.org/abs/2506.07667)
*Prarabdh Shukla,Wei Yin Chong,Yash Patel,Brennan Schaffner,Danish Pruthi,Arjun Bhagoji*

Main category: cs.CL

TL;DR: 本文审核了Twitch的自动审核工具AutoMod，发现其对明显仇恨内容的检测存在高漏报率（高达94%），同时对良性内容误报率高达89.5%，揭示了该系统过度依赖敏感词而缺乏上下文理解能力。


<details>
  <summary>Details</summary>
Motivation: 随着Twitch等平台实时互动功能的发展，内容审核系统面临更高要求。研究旨在评估AutoMod在检测仇恨内容上的实际效果，填补现有研究的空白。

Method: 通过在Twitch创建测试账号，调用API发送10.7万条来自4个数据集的评论（含恶意内容和良性示例），测量AutoMod对明显仇恨内容（性别歧视/种族主义等）的识别准确性。

Result: 1) 对明显仇恨内容漏报率高达94% 2) 添加敏感词后移除率达100% 3) 良性内容误报率高达89.5%，尤其当敏感词出现在教育/赋权语境中

Conclusion: AutoMod存在重大缺陷：依赖敏感词作为信号而忽略语境理解，导致仇恨内容逃脱率高、良性内容误判严重，凸显上下文理解对审核系统的重要性。

Abstract: To meet the demands of content moderation, online platforms have resorted to
automated systems. Newer forms of real-time engagement($\textit{e.g.}$, users
commenting on live streams) on platforms like Twitch exert additional pressures
on the latency expected of such moderation systems. Despite their prevalence,
relatively little is known about the effectiveness of these systems. In this
paper, we conduct an audit of Twitch's automated moderation tool
($\texttt{AutoMod}$) to investigate its effectiveness in flagging hateful
content. For our audit, we create streaming accounts to act as siloed test
beds, and interface with the live chat using Twitch's APIs to send over
$107,000$ comments collated from $4$ datasets. We measure $\texttt{AutoMod}$'s
accuracy in flagging blatantly hateful content containing misogyny, racism,
ableism and homophobia. Our experiments reveal that a large fraction of hateful
messages, up to $94\%$ on some datasets, $\textit{bypass moderation}$.
Contextual addition of slurs to these messages results in $100\%$ removal,
revealing $\texttt{AutoMod}$'s reliance on slurs as a moderation signal. We
also find that contrary to Twitch's community guidelines, $\texttt{AutoMod}$
blocks up to $89.5\%$ of benign examples that use sensitive words in
pedagogical or empowering contexts. Overall, our audit points to large gaps in
$\texttt{AutoMod}$'s capabilities and underscores the importance for such
systems to understand context effectively.

</details>


### [250] [GaRAGe: A Benchmark with Grounding Annotations for RAG Evaluation](https://arxiv.org/abs/2506.07671)
*Ionut-Teodor Sorodoc,Leonardo F. R. Ribeiro,Rexhina Blloshmi,Christopher Davis,Adrià de Gispert*

Main category: cs.CL

TL;DR: 本文提出了一个名为GaRAGe的RAG基准测试，用于评估大语言模型能否识别并有效利用信息片段来生成RAG回答。基准包含2366个多样化问题及超过3.5万条人工标注片段，测试结果表明现有模型难以严格基于相关片段作答（最佳片段相关性分数60%），且在信息不足时难以合理拒答（真实阳性率最高31%）。


<details>
  <summary>Details</summary>
Motivation: 当前RAG任务缺乏细粒度评估标准来验证大语言模型是否精准识别相关证据片段、有效生成RAG回答。论文旨在构建高质量基准推进该领域发展。

Method: 构建GaRAGe基准：包含2366个涉及多领域/复杂性的问题，配以人工标注的文档相关性。从网络/私有文档集收集超3.5万标注片段。评估LLM时关注：是否严格基于标注相关片段作答；信息不足时是否合理拒答；证据标注准确率（F1）。

Result: 测试多个SOTA模型后发现：模型倾向过度总结而非精准依据相关片段作答（最高Relevance-Aware Factuality得分60%）；信息不足时拒答能力弱（真实阳性率最高31%）；证据来源标注准确率最高58.9%。时间敏感/私有稀疏知识场景表现更差。

Conclusion: 现有LLM在RAG任务中存在过度总结、拒答机制不成熟的系统性问题；通过细粒度标注数据集验证了当前方法存在的缺陷，强调了该基准对推动RAG模型改进的价值。

Abstract: We present GaRAGe, a large RAG benchmark with human-curated long-form answers
and annotations of each grounding passage, allowing a fine-grained evaluation
of whether LLMs can identify relevant grounding when generating RAG answers.
Our benchmark contains 2366 questions of diverse complexity, dynamism, and
topics, and includes over 35K annotated passages retrieved from both private
document sets and the Web, to reflect real-world RAG use cases. This makes it
an ideal test bed to evaluate an LLM's ability to identify only the relevant
information necessary to compose a response, or provide a deflective response
when there is insufficient information. Evaluations of multiple
state-of-the-art LLMs on GaRAGe show that the models tend to over-summarise
rather than (a) ground their answers strictly on the annotated relevant
passages (reaching at most a Relevance-Aware Factuality Score of 60%), or (b)
deflect when no relevant grounding is available (reaching at most 31% true
positive rate in deflections). The F1 in attribution to relevant sources is at
most 58.9%, and we show that performance is particularly reduced when answering
time-sensitive questions and when having to draw knowledge from sparser private
grounding sources.

</details>


### [251] [Training Superior Sparse Autoencoders for Instruct Models](https://arxiv.org/abs/2506.07691)
*Jiaming Li,Haoran Ye,Yukun Chen,Xinyue Li,Lei Zhang,Hamid Alinejad-Rokny,Jimmy Chih-Hsien Peng,Min Yang*

Main category: cs.CL

TL;DR: 论文提出FAST方法，针对指令模型的稀疏自编码器训练，在重建质量和特征可解释性上显著优于基线。


<details>
  <summary>Details</summary>
Motivation: 现有稀疏自编码器训练方法应用于指令模型时，重建质量和特征可解释性下降，需要针对指令模型特点的改进方案。

Method: 通过使训练与指令模型的数据分布和激活模式对齐（Finetuning-aligned Sequential Training, FAST），优化自编码器训练过程。

Result: 在Qwen2.5-7B模型上实现0.6468重建MSE（基线为5.1985/1.5096）；在Llama3.2-3B上21.1%特征达高质量（基线7.0%/10.2%）。

Conclusion: FAST有效提升指令模型的自编码器性能，并发现通过特殊token的激活干预可增强输出质量，为模型控制提供新思路。

Abstract: As large language models (LLMs) grow in scale and capability, understanding
their internal mechanisms becomes increasingly critical. Sparse autoencoders
(SAEs) have emerged as a key tool in mechanistic interpretability, enabling the
extraction of human-interpretable features from LLMs. However, existing SAE
training methods are primarily designed for base models, resulting in reduced
reconstruction quality and interpretability when applied to instruct models. To
bridge this gap, we propose
$\underline{\textbf{F}}$inetuning-$\underline{\textbf{a}}$ligned
$\underline{\textbf{S}}$equential $\underline{\textbf{T}}$raining
($\textit{FAST}$), a novel training method specifically tailored for instruct
models. $\textit{FAST}$ aligns the training process with the data distribution
and activation patterns characteristic of instruct models, resulting in
substantial improvements in both reconstruction and feature interpretability.
On Qwen2.5-7B-Instruct, $\textit{FAST}$ achieves a mean squared error of 0.6468
in token reconstruction, significantly outperforming baseline methods with
errors of 5.1985 and 1.5096. In feature interpretability, $\textit{FAST}$
yields a higher proportion of high-quality features, for Llama3.2-3B-Instruct,
$21.1\%$ scored in the top range, compared to $7.0\%$ and $10.2\%$ for
$\textit{BT(P)}$ and $\textit{BT(F)}$. Surprisingly, we discover that
intervening on the activations of special tokens via the SAEs leads to
improvements in output quality, suggesting new opportunities for fine-grained
control of model behavior. Code, data, and 240 trained SAEs are available at
https://github.com/Geaming2002/FAST.

</details>


### [252] [Through the Valley: Path to Effective Long CoT Training for Small Language Models](https://arxiv.org/abs/2506.07712)
*Renjie Luo,Jiaxi Li,Chen Huang,Wei Lu*

Main category: cs.CL

TL;DR: 论文发现小语言模型（SLMs）在长链思维监督（CoT）训练中出现性能下降现象，称为Long CoT Degradation。实验表明这种降级广泛存在于小型模型中，错误积累是主因。


<details>
  <summary>Details</summary>
Motivation: 探索小语言模型在长链思维监督训练中的表现，发现现有方法可能导致性能下降，挑战长CoT训练对小型模型有益的传统认知。

Method: 在Qwen2.5、LLaMA3和Gemma3系列模型上进行广泛实验，测量不同规模长CoT数据训练下的性能变化。通过错误积累分析揭示机制，并验证下游强化学习（RL）的影响。

Result: 小模型（≤3B参数）训练8k长CoT样本时性能下降高达75%，某些模型即使使用220k样本也无法恢复原始性能。错误积累被确认为主因：长响应增加错误叠加风险。RL受影响但可通过扩大SFT缓解。

Conclusion: 长CoT训练对小模型弊大于利，其性能降级现象挑战现有认知。建议通过控制响应长度或扩展SFT来优化小型推理模型。

Abstract: Long chain-of-thought (CoT) supervision has become a common strategy to
enhance reasoning in language models. While effective for large models, we
identify a phenomenon we call Long CoT Degradation, in which small language
models (SLMs; <=3B parameters) trained on limited long CoT data experience
significant performance deterioration. Through extensive experiments on the
Qwen2.5, LLaMA3 and Gemma3 families, we demonstrate that this degradation is
widespread across SLMs. In some settings, models trained on only 8k long CoT
examples lose up to 75% of their original performance before fine-tuning.
Strikingly, we further observe that for some particularly small models, even
training on 220k long CoT examples fails to recover or surpass their original
performance prior to fine-tuning. Our analysis attributes this effect to error
accumulation: while longer responses increase the capacity for multi-step
reasoning, they also amplify the risk of compounding mistakes. Furthermore, we
find that Long CoT Degradation may negatively impacts downstream reinforcement
learning (RL), although this can be alleviated by sufficiently scaled
supervised fine-tuning (SFT). Our findings challenge common assumptions about
the benefits of long CoT training for SLMs and offer practical guidance for
building more effective small-scale reasoning models.

</details>


### [253] [Multilingual Grammatical Error Annotation: Combining Language-Agnostic Framework with Language-Specific Flexibility](https://arxiv.org/abs/2506.07719)
*Mengyang Qiu,Tran Minh Nguyen,Zihao Huang,Zelong Li,Yang Gu,Qingyu Gao,Siliang Liu,Jungyeul Park*

Main category: cs.CL

TL;DR: 论文提出了一个标准化的模块化框架用于多语言语法错误标注，解决了现有工具（如errant）在扩展到类型多样语言时的局限性。该框架结合语言无关基础和语言特定扩展，支持多种语言（如英语、德语、捷克语、韩语、中文）的错误标注，提升多语言环境下语法纠错评估的一致性和可扩展性。


<details>
  <summary>Details</summary>
Motivation: 现有语法错误标注框架（如errant）在扩展到多种类型学语言时存在局限，需要更灵活的多语言解决方案。

Method: 构建模块化框架：①语言无关基础层 ②结构化语言特定扩展层。使用stanza工具重新实现errant以支持更多语言，并在五种语言中验证框架适应性。

Result: 成功应用于英语、德语、捷克语、韩语和中文，涵盖从通用标注到定制化语言细化，证明框架在多语言环境中的有效性和灵活性。

Conclusion: 该框架支持跨语言的可扩展、可解释语法错误标注，促进多语言环境中更一致的评估。开源代码库和工具已发布。

Abstract: Grammatical Error Correction (GEC) relies on accurate error annotation and
evaluation, yet existing frameworks, such as $\texttt{errant}$, face
limitations when extended to typologically diverse languages. In this paper, we
introduce a standardized, modular framework for multilingual grammatical error
annotation. Our approach combines a language-agnostic foundation with
structured language-specific extensions, enabling both consistency and
flexibility across languages. We reimplement $\texttt{errant}$ using
$\texttt{stanza}$ to support broader multilingual coverage, and demonstrate the
framework's adaptability through applications to English, German, Czech,
Korean, and Chinese, ranging from general-purpose annotation to more customized
linguistic refinements. This work supports scalable and interpretable GEC
annotation across languages and promotes more consistent evaluation in
multilingual settings. The complete codebase and annotation tools can be
accessed at https://github.com/open-writing-evaluation/jp_errant_bea.

</details>


### [254] [Swiss Parliaments Corpus Re-Imagined (SPC_R): Enhanced Transcription with RAG-based Correction and Predicted BLEU](https://arxiv.org/abs/2506.07726)
*Vincenzo Timmel,Manfred Vogel,Daniel Perruchoud,Reza Kakooee*

Main category: cs.CL

TL;DR: 本论文介绍了瑞士议会语料库的长篇版本，通过结合Whisper Large-v3转录、GPT-4o两步校正和基于BLEU分数的过滤，将瑞士德语辩论会录音转换为高质量的语音文本对。


<details>
  <summary>Details</summary>
Motivation: 将多小时的瑞士德语辩论录音（与官方会议记录对齐）转化为高质量的长篇语音文本对，解决低资源领域特定语音语料库的数据短缺问题。

Method: 1. 使用Whisper Large-v3在高算力环境下将音频转录为标准德语；2. 通过两个GPT-4o校正步骤：先纠正命名实体等错误，再评估语义完整性；3. 基于预测BLEU分数和GPT-4o评分进行数据过滤。

Result: 生成801小时的音频语料库，其中751小时通过质量控制。相比原句级版本，长文本数据集在BLEU分数上提升6个点。

Conclusion: 结合ASR、基于LLM的校正和数据驱动过滤能有效提升低资源领域特定语音语料库的质量，该方法适用于其他类似任务。

Abstract: This paper presents a new long-form release of the Swiss Parliaments Corpus,
converting entire multi-hour Swiss German debate sessions (each aligned with
the official session protocols) into high-quality speech-text pairs. Our
pipeline starts by transcribing all session audio into Standard German using
Whisper Large-v3 under high-compute settings. We then apply a two-step GPT-4o
correction process: first, GPT-4o ingests the raw Whisper output alongside the
official protocols to refine misrecognitions, mainly named entities. Second, a
separate GPT-4o pass evaluates each refined segment for semantic completeness.
We filter out any segments whose Predicted BLEU score (derived from Whisper's
average token log-probability) and GPT-4o evaluation score fall below a certain
threshold. The final corpus contains 801 hours of audio, of which 751 hours
pass our quality control. Compared to the original sentence-level SPC release,
our long-form dataset achieves a 6-point BLEU improvement, demonstrating the
power of combining robust ASR, LLM-based correction, and data-driven filtering
for low-resource, domain-specific speech corpora.

</details>


### [255] [Augmenting LLMs' Reasoning by Reinforcing Abstract Thinking](https://arxiv.org/abs/2506.07751)
*Silin Gao,Antoine Bosselut,Samy Bengio,Emmanuel Abbe*

Main category: cs.CL

TL;DR: 摘要提出了一种名为AbstraL的新方法，该方法的动机是解决LLM在分布变化时推理性能下降的问题。方法是通过强化学习训练LLM进行问题抽象而非数据增广，结果在GSM扰动基准上减少了性能衰退。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（尤其是小型模型）在面对分布变化（如数值或名义变量的改变、干扰子句插入）时表现脆弱。现有解决方案侧重于生成合成数据来实例化变体，本文则逆向采用抽象化思路，旨在增强鲁棒性并连接符号化工具。

Method: 引入AbstraL方法，使用强化学习训练LLM对推理问题进行抽象（而非监督微调），生成可抵御分布变化的抽象表示。该方法强调通过精细的抽象数据学习抽象过程。

Result: 在GSM扰动基准测试中显著减轻了性能下降（对比监督微调方法），证明RL训练能产生更忠实的抽象表示。

Conclusion: 问题抽象化策略比数据实例化更有效，强化学习是获取抽象能力的更优训练范式。

Abstract: Recent studies have shown that large language models (LLMs), especially
smaller ones, often lack robustness in their reasoning. I.e., they tend to
experience performance drops when faced with distribution shifts, such as
changes to numerical or nominal variables, or insertions of distracting
clauses. A possible strategy to address this involves generating synthetic data
to further "instantiate" reasoning problems on potential variations. In
contrast, our approach focuses on "abstracting" reasoning problems. This not
only helps counteract distribution shifts but also facilitates the connection
to symbolic tools for deriving solutions. We find that this abstraction process
is better acquired through reinforcement learning (RL) than just supervised
fine-tuning, which often fails to produce faithful abstractions. Our method,
AbstraL -- which promotes abstract reasoning in LLMs using RL on granular
abstraction data -- significantly mitigates performance degradation on recent
GSM perturbation benchmarks.

</details>


### [256] [LLM Unlearning Should Be Form-Independent](https://arxiv.org/abs/2506.07795)
*Xiaotian Ye,Mengqi Zhang,Shu Wu*

Main category: cs.CL

TL;DR: 本文研究了LLM遗忘中存在的形式依赖偏差问题，并提出了ROCR方法，通过重定向危险概念实现高效遗忘。


<details>
  <summary>Details</summary>
Motivation: 现有LLM遗忘方法对训练样本形式敏感，难以泛化到相同知识的不同表达形式（形式依赖偏差），导致实际应用效果不佳。

Method: 提出ROCR方法：无需训练的遗忘技术，通过重定向激活的危险概念（修改模型参数），在数秒内将特定遗忘目标概念转向无害概念。

Result: 开发ORT基准测试证明当前方法普遍存在严重形式依赖偏差；实验表明ROCR显著提升遗忘效果，生成结果更自然。

Conclusion: LLM遗忘应具备形式无关性；ROCR为安全关键场景提供有效解决方案，通过概念重定向机制克服现有方法局限。

Abstract: Large Language Model (LLM) unlearning aims to erase or suppress undesirable
knowledge within the model, offering promise for controlling harmful or private
information to prevent misuse. However, recent studies highlight its limited
efficacy in real-world scenarios, hindering practical adoption. In this study,
we identify a pervasive issue underlying many downstream failures: the
effectiveness of existing unlearning methods heavily depends on the form of
training samples and frequently fails to generalize to alternate expressions of
the same knowledge. We formally characterize this problem as Form-Dependent
Bias and systematically investigate its specific manifestation patterns across
various downstream tasks. To quantify its prevalence and support future
research, we introduce ORT, a novel benchmark designed to evaluate the
robustness of unlearning methods against variations in knowledge expression.
Results reveal that Form-Dependent Bias is both widespread and severe among
current techniques.
  We argue that LLM unlearning should be form-independent to address the
endless forms of downstream tasks encountered in real-world security-critical
scenarios. Towards this goal, we introduce Rank-one Concept Redirection (ROCR),
a novel training-free method, as a promising solution path. ROCR performs
unlearning by targeting the invariants in downstream tasks, specifically the
activated dangerous concepts. It is capable of modifying model parameters
within seconds to redirect the model's perception of a specific unlearning
target concept to another harmless concept. Extensive experiments demonstrate
that ROCR significantly improves unlearning effectiveness compared to
traditional methods while generating highly natural outputs.

</details>


### [257] [MultiMatch: Multihead Consistency Regularization Matching for Semi-Supervised Text Classification](https://arxiv.org/abs/2506.07801)
*Iustin Sirbu,Robert-Adrian Popovici,Cornelia Caragea,Stefan Trausan-Matu,Traian Rebedea*

Main category: cs.CL

TL;DR: 多匹配：结合协同训练和一致性正则化的新型半监督学习算法，通过三重伪标签加权模块提升性能，在NLP数据集上达到SOTA，尤其在不平衡数据中表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有的半监督学习方法在处理伪标签时存在不足，特别是在数据不平衡情况下表现不佳。MultiMatch旨在通过改进伪标签的筛选和加权机制，统一现有技术优势，提升SSL的鲁棒性和性能。

Method: 提出三重伪标签加权模块：1) 利用多个分类头的共识选择可靠伪标签；2) 采用自适应阈值过滤标签；3) 根据分类难度加权伪样本。该方法整合了多头协同训练、FreeMatch的自适应阈值和MarginMatch的平均伪边际等技术。

Result: 在5个NLP数据集的10个设置中，9项达到state-of-the-art；Friedman测试排名第一（比较19种方法）；在高度不平衡数据上比次优方法高出3.26%。

Conclusion: MultiMatch通过创新的加权机制显著提升半监督学习性能，尤其适用于文本分类中的不平衡场景，其模块化设计有望启发未来SSL研究。

Abstract: We introduce MultiMatch, a novel semi-supervised learning (SSL) algorithm
combining the paradigms of co-training and consistency regularization with
pseudo-labeling. At its core, MultiMatch features a three-fold pseudo-label
weighting module designed for three key purposes: selecting and filtering
pseudo-labels based on head agreement and model confidence, and weighting them
according to the perceived classification difficulty. This novel module
enhances and unifies three existing techniques -- heads agreement from
Multihead Co-training, self-adaptive thresholds from FreeMatch, and Average
Pseudo-Margins from MarginMatch -- resulting in a holistic approach that
improves robustness and performance in SSL settings. Experimental results on
benchmark datasets highlight the superior performance of MultiMatch, achieving
state-of-the-art results on 9 out of 10 setups from 5 natural language
processing datasets and ranking first according to the Friedman test among 19
methods. Furthermore, MultiMatch demonstrates exceptional robustness in highly
imbalanced settings, outperforming the second-best approach by 3.26% -- and
data imbalance is a key factor for many text classification tasks.

</details>


### [258] [WebUIBench: A Comprehensive Benchmark for Evaluating Multimodal Large Language Models in WebUI-to-Code](https://arxiv.org/abs/2506.07818)
*Zhiyu Lin,Zhengda Zhou,Zhiyuan Zhao,Tianrui Wan,Yilun Ma,Junyu Gao,Xuelong Li*

Main category: cs.CL

TL;DR: We propose WebUIBench, a benchmark for evaluating Multimodal Large Language Models as AI software engineers in web development across four areas: WebUI Perception, HTML Programming, WebUI-HTML Understanding, and WebUI-to-Code.


<details>
  <summary>Details</summary>
Motivation: Existing benchmarks don't assess sub-capabilities needed for web development phases, focusing only on final webpage generation. MLLMs should act as AI software engineers requiring multifaceted skills.

Method: Created WebUIBench with 21K QA pairs from 700+ real websites. Systematic design inspired by software engineering principles, evaluating 4 capability dimensions.

Result: Evaluation of 29 mainstream MLLMs revealed distinct skill characteristics and identified development process weaknesses.

Conclusion: WebUIBench fills critical gap in sub-capability assessment for web development MLLMs, enabling targeted improvements in AI software engineering.

Abstract: With the rapid advancement of Generative AI technology, Multimodal Large
Language Models(MLLMs) have the potential to act as AI software engineers
capable of executing complex web application development. Considering that the
model requires a confluence of multidimensional sub-capabilities to address the
challenges of various development phases, constructing a multi-view evaluation
framework is crucial for accurately guiding the enhancement of development
efficiency. However, existing benchmarks usually fail to provide an assessment
of sub-capabilities and focus solely on webpage generation outcomes. In this
work, we draw inspiration from the principles of software engineering and
further propose WebUIBench, a benchmark systematically designed to evaluate
MLLMs in four key areas: WebUI Perception, HTML Programming,WebUI-HTML
Understanding, and WebUI-to-Code. WebUIBench comprises 21K high-quality
question-answer pairs derived from over 0.7K real-world websites. The extensive
evaluation of 29 mainstream MLLMs uncovers the skill characteristics and
various weakness that models encountered during the development process.

</details>


### [259] [Learning to Focus: Causal Attention Distillation via Gradient-Guided Token Pruning](https://arxiv.org/abs/2506.07851)
*Yiju Guo,Wenkai Yang,Zexu Sun,Ning Ding,Zhiyuan Liu,Yankai Lin*

Main category: cs.CL

TL;DR: LeaF（学习聚焦）两阶段框架通过基于梯度对比识别混淆标记并在蒸馏中剪枝，解决了大语言模型在长文本推理中注意力分散的问题，提高了推理准确性和生成质量。


<details>
  <summary>Details</summary>
Motivation: 大语言模型（LLMs）在长文本推理中可能因训练数据中的虚假关联而被分散注意力，导致冗余推理和错误响应。初步实验表明，移除干扰性模式可提升性能。

Method: LeaF框架分两阶段：1）利用梯度对比和高级教师模型自动识别混淆标记；2）在蒸馏中剪枝这些标记，使学生的注意力分布与教师的关键标记分布对齐。

Result: LeaF在多项数学推理和代码生成基准中取得绝对提升，有效抑制了推理中对混淆标记的关注，产出了更可解释和可靠的模型。

Conclusion: LeaF通过干预式推理消除混杂因素，增强了对关键信息的聚焦能力，为LLMs提供了更鲁棒的推理机制。

Abstract: Large language models (LLMs) have demonstrated significant improvements in
contextual understanding. However, their ability to attend to truly critical
information during long-context reasoning and generation still falls behind the
pace. Specifically, our preliminary experiments reveal that certain distracting
patterns can misdirect the model's attention during inference, and removing
these patterns substantially improves reasoning accuracy and generation
quality. We attribute this phenomenon to spurious correlations in the training
data, which obstruct the model's capacity to infer authentic causal
instruction-response relationships. This phenomenon may induce redundant
reasoning processes, potentially resulting in significant inference overhead
and, more critically, the generation of erroneous or suboptimal responses. To
mitigate this, we introduce a two-stage framework called Learning to Focus
(LeaF) leveraging intervention-based inference to disentangle confounding
factors. In the first stage, LeaF employs gradient-based comparisons with an
advanced teacher to automatically identify confounding tokens based on causal
relationships in the training corpus. Then, in the second stage, it prunes
these tokens during distillation to enact intervention, aligning the student's
attention with the teacher's focus distribution on truly critical context
tokens. Experimental results demonstrate that LeaF not only achieves an
absolute improvement in various mathematical reasoning and code generation
benchmarks but also effectively suppresses attention to confounding tokens
during inference, yielding a more interpretable and reliable reasoning model.

</details>


### [260] [MEMOIR: Lifelong Model Editing with Minimal Overwrite and Informed Retention for LLMs](https://arxiv.org/abs/2506.07899)
*Ke Wang,Yiming Qin,Nikolaos Dimitriadis,Alessandro Favero,Pascal Frossard*

Main category: cs.CL

TL;DR: MEMOIR：一种通过残差记忆模块实现高效、可扩展的语言模型持续编辑框架，能在数千次顺序编辑中保持高性能


<details>
  <summary>Details</summary>
Motivation: 现有语言模型编辑方法存在泛化能力下降、编辑间干扰或难以扩展到长编辑序列的问题，需要一种可靠且可扩展的编辑方案

Method: 使用样本相关掩码稀疏化输入激活，使每个编辑仅影响残差记忆中特定子集；推理时通过匹配稀疏激活模式来定位相关编辑

Result: 在问答、幻觉校正和OOD泛化任务上达到SOTA，支持数千次顺序编辑且几乎不遗忘

Conclusion: MEMOIR通过稀疏激活的残差记忆机制解决了模型编辑的可扩展性与可靠性问题，为持续学习提供新方向

Abstract: Language models deployed in real-world systems often require post-hoc updates
to incorporate new or corrected knowledge. However, editing such models
efficiently and reliably - without retraining or forgetting previous
information - remains a major challenge. Existing methods for lifelong model
editing either compromise generalization, interfere with past edits, or fail to
scale to long editing sequences. We propose MEMOIR, a novel scalable framework
that injects knowledge through a residual memory, i.e., a dedicated parameter
module, while preserving the core capabilities of the pre-trained model. By
sparsifying input activations through sample-dependent masks, MEMOIR confines
each edit to a distinct subset of the memory parameters, minimizing
interference among edits. At inference, it identifies relevant edits by
comparing the sparse activation patterns of new queries to those stored during
editing. This enables generalization to rephrased queries by activating only
the relevant knowledge while suppressing unnecessary memory activation for
unrelated prompts. Experiments on question answering, hallucination correction,
and out-of-distribution generalization benchmarks across LLaMA-3 and Mistral
demonstrate that MEMOIR achieves state-of-the-art performance across
reliability, generalization, and locality metrics, scaling to thousands of
sequential edits with minimal forgetting.

</details>


### [261] [MiniCPM4: Ultra-Efficient LLMs on End Devices](https://arxiv.org/abs/2506.07900)
*MiniCPM Team,Chaojun Xiao,Yuxuan Li,Xu Han,Yuzhuo Bai,Jie Cai,Haotian Chen,Wentong Chen,Xin Cong,Ganqu Cui,Ning Ding,Shengdan Fan,Yewei Fang,Zixuan Fu,Wenyu Guan,Yitong Guan,Junshao Guo,Yufeng Han,Bingxiang He,Yuxiang Huang,Cunliang Kong,Qiuzuo Li,Siyuan Li,Wenhao Li,Yanghao Li,Yishan Li,Zhen Li,Dan Liu,Biyuan Lin,Yankai Lin,Xiang Long,Quanyu Lu,Yaxi Lu,Peiyan Luo,Hongya Lyu,Litu Ou,Yinxu Pan,Zekai Qu,Qundong Shi,Zijun Song,Jiayuan Su,Zhou Su,Ao Sun,Xianghui Sun,Peijun Tang,Fangzheng Wang,Feng Wang,Shuo Wang,Yudong Wang,Yesai Wu,Zhenyu Xiao,Jie Xie,Zihao Xie,Yukun Yan,Jiarui Yuan,Kaihuo Zhang,Lei Zhang,Linyue Zhang,Xueren Zhang,Yudi Zhang,Hengyu Zhao,Weilin Zhao,Weilun Zhao,Yuanqian Zhao,Zhi Zheng,Ge Zhou,Jie Zhou,Wei Zhou,Zihan Zhou,Zixuan Zhou,Zhiyuan Liu,Guoyang Zeng,Chao Jia,Dahai Li,Maosong Sun*

Main category: cs.CL

TL;DR: MiniCPM4 is a high-efficiency LLM for end-side devices with optimizations in architecture (InfLLM v2), training data (UltraClean/UltraChat v2), algorithms (ModelTunnel v2/BitCPM), and inference systems (CPM.cu). Available in 0.5B and 8B versions, it outperforms competitors on multiple benchmarks, offers speed advantages for long sequences, and supports diverse applications.


<details>
  <summary>Details</summary>
Motivation: To create an efficient large language model (LLM) suitable for deployment on resource-constrained end-side devices through comprehensive optimizations.

Method: 1. Architecture: Trainable sparse attention (InfLLM v2) accelerates long-context processing
2. Training Data: UltraClean filters/generates pre-training data; UltraChat v2 provides fine-tuning data
3. Training Algorithms: ModelTunnel v2 for pre-training optimization; chunk-wise rollout RL and tenary quantization (BitCPM)
4. Inference: CPM.cu integrates sparse attention, quantization, and speculative sampling
Offered in 0.5B and 8B parameter variants.

Result: Outperforms open-source models of similar size across benchmarks. MiniCPM4-8B shows significant speed improvements over Qwen3-8B for long sequences. Enables applications like trustworthy survey generation and tool use via model context protocol.

Conclusion: MiniCPM4 demonstrates state-of-the-art efficiency and performance for on-device LLMs through systematic innovations, validated by benchmarks and practical applications.

Abstract: This paper introduces MiniCPM4, a highly efficient large language model (LLM)
designed explicitly for end-side devices. We achieve this efficiency through
systematic innovation in four key dimensions: model architecture, training
data, training algorithms, and inference systems. Specifically, in terms of
model architecture, we propose InfLLM v2, a trainable sparse attention
mechanism that accelerates both prefilling and decoding phases for long-context
processing. Regarding training data, we propose UltraClean, an efficient and
accurate pre-training data filtering and generation strategy, and UltraChat v2,
a comprehensive supervised fine-tuning dataset. These datasets enable
satisfactory model performance to be achieved using just 8 trillion training
tokens. Regarding training algorithms, we propose ModelTunnel v2 for efficient
pre-training strategy search, and improve existing post-training methods by
introducing chunk-wise rollout for load-balanced reinforcement learning and
data-efficient tenary LLM, BitCPM. Regarding inference systems, we propose
CPM.cu that integrates sparse attention, model quantization, and speculative
sampling to achieve efficient prefilling and decoding. To meet diverse
on-device requirements, MiniCPM4 is available in two versions, with 0.5B and 8B
parameters, respectively. Sufficient evaluation results show that MiniCPM4
outperforms open-source models of similar size across multiple benchmarks,
highlighting both its efficiency and effectiveness. Notably, MiniCPM4-8B
demonstrates significant speed improvements over Qwen3-8B when processing long
sequences. Through further adaptation, MiniCPM4 successfully powers diverse
applications, including trustworthy survey generation and tool use with model
context protocol, clearly showcasing its broad usability.

</details>


### [262] [Quantum Graph Transformer for NLP Sentiment Classification](https://arxiv.org/abs/2506.07937)
*Shamminuj Aktar,Andreas Bärtschi,Abdel-Hameed A. Badawy,Stephan Eidenbenz*

Main category: cs.CL

TL;DR: 提出了量子图变换器(QGT)，整合量子自注意力机制，在情感分类任务中超越现有QNLP模型和等效经典模型，并提高样本效率。


<details>
  <summary>Details</summary>
Motivation: 量子机器学习在理解复杂结构化数据方面具有潜力，QGT旨在通过量子自注意力机制提升图模型的表达能力并减少参数。

Method: 在消息传递框架中融入基于参数化量子电路(PQC)的自注意力机制，构建混合图结构架构。

Result: 在五个情感分类基准测试中：1) 准确率超过现有QNLP模型；2) 比经典图变换器平均提升5.42%(真实数据)/4.76%(合成数据)；3) 在Yelp数据集上实现50%样本效率提升。

Conclusion: 图结构QNLP技术有望推动高效可扩展的语言理解发展。

Abstract: Quantum machine learning is a promising direction for building more efficient
and expressive models, particularly in domains where understanding complex,
structured data is critical. We present the Quantum Graph Transformer (QGT), a
hybrid graph-based architecture that integrates a quantum self-attention
mechanism into the message-passing framework for structured language modeling.
The attention mechanism is implemented using parameterized quantum circuits
(PQCs), which enable the model to capture rich contextual relationships while
significantly reducing the number of trainable parameters compared to classical
attention mechanisms. We evaluate QGT on five sentiment classification
benchmarks. Experimental results show that QGT consistently achieves higher or
comparable accuracy than existing quantum natural language processing (QNLP)
models, including both attention-based and non-attention-based approaches. When
compared with an equivalent classical graph transformer, QGT yields an average
accuracy improvement of 5.42% on real-world datasets and 4.76% on synthetic
datasets. Additionally, QGT demonstrates improved sample efficiency, requiring
nearly 50% fewer labeled samples to reach comparable performance on the Yelp
dataset. These results highlight the potential of graph-based QNLP techniques
for advancing efficient and scalable language understanding.

</details>


### [263] [Statistical Hypothesis Testing for Auditing Robustness in Language Models](https://arxiv.org/abs/2506.07947)
*Paulius Rauba,Qiyao Wei,Mihaela van der Schaar*

Main category: cs.CL

TL;DR: 提出了一个名为'基于分布的扰动分析'的统计框架，用于检验大型语言模型(LLM)在干预(如输入扰动或模型变更)下输出分布是否发生显著变化。该方法通过蒙特卡洛采样在低维语义空间构建经验分布，进行可解释的假设检验，解决现有方法无法处理的随机性和计算复杂性问题。


<details>
  <summary>Details</summary>
Motivation: 现有的文本分析方法主要关注偏差或公平性测量，无法解决LLM输出因随机性导致直接比较无效的问题，且完整输出分布比较计算不可行。需要一种可解释、计算高效的统计检验方法来系统评估干预对LLM输出的影响。

Method: 1) 将输出嵌入低维语义相似空间 2) 通过蒙特卡洛采样构建干预前后的经验零分布/备择分布 3) 设计无需严格分布假设的假设检验流程 4) 提供p值、效应量和多重检验校正

Result: 框架具有模型无关性（i）、支持任意输入扰动（ii）、产生可解释p值（iii）、通过错误率控制处理多重扰动（iv）、提供标量效应量（v）。案例研究证明其能可靠量化响应变化、评估真/假阳性率以及与参考模型对齐度。

Conclusion: 该框架为LLM审计提供了首个可解释的频率派假设检验工具，能有效检测模型变化对输出的统计显著影响，解决了关键的可重复性和鲁棒性验证需求。

Abstract: Consider the problem of testing whether the outputs of a large language model
(LLM) system change under an arbitrary intervention, such as an input
perturbation or changing the model variant. We cannot simply compare two LLM
outputs since they might differ due to the stochastic nature of the system, nor
can we compare the entire output distribution due to computational
intractability. While existing methods for analyzing text-based outputs exist,
they focus on fundamentally different problems, such as measuring bias or
fairness. To this end, we introduce distribution-based perturbation analysis, a
framework that reformulates LLM perturbation analysis as a frequentist
hypothesis testing problem. We construct empirical null and alternative output
distributions within a low-dimensional semantic similarity space via Monte
Carlo sampling, enabling tractable inference without restrictive distributional
assumptions. The framework is (i) model-agnostic, (ii) supports the evaluation
of arbitrary input perturbations on any black-box LLM, (iii) yields
interpretable p-values; (iv) supports multiple perturbations via controlled
error rates; and (v) provides scalar effect sizes. We demonstrate the
usefulness of the framework across multiple case studies, showing how we can
quantify response changes, measure true/false positive rates, and evaluate
alignment with reference models. Above all, we see this as a reliable
frequentist hypothesis testing framework for LLM auditing.

</details>


### [264] [Language Models over Canonical Byte-Pair Encodings](https://arxiv.org/abs/2506.07956)
*Tim Vieira,Tianyu Liu,Clemente Pasti,Yahya Emara,Brian DuSell,Benjamin LeBrun,Mario Giulianelli,Juan Luis Gastaldi,Timothy J. O'Donnell,Ryan Cotterell*

Main category: cs.CL

TL;DR: 现代语言模型使用tokenizer将字符串转化为token序列，但存在为非规范token编码分配概率的问题。本文提出两种方法：通过条件推理在推理时确保输出规范，以及通过模型参数化在训练时保证输出规范，提高了模型性能。


<details>
  <summary>Details</summary>
Motivation: 当前token化方法导致语言模型为大量不可能出现的非规范token序列分配概率，这既错误又浪费概率质量。

Method: 提出两种方案：1) 推理时通过条件采样确保规范性的方法；2) 训练时通过模型参数化保证规范性的方法。

Result: 实验证明修正规范性问题能提升多个模型在多个语料库上的似然度表现。

Conclusion: 强制保证token序列的规范性可有效提升语言模型的效率与准确性，避免概率资源浪费。

Abstract: Modern language models represent probability distributions over character
strings as distributions over (shorter) token strings derived via a
deterministic tokenizer, such as byte-pair encoding. While this approach is
highly effective at scaling up language models to large corpora, its current
incarnations have a concerning property: the model assigns nonzero probability
mass to an exponential number of $\it{noncanonical}$ token encodings of each
character string -- these are token strings that decode to valid character
strings but are impossible under the deterministic tokenizer (i.e., they will
never be seen in any training corpus, no matter how large). This misallocation
is both erroneous, as noncanonical strings never appear in training data, and
wasteful, diverting probability mass away from plausible outputs. These are
avoidable mistakes! In this work, we propose methods to enforce canonicality in
token-level language models, ensuring that only canonical token strings are
assigned positive probability. We present two approaches: (1) canonicality by
conditioning, leveraging test-time inference strategies without additional
training, and (2) canonicality by construction, a model parameterization that
guarantees canonical outputs but requires training. We demonstrate that fixing
canonicality mistakes improves the likelihood of held-out data for several
models and corpora.

</details>


### [265] [Correlated Errors in Large Language Models](https://arxiv.org/abs/2506.07962)
*Elliot Kim,Avi Garg,Kenny Peng,Nikhil Garg*

Main category: cs.CL

TL;DR: 本文通过大规模实证研究发现，尽管LLMs在训练数据、架构和提供商上存在多样性，但它们在错误上存在高度相关性。特别是更大、更准确的模型，即使架构和提供商不同，错误也高度相关。这种相关性在LLM作为裁判评估和招聘等下游任务中产生了负面影响，反映了算法单一化的风险。


<details>
  <summary>Details</summary>
Motivation: 尽管训练数据、架构和提供商的多样性被认为可以减少LLMs的同质性，但缺乏实证证据证明不同LLMs是否存在显著差异。本研究旨在通过大规模评估探究不同LLMs的错误相关性及其影响因素。

Method: 在超过350个LLMs上进行大规模实证评估，使用两个流行的排行榜数据集和一个简历筛选任务。通过错误一致性分析、影响因素检验（如共享架构和提供商）等方法来衡量模型间错误相关性。

Result: 发现模型间存在显著错误相关性：在一个排行榜数据集上，当两个模型都出错时，它们有60%的错误是一致的。更大的、更准确的模型错误高度相关，即使架构和提供商不同。在LLM-as-judge评估和招聘等下游任务中，这种错误相关性带来了负面影响。错误相关性的驱动因素包括共享架构、提供商，以及模型的大小和准确度。

Conclusion: LLMs在错误上存在高度相关性，反映了算法单一化的风险。这种错误相关性在多个下游任务中产生负面影响。这挑战了训练数据、架构和提供商等多样性因素能够有效避免LLMs同质化的假设。

Abstract: Diversity in training data, architecture, and providers is assumed to
mitigate homogeneity in LLMs. However, we lack empirical evidence on whether
different LLMs differ meaningfully. We conduct a large-scale empirical
evaluation on over 350 LLMs overall, using two popular leaderboards and a
resume-screening task. We find substantial correlation in model errors -- on
one leaderboard dataset, models agree 60% of the time when both models err. We
identify factors driving model correlation, including shared architectures and
providers. Crucially, however, larger and more accurate models have highly
correlated errors, even with distinct architectures and providers. Finally, we
show the effects of correlation in two downstream tasks: LLM-as-judge
evaluation and hiring -- the latter reflecting theoretical predictions
regarding algorithmic monoculture.

</details>


### [266] [Reinforcement Pre-Training](https://arxiv.org/abs/2506.08007)
*Qingxiu Dong,Li Dong,Yao Tang,Tianzhu Ye,Yutao Sun,Zhifang Sui,Furu Wei*

Main category: cs.CL

TL;DR: 提出了强化预训练（RPT）作为一种新的扩展范式，通过将token预测重构为可验证奖励的推理任务，提升语言模型准确性并为强化学习微调提供基础。


<details>
  <summary>Details</summary>
Motivation: 传统语言模型预训练主要依赖无监督的next-token预测，但缺乏可验证的反馈。RPT旨在利用强化学习框架，从海量文本数据中提取通用强化学习信号，打破领域特定标注数据的限制。

Method: 1. 重构next-token预测为推理任务；2. 为正确预测提供可验证奖励；3. 设计基于奖励的强化学习训练机制；4. 构建可扩展的计算架构处理大规模文本数据。

Result: 1. 显著提升next-token预测准确率；2. 计算资源投入与准确率呈现持续正相关；3. 预训练模型为下游强化微调提供优质基础。

Conclusion: RPT被验证为一种有效且可扩展的语言模型预训练新范式，通过强化学习机制将原始文本转化为通用RL训练数据，为语言模型进步开辟新路径。

Abstract: In this work, we introduce Reinforcement Pre-Training (RPT) as a new scaling
paradigm for large language models and reinforcement learning (RL).
Specifically, we reframe next-token prediction as a reasoning task trained
using RL, where it receives verifiable rewards for correctly predicting the
next token for a given context. RPT offers a scalable method to leverage vast
amounts of text data for general-purpose RL, rather than relying on
domain-specific annotated answers. By incentivizing the capability of
next-token reasoning, RPT significantly improves the language modeling accuracy
of predicting the next tokens. Moreover, RPT provides a strong pre-trained
foundation for further reinforcement fine-tuning. The scaling curves show that
increased training compute consistently improves the next-token prediction
accuracy. The results position RPT as an effective and promising scaling
paradigm to advance language model pre-training.

</details>


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [267] [Facial Foundational Model Advances Early Warning of Coronary Artery Disease from Live Videos with DigitalShadow](https://arxiv.org/abs/2506.06283)
*Juexiao Zhou,Zhongyi Han,Mankun Xin,Xingwei He,Guotao Wang,Jiaoyan Song,Gongning Luo,Wenjia He,Xintong Li,Yuetan Chu,Juanwen Chen,Bo Wang,Xia Wu,Wenwen Duan,Zhixia Guo,Liyan Bai,Yilin Pan,Xuefei Bi,Lu Liu,Long Feng,Xiaonan He,Xin Gao*

Main category: cs.CV

TL;DR: DigitalShadow是用于无创检测冠状动脉疾病风险的早期预警系统，通过微调的面部基础模型分析视频流中的面部特征，为患者生成语言报告和健康建议。


<details>
  <summary>Details</summary>
Motivation: 冠状动脉疾病（CAD）是全球主要死因，早期预防至关重要。现有检测手段存在侵入性或需主动参与的问题，需要被动、无接触的解决方案。

Method: 基于2100万张面部图像预训练模型，在来自中国四家医院的7004张图像（1751名受试者）上微调为LiveCAD模型，从视频流中被动提取面部特征并生成报告。

Result: 开发了集成个性化数据库的预警系统，支持本地部署以保护隐私，可输出自然语言风险评估和健康建议。

Conclusion: DigitalShadow作为无接触式CAD早期筛查工具，具有隐私保护特性，有望补充现有医疗系统，但仍需更大规模临床验证。

Abstract: Global population aging presents increasing challenges to healthcare systems,
with coronary artery disease (CAD) responsible for approximately 17.8 million
deaths annually, making it a leading cause of global mortality. As CAD is
largely preventable, early detection and proactive management are essential. In
this work, we introduce DigitalShadow, an advanced early warning system for
CAD, powered by a fine-tuned facial foundation model. The system is pre-trained
on 21 million facial images and subsequently fine-tuned into LiveCAD, a
specialized CAD risk assessment model trained on 7,004 facial images from 1,751
subjects across four hospitals in China. DigitalShadow functions passively and
contactlessly, extracting facial features from live video streams without
requiring active user engagement. Integrated with a personalized database, it
generates natural language risk reports and individualized health
recommendations. With privacy as a core design principle, DigitalShadow
supports local deployment to ensure secure handling of user data.

</details>


### [268] [Exploring Adversarial Watermarking in Transformer-Based Models: Transferability and Robustness Against Defense Mechanism for Medical Images](https://arxiv.org/abs/2506.06389)
*Rifat Sadik,Tanvir Rahman,Arpan Bhattacharjee,Bikash Chandra Halder,Ismail Hossain*

Main category: cs.CV

TL;DR: 该论文研究了基于视觉Transformer（ViT）的皮肤图像识别模型对对抗水印攻击的脆弱性，并评估了对抗训练作为一种防御机制的效果。


<details>
  <summary>Details</summary>
Motivation: 尽管ViT在计算机视觉任务中展现了优越性能，但其全局注意力机制使其易受对抗扰动攻击。本研究旨在评估ViT在医学图像领域对对抗水印的脆弱性，特别是在皮肤科诊断应用中的安全性问题。

Method: 使用投影梯度下降（PGD）生成对抗水印攻击ViT模型，测试攻击对传统CNN模型的可迁移性，并评估对抗训练（adversarial training）作为防御策略的有效性。

Result: 1）ViT在干净图像上性能不受影响，但对PGD攻击极其敏感（准确率最低降至27.6%）；2）该攻击部分可迁移至CNN模型；3）对抗训练显著提升ViT鲁棒性（准确率恢复至90.0%）。

Conclusion: ViT在医学图像分析中存在安全漏洞，但对抗训练是有效的防御手段。研究强调在临床部署前必须加强深度学习模型对抗鲁棒性的验证。

Abstract: Deep learning models have shown remarkable success in dermatological image
analysis, offering potential for automated skin disease diagnosis. Previously,
convolutional neural network(CNN) based architectures have achieved immense
popularity and success in computer vision (CV) based task like skin image
recognition, generation and video analysis. But with the emergence of
transformer based models, CV tasks are now are nowadays carrying out using
these models. Vision Transformers (ViTs) is such a transformer-based models
that have shown success in computer vision. It uses self-attention mechanisms
to achieve state-of-the-art performance across various tasks. However, their
reliance on global attention mechanisms makes them susceptible to adversarial
perturbations. This paper aims to investigate the susceptibility of ViTs for
medical images to adversarial watermarking-a method that adds so-called
imperceptible perturbations in order to fool models. By generating adversarial
watermarks through Projected Gradient Descent (PGD), we examine the
transferability of such attacks to CNNs and analyze the performance defense
mechanism -- adversarial training. Results indicate that while performance is
not compromised for clean images, ViTs certainly become much more vulnerable to
adversarial attacks: an accuracy drop of as low as 27.6%. Nevertheless,
adversarial training raises it up to 90.0%.

</details>


### [269] [(LiFT) Lightweight Fitness Transformer: A language-vision model for Remote Monitoring of Physical Training](https://arxiv.org/abs/2506.06480)
*A. Postlmayr,P. Cosman,S. Dey*

Main category: cs.CV

TL;DR: 开发了一种基于智能手机RGB摄像头的远程健身跟踪系统，使健身跟踪更私密、可扩展且成本低廉。


<details>
  <summary>Details</summary>
Motivation: 现有健身监督模型适用范围有限或部署复杂，难以在多样化动作中泛化。

Method: 构建大规模数据集Olympia（含1900+练习），采用视觉-语言转换器实现多任务运动分析。

Result: 动作识别准确率76.5%，重复次数计数精度85.3%（误差±1范围内）。

Conclusion: 首个统一模型同时实现训练动作识别和重复计数，推动AI健身跟踪普及化。

Abstract: We introduce a fitness tracking system that enables remote monitoring for
exercises using only a RGB smartphone camera, making fitness tracking more
private, scalable, and cost effective. Although prior work explored automated
exercise supervision, existing models are either too limited in exercise
variety or too complex for real-world deployment. Prior approaches typically
focus on a small set of exercises and fail to generalize across diverse
movements. In contrast, we develop a robust, multitask motion analysis model
capable of performing exercise detection and repetition counting across
hundreds of exercises, a scale far beyond previous methods. We overcome
previous data limitations by assembling a large-scale fitness dataset, Olympia
covering more than 1,900 exercises. To our knowledge, our vision-language model
is the first that can perform multiple tasks on skeletal fitness data. On
Olympia, our model can detect exercises with 76.5% accuracy and count
repetitions with 85.3% off-by-one accuracy, using only RGB video. By presenting
a single vision-language transformer model for both exercise identification and
rep counting, we take a significant step toward democratizing AI-powered
fitness tracking.

</details>


### [270] [GS4: Generalizable Sparse Splatting Semantic SLAM](https://arxiv.org/abs/2506.06517)
*Mingqi Jiang,Chanho Kim,Chen Ziwen,Li Fuxin*

Main category: cs.CV

TL;DR: 提出首个通用的高斯溅射语义SLAM算法，可增量构建3D语义地图，解决现有方法依赖逐场景优化和泛化差的问题。


<details>
  <summary>Details</summary>
Motivation: 现存高斯溅射SLAM方法需逐场景优化，效率低且难以泛化到多样场景，需要开发通用高效的方法。

Method: 1. 使用RGB-D图像识别主干网络预测高斯参数；2. 集成3D语义分割；3. 全局定位后仅优化1次高斯溅射以校正漂移。

Result: 在ScanNet上达到SOTA，高斯点数量少一个数量级；零样本迁移到NYUv2和TUM RGB-D验证泛化能力。

Conclusion: 该方法实现了高效通用的语义SLAM，显著减少计算资源需求并保持高精度。

Abstract: Traditional SLAM algorithms are excellent at camera tracking but might
generate lower resolution and incomplete 3D maps. Recently, Gaussian Splatting
(GS) approaches have emerged as an option for SLAM with accurate, dense 3D map
building. However, existing GS-based SLAM methods rely on per-scene
optimization which is time-consuming and does not generalize to diverse scenes
well. In this work, we introduce the first generalizable GS-based semantic SLAM
algorithm that incrementally builds and updates a 3D scene representation from
an RGB-D video stream using a learned generalizable network. Our approach
starts from an RGB-D image recognition backbone to predict the Gaussian
parameters from every downsampled and backprojected image location.
Additionally, we seamlessly integrate 3D semantic segmentation into our GS
framework, bridging 3D mapping and recognition through a shared backbone. To
correct localization drifting and floaters, we propose to optimize the GS for
only 1 iteration following global localization. We demonstrate state-of-the-art
semantic SLAM performance on the real-world benchmark ScanNet with an order of
magnitude fewer Gaussians compared to other recent GS-based methods, and
showcase our model's generalization capability through zero-shot transfer to
the NYUv2 and TUM RGB-D datasets.

</details>


### [271] [Bridging Audio and Vision: Zero-Shot Audiovisual Segmentation by Connecting Pretrained Models](https://arxiv.org/abs/2506.06537)
*Seung-jae Lee,Paul Hongsuck Seo*

Main category: cs.CV

TL;DR: 本文提出了一种新颖的零样本视听分割框架，利用多个预训练模型进行集成，无需特定任务的训练即可实现精确的声源分割。


<details>
  <summary>Details</summary>
Motivation: 传统视听分割方法依赖像素级标注，成本高昂且耗时。该研究旨在消除这些限制，通过跨模态整合实现无需标注的分割。

Method: 构建多模态集成框架：综合预训练的音频、视觉和文本模型的特征表示，设计策略弥合模态差异，实现零样本声音目标分割。

Result: 在多个数据集上实现SOTA零样本性能，证明该集成方法有效克服了预训练模型间的模态隔阂。

Conclusion: 通过集成不同模态的预训练模型完成细粒度视听分割是可行的，为解决标注依赖性问题提供了新思路。

Abstract: Audiovisual segmentation (AVS) aims to identify visual regions corresponding
to sound sources, playing a vital role in video understanding, surveillance,
and human-computer interaction. Traditional AVS methods depend on large-scale
pixel-level annotations, which are costly and time-consuming to obtain. To
address this, we propose a novel zero-shot AVS framework that eliminates
task-specific training by leveraging multiple pretrained models. Our approach
integrates audio, vision, and text representations to bridge modality gaps,
enabling precise sound source segmentation without AVS-specific annotations. We
systematically explore different strategies for connecting pretrained models
and evaluate their efficacy across multiple datasets. Experimental results
demonstrate that our framework achieves state-of-the-art zero-shot AVS
performance, highlighting the effectiveness of multimodal model integration for
finegrained audiovisual segmentation.

</details>


### [272] [Securing Traffic Sign Recognition Systems in Autonomous Vehicles](https://arxiv.org/abs/2506.06563)
*Thushari Hapuarachchi,Long Dang,Kaiqi Xiong*

Main category: cs.CV

TL;DR: 论文研究了深度神经网络（DNN）在交通标志识别中对数据中毒攻击的脆弱性，提出了基于数据增强的训练方法和检测模型来抵御误差最小化攻击，实验证明方法有效恢复模型精度并优于对抗训练。


<details>
  <summary>Details</summary>
Motivation: 由于交通标志识别DNN模型常使用来源未知的大规模数据集训练，需确保模型安全性。研究发现DNN易受训练数据中微小扰动导致的误差最小化攻击，导致准确性骤降，因此需要开发防御方法。

Method: 1. 在交通标志数据集上实施误差最小化攻击（添加人眼不可察觉的扰动）
2. 提出基于数据增强的鲁棒训练方法：利用非线性变换破坏扰动
3. 针对中毒数据开发检测模型（可识别不可察觉扰动）

Result: 1. 攻击使DNN准确率从99.90%降至10.6%
2. 防御方法将准确率恢复至96.05%，优于对抗训练
3. 检测模型识别中毒数据成功率超99%

Conclusion: 交通标志识别系统需采用先进训练方法抵御数据中毒攻击。所提数据增强训练方案和检测模型能有效提升鲁棒性，为部署安全可靠的DNN系统提供解决方案。

Abstract: Deep Neural Networks (DNNs) are widely used for traffic sign recognition
because they can automatically extract high-level features from images. These
DNNs are trained on large-scale datasets obtained from unknown sources.
Therefore, it is important to ensure that the models remain secure and are not
compromised or poisoned during training. In this paper, we investigate the
robustness of DNNs trained for traffic sign recognition. First, we perform the
error-minimizing attacks on DNNs used for traffic sign recognition by adding
imperceptible perturbations on training data. Then, we propose a data
augmentation-based training method to mitigate the error-minimizing attacks.
The proposed training method utilizes nonlinear transformations to disrupt the
perturbations and improve the model robustness. We experiment with two
well-known traffic sign datasets to demonstrate the severity of the attack and
the effectiveness of our mitigation scheme. The error-minimizing attacks reduce
the prediction accuracy of the DNNs from 99.90% to 10.6%. However, our
mitigation scheme successfully restores the prediction accuracy to 96.05%.
Moreover, our approach outperforms adversarial training in mitigating the
error-minimizing attacks. Furthermore, we propose a detection model capable of
identifying poisoned data even when the perturbations are imperceptible to
human inspection. Our detection model achieves a success rate of over 99% in
identifying the attack. This research highlights the need to employ advanced
training methods for DNNs in traffic sign recognition systems to mitigate the
effects of data poisoning attacks.

</details>


### [273] [Textile Analysis for Recycling Automation using Transfer Learning and Zero-Shot Foundation Models](https://arxiv.org/abs/2506.06569)
*Yannis Spyridis,Vasileios Argyriou*

Main category: cs.CV

TL;DR: 该论文研究了使用RGB图像和深度学习技术（包括迁移学习和基础模型）来实现纺织品自动化回收中的分类和分割任务。


<details>
  <summary>Details</summary>
Motivation: 自动化分类对纺织品回收的效率和可扩展性至关重要，但准确识别材料成分和污染物的检测面临挑战。因此，研究者探索了低成本RGB图像在自动化系统中的预处理任务应用。

Method: 在传送带设置中开发计算机视觉组件：(a) 使用迁移学习评估预训练架构对4种纺织品分类，其中EfficientNetB0表现最佳；(b) 使用零样本方法（结合Grounding DINO和Segment Anything Model）进行非纺织物特征（如纽扣）的语义分割。

Result: 分类任务中，EfficientNetB0在测试集上达到81.25%准确率；分割任务中，生成的掩模与真实标注的mIoU达0.90。

Conclusion: 该研究证明，将RGB图像与现代深度学习技术（迁移学习+基础模型）结合，可有效实现纺织品回收中关键预处理步骤。

Abstract: Automated sorting is crucial for improving the efficiency and scalability of
textile recycling, but accurately identifying material composition and
detecting contaminants from sensor data remains challenging. This paper
investigates the use of standard RGB imagery, a cost-effective sensing
modality, for key pre-processing tasks in an automated system. We present
computer vision components designed for a conveyor belt setup to perform (a)
classification of four common textile types and (b) segmentation of non-textile
features such as buttons and zippers. For classification, several pre-trained
architectures were evaluated using transfer learning and cross-validation, with
EfficientNetB0 achieving the best performance on a held-out test set with
81.25\% accuracy. For feature segmentation, a zero-shot approach combining the
Grounding DINO open-vocabulary detector with the Segment Anything Model (SAM)
was employed, demonstrating excellent performance with a mIoU of 0.90 for the
generated masks against ground truth. This study demonstrates the feasibility
of using RGB images coupled with modern deep learning techniques, including
transfer learning for classification and foundation models for zero-shot
segmentation, to enable essential analysis steps for automated textile
recycling pipelines.

</details>


### [274] [A Deep Learning Approach for Facial Attribute Manipulation and Reconstruction in Surveillance and Reconnaissance](https://arxiv.org/abs/2506.06578)
*Anees Nashath Shaik,Barbara Villarini,Vasileios Argyriou*

Main category: cs.CV

TL;DR: 提出了一个数据驱动平台，通过生成合成训练数据来克服监控系统在低质量图像和视频中的人脸识别限制。该平台利用深度学习方法增强数据集多样性并减少基于AI的人脸分析中的偏见。


<details>
  <summary>Details</summary>
Motivation: 现有监控系统在低质量图像和视频中的人脸识别准确率受限制。同时，人脸分析模型存在肤色变化和部分遮挡的偏见问题，这些问题源于训练数据集的局限性和不平衡。

Method: 开发了数据驱动平台，利用基于深度学习的人脸属性操作和重建技术，采用自编码器和生成对抗网络（GANs）生成多样化的合成训练数据，并整合图像增强模块提高低分辨率或遮挡人脸的清晰度。

Result: 在CelebA数据集上评估的平台显示，提出的方法提高了训练数据的多样性和模型的公平性。

Conclusion: 该平台有助于减少基于AI的人脸分析的偏见，提升监控系统在挑战性环境中的准确性，从而实现更公平可靠的安全应用。

Abstract: Surveillance systems play a critical role in security and reconnaissance, but
their performance is often compromised by low-quality images and videos,
leading to reduced accuracy in face recognition. Additionally, existing
AI-based facial analysis models suffer from biases related to skin tone
variations and partially occluded faces, further limiting their effectiveness
in diverse real-world scenarios. These challenges are the results of data
limitations and imbalances, where available training datasets lack sufficient
diversity, resulting in unfair and unreliable facial recognition performance.
To address these issues, we propose a data-driven platform that enhances
surveillance capabilities by generating synthetic training data tailored to
compensate for dataset biases. Our approach leverages deep learning-based
facial attribute manipulation and reconstruction using autoencoders and
Generative Adversarial Networks (GANs) to create diverse and high-quality
facial datasets. Additionally, our system integrates an image enhancement
module, improving the clarity of low-resolution or occluded faces in
surveillance footage. We evaluate our approach using the CelebA dataset,
demonstrating that the proposed platform enhances both training data diversity
and model fairness. This work contributes to reducing bias in AI-based facial
analysis and improving surveillance accuracy in challenging environments,
leading to fairer and more reliable security applications.

</details>


### [275] [EV-LayerSegNet: Self-supervised Motion Segmentation using Event Cameras](https://arxiv.org/abs/2506.06596)
*Youssef Farah,Federico Paredes-Vallés,Guido De Croon,Muhammad Ahmed Humais,Hussain Sajwani,Yahya Zweiri*

Main category: cs.CV

TL;DR: 本文提出了一种名为EV-LayerSegNet的自监督CNN模型，用于事件相机的运动分割，通过分层场景动态表示，分别学习仿射光流和分割掩码，并利用去模糊质量作为自监督损失，在模拟数据集上实现了71%的IoU和87%的检测率。


<details>
  <summary>Details</summary>
Motivation: 事件相机的高时间分辨率适合运动分割任务，但获取监督式训练所需的真实标注成本高且困难，因此需要自监督方法突破这一限制。

Method: 受场景动态分层表示的启发，设计了分离学习仿射光流和分割掩码的网络，利用两者对输入事件去模糊，并将去模糊质量度量作为自监督损失函数。

Result: 在仅含仿射运动的模拟数据集上训练测试，模型达到71%的交并比(IoU)和87%的检测率。

Conclusion: EV-LayerSegNet证明了通过分层动态表示实现自监督运动分割的可行性，为事件相机的高效学习提供了新方向，但仍需在真实数据上进一步验证。

Abstract: Event cameras are novel bio-inspired sensors that capture motion dynamics
with much higher temporal resolution than traditional cameras, since pixels
react asynchronously to brightness changes. They are therefore better suited
for tasks involving motion such as motion segmentation. However, training
event-based networks still represents a difficult challenge, as obtaining
ground truth is very expensive, error-prone and limited in frequency. In this
article, we introduce EV-LayerSegNet, a self-supervised CNN for event-based
motion segmentation. Inspired by a layered representation of the scene
dynamics, we show that it is possible to learn affine optical flow and
segmentation masks separately, and use them to deblur the input events. The
deblurring quality is then measured and used as self-supervised learning loss.
We train and test the network on a simulated dataset with only affine motion,
achieving IoU and detection rate up to 71% and 87% respectively.

</details>


### [276] [RARL: Improving Medical VLM Reasoning and Generalization with Reinforcement Learning and LoRA under Data and Hardware Constraints](https://arxiv.org/abs/2506.06600)
*Tan-Hanh Pham,Chris Ngo*

Main category: cs.CV

TL;DR: 提出了一个名为 RARL 的推理感知强化学习框架，用于提升医疗视觉语言模型在诊断准确性和推理能力上的表现，同时保持计算效率，适应低资源环境。


<details>
  <summary>Details</summary>
Motivation: 当前医疗视觉语言模型在泛化性、透明性和计算效率方面存在限制，阻碍了其在资源有限的实际环境中的部署。

Method: 使用低秩适配和定制奖励函数（同时考虑诊断准确性和推理质量），在轻量级基础模型上微调。训练在单张 GPU 上完成。

Result: 推理集中任务上比监督微调提升约 7.78%，泛化能力上比监督微调高约 27%，比传统强化学习微调高约 4%。训练中的多样提示和推理中的推理提示对性能提升至关重要。

Conclusion: 推理引导学习和推理提示可推动医疗视觉语言模型实现更透明、准确和资源高效的临床决策。

Abstract: The growing integration of vision-language models (VLMs) in medical
applications offers promising support for diagnostic reasoning. However,
current medical VLMs often face limitations in generalization, transparency,
and computational efficiency-barriers that hinder deployment in real-world,
resource-constrained settings. To address these challenges, we propose a
Reasoning-Aware Reinforcement Learning framework, \textbf{RARL}, that enhances
the reasoning capabilities of medical VLMs while remaining efficient and
adaptable to low-resource environments. Our approach fine-tunes a lightweight
base model, Qwen2-VL-2B-Instruct, using Low-Rank Adaptation and custom reward
functions that jointly consider diagnostic accuracy and reasoning quality.
Training is performed on a single NVIDIA A100-PCIE-40GB GPU, demonstrating the
feasibility of deploying such models in constrained environments. We evaluate
the model using an LLM-as-judge framework that scores both correctness and
explanation quality. Experimental results show that RARL significantly improves
VLM performance in medical image analysis and clinical reasoning, outperforming
supervised fine-tuning on reasoning-focused tasks by approximately 7.78%, while
requiring fewer computational resources. Additionally, we demonstrate the
generalization capabilities of our approach on unseen datasets, achieving
around 27% improved performance compared to supervised fine-tuning and about 4%
over traditional RL fine-tuning. Our experiments also illustrate that diversity
prompting during training and reasoning prompting during inference are crucial
for enhancing VLM performance. Our findings highlight the potential of
reasoning-guided learning and reasoning prompting to steer medical VLMs toward
more transparent, accurate, and resource-efficient clinical decision-making.
Code and data are publicly available.

</details>


### [277] [Zero Shot Composed Image Retrieval](https://arxiv.org/abs/2506.06602)
*Santhosh Kakarla,Gautama Shastry Bulusu Venkata*

Main category: cs.CV

TL;DR: 提出了两种改进零样本科普图像检索的方法：使用BLIP-2和轻量级Q-Former融合视觉文本特征，效果显著提升；尝试用Retrieval-DPO微调CLIP文本编码器但失败，分析原因并指出有效方法需多模态融合、排名感知目标和高质量负样本。


<details>
  <summary>Details</summary>
Motivation: 解决现有零样本科普图像检索在FashionIQ基准上效果不佳的问题

Method: 1. 微调BLIP-2模型配合轻量级Q-Former融合视觉文本特征 2. 尝试用Retrieval-DPO微调CLIP文本编码器并使用DPO损失

Result: BLIP-2方法显著提升效果（Recall@10达45.6%/40.1%/50.4%，平均Recall@50达67.6%），Retrieval-DPO完全失败（Recall@10仅0.02%）

Conclusion: 有效的偏好性科普检索需具备：真正的多模态融合、符合排名指标的损失函数、精心筛选的负样本

Abstract: Composed image retrieval (CIR) allows a user to locate a target image by
applying a fine-grained textual edit (e.g., ``turn the dress blue'' or ``remove
stripes'') to a reference image. Zero-shot CIR, which embeds the image and the
text with separate pretrained vision-language encoders, reaches only 20-25\%
Recall@10 on the FashionIQ benchmark. We improve this by fine-tuning BLIP-2
with a lightweight Q-Former that fuses visual and textual features into a
single embedding, raising Recall@10 to 45.6\% (shirt), 40.1\% (dress), and
50.4\% (top-tee) and increasing the average Recall@50 to 67.6\%. We also
examine Retrieval-DPO, which fine-tunes CLIP's text encoder with a Direct
Preference Optimization loss applied to FAISS-mined hard negatives. Despite
extensive tuning of the scaling factor, index, and sampling strategy,
Retrieval-DPO attains only 0.02\% Recall@10 -- far below zero-shot and
prompt-tuned baselines -- because it (i) lacks joint image-text fusion, (ii)
uses a margin objective misaligned with top-$K$ metrics, (iii) relies on
low-quality negatives, and (iv) keeps the vision and Transformer layers frozen.
Our results show that effective preference-based CIR requires genuine
multimodal fusion, ranking-aware objectives, and carefully curated negatives.

</details>


### [278] [PhysLab: A Benchmark Dataset for Multi-Granularity Visual Parsing of Physics Experiments](https://arxiv.org/abs/2506.06631)
*Minghao Zou,Qingtian Zeng,Yongping Miao,Shangkun Liu,Zilong Wang,Hantao Liu,Wei Zhou*

Main category: cs.CV

TL;DR: 介绍了PhysLab数据集，一个专为教育场景设计、支持细粒度解析的物理实验视频数据集，用于解决现有数据集在注释粒度、领域覆盖和过程指导方面的不足。


<details>
  <summary>Details</summary>
Motivation: 现有数据集存在三个主要限制：(1)注释粒度不足，阻碍细粒度场景理解；(2)教育领域数据缺乏；(3)缺乏明确过程指导和结构化任务表示。为填补这些空白，作者创建了PhysLab数据集。

Method: 收集了620个长视频，涵盖4个代表性的物理实验，包含丰富的科学仪器和人-物交互模式。数据集提供多层次注释，支持动作识别、目标检测、HOI分析等多种任务。同时建立了强基线模型并进行广泛评估。

Result: 构建了首个面向复杂物理实验的视频数据集，公开了数据集和评估工具包。实验揭示了教育视频解析的关键挑战。

Conclusion: PhysLab可推动细粒度视觉解析发展，促进智能课堂系统建设，加强计算机视觉与教育技术的融合。

Abstract: Visual parsing of images and videos is critical for a wide range of
real-world applications. However, progress in this field is constrained by
limitations of existing datasets: (1) insufficient annotation granularity,
which impedes fine-grained scene understanding and high-level reasoning; (2)
limited coverage of domains, particularly a lack of datasets tailored for
educational scenarios; and (3) lack of explicit procedural guidance, with
minimal logical rules and insufficient representation of structured task
process. To address these gaps, we introduce PhysLab, the first video dataset
that captures students conducting complex physics experiments. The dataset
includes four representative experiments that feature diverse scientific
instruments and rich human-object interaction (HOI) patterns. PhysLab comprises
620 long-form videos and provides multilevel annotations that support a variety
of vision tasks, including action recognition, object detection, HOI analysis,
etc. We establish strong baselines and perform extensive evaluations to
highlight key challenges in the parsing of procedural educational videos. We
expect PhysLab to serve as a valuable resource for advancing fine-grained
visual parsing, facilitating intelligent classroom systems, and fostering
closer integration between computer vision and educational technologies. The
dataset and the evaluation toolkit are publicly available at
https://github.com/ZMH-SDUST/PhysLab.

</details>


### [279] [Dark Channel-Assisted Depth-from-Defocus from a Single Image](https://arxiv.org/abs/2506.06643)
*Moushumi Medhi,Rajiv Ranjan Sahay*

Main category: cs.CV

TL;DR: 该论文提出了一种利用暗通道先验结合单张图像中空间变化离焦模糊信息进行深度估计的方法。传统的离焦深度恢复(DFD)技术依赖多张不同光圈或对焦设置的图像，而本文创新性地解决了单张离焦图像深度估计这一欠约束问题。


<details>
  <summary>Details</summary>
Motivation: 现有基于单张离焦图像的深度估计方法因问题欠约束而非常罕见。论文观察到暗通道能有效隐式捕捉模糊图像的局部统计特性和场景结构，因此决定将其作为补充线索来提升深度估计性能。

Method: 利用局部离焦模糊与对比度变化之间的关系作为关键深度线索，建立完全端到端的对抗训练流程。具体将暗通道先验整合到单张图像DFD框架中，通过神经网络学习从单张离焦图像到深度图的映射。

Result: 在具有真实深度诱导离焦模糊的实际数据上进行实验，结果表明融入暗通道先验后，单张图像DFD能产生有意义的深度估计结果。

Conclusion: 暗通道先验的引入有效增强了单张离焦图像的深度估计能力，验证了所提方法的有效性。

Abstract: In this paper, we utilize the dark channel as a complementary cue to estimate
the depth of a scene from a single space-variant defocus blurred image due to
its effectiveness in implicitly capturing the local statistics of blurred
images and the scene structure. Existing depth-from-defocus (DFD) techniques
typically rely on multiple images with varying apertures or focus settings to
recover depth information. Very few attempts have focused on DFD from a single
defocused image due to the underconstrained nature of the problem. Our method
capitalizes on the relationship between local defocus blur and contrast
variations as key depth cues to enhance the overall performance in estimating
the scene's structure. The entire pipeline is trained adversarially in a fully
end-to-end fashion. Experiments conducted on real data with realistic
depth-induced defocus blur demonstrate that incorporating dark channel prior
into single image DFD yields meaningful depth estimation results, validating
the effectiveness of our approach.

</details>


### [280] [Parametric Gaussian Human Model: Generalizable Prior for Efficient and Realistic Human Avatar Modeling](https://arxiv.org/abs/2506.06645)
*Cheng Peng,Jingxiang Sun,Yushuo Chen,Zhaoqi Su,Zhuo Su,Yebin Liu*

Main category: cs.CV

TL;DR: 本文提出了参数化高斯人体模型（PGHM）框架，从单目视频中快速重建逼真、高保真化身的通用高效方法。该框架集成人体先验知识到3D高斯泼溅中，核心包括UV对齐隐身份图谱和分离多头U-Net，能在20分钟内完成高质量建模，显着优于逐项优化方法。


<details>
  <summary>Details</summary>
Motivation: 现有3D高斯泼溅方法存在两个根本挑战：每个对象耗时的优化过程，以及在稀疏单目输入下泛化能力差。

Method: 1) UV对齐隐身份图谱：压缩编码对象特定几何和外观特征；2) 分离多头U-Net：通过条件解码器分解静态/姿态相关/视角相关组件来预测高斯属性。

Result: 该方法在挑战性姿态和视角下保持稳健渲染质量，每个主体适应仅需约20分钟，视觉质量媲美优化方法。

Conclusion: PGHM突破了单目化身创建在效率和质量上的限制，为虚拟/增强现实等应用提供实用解决方案。

Abstract: Photorealistic and animatable human avatars are a key enabler for
virtual/augmented reality, telepresence, and digital entertainment. While
recent advances in 3D Gaussian Splatting (3DGS) have greatly improved rendering
quality and efficiency, existing methods still face fundamental challenges,
including time-consuming per-subject optimization and poor generalization under
sparse monocular inputs. In this work, we present the Parametric Gaussian Human
Model (PGHM), a generalizable and efficient framework that integrates human
priors into 3DGS for fast and high-fidelity avatar reconstruction from
monocular videos. PGHM introduces two core components: (1) a UV-aligned latent
identity map that compactly encodes subject-specific geometry and appearance
into a learnable feature tensor; and (2) a disentangled Multi-Head U-Net that
predicts Gaussian attributes by decomposing static, pose-dependent, and
view-dependent components via conditioned decoders. This design enables robust
rendering quality under challenging poses and viewpoints, while allowing
efficient subject adaptation without requiring multi-view capture or long
optimization time. Experiments show that PGHM is significantly more efficient
than optimization-from-scratch methods, requiring only approximately 20 minutes
per subject to produce avatars with comparable visual quality, thereby
demonstrating its practical applicability for real-world monocular avatar
creation.

</details>


### [281] [Flood-DamageSense: Multimodal Mamba with Multitask Learning for Building Flood Damage Assessment using SAR Remote Sensing Imagery](https://arxiv.org/abs/2506.06667)
*Yu-Hsuan Ho,Ali Mostafavi*

Main category: cs.CV

TL;DR: Flood-DamageSense：首个专为建筑级洪水损害评估设计的深度学习框架，融合多模态数据，性能提升19%，并提供端到端处理流水线。


<details>
  <summary>Details</summary>
Motivation: 现有模型难以识别洪水破坏的建筑物，因为洪水破坏常缺乏明显光谱或结构特征。

Method: 1. 多模态数据融合：前/后事件SAR/InSAR影像、高分辨率光学底图、固有洪水风险层。
2. 多任务Mamba主干网络：半孪生编码器+任务特定解码器，联合预测三项任务。
3. 基于保险公司的洪灾范围数据进行训练验证。

Result: Hurricane Harvey（2017）数据集上：
- F1分数比SOTA基线提升最高19个百分点
- 在难分类的轻微/中度破坏类别提升最显著
- 洪水风险层是性能提升最大贡献因素


Conclusion: 1. 融合风险感知建模与全天候SAR能力，实现更快+更细粒度+更可靠的灾害评估。
2. 端到端处理流水线可在获取影像数分钟内生成建筑物级的损失地图。
3. 支持灾后决策和资源分配。

Abstract: Most post-disaster damage classifiers succeed only when destructive forces
leave clear spectral or structural signatures -- conditions rarely present
after inundation. Consequently, existing models perform poorly at identifying
flood-related building damages. The model presented in this study,
Flood-DamageSense, addresses this gap as the first deep-learning framework
purpose-built for building-level flood-damage assessment. The architecture
fuses pre- and post-event SAR/InSAR scenes with very-high-resolution optical
basemaps and an inherent flood-risk layer that encodes long-term exposure
probabilities, guiding the network toward plausibly affected structures even
when compositional change is minimal. A multimodal Mamba backbone with a
semi-Siamese encoder and task-specific decoders jointly predicts (1) graded
building-damage states, (2) floodwater extent, and (3) building footprints.
Training and evaluation on Hurricane Harvey (2017) imagery from Harris County,
Texas -- supported by insurance-derived property-damage extents -- show a mean
F1 improvement of up to 19 percentage points over state-of-the-art baselines,
with the largest gains in the frequently misclassified "minor" and "moderate"
damage categories. Ablation studies identify the inherent-risk feature as the
single most significant contributor to this performance boost. An end-to-end
post-processing pipeline converts pixel-level outputs to actionable,
building-scale damage maps within minutes of image acquisition. By combining
risk-aware modeling with SAR's all-weather capability, Flood-DamageSense
delivers faster, finer-grained, and more reliable flood-damage intelligence to
support post-disaster decision-making and resource allocation.

</details>


### [282] [Interpretation of Deep Learning Model in Embryo Selection for In Vitro Fertilization (IVF) Treatment](https://arxiv.org/abs/2506.06680)
*Radha Kodali,Venkata Rao Dhulipalla,Venkata Siva Kishor Tatavarty,Madhavi Nadakuditi,Bharadwaj Thiruveedhula,Suryanarayana Gunnam,Durga Prasad Bavirisetti*

Main category: cs.CV

TL;DR: 提出一种基于可解释人工智能（XAI）的胚胎分类框架，融合CNN和LSTM架构，旨在高效解决试管婴儿胚胎人工筛选的低效率问题。


<details>
  <summary>Details</summary>
Motivation: 不孕不育严重影响生活质量且呈上升趋势，当前试管婴儿技术依赖胚胎学家人工评估胚胎，效率低下且耗时。

Method: 采用CNN-LSTM混合神经网络模型处理囊胚图像，结合可解释人工智能技术（XAI）保持模型可解释性。

Result: 模型实现了高精度胚胎分类。

Conclusion: 该框架为胚胎筛选提供高效准确且可解释的自动化解决方案，可提升辅助生殖技术效率。

Abstract: Infertility has a considerable impact on individuals' quality of life,
affecting them socially and psychologically, with projections indicating a rise
in the upcoming years. In vitro fertilization (IVF) emerges as one of the
primary techniques within economically developed nations, employed to address
the rising problem of low fertility. Expert embryologists conventionally grade
embryos by reviewing blastocyst images to select the most optimal for transfer,
yet this process is time-consuming and lacks efficiency. Blastocyst images
provide a valuable resource for assessing embryo viability. In this study, we
introduce an explainable artificial intelligence (XAI) framework for
classifying embryos, employing a fusion of convolutional neural network (CNN)
and long short-term memory (LSTM) architecture, referred to as CNN-LSTM.
Utilizing deep learning, our model achieves high accuracy in embryo
classification while maintaining interpretability through XAI.

</details>


### [283] [A Systematic Investigation on Deep Learning-Based Omnidirectional Image and Video Super-Resolution](https://arxiv.org/abs/2506.06710)
*Qianqian Zhao,Chunle Guo,Tianyi Zhang,Junpei Zhang,Peiyang Jia,Tan Su,Wenjie Jiang,Chongyi Li*

Main category: cs.CV

TL;DR: 该论文是一篇关于全景图像和视频超分辨率的系统综述，介绍了新数据集360Insta以解决现有数据集合成失真与真实场景的差异问题，并对现有方法在公开数据集和新数据集上进行了评估，讨论了未来研究方向。


<details>
  <summary>Details</summary>
Motivation: 现有全景图像和视频超分辨率数据集主要基于合成生成，无法充分反映真实场景中的复杂退化（如光线、运动和曝光变化），这限制了超分辨率方法的泛化能力评估和实际应用。

Method: 1. 提出360Insta全景数据集，包含真实拍摄过程中的退化图像和视频；2. 对现有方法在公共数据集和360Insta上进行定性与定量评估；3. 系统梳理该领域研究现状并讨论未来方向。

Result: 1. 360Insta数据集填补了真实退化全景数据的空白；2. 实验表明现有方法在真实退化数据上的表现存在显著差距；3. 公开了数据集、评估指标和项目页面，促进领域发展。

Conclusion: 该论文强调了真实退化数据对全景超分辨率研究的重要性，360Insta数据集为评估模型泛化能力提供了可靠基准；未来需开发更强鲁棒性的方法应对真实场景挑战。

Abstract: Omnidirectional image and video super-resolution is a crucial research topic
in low-level vision, playing an essential role in virtual reality and augmented
reality applications. Its goal is to reconstruct high-resolution images or
video frames from low-resolution inputs, thereby enhancing detail preservation
and enabling more accurate scene analysis and interpretation. In recent years,
numerous innovative and effective approaches have been proposed, predominantly
based on deep learning techniques, involving diverse network architectures,
loss functions, projection strategies, and training datasets. This paper
presents a systematic review of recent progress in omnidirectional image and
video super-resolution, focusing on deep learning-based methods. Given that
existing datasets predominantly rely on synthetic degradation and fall short in
capturing real-world distortions, we introduce a new dataset, 360Insta, that
comprises authentically degraded omnidirectional images and videos collected
under diverse conditions, including varying lighting, motion, and exposure
settings. This dataset addresses a critical gap in current omnidirectional
benchmarks and enables more robust evaluation of the generalization
capabilities of omnidirectional super-resolution methods. We conduct
comprehensive qualitative and quantitative evaluations of existing methods on
both public datasets and our proposed dataset. Furthermore, we provide a
systematic overview of the current status of research and discuss promising
directions for future exploration. All datasets, methods, and evaluation
metrics introduced in this work are publicly available and will be regularly
updated. Project page: https://github.com/nqian1/Survey-on-ODISR-and-ODVSR.

</details>


### [284] [Active Contour Models Driven by Hyperbolic Mean Curvature Flow for Image Segmentation](https://arxiv.org/abs/2506.06712)
*Saiyu Hu,Chunlei He,Jianfeng Zhang,Dexing Kong,Shoujun Huang*

Main category: cs.CV

TL;DR: 本文提出了基于双曲平均曲率流驱动的主动轮廓模型（HMCF-ACMs）和双曲双模正则化流驱动模型（HDRF-ACMs），通过可调节初始速度场提升分割精度。方法结合水平集和波动方程理论，采用优化Runge-Kutta算法求解。实验验证了其抗噪性和稳定性优势。


<details>
  <summary>Details</summary>
Motivation: 现有抛物线平均曲率流驱动模型（PMCF-ACMs）严重依赖初始轮廓选择，难以适应多样化分割场景。为突破该限制，需要开发能自适应优化初始配置的新方法。

Method: 1. 建立HMCF-ACMs理论框架，证明其作为法向流的特性，并通过符号距离函数将耗散HMCF与波动方程数值等效 2. 提出HDRF-ACMs，利用平滑Heaviside函数进行边缘感知力调节以抑制弱边界过扩散 3. 设计九点模板空间离散的加权四阶Runge-Kutta求解算法

Result: 实验表明：1. HMCF-ACMs和HDRF-ACMs通过初始速度和轮廓的自适应配置，实现更精确分割 2. 相较传统方法具备更优的抗噪性和数值稳定性 3. 弱边界保持能力显著提升

Conclusion: 本文发展的双曲流驱动模型克服了抛物线模型对初始配置的敏感性问题，其自适应特性和优化算法为复杂图像分割提供了新范式，尤其在弱边界和噪声场景中展现出显著优势。

Abstract: Parabolic mean curvature flow-driven active contour models (PMCF-ACMs) are
widely used in image segmentation, which however depend heavily on the
selection of initial curve configurations. In this paper, we firstly propose
several hyperbolic mean curvature flow-driven ACMs (HMCF-ACMs), which introduce
tunable initial velocity fields, enabling adaptive optimization for diverse
segmentation scenarios. We shall prove that HMCF-ACMs are indeed normal flows
and establish the numerical equivalence between dissipative HMCF formulations
and certain wave equations using the level set method with signed distance
function. Building on this framework, we furthermore develop hyperbolic
dual-mode regularized flow-driven ACMs (HDRF-ACMs), which utilize smooth
Heaviside functions for edge-aware force modulation to suppress over-diffusion
near weak boundaries. Then, we optimize a weighted fourth-order Runge-Kutta
algorithm with nine-point stencil spatial discretization when solving the
above-mentioned wave equations. Experiments show that both HMCF-ACMs and
HDRF-ACMs could achieve more precise segmentations with superior noise
resistance and numerical stability due to task-adaptive configurations of
initial velocities and initial contours.

</details>


### [285] [Improving Wildlife Out-of-Distribution Detection: Africas Big Five](https://arxiv.org/abs/2506.06719)
*Mufhumudzi Muthivhi,Jiahao Huo,Fredrik Gustafsson,Terence L. van Zyl*

Main category: cs.CV

TL;DR: 本文研究野生动物（特别是非洲五大动物）的分布外（OOD）检测，因为现有动物分类模型在封闭世界假设下训练，遇到未知类别时会过度自信。通过比较参数化的NCM和非参数化的对比学习方法与主流OOD方法，发现基于特征的方法（如ImageNet预训练的NCM）在泛化能力上表现最佳，关键指标提升显著。


<details>
  <summary>Details</summary>
Motivation: 现有野生动物分类模型基于封闭世界假设，无法识别训练集外的新物种（OOD样本），导致过度自信的预测。这限制了人类与野生动物冲突的自动化解决方案，需要构建能区分已知/未知物种的鲁棒系统。

Method: 采用两种基线方案：1）参数化的最近类均值（NCM）；2）非参数化的对比学习方法。均利用预训练分类编码器的特征，并与多种主流OOD检测方法（如MSP、ODIN、Energy等）对比。通过AUPR-IN/AUPR-OUT/AUTC指标评估模型在Big Five数据集上的OOD检测能力。

Result: ImageNet预训练的NCM表现最优：AUPR-IN提升2%（已知类检测），AUPR-OUT提升4%（未知类检测），AUTC提升22%（综合检测能力）。证明基于特征的OOD方法在泛化性和分类阈值适应性上超越传统方法。

Conclusion: 简单有效的特征空间方法（NCM）可显著提升野生动物OOD检测性能，尤其在处理实际环境中未知物种时。该方法为动态开放环境下的动物监测提供更可靠的技术路径。

Abstract: Mitigating human-wildlife conflict seeks to resolve unwanted encounters
between these parties. Computer Vision provides a solution to identifying
individuals that might escalate into conflict, such as members of the Big Five
African animals. However, environments often contain several varied species.
The current state-of-the-art animal classification models are trained under a
closed-world assumption. They almost always remain overconfident in their
predictions even when presented with unknown classes. This study investigates
out-of-distribution (OOD) detection of wildlife, specifically the Big Five. To
this end, we select a parametric Nearest Class Mean (NCM) and a non-parametric
contrastive learning approach as baselines to take advantage of pretrained and
projected features from popular classification encoders. Moreover, we compare
our baselines to various common OOD methods in the literature. The results show
feature-based methods reflect stronger generalisation capability across varying
classification thresholds. Specifically, NCM with ImageNet pre-trained features
achieves a 2%, 4% and 22% improvement on AUPR-IN, AUPR-OUT and AUTC over the
best OOD methods, respectively. The code can be found here
https://github.com/pxpana/BIG5OOD

</details>


### [286] [Mitigating Object Hallucination via Robust Local Perception Search](https://arxiv.org/abs/2506.06729)
*Zixian Gao,Chao Yang,Zhanhui Zhou,Xing Xu,Chaochao Lu*

Main category: cs.CV

TL;DR: Introduces Local Perception Search (LPS), a training-free decoding method to suppress hallucinations in Multimodal Large Language Models by leveraging local visual prior information during inference.


<details>
  <summary>Details</summary>
Motivation: To address hallucination problems in MLLMs where outputs appear plausible but misalign with image content, especially in noisy settings.

Method: LPS uses local visual priors as a value function to correct the decoding process, acting as a plug-and-play inference-time technique without requiring model retraining.

Result: LPS significantly reduces hallucinations on standard benchmarks, showing exceptional performance in noisy scenarios compared to baselines.

Conclusion: LPS is an effective, model-agnostic solution for hallucination suppression, particularly valuable in high-noise environments.

Abstract: Recent advancements in Multimodal Large Language Models (MLLMs) have enabled
them to effectively integrate vision and language, addressing a variety of
downstream tasks. However, despite their significant success, these models
still exhibit hallucination phenomena, where the outputs appear plausible but
do not align with the content of the images. To mitigate this issue, we
introduce Local Perception Search (LPS), a decoding method during inference
that is both simple and training-free, yet effectively suppresses
hallucinations. This method leverages local visual prior information as a value
function to correct the decoding process. Additionally, we observe that the
impact of the local visual prior on model performance is more pronounced in
scenarios with high levels of image noise. Notably, LPS is a plug-and-play
approach that is compatible with various models. Extensive experiments on
widely used hallucination benchmarks and noisy data demonstrate that LPS
significantly reduces the incidence of hallucinations compared to the baseline,
showing exceptional performance, particularly in noisy settings.

</details>


### [287] [RecipeGen: A Step-Aligned Multimodal Benchmark for Real-World Recipe Generation](https://arxiv.org/abs/2506.06733)
*Ruoxuan Zhang,Jidong Gao,Bin Wen,Hongxia Xie,Chenming Zhang,Honghan-shuai,Wen-Huang Cheng*

Main category: cs.CV

TL;DR: RecipeGen是一个大规模、真实世界的基准数据集，用于基于食谱的文本到图像（T2I）、图像到视频（I2V）和文本到视频（T2V）生成。它包含26,453个食谱，196,724张图像和4,491个视频，覆盖多样化的食材、烹饪程序、风格和菜肴类型。作者还提出了特定领域的评估指标，用于评估成分保真度和交互建模。


<details>
  <summary>Details</summary>
Motivation: 现有的数据集缺乏食谱目标、分步说明和视觉内容之间的细粒度对齐。这在食品计算领域是一个关键挑战，影响了烹饪教育和多模态食谱助手等应用。

Method: 作者构建了RecipeGen基准，包含大量多样化食谱数据，并提出特定领域指标（成分保真度和交互建模）用于评估。同时对代表性T2I/I2V/T2V模型进行了基准测试。

Result: 建立了首个大规模食谱生成基准，包含26k+食谱、197k+图像和4k+视频。提出的指标能有效评估模型在食谱生成中的表现。

Conclusion: RecipeGen填补了现有数据集的不足，为未来食谱生成模型提供了新的评估基准和见解。

Abstract: Creating recipe images is a key challenge in food computing, with
applications in culinary education and multimodal recipe assistants. However,
existing datasets lack fine-grained alignment between recipe goals, step-wise
instructions, and visual content. We present RecipeGen, the first large-scale,
real-world benchmark for recipe-based Text-to-Image (T2I), Image-to-Video
(I2V), and Text-to-Video (T2V) generation. RecipeGen contains 26,453 recipes,
196,724 images, and 4,491 videos, covering diverse ingredients, cooking
procedures, styles, and dish types. We further propose domain-specific
evaluation metrics to assess ingredient fidelity and interaction modeling,
benchmark representative T2I, I2V, and T2V models, and provide insights for
future recipe generation models. Project page is available now.

</details>


### [288] [THU-Warwick Submission for EPIC-KITCHEN Challenge 2025: Semi-Supervised Video Object Segmentation](https://arxiv.org/abs/2506.06748)
*Mingqi Gao,Haoran Duan,Tianlu Zhang,Jungong Han*

Main category: cs.CV

TL;DR: 我们提出了一个结合视觉预训练和深度几何线索的自中心视频对象分割方法，在VISOR测试集上达到90.1%的J&F分数。


<details>
  <summary>Details</summary>
Motivation: 处理复杂场景和长期追踪的自中心视频对象分割需要有效方法，结合语义和几何信息可能提升分割性能。

Method: 将大规模视觉预训练模型（SAM2）与基于深度的几何线索整合到统一框架。

Result: 在VISOR测试集上取得90.1%的J&F分数，表明性能优越。

Conclusion: 结合视觉预训练和深度几何线索的框架能有效解决自中心视频分割挑战，达到最先进水平。

Abstract: In this report, we describe our approach to egocentric video object
segmentation. Our method combines large-scale visual pretraining from SAM2 with
depth-based geometric cues to handle complex scenes and long-term tracking. By
integrating these signals in a unified framework, we achieve strong
segmentation performance. On the VISOR test set, our method reaches a J&F score
of 90.1%.

</details>


### [289] [SAR2Struct: Extracting 3D Semantic Structural Representation of Aircraft Targets from Single-View SAR Image](https://arxiv.org/abs/2506.06757)
*Ziyu Yue,Ruixi You,Feng Xu*

Main category: cs.CV

TL;DR: 提出SAR目标结构恢复新任务:从单视图SAR图像推断目标部件及其对称/邻接结构关系。通过跨图像学习结构一致性与几何多样性,建立二维图像到三维层次结构的映射框架。实验首次证明可从单视图SAR图像直接获得飞机目标的3D语义结构表示。


<details>
  <summary>Details</summary>
Motivation: 现有SAR图像解释方法主要关注三维表面重建或局部几何特征提取,忽视了结构建模在获取语义信息中的作用。为弥补这一不足,本文提出SAR目标结构恢复任务,旨在通过结构一致性学习,直接从二维SAR图像推导目标语义表示。

Method: 开发基于结构描述符的两步算法框架:1)训练阶段从真实SAR图像检测二维关键点,利用模拟数据学习关键点到三维层次结构的映射;2)测试阶段集成两步过程,从真实SAR图像推断三维结构。

Result: 实验验证了各步骤的有效性,首次证明可直接从单视图SAR图像推导飞机目标的三维语义结构表示。

Conclusion: 本文提出的SAR目标结构恢复任务及两步框架,通过结构建模有效解决了从单视图SAR图像获取语义信息的挑战,为SAR图像高级理解开辟了新途径。

Abstract: To translate synthetic aperture radar (SAR) image into interpretable forms
for human understanding is the ultimate goal of SAR advanced information
retrieval. Existing methods mainly focus on 3D surface reconstruction or local
geometric feature extraction of targets, neglecting the role of structural
modeling in capturing semantic information. This paper proposes a novel task:
SAR target structure recovery, which aims to infer the components of a target
and the structural relationships between its components, specifically symmetry
and adjacency, from a single-view SAR image. Through learning the structural
consistency and geometric diversity across the same type of targets as observed
in different SAR images, it aims to derive the semantic representation of
target directly from its 2D SAR image. To solve this challenging task, a
two-step algorithmic framework based on structural descriptors is developed.
Specifically, in the training phase, it first detects 2D keypoints from real
SAR images, and then learns the mapping from these keypoints to 3D hierarchical
structures using simulated data. During the testing phase, these two steps are
integrated to infer the 3D structure from real SAR images. Experimental results
validated the effectiveness of each step and demonstrated, for the first time,
that 3D semantic structural representation of aircraft targets can be directly
derived from a single-view SAR image.

</details>


### [290] [LitMAS: A Lightweight and Generalized Multi-Modal Anti-Spoofing Framework for Biometric Security](https://arxiv.org/abs/2506.06759)
*Nidheesh Gorthi,Kartik Thakral,Rishabh Ranjan,Richa Singh,Mayank Vatsa*

Main category: cs.CV

TL;DR: 提出了一个轻量级通用多模态反欺骗框架LitMAS，用于检测语音、人脸、虹膜和指纹等多种生物识别系统中的欺骗攻击。该框架核心是模态对齐集中损失函数，仅用600万参数在七个数据集上平均EER超越现有方法1.36%。


<details>
  <summary>Details</summary>
Motivation: 现有生物认证系统易受欺骗攻击，且当前反欺骗技术多为模态特定方案，缺乏跨模态的轻量级统一解决方案。

Method: 开发LitMAS框架：1) 设计模态对齐集中损失函数以增强类间分离性并保持跨模态一致性；2) 构建轻量级模型结构（600万参数）。

Result: 在七个生物识别数据集测试中，平均等错误率(EER)比现有最优方法降低1.36%，展示高效性、强泛化性和边缘部署适用性。

Conclusion: LitMAS首次实现轻量化跨模态反欺骗，性能优于专用模型，为资源受限场景提供实用解决方案。模型开源促进社区发展。

Abstract: Biometric authentication systems are increasingly being deployed in critical
applications, but they remain susceptible to spoofing. Since most of the
research efforts focus on modality-specific anti-spoofing techniques, building
a unified, resource-efficient solution across multiple biometric modalities
remains a challenge. To address this, we propose LitMAS, a
$\textbf{Li}$gh$\textbf{t}$ weight and generalizable $\textbf{M}$ulti-modal
$\textbf{A}$nti-$\textbf{S}$poofing framework designed to detect spoofing
attacks in speech, face, iris, and fingerprint-based biometric systems. At the
core of LitMAS is a Modality-Aligned Concentration Loss, which enhances
inter-class separability while preserving cross-modal consistency and enabling
robust spoof detection across diverse biometric traits. With just 6M
parameters, LitMAS surpasses state-of-the-art methods by $1.36\%$ in average
EER across seven datasets, demonstrating high efficiency, strong
generalizability, and suitability for edge deployment. Code and trained models
are available at https://github.com/IAB-IITJ/LitMAS.

</details>


### [291] [LoopDB: A Loop Closure Dataset for Large Scale Simultaneous Localization and Mapping](https://arxiv.org/abs/2506.06771)
*Mohammad-Maher Nakshbandi,Ziad Sharawy,Dorian Cojocaru,Sorin Grigorescu*

Main category: cs.CV

TL;DR: 提出了 LoopDB，一个包含1000多张图像的具有挑战性的闭环检测数据集，覆盖公园、室内、停车场和单个物体等多种环境。每个场景包含五张连续图像。


<details>
  <summary>Details</summary>
Motivation: 缺乏一个全面的数据集来评估和训练视觉环路闭环检测算法，特别是在各种复杂环境下。

Method: 使用高分辨率相机实地采集多种环境下的图像序列，每场景五张连续图像，并提供相邻帧之间的姿态变化作为真值。

Result: 构建了一个包含精确姿态真值的闭环检测公开数据集，适用于算法评估和深度学习模型训练。

Conclusion: LoopDB 填补了相关研究领域的数据空白，可有效促进视觉环路闭环算法的发展，并已公开共享。

Abstract: In this study, we introduce LoopDB, which is a challenging loop closure
dataset comprising over 1000 images captured across diverse environments,
including parks, indoor scenes, parking spaces, as well as centered around
individual objects. Each scene is represented by a sequence of five consecutive
images. The dataset was collected using a high resolution camera, providing
suitable imagery for benchmarking the accuracy of loop closure algorithms,
typically used in simultaneous localization and mapping. As ground truth
information, we provide computed rotations and translations between each
consecutive images. Additional to its benchmarking goal, the dataset can be
used to train and fine-tune loop closure methods based on deep neural networks.
LoopDB is publicly available at https://github.com/RovisLab/LoopDB.

</details>


### [292] [Continuous-Time SO(3) Forecasting with Savitzky--Golay Neural Controlled Differential Equations](https://arxiv.org/abs/2506.06780)
*Lennart Bastian,Mohammad Rashed,Nassir Navab,Tolga Birdal*

Main category: cs.CV

TL;DR: 该论文提出了一种基于神经控制微分方程的方法，结合Savitzky-Golay路径，在SO(3)上建模连续时间旋转物体动力学问题，从而解决噪声稀疏观测、复杂动力学模式及长期预测等挑战。实验证明其在旋转预测任务上超越现有方法。


<details>
  <summary>Details</summary>
Motivation: 在计算机视觉和机器人领域，旋转物体的跟踪与预测至关重要。然而（1）传感器观测可能噪声大且稀疏，（2）运动模式受复杂动力学支配，（3）应用场景需长期预测，这使SO(3)外推问题极具挑战性。现有方法依赖简化运动假设，难以解决上述问题。

Method: 在SO(3)上建立神经控制微分方程模型，利用Savitzky-Golay路径引导，学习旋转轨迹的潜在动力学系统，同时保持旋转的几何结构特性。该模型能处理连续时间动态。

Result: 在真实数据集上的实验结果表明，该方法在旋转预测任务上展现出比现有方法更优越的性能，尤其是在处理噪声数据、复杂动态和长期预测方面。

Conclusion: 本研究证明基于神经控制微分方程的框架能有效建模SO(3)空间中的复杂旋转动态，同时保持几何特性，为旋转物体的长期精确预测提供了新方案。

Abstract: Tracking and forecasting the rotation of objects is fundamental in computer
vision and robotics, yet SO(3) extrapolation remains challenging as (1) sensor
observations can be noisy and sparse, (2) motion patterns can be governed by
complex dynamics, and (3) application settings can demand long-term
forecasting. This work proposes modeling continuous-time rotational object
dynamics on $SO(3)$ using Neural Controlled Differential Equations guided by
Savitzky-Golay paths. Unlike existing methods that rely on simplified motion
assumptions, our method learns a general latent dynamical system of the
underlying object trajectory while respecting the geometric structure of
rotations. Experimental results on real-world data demonstrate compelling
forecasting capabilities compared to existing approaches.

</details>


### [293] [Training-Free Identity Preservation in Stylized Image Generation Using Diffusion Models](https://arxiv.org/abs/2506.06802)
*Mohammad Ali Rezaei,Helia Hajikazem,Saeed Khanehgir,Mahdi Javanmardi*

Main category: cs.CV

TL;DR: 提出一种无需训练的扩散模型框架，用于保持身份的同时进行高质量风格化，解决小面部或远距离时身份保留不足的问题。


<details>
  <summary>Details</summary>
Motivation: 现有风格迁移技术在保持身份和高品质风格化之间存在矛盾，尤其在小脸或远距离场景中易丢失身份信息。

Method: （1）引入马赛克修复内容图像技术增强身份保留；（2）设计无需训练的内容一致性损失，通过关注原图细节提升内容保真度。

Result: 新方法显著超越基线模型，在保持风格逼真度和身份完整性方面表现优异，尤其适用于小面部或远距离场景。

Conclusion: 该训练免费框架实现了身份保留与风格化的平衡，无需微调即可处理复杂场景。

Abstract: While diffusion models have demonstrated remarkable generative capabilities,
existing style transfer techniques often struggle to maintain identity while
achieving high-quality stylization. This limitation is particularly acute for
images where faces are small or exhibit significant camera-to-face distances,
frequently leading to inadequate identity preservation. To address this, we
introduce a novel, training-free framework for identity-preserved stylized
image synthesis using diffusion models. Key contributions include: (1) the
"Mosaic Restored Content Image" technique, significantly enhancing identity
retention, especially in complex scenes; and (2) a training-free content
consistency loss that enhances the preservation of fine-grained content details
by directing more attention to the original image during stylization. Our
experiments reveal that the proposed approach substantially surpasses the
baseline model in concurrently maintaining high stylistic fidelity and robust
identity integrity, particularly under conditions of small facial regions or
significant camera-to-face distances, all without necessitating model
retraining or fine-tuning.

</details>


### [294] [Stepwise Decomposition and Dual-stream Focus: A Novel Approach for Training-free Camouflaged Object Segmentation](https://arxiv.org/abs/2506.06818)
*Chao Yin,Hao Li,Kequan Yang,Jide Li,Pinpin Zhu,Xiaoqiang Li*

Main category: cs.CV

TL;DR: RDVP-MSD框架整合视觉提示和多模态逐步分解链式思维，通过空间约束的双流视觉提示解决伪装物体分割中的语义模糊和语义差异问题。无需训练即可在多个基准测试上获得先进的分割效果。


<details>
  <summary>Details</summary>
Motivation: 现有可提示分割方法在伪装物体分割中存在两个主要问题：整体描述导致的语义模糊（前景背景混淆）和全局背景采样导致的语义差异与空间分离（分割无关区域）。

Method: 提出RDVP-MSD：1) MSD-CoT通过逐步分解图像描述消除语义模糊；2) RDVP通过空间约束的双流视觉提示（独立采样前景/背景点）解决语义差异和空间分离问题。无需训练，实现测试时自适应。

Result: 无需训练或监督即在多个COS基准测试中达到SOTA分割效果，推理速度更快，准确率和效率显著提升。代码开源。

Conclusion: 结合区域约束双流视觉提示和多模态逐步分解链式思维，有效解决了伪装物体分割中的语义模糊和采样偏差问题，实现高效零训练分割。

Abstract: While promptable segmentation (\textit{e.g.}, SAM) has shown promise for
various segmentation tasks, it still requires manual visual prompts for each
object to be segmented. In contrast, task-generic promptable segmentation aims
to reduce the need for such detailed prompts by employing only a task-generic
prompt to guide segmentation across all test samples. However, when applied to
Camouflaged Object Segmentation (COS), current methods still face two critical
issues: 1) \textit{\textbf{semantic ambiguity in getting instance-specific text
prompts}}, which arises from insufficient discriminative cues in holistic
captions, leading to foreground-background confusion; 2)
\textit{\textbf{semantic discrepancy combined with spatial separation in
getting instance-specific visual prompts}}, which results from global
background sampling far from object boundaries with low feature correlation,
causing SAM to segment irrelevant regions. To address the issues above, we
propose \textbf{RDVP-MSD}, a novel training-free test-time adaptation framework
that synergizes \textbf{R}egion-constrained \textbf{D}ual-stream
\textbf{V}isual \textbf{P}rompting (RDVP) via \textbf{M}ultimodal
\textbf{S}tepwise \textbf{D}ecomposition Chain of Thought (MSD-CoT). MSD-CoT
progressively disentangles image captions to eliminate semantic ambiguity,
while RDVP injects spatial constraints into visual prompting and independently
samples visual prompts for foreground and background points, effectively
mitigating semantic discrepancy and spatial separation. Without requiring any
training or supervision, RDVP-MSD achieves a state-of-the-art segmentation
result on multiple COS benchmarks and delivers a faster inference speed than
previous methods, demonstrating significantly improved accuracy and efficiency.
The codes will be available at
\href{https://github.com/ycyinchao/RDVP-MSD}{https://github.com/ycyinchao/RDVP-MSD}

</details>


### [295] [Hi-LSplat: Hierarchical 3D Language Gaussian Splatting](https://arxiv.org/abs/2506.06822)
*Chenlu Zhan,Yufei Zhang,Gaoang Wang,Hongwei Wang*

Main category: cs.CV

TL;DR: 提出 Hi-LSplat，一种基于高斯泼溅的层次化语言场，通过构建3D层次语义树和实例聚类来解决视角不一致和开放词汇挑战。


<details>
  <summary>Details</summary>
Motivation: 现有方法使用视图依赖的2D基础模型提炼3D语义，但缺乏统一3D表示导致视角不一致；开放词汇特性引发对象和关系描述不一致。

Method: 1. 通过分层实例聚类构建3D层次语义树，将2D特征提升为3D特征；2. 引入实例级/部件级对比损失；3. 构建两个层次语义评估数据集。

Result: 在3D开放词汇分割/定位任务中表现优异，尤其在构建的层次语义数据集上展现复杂语义理解能力。

Conclusion: Hi-LSplat 实现了视角一致性的3D层次语义建模，开创性解决开放场景下的层次语义理解挑战。

Abstract: Modeling 3D language fields with Gaussian Splatting for open-ended language
queries has recently garnered increasing attention. However, recent 3DGS-based
models leverage view-dependent 2D foundation models to refine 3D semantics but
lack a unified 3D representation, leading to view inconsistencies.
Additionally, inherent open-vocabulary challenges cause inconsistencies in
object and relational descriptions, impeding hierarchical semantic
understanding. In this paper, we propose Hi-LSplat, a view-consistent
Hierarchical Language Gaussian Splatting work for 3D open-vocabulary querying.
To achieve view-consistent 3D hierarchical semantics, we first lift 2D features
to 3D features by constructing a 3D hierarchical semantic tree with layered
instance clustering, which addresses the view inconsistency issue caused by 2D
semantic features. Besides, we introduce instance-wise and part-wise
contrastive losses to capture all-sided hierarchical semantic representations.
Notably, we construct two hierarchical semantic datasets to better assess the
model's ability to distinguish different semantic levels. Extensive experiments
highlight our method's superiority in 3D open-vocabulary segmentation and
localization. Its strong performance on hierarchical semantic datasets
underscores its ability to capture complex hierarchical semantics within 3D
scenes.

</details>


### [296] [Exploring Visual Prompting: Robustness Inheritance and Beyond](https://arxiv.org/abs/2506.06823)
*Qi Li,Liangzhi Li,Zhouqiang Jiang,Bowen Wang,Keke Tang*

Main category: cs.CV

TL;DR: 本文探讨了在稳健源模型下的视觉提示（VP）性能，并提出Prompt Boundary Loosening（PBL）策略以解决VP在继承稳健性和泛化能力之间的权衡问题。


<details>
  <summary>Details</summary>
Motivation: 先前工作仅关注标准源模型下的VP，本文首次研究：稳健源模型能否成功继承稳健性？VP是否面临相同权衡？如何缓解？

Method: 提出轻量级即插即用策略PBL，自然兼容VP设计。通过放松提示边界，确保稳健性继承的同时增强下游数据集泛化能力。

Result: 跨多数据集实验证明：1) VP可继承源模型稳健性但存在权衡 2) PBL在保持稳健性同时显著提升泛化能力（如CIFAR-100上平均提升3.23%）

Conclusion: 首次系统验证VP在稳健源模型下的三个核心问题，所提PBL策略有效解决稳健性-泛化权衡，为VP的稳健迁移提供新方案。

Abstract: Visual Prompting (VP), an efficient method for transfer learning, has shown
its potential in vision tasks. However, previous works focus exclusively on VP
from standard source models, it is still unknown how it performs under the
scenario of a robust source model: Can the robustness of the source model be
successfully inherited? Does VP also encounter the same trade-off between
robustness and generalization ability as the source model during this process?
If such a trade-off exists, is there a strategy specifically tailored to VP to
mitigate this limitation? In this paper, we thoroughly explore these three
questions for the first time and provide affirmative answers to them. To
mitigate the trade-off faced by VP, we propose a strategy called Prompt
Boundary Loosening (PBL). As a lightweight, plug-and-play strategy naturally
compatible with VP, PBL effectively ensures the successful inheritance of
robustness when the source model is a robust model, while significantly
enhancing VP's generalization ability across various downstream datasets.
Extensive experiments across various datasets show that our findings are
universal and demonstrate the significant benefits of the proposed strategy.

</details>


### [297] [Controllable Coupled Image Generation via Diffusion Models](https://arxiv.org/abs/2506.06826)
*Chenfei Yuan,Nanshan Jia,Hangqi Li,Peter W. Glynn,Zeyu Zheng*

Main category: cs.CV

TL;DR: 本文提出了一种注意力级别控制方法，用于解决耦合图像生成任务中背景需保持一致而中心物体需根据文本提示自由生成的问题。该方法通过分离交叉注意力模块中的背景与实体成分，并引入时间相关的权重控制序列，实现了背景耦合与生成灵活性的平衡。


<details>
  <summary>Details</summary>
Motivation: 在耦合图像生成中，需要同时生成多张具有相同背景但中心物体各异的图像。现有方法难以兼顾背景一致性与物体生成自由度，导致背景耦合不足或物体灵活性受限。

Method: 在交叉注意力模块中解耦背景与实体成分；设计时间步相关的权重控制序列，并用综合目标函数优化这些参数。目标函数评估背景耦合度、图文对齐性和视觉质量。

Result: 通过实验证明，本方法在背景耦合度、图文对齐性和视觉质量上均优于现有方法。

Conclusion: 所提出的注意力解耦与动态权重控制机制有效提升了耦合图像生成的性能，为多图像协同生成提供了新思路。

Abstract: We provide an attention-level control method for the task of coupled image
generation, where "coupled" means that multiple simultaneously generated images
are expected to have the same or very similar backgrounds. While backgrounds
coupled, the centered objects in the generated images are still expected to
enjoy the flexibility raised from different text prompts. The proposed method
disentangles the background and entity components in the model's
cross-attention modules, attached with a sequence of time-varying weight
control parameters depending on the time step of sampling. We optimize this
sequence of weight control parameters with a combined objective that assesses
how coupled the backgrounds are as well as text-to-image alignment and overall
visual quality. Empirical results demonstrate that our method outperforms
existing approaches across these criteria.

</details>


### [298] [EndoARSS: Adapting Spatially-Aware Foundation Model for Efficient Activity Recognition and Semantic Segmentation in Endoscopic Surgery](https://arxiv.org/abs/2506.06830)
*Guankun Wang,Rui Tang,Mengya Xu,Long Bai,Huxin Gao,Hongliang Ren*

Main category: cs.CV

TL;DR: 提出了一种名为EndoARSS的多任务学习框架，用于内窥镜手术中的活动识别和语义分割，基于DINOv2基础模型，结合低秩适配器和空间感知多尺度注意力机制，并在三个新数据集上验证了其优越性能。


<details>
  <summary>Details</summary>
Motivation: 内窥镜手术场景复杂，目标与背景特征易混淆，传统深度学习模型在跨活动干扰下表现不佳。通过多任务学习利用任务间关联特征提升整体性能。

Method: 1. 基于DINOv2基础模型进行低秩适配微调；2. 使用任务效率共享低秩适配器减少梯度冲突；3. 引入空间感知多尺度注意力增强全局信息学习。

Result: 在三个新数据集（MTLESD等）上实验表明，EndoARSS在准确性和鲁棒性上显著超越现有模型。

Conclusion: EndoARSS框架通过多任务协同学习有效提升内窥镜手术场景理解能力，为AI驱动的内窥镜手术系统发展提供新方向，有望提高手术安全性和效率。

Abstract: Endoscopic surgery is the gold standard for robotic-assisted minimally
invasive surgery, offering significant advantages in early disease detection
and precise interventions. However, the complexity of surgical scenes,
characterized by high variability in different surgical activity scenarios and
confused image features between targets and the background, presents challenges
for surgical environment understanding. Traditional deep learning models often
struggle with cross-activity interference, leading to suboptimal performance in
each downstream task. To address this limitation, we explore multi-task
learning, which utilizes the interrelated features between tasks to enhance
overall task performance. In this paper, we propose EndoARSS, a novel
multi-task learning framework specifically designed for endoscopy surgery
activity recognition and semantic segmentation. Built upon the DINOv2
foundation model, our approach integrates Low-Rank Adaptation to facilitate
efficient fine-tuning while incorporating Task Efficient Shared Low-Rank
Adapters to mitigate gradient conflicts across diverse tasks. Additionally, we
introduce the Spatially-Aware Multi-Scale Attention that enhances feature
representation discrimination by enabling cross-spatial learning of global
information. In order to evaluate the effectiveness of our framework, we
present three novel datasets, MTLESD, MTLEndovis and MTLEndovis-Gen, tailored
for endoscopic surgery scenarios with detailed annotations for both activity
recognition and semantic segmentation tasks. Extensive experiments demonstrate
that EndoARSS achieves remarkable performance across multiple benchmarks,
significantly improving both accuracy and robustness in comparison to existing
models. These results underscore the potential of EndoARSS to advance AI-driven
endoscopic surgical systems, offering valuable insights for enhancing surgical
safety and efficiency.

</details>


### [299] [Harnessing Vision-Language Models for Time Series Anomaly Detection](https://arxiv.org/abs/2506.06836)
*Zelin He,Sarah Alnegheimish,Matthew Reimherr*

Main category: cs.CV

TL;DR: 提出ViT4TS和VLM4TS两阶段方法，利用视觉语言模型进行时间序列异常检测，解决传统方法缺乏视觉时间推理能力的问题，准确率和效率显著提升。


<details>
  <summary>Details</summary>
Motivation: 现有时间序列异常检测方法缺乏人类专家的视觉时间上下文推理能力，无法有效识别情境异常。

Method: 两阶段框架：1) ViT4TS基于轻量级预训练视觉编码器定位候选异常；2) VLM4TS整合全局时间上下文和VLM推理能力精炼检测结果。

Result: 未经时间序列训练的VLM4TS在F1-max指标上超越最佳基线24.6%，比基于语言模型的方法效率高36倍。

Conclusion: 视觉语言模型可有效提升时间序列异常检测性能，实现准确高效的上下文异常识别。

Abstract: Time-series anomaly detection (TSAD) has played a vital role in a variety of
fields, including healthcare, finance, and industrial monitoring. Prior
methods, which mainly focus on training domain-specific models on numerical
data, lack the visual-temporal reasoning capacity that human experts have to
identify contextual anomalies. To fill this gap, we explore a solution based on
vision language models (VLMs). Recent studies have shown the ability of VLMs
for visual reasoning tasks, yet their direct application to time series has
fallen short on both accuracy and efficiency. To harness the power of VLMs for
TSAD, we propose a two-stage solution, with (1) ViT4TS, a vision-screening
stage built on a relatively lightweight pretrained vision encoder, which
leverages 2-D time-series representations to accurately localize candidate
anomalies; (2) VLM4TS, a VLM-based stage that integrates global temporal
context and VLM reasoning capacity to refine the detection upon the candidates
provided by ViT4TS. We show that without any time-series training, VLM4TS
outperforms time-series pretrained and from-scratch baselines in most cases,
yielding a 24.6 percent improvement in F1-max score over the best baseline.
Moreover, VLM4TS also consistently outperforms existing language-model-based
TSAD methods and is on average 36 times more efficient in token usage.

</details>


### [300] [Multi-StyleGS: Stylizing Gaussian Splatting with Multiple Styles](https://arxiv.org/abs/2506.06846)
*Yangkai Lin,Jiabao Lei,Kui jia*

Main category: cs.CV

TL;DR: 提出Multi-StyleGS方法，使用双向匹配和语义风格损失实现3D高斯点云场景的多风格迁移，保持内存高效并提升视觉一致性。


<details>
  <summary>Details</summary>
Motivation: 现有3D高斯点云建模难以适应多风格迁移需求，且缺乏局部风格控制和训练效率优化。

Method: 使用双向匹配机制关联风格图与局部区域；提出基于分割网络的语义风格损失实现局部风格迁移；采用局部-全局特征匹配增强多视角一致性；正则化分割网络以优化语义标注。

Result: 在内存效率、纹理细节和颜色匹配方面表现优异，实验证明优于现有方法，支持灵活编辑。

Conclusion: Multi-StyleGS通过局部风格控制和一致性优化，有效解决了3D高斯点云多风格化难题，为创意应用提供新工具。

Abstract: In recent years, there has been a growing demand to stylize a given 3D scene
to align with the artistic style of reference images for creative purposes.
While 3D Gaussian Splatting(GS) has emerged as a promising and efficient method
for realistic 3D scene modeling, there remains a challenge in adapting it to
stylize 3D GS to match with multiple styles through automatic local style
transfer or manual designation, while maintaining memory efficiency for
stylization training. In this paper, we introduce a novel 3D GS stylization
solution termed Multi-StyleGS to tackle these challenges. In particular, we
employ a bipartite matching mechanism to au tomatically identify
correspondences between the style images and the local regions of the rendered
images. To facilitate local style transfer, we introduce a novel semantic style
loss function that employs a segmentation network to apply distinct styles to
various objects of the scene and propose a local-global feature matching to
enhance the multi-view consistency. Furthermore, this technique can achieve
memory efficient training, more texture details and better color match. To
better assign a robust semantic label to each Gaussian, we propose several
techniques to regularize the segmentation network. As demonstrated by our
comprehensive experiments, our approach outperforms existing ones in producing
plausible stylization results and offering flexible editing.

</details>


### [301] [Deep Inertial Pose: A deep learning approach for human pose estimation](https://arxiv.org/abs/2506.06850)
*Sara M. Cerqueira,Manuel Palermo,Cristina P. Santos*

Main category: cs.CV

TL;DR: 该研究比较了不同神经网络架构和方法在低成本和高端IMU传感器上进行人体姿态估计的效果，发现结合LSTM的Hybrid LSTM-Madgwick方法误差最低（7.96°），证明神经网络能达到与传统滤波方法相当的精度。


<details>
  <summary>Details</summary>
Motivation: 由于IMU运动捕捉系统需要复杂且专业性的步骤，导致成本高昂（如Xsens的MVN Awinda）。本研究旨在用神经网络取代复杂的生物力学模型和解析数学方法，降低姿态估计的技术门槛。

Method: 1. 对比多种神经网络架构（包括RNN/LSTM等）
2. 使用不同成本传感器数据（MPU9250低端 vs Mtw Awinda高端）
3. 消融实验分析数据增强、输出表示、窗口大小等影响因素

Result: 1. 最佳方法Hybrid LSTM-Madgwick在高端传感器上实现7.96°的四元数角度误差
2. 神经网络方法达到与传统融合滤波器相当的精度（接近当前最优Xsens系统）

Conclusion: 神经网络能有效估计人体姿态，其精度接近工业级动作捕捉系统。通过消融实验明确了关键影响因素（如窗口大小对LSTM的重要性），为低成本IMU系统提供了新方案。

Abstract: Inertial-based Motion capture system has been attracting growing attention
due to its wearability and unsconstrained use. However, accurate human joint
estimation demands several complex and expertise demanding steps, which leads
to expensive software such as the state-of-the-art MVN Awinda from Xsens
Technologies. This work aims to study the use of Neural Networks to abstract
the complex biomechanical models and analytical mathematics required for pose
estimation. Thus, it presents a comparison of different Neural Network
architectures and methodologies to understand how accurately these methods can
estimate human pose, using both low cost(MPU9250) and high end (Mtw Awinda)
Magnetic, Angular Rate, and Gravity (MARG) sensors. The most efficient method
was the Hybrid LSTM-Madgwick detached, which achieved an Quaternion Angle
distance error of 7.96, using Mtw Awinda data. Also, an ablation study was
conducted to study the impact of data augmentation, output representation,
window size, loss function and magnetometer data on the pose estimation error.
This work indicates that Neural Networks can be trained to estimate human pose,
with results comparable to the state-of-the-art fusion filters.

</details>


### [302] [Position Prediction Self-Supervised Learning for Multimodal Satellite Imagery Semantic Segmentation](https://arxiv.org/abs/2506.06852)
*John Waithaka,Moise Busogi*

Main category: cs.CV

TL;DR: 该论文提出了一种针对多模态卫星图像语义分割的自监督学习方法LOCA，通过位置预测任务替代传统的重建方法，显著提升了洪水测绘数据集的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的自监督预训练方法（如MAE）主要关注重建任务，而忽略了定位能力，这对分割至关重要。卫星图像的多模态特性带来了独特挑战。

Method: 扩展SatMAE的通道分组技术以适应多模态数据，引入同组注意力掩码促进跨模态交互，采用相对块位置预测任务训练模型。

Result: 在Sen1Floods11洪水测绘数据集上显著优于现存基于重建的自监督方法。

Conclusion: 针对多模态卫星图像适配的位置预测任务，比基于重建的自监督方法更能学习到适用于语义分割的有效表征。

Abstract: Semantic segmentation of satellite imagery is crucial for Earth observation
applications, but remains constrained by limited labelled training data. While
self-supervised pretraining methods like Masked Autoencoders (MAE) have shown
promise, they focus on reconstruction rather than localisation-a fundamental
aspect of segmentation tasks. We propose adapting LOCA (Location-aware), a
position prediction self-supervised learning method, for multimodal satellite
imagery semantic segmentation. Our approach addresses the unique challenges of
satellite data by extending SatMAE's channel grouping from multispectral to
multimodal data, enabling effective handling of multiple modalities, and
introducing same-group attention masking to encourage cross-modal interaction
during pretraining. The method uses relative patch position prediction,
encouraging spatial reasoning for localisation rather than reconstruction. We
evaluate our approach on the Sen1Floods11 flood mapping dataset, where it
significantly outperforms existing reconstruction-based self-supervised
learning methods for satellite imagery. Our results demonstrate that position
prediction tasks, when properly adapted for multimodal satellite imagery, learn
representations more effective for satellite image semantic segmentation than
reconstruction-based approaches.

</details>


### [303] [DONUT: A Decoder-Only Model for Trajectory Prediction](https://arxiv.org/abs/2506.06854)
*Markus Knoche,Daan de Geus,Bastian Leibe*

Main category: cs.CV

TL;DR: 提出DONUT，一种仅使用解码器的网络，用于轨迹预测，通过自回归模型处理历史轨迹并预测未来轨迹，引入'过预测'策略提升性能，在Argoverse 2基准测试中达到SOTA。


<details>
  <summary>Details</summary>
Motivation: 现有编码器-解码器模型在轨迹预测中存在信息滞后问题，受语言模型中仅解码器模型启发，寻求更一致且实时的预测方法。

Method: 使用单一自回归模型（DONUT）同时编码历史轨迹和预测未来轨迹；引入'过预测'策略，让模型额外预测更长时域的轨迹以增强前瞻能力。

Result: 在Argoverse 2单智能体运动预测基准测试中超越编码器-解码器基线模型，实现新的最先进性能。

Conclusion: 仅解码器结构通过迭代预测提供实时信息更新，配合多时间尺度预测策略，显著提升轨迹预测准确率，为自动驾驶领域提供高效解决方案。

Abstract: Predicting the motion of other agents in a scene is highly relevant for
autonomous driving, as it allows a self-driving car to anticipate. Inspired by
the success of decoder-only models for language modeling, we propose DONUT, a
Decoder-Only Network for Unrolling Trajectories. Different from existing
encoder-decoder forecasting models, we encode historical trajectories and
predict future trajectories with a single autoregressive model. This allows the
model to make iterative predictions in a consistent manner, and ensures that
the model is always provided with up-to-date information, enhancing the
performance. Furthermore, inspired by multi-token prediction for language
modeling, we introduce an 'overprediction' strategy that gives the network the
auxiliary task of predicting trajectories at longer temporal horizons. This
allows the model to better anticipate the future, and further improves the
performance. With experiments, we demonstrate that our decoder-only approach
outperforms the encoder-decoder baseline, and achieves new state-of-the-art
results on the Argoverse 2 single-agent motion forecasting benchmark.

</details>


### [304] [Vision-EKIPL: External Knowledge-Infused Policy Learning for Visual Reasoning](https://arxiv.org/abs/2506.06856)
*Chaoyang Wang,Zeyu Zhang,Haiyun Jiang*

Main category: cs.CV

TL;DR: 本文提出了一种名为Vision-EKIPL的新型强化学习框架，旨在通过引入外部辅助模型生成的高质量动作来增强多模态大语言模型（MLLMs）的视觉推理能力。该方法解决了传统RL训练中采样效率低和模型性能边界受限的问题。


<details>
  <summary>Details</summary>
Motivation: 现有基于强化学习的MLLMs视觉推理方法（如GRPO）仅从策略模型自身采样动作组，限制了模型性能上限并导致训练效率低下。为突破这些限制，需扩展模型探索空间并注入优质知识。

Method: 在RL训练过程中系统性引入外部辅助模型生成的动作作为指导，形成知识注入机制。该架构同时优化策略模型和自我反馈模块，通过知识蒸馏扩展模型边界并加速收敛。

Result: 在Reason-RFT-CoT基准测试中实现最高5%的性能提升（相比SOTA），显著加快训练收敛速度（例如减少40%训练步数达到相同准确率）。

Conclusion: Vision-EKIPL克服了传统RL方法的固有局限性，为增强MLLMs的视觉推理性能提供了新范式，其知识注入机制可扩展应用于其它序列决策任务。

Abstract: Visual reasoning is crucial for understanding complex multimodal data and
advancing Artificial General Intelligence. Existing methods enhance the
reasoning capability of Multimodal Large Language Models (MLLMs) through
Reinforcement Learning (RL) fine-tuning (e.g., GRPO). However, current RL
approaches sample action groups solely from the policy model itself, which
limits the upper boundary of the model's reasoning capability and leads to
inefficient training. To address these limitations, this paper proposes a novel
RL framework called \textbf{Vision-EKIPL}. The core of this framework lies in
introducing high-quality actions generated by external auxiliary models during
the RL training process to guide the optimization of the policy model. The
policy learning with knowledge infusion from external models significantly
expands the model's exploration space, effectively improves the reasoning
boundary, and substantially accelerates training convergence speed and
efficiency. Experimental results demonstrate that our proposed Vision-EKIPL
achieved up to a 5\% performance improvement on the Reason-RFT-CoT Benchmark
compared to the state-of-the-art (SOTA). It reveals that Vision-EKIPL can
overcome the limitations of traditional RL methods, significantly enhance the
visual reasoning performance of MLLMs, and provide a new effective paradigm for
research in this field.

</details>


### [305] [Face recognition on point cloud with cgan-top for denoising](https://arxiv.org/abs/2506.06864)
*Junyu Liu,Jianfeng Ren,Sunhong Liang,Xudong Jiang*

Main category: cs.CV

TL;DR: 提出了一种端到端的3D点云人脸识别方法，集成了去噪和识别模块。使用cGAN-TOP去除噪声并恢复特征，采用LDGCNN进行多尺度特征提取的人脸识别。在Bosphorus数据集上验证，最大提升14.81%的准确率。


<details>
  <summary>Details</summary>
Motivation: 原始点云常因传感器不完善含有大量噪声，影响人脸识别性能。需要同时解决去噪和识别问题以提升准确性。

Method: 1) 设计基于三正交平面的条件生成对抗网络(cGAN-TOP)进行点云去噪；2) 改进链接动态图卷积神经网络(LDGCNN)，分层融合局部点特征和多尺度邻域特征进行识别。

Result: 在Bosphorus数据集上测试，所有噪声设置下识别准确率均显著提升，最高提升幅度达14.81%。

Conclusion: 通过联合优化去噪与识别模块的端到端框架，有效提升噪声点云环境下的3D人脸识别精度，证实了集成方法的优越性。

Abstract: Face recognition using 3D point clouds is gaining growing interest, while raw
point clouds often contain a significant amount of noise due to imperfect
sensors. In this paper, an end-to-end 3D face recognition on a noisy point
cloud is proposed, which synergistically integrates the denoising and
recognition modules. Specifically, a Conditional Generative Adversarial Network
on Three Orthogonal Planes (cGAN-TOP) is designed to effectively remove the
noise in the point cloud, and recover the underlying features for subsequent
recognition. A Linked Dynamic Graph Convolutional Neural Network (LDGCNN) is
then adapted to recognize faces from the processed point cloud, which
hierarchically links both the local point features and neighboring features of
multiple scales. The proposed method is validated on the Bosphorus dataset. It
significantly improves the recognition accuracy under all noise settings, with
a maximum gain of 14.81%.

</details>


### [306] [Hybrid Vision Transformer-Mamba Framework for Autism Diagnosis via Eye-Tracking Analysis](https://arxiv.org/abs/2506.06886)
*Wafaa Kasri,Yassine Himeur,Abigail Copiaco,Wathiq Mansoor,Ammar Albanna,Valsamma Eapen*

Main category: cs.CV

TL;DR: 本研究提出了一个结合视觉Transformer(ViT)和Vision Mamba的混合深度学习框架，利用眼动追踪数据检测自闭症谱系障碍(ASD)，通过多模态融合和可解释AI技术，在Saliency4ASD数据集上取得SOTA性能（准确率0.96），为资源有限地区提供 scalable 的ASD筛查方案。


<details>
  <summary>Details</summary>
Motivation: 自闭症的早期诊断对干预治疗至关重要，但在资源有限或偏远地区，专业诊断可及性差。目前基于手工特征的传统方法在准确性和可解释性上存在局限，需要开发更精确透明的自动化诊断工具。

Method: 1. 提出ViT-Mamba混合架构，结合视觉Transformer的空间建模能力和Mamba模型的长序列建模优势；2. 采用注意力融合机制整合视觉、语音和面部表情多模态线索；3. 应用可解释AI技术提高模型透明度。

Result: 在Saliency4ASD数据集上评估：准确率0.96，F1值0.95，灵敏度0.97，特异度0.94，全面超越现有方法。

Conclusion: 该模型通过多模态时序特征融合和可解释设计，实现了高精度且透明的ASD筛查，特别适合医疗资源匮乏地区部署，为自闭症早期诊断提供了有效的深度学习解决方案。

Abstract: Accurate Autism Spectrum Disorder (ASD) diagnosis is vital for early
intervention. This study presents a hybrid deep learning framework combining
Vision Transformers (ViT) and Vision Mamba to detect ASD using eye-tracking
data. The model uses attention-based fusion to integrate visual, speech, and
facial cues, capturing both spatial and temporal dynamics. Unlike traditional
handcrafted methods, it applies state-of-the-art deep learning and explainable
AI techniques to enhance diagnostic accuracy and transparency. Tested on the
Saliency4ASD dataset, the proposed ViT-Mamba model outperformed existing
methods, achieving 0.96 accuracy, 0.95 F1-score, 0.97 sensitivity, and 0.94
specificity. These findings show the model's promise for scalable,
interpretable ASD screening, especially in resource-constrained or remote
clinical settings where access to expert diagnosis is limited.

</details>


### [307] [NSD-Imagery: A benchmark dataset for extending fMRI vision decoding methods to mental imagery](https://arxiv.org/abs/2506.06898)
*Reese Kneeland,Paul S. Scotti,Ghislain St-Yves,Jesse Breedlove,Kendrick Kay,Thomas Naselaris*

Main category: cs.CV

TL;DR: 本文提出了一个新的基准数据集NSD-Imagery用于分析心智图像重建中的视觉解码模型性能。实验发现模型在视觉重建和心智图像解码之间存在性能解耦现象，并且线性架构在跨任务解码方面表现更佳。


<details>
  <summary>Details</summary>
Motivation: 随着自然场景数据集NSD的出现，视觉重建模型在'所见图像'重建上表现优异，但这些模型在'心智图像'（大脑内部生成图像）上是否具有泛化能力尚未被验证。而这一能力对医学和脑机接口的实际应用至关重要。

Method: 首先建立NSD-Imagery数据集（包含心智图像的fMRI数据）、然后在多个NSD训练的开源视觉解码模型（MindEye1/2, Brain Diffuser等）上进行能力评估。使用线性回归和交叉验证方法衡量不同架构在'所见图像→心智图像'跨任务解码中的效果。

Result: 模型在视觉重建任务和心智图像解码任务上的性能存在明显差异（相关性仅为0.04）；线性解码架构相比复杂模型在跨任务解码中显示出更强的泛化性能，尤其在样本外测试条件下差距可达20%-35%。

Conclusion: 说明模型在所见图像上的优秀表现不能泛化到心智图像任务；心智图像数据集对开发实际应用至关重要；简单线性模型在图像特征解码上更具迁移优势。该数据集可作为研究基准支持相关领域的评估需求。

Abstract: We release NSD-Imagery, a benchmark dataset of human fMRI activity paired
with mental images, to complement the existing Natural Scenes Dataset (NSD), a
large-scale dataset of fMRI activity paired with seen images that enabled
unprecedented improvements in fMRI-to-image reconstruction efforts. Recent
models trained on NSD have been evaluated only on seen image reconstruction.
Using NSD-Imagery, it is possible to assess how well these models perform on
mental image reconstruction. This is a challenging generalization requirement
because mental images are encoded in human brain activity with relatively lower
signal-to-noise and spatial resolution; however, generalization from seen to
mental imagery is critical for real-world applications in medical domains and
brain-computer interfaces, where the desired information is always internally
generated. We provide benchmarks for a suite of recent NSD-trained open-source
visual decoding models (MindEye1, MindEye2, Brain Diffuser, iCNN, Takagi et
al.) on NSD-Imagery, and show that the performance of decoding methods on
mental images is largely decoupled from performance on vision reconstruction.
We further demonstrate that architectural choices significantly impact
cross-decoding performance: models employing simple linear decoding
architectures and multimodal feature decoding generalize better to mental
imagery, while complex architectures tend to overfit visual training data. Our
findings indicate that mental imagery datasets are critical for the development
of practical applications, and establish NSD-Imagery as a useful resource for
better aligning visual decoding methods with this goal.

</details>


### [308] [KNN-Defense: Defense against 3D Adversarial Point Clouds using Nearest-Neighbor Search](https://arxiv.org/abs/2506.06906)
*Nima Jamali,Matina Mahdizadeh Sani,Hanieh Naderi,Shohreh Kasaei*

Main category: cs.CV

TL;DR: 论文提出KNN-Defense方法，通过特征空间最近邻搜索恢复受对抗攻击的点云，显著提升3D点云分类器的鲁棒性


<details>
  <summary>Details</summary>
Motivation: 3D点云容易受对抗攻击（如点丢弃、移动、添加），现有防御机制效果有限，需要兼顾语义完整性和实时性的解决方案

Method: 基于流形假设和特征空间最近邻搜索，利用训练集样本的语义相似性恢复被篡改点云

Result: 在ModelNet40数据集上，针对点丢弃攻击，PointNet/PointNet++/DGCNN/PCT模型准确率分别提升20.1%/3.6%/3.44%/7.74%

Conclusion: KNN-Defense是轻量高效的可扩展方案，能增强3D点云分类器的对抗鲁棒性

Abstract: Deep neural networks (DNNs) have demonstrated remarkable performance in
analyzing 3D point cloud data. However, their vulnerability to adversarial
attacks-such as point dropping, shifting, and adding-poses a critical challenge
to the reliability of 3D vision systems. These attacks can compromise the
semantic and structural integrity of point clouds, rendering many existing
defense mechanisms ineffective. To address this issue, a defense strategy named
KNN-Defense is proposed, grounded in the manifold assumption and
nearest-neighbor search in feature space. Instead of reconstructing surface
geometry or enforcing uniform point distributions, the method restores
perturbed inputs by leveraging the semantic similarity of neighboring samples
from the training set. KNN-Defense is lightweight and computationally
efficient, enabling fast inference and making it suitable for real-time and
practical applications. Empirical results on the ModelNet40 dataset
demonstrated that KNN-Defense significantly improves robustness across various
attack types. In particular, under point-dropping attacks-where many existing
methods underperform due to the targeted removal of critical points-the
proposed method achieves accuracy gains of 20.1%, 3.6%, 3.44%, and 7.74% on
PointNet, PointNet++, DGCNN, and PCT, respectively. These findings suggest that
KNN-Defense offers a scalable and effective solution for enhancing the
adversarial resilience of 3D point cloud classifiers. (An open-source
implementation of the method, including code and data, is available at
https://github.com/nimajam41/3d-knn-defense).

</details>


### [309] [Gaussian Mapping for Evolving Scenes](https://arxiv.org/abs/2506.06909)
*Vladimir Yugay,Thies Kersten,Luca Carlone,Theo Gevers,Martin R. Oswald,Lukas Schmid*

Main category: cs.CV

TL;DR: GaME是一种适用于长期动态场景的3D建图方法，通过动态场景适应机制和关键帧管理机制解决现有静态场景方法的局限性，在合成和真实数据集上优于现有技术。


<details>
  <summary>Details</summary>
Motivation: 现有基于3D高斯泼溅的建图系统主要针对静态场景，虽然近期工作开始处理短期动态（镜头内运动），但长期动态（镜头外场景演变）仍缺乏研究。为此，需要解决场景持续更新时几何与语义一致性的挑战。

Method: 1) 动态场景适应机制：持续更新3D表示以反映最新变化；2) 关键帧管理机制：通过选择性丢弃过时观测来维持重建过程的连贯性，同时保留最大化有效信息。

Result: 在合成与真实数据集上，GaME的精度优于现有最优方法（state of the art）。

Conclusion: GaME通过两种创新机制有效解决了长期动态场景建模问题，为增强现实、机器人等应用提供了更鲁棒的建图方案。

Abstract: Mapping systems with novel view synthesis (NVS) capabilities are widely used
in computer vision, with augmented reality, robotics, and autonomous driving
applications. Most notably, 3D Gaussian Splatting-based systems show high NVS
performance; however, many current approaches are limited to static scenes.
While recent works have started addressing short-term dynamics (motion within
the view of the camera), long-term dynamics (the scene evolving through changes
out of view) remain less explored. To overcome this limitation, we introduce a
dynamic scene adaptation mechanism that continuously updates the 3D
representation to reflect the latest changes. In addition, since maintaining
geometric and semantic consistency remains challenging due to stale
observations disrupting the reconstruction process, we propose a novel keyframe
management mechanism that discards outdated observations while preserving as
much information as possible. We evaluate Gaussian Mapping for Evolving Scenes
(GaME) on both synthetic and real-world datasets and find it to be more
accurate than the state of the art.

</details>


### [310] [Sleep Stage Classification using Multimodal Embedding Fusion from EOG and PSM](https://arxiv.org/abs/2506.06912)
*Olivier Papillon,Rafik Goubran,James Green,Julien Larivière-Chartier,Caitlin Higginson,Frank Knoefel,Rébecca Robillard*

Main category: cs.CV

TL;DR: 该论文提出了一种利用ImageBind多模态嵌入深度学习模型，融合压感垫（PSM）和双通道眼电图（EOG）数据进行睡眠阶段分类的新方法，在家庭睡眠监测中作为传统脑电图（EEG）的替代方案。


<details>
  <summary>Details</summary>
Motivation: 传统的多导睡眠图（PSG）依赖EEG作为金标准，但其复杂性和对专业设备的需求使得家庭睡眠监测困难。因此研究使用更便捷的EOG和PSM作为替代方案。

Method: 引入ImageBind模型融合PSM数据和双通道EOG信号进行分类，是首个融合这两种数据并使用ImageBind的方法。包括微调和非微调两种模式。

Result: 微调后显著提升分类准确率，优于基于单通道EOG的DeepSleepNet、纯PSM的ViViT及其他多模态方法（MBT）。在85晚临床数据上验证，接近需要复杂EEG的系统的准确率。

Conclusion: 预训练多模态嵌入模型（即使是非医学领域开发的）能有效应用于睡眠分期，在有限标注数据下表现优异，为家庭睡眠监测提供可行替代方案。

Abstract: Accurate sleep stage classification is essential for diagnosing sleep
disorders, particularly in aging populations. While traditional polysomnography
(PSG) relies on electroencephalography (EEG) as the gold standard, its
complexity and need for specialized equipment make home-based sleep monitoring
challenging. To address this limitation, we investigate the use of
electrooculography (EOG) and pressure-sensitive mats (PSM) as less obtrusive
alternatives for five-stage sleep-wake classification. This study introduces a
novel approach that leverages ImageBind, a multimodal embedding deep learning
model, to integrate PSM data with dual-channel EOG signals for sleep stage
classification. Our method is the first reported approach that fuses PSM and
EOG data for sleep stage classification with ImageBind. Our results demonstrate
that fine-tuning ImageBind significantly improves classification accuracy,
outperforming existing models based on single-channel EOG (DeepSleepNet),
exclusively PSM data (ViViT), and other multimodal deep learning approaches
(MBT). Notably, the model also achieved strong performance without fine-tuning,
highlighting its adaptability to specific tasks with limited labeled data,
making it particularly advantageous for medical applications. We evaluated our
method using 85 nights of patient recordings from a sleep clinic. Our findings
suggest that pre-trained multimodal embedding models, even those originally
developed for non-medical domains, can be effectively adapted for sleep
staging, with accuracies approaching systems that require complex EEG data.

</details>


### [311] [Reading in the Dark with Foveated Event Vision](https://arxiv.org/abs/2506.06918)
*Carl Brander,Giovanni Cioffi,Nico Messikommer,Davide Scaramuzza*

Main category: cs.CV

TL;DR: 提出一种基于事件相机和眼动追踪的智能眼镜OCR方法，在弱光和高速场景下优于传统方案，大幅降低带宽需求。


<details>
  <summary>Details</summary>
Motivation: 智能眼镜的RGB相机在弱光、高速运动场景存在动态范围有限、运动模糊问题，且密集图像采集导致高带宽、高功耗。为解决文本读取难题，需创新方案。

Method: 1) 利用用户眼动聚焦事件流，减少98%带宽 2) 基于合成数据训练深度二值重建模型 3) 结合多模态大语言模型实现OCR

Result: 在RGB相机失效的弱光环境下成功读取文本，比可穿戴RGB相机降低2400倍带宽消耗，性能超越传统OCR方案。

Conclusion: 事件相机结合眼动追踪的OCR架构突破传统限制，为智能眼镜文本读取提供高效低功耗解决方案。

Abstract: Current smart glasses equipped with RGB cameras struggle to perceive the
environment in low-light and high-speed motion scenarios due to motion blur and
the limited dynamic range of frame cameras. Additionally, capturing dense
images with a frame camera requires large bandwidth and power consumption,
consequently draining the battery faster. These challenges are especially
relevant for developing algorithms that can read text from images. In this
work, we propose a novel event-based Optical Character Recognition (OCR)
approach for smart glasses. By using the eye gaze of the user, we foveate the
event stream to significantly reduce bandwidth by around 98% while exploiting
the benefits of event cameras in high-dynamic and fast scenes. Our proposed
method performs deep binary reconstruction trained on synthetic data and
leverages multimodal LLMs for OCR, outperforming traditional OCR solutions. Our
results demonstrate the ability to read text in low light environments where
RGB cameras struggle while using up to 2400 times less bandwidth than a
wearable RGB camera.

</details>


### [312] [How Important are Videos for Training Video LLMs?](https://arxiv.org/abs/2506.06928)
*George Lydakis,Alexander Hermans,Ali Athar,Daan de Geus,Bastian Leibe*

Main category: cs.CV

TL;DR: 本文发现经过图像训练的V-LLMs在时序推理上的表现超出预期，而针对视频的特定训练提升效果却很小。作者引入了一种基于标注图像序列的微调方案，其表现与视频训练的模型相当，甚至更好，表明当前模型未能充分利用视频中的时序特征。


<details>
  <summary>Details</summary>
Motivation: 当前视频大语言模型通常使用预训练的文本LLM初始化后，在图像和视频数据上微调。本文旨在研究图像训练对V-LLMs时序推理能力的影响，并发现视频训练的收益有限。

Method: 使用LongVU算法训练两模型，在图像数据集上训练后评估其在时序基准TVBench上的表现。并引入一种简单基线：使用带有时序问题的标注图像序列进行微调。

Result: (1)仅图像训练的模型在TVBench上表现显著高于随机水平； (2)新微调方案在时序任务上与视频训练模型相当或更好； (3)当前视频模型未能有效利用视频中的丰富时序特征。

Conclusion: 传统视频训练方案效率低下，图像训练已具备隐含时序推理能力。需深入研究图像模型为何能学习时序推理，以及现有视频模型低效的瓶颈。

Abstract: Research into Video Large Language Models (LLMs) has progressed rapidly, with
numerous models and benchmarks emerging in just a few years. Typically, these
models are initialized with a pretrained text-only LLM and finetuned on both
image- and video-caption datasets. In this paper, we present findings
indicating that Video LLMs are more capable of temporal reasoning after
image-only training than one would assume, and that improvements from
video-specific training are surprisingly small. Specifically, we show that
image-trained versions of two LLMs trained with the recent LongVU algorithm
perform significantly above chance level on TVBench, a temporal reasoning
benchmark. Additionally, we introduce a simple finetuning scheme involving
sequences of annotated images and questions targeting temporal capabilities.
This baseline results in temporal reasoning performance close to, and
occasionally higher than, what is achieved by video-trained LLMs. This suggests
suboptimal utilization of rich temporal features found in real video by current
models. Our analysis motivates further research into the mechanisms that allow
image-trained LLMs to perform temporal reasoning, as well as into the
bottlenecks that render current video training schemes inefficient.

</details>


### [313] [Polar Hierarchical Mamba: Towards Streaming LiDAR Object Detection with Point Clouds as Egocentric Sequences](https://arxiv.org/abs/2506.06944)
*Mellon M. Zhang,Glen Chou,Saibal Mukhopadhyay*

Main category: cs.CV

TL;DR: 我们提出了Polar Hierarchical Mamba (PHiM)，一种用于极坐标流式LiDAR的新型状态空间模型架构，在Waymo开放数据集上超越了现有流式检测器10%，并在吞吐量翻倍的情况下达到全扫描基线水平。


<details>
  <summary>Details</summary>
Motivation: 当前LiDAR流式处理方法在极坐标系中使用平移不变的卷积，导致性能下降或需要复杂的畸变校正；而现有的Mamba模型仅适用于全扫描场景且依赖内存密集型的位置嵌入。

Method: PHiM采用局部双向Mamba块进行扇区内空间编码，用全局前向Mamba实现扇区间时序建模，通过维度分解操作替代卷积和位置编码。

Result: 在Waymo数据集上，PHiM将流式检测器性能提升10%，吞吐量达全扫描基准的2倍，且无需位置嵌入。

Conclusion: PHiM证明了在极坐标流式LiDAR感知中，通过层级Mamba架构替代卷积的优越性，为实时自动驾驶感知提供了高效解决方案。

Abstract: Accurate and efficient object detection is essential for autonomous vehicles,
where real-time perception requires low latency and high throughput. LiDAR
sensors provide robust depth information, but conventional methods process full
360{\deg} scans in a single pass, introducing significant delay. Streaming
approaches address this by sequentially processing partial scans in the native
polar coordinate system, yet they rely on translation-invariant convolutions
that are misaligned with polar geometry -- resulting in degraded performance or
requiring complex distortion mitigation. Recent Mamba-based state space models
(SSMs) have shown promise for LiDAR perception, but only in the full-scan
setting, relying on geometric serialization and positional embeddings that are
memory-intensive and ill-suited to streaming. We propose Polar Hierarchical
Mamba (PHiM), a novel SSM architecture designed for polar-coordinate streaming
LiDAR. PHiM uses local bidirectional Mamba blocks for intra-sector spatial
encoding and a global forward Mamba for inter-sector temporal modeling,
replacing convolutions and positional encodings with distortion-aware,
dimensionally-decomposed operations. PHiM sets a new state-of-the-art among
streaming detectors on the Waymo Open Dataset, outperforming the previous best
by 10\% and matching full-scan baselines at twice the throughput. Code will be
available at https://github.com/meilongzhang/Polar-Hierarchical-Mamba .

</details>


### [314] [LaTtE-Flow: Layerwise Timestep-Expert Flow-based Transformer](https://arxiv.org/abs/2506.06952)
*Ying Shen,Zhiyang Xu,Jiuhai Chen,Shizhe Diao,Jiaxin Zhang,Yuguang Yao,Joy Rimchala,Ismini Lourentzou,Lifu Huang*

Main category: cs.CV

TL;DR: LaTtE-Flow是一种新型高效的多模态架构，通过层间时间步专家和流匹配技术统一图像理解和生成。在继承视觉语言模型强大理解能力的同时，显著提升生成速度6倍，并保持竞争力表现。


<details>
  <summary>Details</summary>
Motivation: 现有统一模型需要大量预训练且难以兼顾理解/生成任务性能，尤其生成速度慢影响实际部署。

Method: 在预训练VLM基础上引入层间时间步专家流结构：1) 分层分配时间步给特定层组 2) 添加时间步条件残差注意力机制复用信息。

Result: 多模态理解任务表现强劲；图像生成质量具竞争力且推理速度比同类统一模型快约6倍。

Conclusion: 通过专用层结构和注意力机制，首次在单一模型中高效统一理解与生成，为实时多模态应用铺平道路。

Abstract: Recent advances in multimodal foundation models unifying image understanding
and generation have opened exciting avenues for tackling a wide range of
vision-language tasks within a single framework. Despite progress, existing
unified models typically require extensive pretraining and struggle to achieve
the same level of performance compared to models dedicated to each task.
Additionally, many of these models suffer from slow image generation speeds,
limiting their practical deployment in real-time or resource-constrained
settings. In this work, we propose Layerwise Timestep-Expert Flow-based
Transformer (LaTtE-Flow), a novel and efficient architecture that unifies image
understanding and generation within a single multimodal model. LaTtE-Flow
builds upon powerful pretrained Vision-Language Models (VLMs) to inherit strong
multimodal understanding capabilities, and extends them with a novel Layerwise
Timestep Experts flow-based architecture for efficient image generation.
LaTtE-Flow distributes the flow-matching process across specialized groups of
Transformer layers, each responsible for a distinct subset of timesteps. This
design significantly improves sampling efficiency by activating only a small
subset of layers at each sampling timestep. To further enhance performance, we
propose a Timestep-Conditioned Residual Attention mechanism for efficient
information reuse across layers. Experiments demonstrate that LaTtE-Flow
achieves strong performance on multimodal understanding tasks, while achieving
competitive image generation quality with around 6x faster inference speed
compared to recent unified multimodal models.

</details>


### [315] [Task-driven real-world super-resolution of document scans](https://arxiv.org/abs/2506.06953)
*Maciej Zyrek,Tomasz Tarasiewicz,Jakub Sadel,Aleksandra Krzywon,Michal Kawulok*

Main category: cs.CV

TL;DR: 本文介绍了一种面向OCR任务优化的多任务学习图像超分辨率框架，通过结合文字检测、识别、关键点定位和色调一致性等多个辅助任务的动态加权损失函数，提升了在真实场景文档扫描图像上的超分辨率性能，弥补仿真训练与实际应用间的差距。


<details>
  <summary>Details</summary>
Motivation: 解决现有深度超分辨率方法在真实场景（如文档扫描）中因复杂退化等问题导致的泛化不足，通过优化OCR任务效果提升实用价值。

Method: 在SRResNet架构上加入多个辅助损失函数（包括文本检测、文本识别、关键点定位和色调一致性），采用动态加权平均机制调整各损失权重。

Result: 在仿真和真实文档数据集上验证表明，该方法改善了IoU指标衡量的文本检测精度，同时保持图像整体保真度。

Conclusion: 多目标优化能有效弥合超分辨率模型在仿真训练与实际部署间的差异，且动态加权机制对多任务平衡至关重要。

Abstract: Single-image super-resolution refers to the reconstruction of a
high-resolution image from a single low-resolution observation. Although recent
deep learning-based methods have demonstrated notable success on simulated
datasets -- with low-resolution images obtained by degrading and downsampling
high-resolution ones -- they frequently fail to generalize to real-world
settings, such as document scans, which are affected by complex degradations
and semantic variability. In this study, we introduce a task-driven, multi-task
learning framework for training a super-resolution network specifically
optimized for optical character recognition tasks. We propose to incorporate
auxiliary loss functions derived from high-level vision tasks, including text
detection using the connectionist text proposal network, text recognition via a
convolutional recurrent neural network, keypoints localization using Key.Net,
and hue consistency. To balance these diverse objectives, we employ dynamic
weight averaging mechanism, which adaptively adjusts the relative importance of
each loss term based on its convergence behavior. We validate our approach upon
the SRResNet architecture, which is a well-established technique for
single-image super-resolution. Experimental evaluations on both simulated and
real-world scanned document datasets demonstrate that the proposed approach
improves text detection, measured with intersection over union, while
preserving overall image fidelity. These findings underscore the value of
multi-objective optimization in super-resolution models for bridging the gap
between simulated training regimes and practical deployment in real-world
scenarios.

</details>


### [316] [AR-RAG: Autoregressive Retrieval Augmentation for Image Generation](https://arxiv.org/abs/2506.06962)
*Jingyuan Qi,Zhiyang Xu,Qifan Wang,Lifu Huang*

Main category: cs.CV

TL;DR: 本文提出AR-RAG新框架，通过自回归式检索增强实现动态图像生成，缓解传统单次检索的局限性，并开发了DAiD和FAiD两种实现方案，在多个基准测试中超越SOTA。


<details>
  <summary>Details</summary>
Motivation: 解决现有图像生成方法中单次静态检索导致的过复制、风格僵化等问题，实现动态适应生成需求的增强机制。

Method: 提出两种方案：1) DAiD训练即插即用策略：将模型预测分布与检索分布融合；2) FAiD参数微调方法：通过多尺度卷积处理检索特征并增强生成过程。在patch级别进行自回归检索。

Result: 在Midjourney-30K/GenEval/DPG-Bench等基准测试中显著超越现有最佳图像生成模型。

Conclusion: AR-RAG通过动态检索机制突破传统限制，DAiD/FAiD两种实现方案各具优势，为生成模型提供新范式。

Abstract: We introduce Autoregressive Retrieval Augmentation (AR-RAG), a novel paradigm
that enhances image generation by autoregressively incorporating knearest
neighbor retrievals at the patch level. Unlike prior methods that perform a
single, static retrieval before generation and condition the entire generation
on fixed reference images, AR-RAG performs context-aware retrievals at each
generation step, using prior-generated patches as queries to retrieve and
incorporate the most relevant patch-level visual references, enabling the model
to respond to evolving generation needs while avoiding limitations (e.g.,
over-copying, stylistic bias, etc.) prevalent in existing methods. To realize
AR-RAG, we propose two parallel frameworks: (1) Distribution-Augmentation in
Decoding (DAiD), a training-free plug-and-use decoding strategy that directly
merges the distribution of model-predicted patches with the distribution of
retrieved patches, and (2) Feature-Augmentation in Decoding (FAiD), a
parameter-efficient fine-tuning method that progressively smooths the features
of retrieved patches via multi-scale convolution operations and leverages them
to augment the image generation process. We validate the effectiveness of
AR-RAG on widely adopted benchmarks, including Midjourney-30K, GenEval and
DPG-Bench, demonstrating significant performance gains over state-of-the-art
image generation models.

</details>


### [317] [Dual-view Spatio-Temporal Feature Fusion with CNN-Transformer Hybrid Network for Chinese Isolated Sign Language Recognition](https://arxiv.org/abs/2506.06966)
*Siyuan Jing,Guangxue Wang,Haoyang Zhai,Qin Tao,Jun Yang,Bing Wang,Peng Jin*

Main category: cs.CV

TL;DR: 该论文提出了一个双视角的中国手语数据集NationalCSL-DP，包含134140个手语视频，覆盖全部国家手语词汇。针对单视角视频的手部遮挡问题，作者同时提出基于CNN-Transformer的基线模型及简单有效的预测融合策略。实验表明该融合策略显著提升识别性能，但序列模型难以有效学习双视角互补特征。


<details>
  <summary>Details</summary>
Motivation: 现有手语数据集存在两个主要问题：(1)词汇覆盖不完整；(2)仅提供单视角RGB视频导致手部遮挡难以处理。为此，作者构建双视角数据集并开发融合方法，旨在提升孤立手语识别的实际应用能力。

Method: 1) 创建NationalCSL-DP数据集：10位手语表演者录制134140个双视角（正面+左侧）视频，覆盖中国国家标准手语词汇。2) 提出CNN-Transformer基线模型，设计简单但有效的预测融合策略（非特征级融合）。

Result: 实验证明：1) 双视角数据有效解决手部遮挡问题；2) 提出的预测融合策略显著提升识别准确率（具体数值未提及）；3) 序列模型（如RNN/LSTM）的早期/晚期融合策略难以有效学习双视角互补特征。

Conclusion: NationalCSL-DP是首个覆盖完整中国手语词汇的双视角数据集；所提预测融合策略优于传统序列模型融合方法；未来需探索更有效的多视角特征融合架构。

Abstract: Due to the emergence of many sign language datasets, isolated sign language
recognition (ISLR) has made significant progress in recent years. In addition,
the development of various advanced deep neural networks is another reason for
this breakthrough. However, challenges remain in applying the technique in the
real world. First, existing sign language datasets do not cover the whole sign
vocabulary. Second, most of the sign language datasets provide only single view
RGB videos, which makes it difficult to handle hand occlusions when performing
ISLR. To fill this gap, this paper presents a dual-view sign language dataset
for ISLR named NationalCSL-DP, which fully covers the Chinese national sign
language vocabulary. The dataset consists of 134140 sign videos recorded by ten
signers with respect to two vertical views, namely, the front side and the left
side. Furthermore, a CNN transformer network is also proposed as a strong
baseline and an extremely simple but effective fusion strategy for prediction.
Extensive experiments were conducted to prove the effectiveness of the datasets
as well as the baseline. The results show that the proposed fusion strategy can
significantly increase the performance of the ISLR, but it is not easy for the
sequence-to-sequence model, regardless of whether the early-fusion or
late-fusion strategy is applied, to learn the complementary features from the
sign videos of two vertical views.

</details>


### [318] [Guiding Cross-Modal Representations with MLLM Priors via Preference Alignment](https://arxiv.org/abs/2506.06970)
*Pengfei Zhao,Rongbo Luan,Wei Zhang,Peng Wu,Sifeng He*

Main category: cs.CV

TL;DR: MAPLE框架通过MLLMs的精细对齐先验指导跨模态表示学习，提出了自动偏好数据构建和相对偏好对齐损失，在细粒度跨模态检索中取得显著效果提升。


<details>
  <summary>Details</summary>
Motivation: 尽管CLIP在跨模态检索中表现出色，但其特征空间仍存在显著模态差异。现有MLLMs具有内在模态对齐特性，但其粗粒度对齐机制限制了潜力。

Method: 提出MAPLE框架：1) 利用现成MLLMs自动构建偏好数据；2) 创新相对偏好对齐(RPA)损失函数，将DPO适应嵌入学习场景。

Result: 实验证明该方法在细粒度跨模态检索任务中取得显著提升，有效处理细微语义差异。

Conclusion: MAPLE通过MLLMs的精细对齐先验指导学习，以强化学习形式显著减小模态鸿沟，为跨模态表示学习提供新方向。

Abstract: Despite Contrastive Language-Image Pretraining (CLIP)'s remarkable capability
to retrieve content across modalities, a substantial modality gap persists in
its feature space. Intriguingly, we discover that off-the-shelf MLLMs
(Multimodal Large Language Models) demonstrate powerful inherent modality
alignment properties. While recent MLLM-based retrievers with unified
architectures partially mitigate this gap, their reliance on coarse modality
alignment mechanisms fundamentally limits their potential. In this work, We
introduce MAPLE (Modality-Aligned Preference Learning for Embeddings), a novel
framework that leverages the fine grained alignment priors inherent in MLLM to
guide cross modal representation learning. MAPLE formulates the learning
process as reinforcement learning with two key components: (1) Automatic
preference data construction using off-the-shelf MLLM, and (2) a new Relative
Preference Alignment (RPA) loss, which adapts Direct Preference Optimization
(DPO) to the embedding learning setting. Experimental results show that our
preference-guided alignment achieves substantial gains in fine-grained
cross-modal retrieval, underscoring its effectiveness in handling nuanced
semantic distinctions.

</details>


### [319] [Hybrid Mesh-Gaussian Representation for Efficient Indoor Scene Reconstruction](https://arxiv.org/abs/2506.06988)
*Binxiao Huang,Zhihao Li,Shiyong Liu,Xiao Tang,Jiajun Tang,Jiaqi Lin,Yuxin Cheng,Zhenyu Chen,Xiaofei Wu,Ngai Wong*

Main category: cs.CV

TL;DR: 该文提出了一种结合3D高斯点云与纹理网格的混合表示方法，用于提升室内场景复杂纹理区域的渲染效率，在保持质量的同时减少了高斯图元数量并提高了帧率。


<details>
  <summary>Details</summary>
Motivation: 3D高斯点云在图像重建和实时渲染中表现出色，但复杂纹理区域需要大量高斯图元来捕捉颜色变化，导致渲染速度低下。为解决此问题，提出了混合表示法。

Method: 1. 用纹理网格处理纹理丰富的平面区域，保留高斯点云处理复杂几何。2. 对提取的网格进行修剪和优化以消除几何复杂区域。3. 采用联合优化结合预热策略和透光率感知监督。

Result: 混合表示法在保持渲染质量的同时，显著减少了高斯图元数量，实现了更高的每秒帧数（FPS）。

Conclusion: 该方法有效平衡了室内场景渲染的效率和质量，证明了混合表示优于单一表示，尤其在处理复杂纹理与几何相结合的场景时。

Abstract: 3D Gaussian splatting (3DGS) has demonstrated exceptional performance in
image-based 3D reconstruction and real-time rendering. However, regions with
complex textures require numerous Gaussians to capture significant color
variations accurately, leading to inefficiencies in rendering speed. To address
this challenge, we introduce a hybrid representation for indoor scenes that
combines 3DGS with textured meshes. Our approach uses textured meshes to handle
texture-rich flat areas, while retaining Gaussians to model intricate
geometries. The proposed method begins by pruning and refining the extracted
mesh to eliminate geometrically complex regions. We then employ a joint
optimization for 3DGS and mesh, incorporating a warm-up strategy and
transmittance-aware supervision to balance their contributions
seamlessly.Extensive experiments demonstrate that the hybrid representation
maintains comparable rendering quality and achieves superior frames per second
FPS with fewer Gaussian primitives.

</details>


### [320] [Boosting Adversarial Transferability via Commonality-Oriented Gradient Optimization](https://arxiv.org/abs/2506.06992)
*Yanting Gao,Yepeng Liu,Junming Liu,Qi Zhang,Hongyun Zhang,Duoqian Miao,Cairong Zhao*

Main category: cs.CV

TL;DR: 本文提出COGO方法，通过增强共享中低频扰动和抑制模型个体特征来提升对抗样本在ViT间的迁移性。


<details>
  <summary>Details</summary>
Motivation: 现有方法未能充分利用多个代理模型间的共性特征，导致对抗样本迁移效率不佳。ViT在同数据集训练时倾向于使用中低频信息，这为提升迁移性提供了新思路。

Method: 1) 共性增强：针对中低频扰动区域进行优化；2) 个性抑制：通过自适应阈值评估梯度相关性，加权抑制与模型个体特性相关的梯度。

Result: COGO显著提升了对抗样本在黑盒设置下的迁移攻击成功率，超越当前最佳方法。

Conclusion: 挖掘代理模型间共享信息（尤其是频率特征）并抑制个体特性，可有效提升对抗样本的泛化能力。

Abstract: Exploring effective and transferable adversarial examples is vital for
understanding the characteristics and mechanisms of Vision Transformers (ViTs).
However, adversarial examples generated from surrogate models often exhibit
weak transferability in black-box settings due to overfitting. Existing methods
improve transferability by diversifying perturbation inputs or applying uniform
gradient regularization within surrogate models, yet they have not fully
leveraged the shared and unique features of surrogate models trained on the
same task, leading to suboptimal transfer performance. Therefore, enhancing
perturbations of common information shared by surrogate models and suppressing
those tied to individual characteristics offers an effective way to improve
transferability. Accordingly, we propose a commonality-oriented gradient
optimization strategy (COGO) consisting of two components: Commonality
Enhancement (CE) and Individuality Suppression (IS). CE perturbs the mid-to-low
frequency regions, leveraging the fact that ViTs trained on the same dataset
tend to rely more on mid-to-low frequency information for classification. IS
employs adaptive thresholds to evaluate the correlation between backpropagated
gradients and model individuality, assigning weights to gradients accordingly.
Extensive experiments demonstrate that COGO significantly improves the transfer
success rates of adversarial attacks, outperforming current state-of-the-art
methods.

</details>


### [321] [DM$^3$Net: Dual-Camera Super-Resolution via Domain Modulation and Multi-scale Matching](https://arxiv.org/abs/2506.06993)
*Cong Guan,Jiacheng Ying,Yuya Ieiri,Osamu Yoshie*

Main category: cs.CV

TL;DR: 论文提出了一种名为DM$^3$Net的双摄像头超分辨率网络，旨在利用长焦镜头图像增强广角图像的清晰度。该方法通过域调制缩小高分辨率域与退化域之间的差距，并采用多尺度匹配实现高频细节的准确转移。此外，通过关键剪枝技术减少了内存和计算开销。实验结果在三个真实数据集上超越了现有方法。


<details>
  <summary>Details</summary>
Motivation: 智能手机双摄像头系统中，广角镜头图像分辨率通常较低，需要利用高分辨率的长焦镜头图像作为参考来提升。但现有方法在跨域转换和细节迁移方面存在效率不足的问题。

Method: 1. 域调制：学习两个压缩全局表示分别对应高分辨率域和退化域；2. 多尺度匹配模块：通过多感受野的块级特征匹配提升细节迁移准确性和鲁棒性；3. 关键剪枝：大幅降低内存占用和推理时间。

Result: 在三个真实数据集上的实验表明，DM$^3$Net在超分辨率任务中优于现有最先进方法（SOTA）。

Conclusion: 本文提出的域调制和多尺度匹配机制有效提升了双摄像头超分辨率性能，关键剪枝技术则平衡了模型效率和精度，为智能手机摄影提供了实用解决方案。

Abstract: Dual-camera super-resolution is highly practical for smartphone photography
that primarily super-resolve the wide-angle images using the telephoto image as
a reference. In this paper, we propose DM$^3$Net, a novel dual-camera
super-resolution network based on Domain Modulation and Multi-scale Matching.
To bridge the domain gap between the high-resolution domain and the degraded
domain, we learn two compressed global representations from image pairs
corresponding to the two domains. To enable reliable transfer of high-frequency
structural details from the reference image, we design a multi-scale matching
module that conducts patch-level feature matching and retrieval across multiple
receptive fields to improve matching accuracy and robustness. Moreover, we also
introduce Key Pruning to achieve a significant reduction in memory usage and
inference time with little model performance sacrificed. Experimental results
on three real-world datasets demonstrate that our DM$^3$Net outperforms the
state-of-the-art approaches.

</details>


### [322] [Technical Report for ICRA 2025 GOOSE 3D Semantic Segmentation Challenge: Adaptive Point Cloud Understanding for Heterogeneous Robotic Systems](https://arxiv.org/abs/2506.06995)
*Xiaoya Zhang*

Main category: cs.CV

TL;DR: 该技术报告介绍了ICRA 2025 GOOSE 3D语义分割挑战赛冠军解决方案的实现细节。该方法通过集成点提示微调（PPT）与点Transformer v3（PTv3）主干网络，结合平台特定条件策略和跨数据集类别对齐，在不使用额外外部数据的情况下，在异构LiDAR点云分割任务中实现了最高22.59%的mIoU提升。


<details>
  <summary>Details</summary>
Motivation: 解决多平台采集的异构LiDAR点云在户外非结构化环境中的语义分割难题，突破传统方法对数据同质性的依赖。

Method: 将Point Prompt Tuning（PPT）与Point Transformer v3（PTv3）主干网络结合，采用平台特定条件机制适应不同传感器特征，并设计跨数据集类别对齐策略处理标注差异问题，且不依赖外部训练数据。

Result: 在挑战性平台上的平均交并比（mIoU）最高提升22.59%（相较于PTv3基线模型），证明了该方法对实际机器人应用的适应性。

Conclusion: 自适应点云理解框架有效解决了野外机器人应用中的跨平台异质数据挑战，展示了提示微调在3D分割任务中的巨大潜力。

Abstract: This technical report presents the implementation details of the winning
solution for the ICRA 2025 GOOSE 3D Semantic Segmentation Challenge. This
challenge focuses on semantic segmentation of 3D point clouds from diverse
unstructured outdoor environments collected from multiple robotic platforms.
This problem was addressed by implementing Point Prompt Tuning (PPT) integrated
with Point Transformer v3 (PTv3) backbone, enabling adaptive processing of
heterogeneous LiDAR data through platform-specific conditioning and
cross-dataset class alignment strategies. The model is trained without
requiring additional external data. As a result, this approach achieved
substantial performance improvements with mIoU increases of up to 22.59% on
challenging platforms compared to the baseline PTv3 model, demonstrating the
effectiveness of adaptive point cloud understanding for field robotics
applications.

</details>


### [323] [BePo: Leveraging Birds Eye View and Sparse Points for Efficient and Accurate 3D Occupancy Prediction](https://arxiv.org/abs/2506.07002)
*Yunxiao Shi,Hong Cai,Jisoo Jeong,Yinhao Zhu,Shizhong Han,Amin Ansari,Fatih Porikli*

Main category: cs.CV

TL;DR: 论文提出了一种名为BePo的方法，将BEV和稀疏点表示相结合，通过双分支设计融合两种表示的优势，以在3D占用预测中平衡效率与对小物体和平面的准确性，提升自动驾驶场景理解性能。


<details>
  <summary>Details</summary>
Motivation: 解决3D占用预测中现有方法的局限性：密集3D特征高计算成本，BEV对小物体信息损失大，稀疏点对平面建模效率低的问题；通过融合BEV和稀疏点表示的优势实现高效且精细的场景理解。

Method: 双分支架构：1）查询型稀疏点分支处理小物体细节；2）BEV分支处理大平面区域。通过跨注意力机制将稀疏点分支的3D信息增强BEV特征，最终融合两分支输出预测3D占用。

Result: 在Occ3D-nuScenes和Occ3D-Waymo基准测试中表现优越，同时推理速度与最新高效方法相当。

Conclusion: BePo有效平衡了3D占用预测的效率和精度问题，通过异构表示融合提升了小物体和大型平面的建模能力，为自动驾驶提供更鲁棒的场景理解。

Abstract: 3D occupancy provides fine-grained 3D geometry and semantics for scene
understanding which is critical for autonomous driving. Most existing methods,
however, carry high compute costs, requiring dense 3D feature volume and
cross-attention to effectively aggregate information. More recent works have
adopted Bird's Eye View (BEV) or sparse points as scene representation with
much reduced cost, but still suffer from their respective shortcomings. More
concretely, BEV struggles with small objects that often experience significant
information loss after being projected to the ground plane. On the other hand,
points can flexibly model little objects in 3D, but is inefficient at capturing
flat surfaces or large objects. To address these challenges, in this paper, we
present a novel 3D occupancy prediction approach, BePo, which combines BEV and
sparse points based representations. We propose a dual-branch design: a
query-based sparse points branch and a BEV branch. The 3D information learned
in the sparse points branch is shared with the BEV stream via cross-attention,
which enriches the weakened signals of difficult objects on the BEV plane. The
outputs of both branches are finally fused to generate predicted 3D occupancy.
We conduct extensive experiments on the Occ3D-nuScenes and Occ3D-Waymo
benchmarks that demonstrate the superiority of our proposed BePo. Moreover,
BePo also delivers competitive inference speed when compared to the latest
efficient approaches.

</details>


### [324] [UNO: Unified Self-Supervised Monocular Odometry for Platform-Agnostic Deployment](https://arxiv.org/abs/2506.07013)
*Wentao Zhao,Yihe Niu,Yanbo Wang,Tianchen Deng,Shenghai Yuan,Zhenli Wang,Rui Guo,Jingchuan Wang*

Main category: cs.CV

TL;DR: UNO is a unified monocular visual odometry framework that provides robust and adaptable pose estimation across different environments, platforms, and motion patterns without deployment-specific tuning.


<details>
  <summary>Details</summary>
Motivation: Traditional visual odometry methods require deployment-specific tuning or predefined motion priors, limiting their generalization across diverse real-world scenarios like autonomous vehicles, drones, robots, and handheld devices.

Method: Uses a Mixture-of-Experts strategy for local state estimation with specialized decoders for different ego-motion classes. Incorporates a differentiable Gumbel-Softmax module to build robust inter-frame correlations, select optimal decoders, and prune errors. Combines pre-trained scale-independent depth priors with lightweight bundle adjustment for geometric consistency.

Result: State-of-the-art performance achieved on KITTI (outdoor/autonomous driving), EuRoC-MAV (indoor/aerial drones), and TUM-RGBD (indoor/handheld) benchmark datasets.

Conclusion: UNO demonstrates strong generalization capabilities across diverse scenarios by unifying specialized motion decoders with robust optimization, outperforming existing methods without scenario-specific tuning.

Abstract: This work presents UNO, a unified monocular visual odometry framework that
enables robust and adaptable pose estimation across diverse environments,
platforms, and motion patterns. Unlike traditional methods that rely on
deployment-specific tuning or predefined motion priors, our approach
generalizes effectively across a wide range of real-world scenarios, including
autonomous vehicles, aerial drones, mobile robots, and handheld devices. To
this end, we introduce a Mixture-of-Experts strategy for local state
estimation, with several specialized decoders that each handle a distinct class
of ego-motion patterns. Moreover, we introduce a fully differentiable
Gumbel-Softmax module that constructs a robust inter-frame correlation graph,
selects the optimal expert decoder, and prunes erroneous estimates. These cues
are then fed into a unified back-end that combines pre-trained,
scale-independent depth priors with a lightweight bundling adjustment to
enforce geometric consistency. We extensively evaluate our method on three
major benchmark datasets: KITTI (outdoor/autonomous driving), EuRoC-MAV
(indoor/aerial drones), and TUM-RGBD (indoor/handheld), demonstrating
state-of-the-art performance.

</details>


### [325] [TABLET: Table Structure Recognition using Encoder-only Transformers](https://arxiv.org/abs/2506.07015)
*Qiyu Hou,Jun Wang*

Main category: cs.CV

TL;DR: 该论文提出了一种基于Split-Merge的自顶向下模型，用于表格结构识别。模型通过双Transformer编码器处理行/列拆分，并用额外Transformer进行网格合并，消除了不稳定的边界框预测，在速度和准确率上实现突破。


<details>
  <summary>Details</summary>
Motivation: 为了解决传统表格结构识别方法中边界框预测不稳定导致的精度损失和计算效率问题，特别是在处理大型密集型表格时。

Method: 1. 将行/列拆分建模为序列标注任务（双Transformer编码器）；2. 将合并过程建模为网格单元分类任务（额外Transformer编码器）；3. 取消边界框回归设计。

Result: 在FinTabNet和PubTabNet数据集上取得最优效果，尤其在大型表格处理中展现高精度（减少分割错误90%）和高速（处理时间缩短40%）。

Conclusion: 该模型为大规模工业级表格识别提供了鲁棒且高效的解决方案，首次实现精度与速度的平衡，具有直接部署价值。

Abstract: To address the challenges of table structure recognition, we propose a novel
Split-Merge-based top-down model optimized for large, densely populated tables.
Our approach formulates row and column splitting as sequence labeling tasks,
utilizing dual Transformer encoders to capture feature interactions. The
merging process is framed as a grid cell classification task, leveraging an
additional Transformer encoder to ensure accurate and coherent merging. By
eliminating unstable bounding box predictions, our method reduces resolution
loss and computational complexity, achieving high accuracy while maintaining
fast processing speed. Extensive experiments on FinTabNet and PubTabNet
demonstrate the superiority of our model over existing approaches, particularly
in real-world applications. Our method offers a robust, scalable, and efficient
solution for large-scale table recognition, making it well-suited for
industrial deployment.

</details>


### [326] [MAGNET: A Multi-agent Framework for Finding Audio-Visual Needles by Reasoning over Multi-Video Haystacks](https://arxiv.org/abs/2506.07016)
*Sanjoy Chowdhury,Mohamed Elmoghany,Yohan Abeysinghe,Junjie Fei,Sayan Nag,Salman Khan,Mohamed Elhoseiny,Dinesh Manocha*

Main category: cs.CV

TL;DR: 提出了名为 AV-HaystacksQA 的新任务以解决多视频检索和时态定位问题，并构建了包含 3100 个标注 QA 对的 AVHaystacks 数据集。同时提出多智能体框架 MAGNET，在 BLEU@4 和 GPT 评分上超越基线方法达 89% 和 65%，并设计了 STEM 和 MTGS 两项新评估指标。


<details>
  <summary>Details</summary>
Motivation: 现有视频问答基准通常局限于单剪辑查询，无法评估模型在大规模音视频检索和跨视频复杂推理场景的能力，因此需要构建更贴近实际应用场景的评估体系。

Method: 1. 提出新型多视频检索与推理任务 AV-HaystacksQA 
2. 发布包含 3100 个标注对的 AVHaystacks 数据集 
3. 设计模型无关的多智能体框架 MAGNET 
4. 提出评估指标 STEM（步骤序列对齐度）和 MTGS（分段定位性能）

Result: 1. MAGNET 在 BLEU@4 分数上相对基线提升 89%，GPT 评估分数提升 65% 
2. 新指标 STEM 和 MTGS 实现细粒度性能评估，比传统指标更具解释性

Conclusion: 该工作通过构建新任务、数据集和评估框架，显著推进了大规模音视频理解的发展，同时提出的多智能体方法 MAGNET 和新评估体系为后续研究提供新范式。

Abstract: Large multimodal models (LMMs) have shown remarkable progress in audio-visual
understanding, yet they struggle with real-world scenarios that require complex
reasoning across extensive video collections. Existing benchmarks for video
question answering remain limited in scope, typically involving one clip per
query, which falls short of representing the challenges of large-scale,
audio-visual retrieval and reasoning encountered in practical applications. To
bridge this gap, we introduce a novel task named AV-HaystacksQA, where the goal
is to identify salient segments across different videos in response to a query
and link them together to generate the most informative answer. To this end, we
present AVHaystacks, an audio-visual benchmark comprising 3100 annotated QA
pairs designed to assess the capabilities of LMMs in multi-video retrieval and
temporal grounding task. Additionally, we propose a model-agnostic, multi-agent
framework MAGNET to address this challenge, achieving up to 89% and 65%
relative improvements over baseline methods on BLEU@4 and GPT evaluation scores
in QA task on our proposed AVHaystacks. To enable robust evaluation of
multi-video retrieval and temporal grounding for optimal response generation,
we introduce two new metrics, STEM, which captures alignment errors between a
ground truth and a predicted step sequence and MTGS, to facilitate balanced and
interpretable evaluation of segment-level grounding performance. Project:
https://schowdhury671.github.io/magnet_project/

</details>


### [327] [Interpretable and Reliable Detection of AI-Generated Images via Grounded Reasoning in MLLMs](https://arxiv.org/abs/2506.07045)
*Yikun Ji,Hong Yan,Jun Lan,Huijia Zhu,Weiqiang Wang,Qi Fan,Liqing Zhang,Jianfu Zhang*

Main category: cs.CV

TL;DR: A methodology is introduced to enhance interpretability in AI-generated image detection by fine-tuning MLLMs with annotated datasets and multi-stage training to boost detection/location accuracy while providing human-readable explanations.


<details>
  <summary>Details</summary>
Motivation: To create interpretable AI-generated image detectors that supply human-understandable evidence of forgery, addressing limitations like hallucination in MLLMs when applied as detectors.

Method: Curated dataset with annotated artifacts → Multi-stage fine-tuning balancing detection/localization/explanation → Optimizing MLLM outputs via visual-textual grounded reasoning.

Result: Developed model achieves superior AI-image detection/artifact localization, outpacing baselines significantly with improved explanation-reality alignment.

Conclusion: Combining artifact-centric annotation and balanced multi-task tuning significantly advances interpretable forensic methods while reducing MLLM hallucination.

Abstract: The rapid advancement of image generation technologies intensifies the demand
for interpretable and robust detection methods. Although existing approaches
often attain high accuracy, they typically operate as black boxes without
providing human-understandable justifications. Multi-modal Large Language
Models (MLLMs), while not originally intended for forgery detection, exhibit
strong analytical and reasoning capabilities. When properly fine-tuned, they
can effectively identify AI-generated images and offer meaningful explanations.
However, existing MLLMs still struggle with hallucination and often fail to
align their visual interpretations with actual image content and human
reasoning. To bridge this gap, we construct a dataset of AI-generated images
annotated with bounding boxes and descriptive captions that highlight synthesis
artifacts, establishing a foundation for human-aligned visual-textual grounded
reasoning. We then finetune MLLMs through a multi-stage optimization strategy
that progressively balances the objectives of accurate detection, visual
localization, and coherent textual explanation. The resulting model achieves
superior performance in both detecting AI-generated images and localizing
visual flaws, significantly outperforming baseline methods.

</details>


### [328] [From Swath to Full-Disc: Advancing Precipitation Retrieval with Multimodal Knowledge Expansion](https://arxiv.org/abs/2506.07050)
*Zheng Wang,Kai Ying,Bin Xu,Chunjiao Wang,Cong Bai*

Main category: cs.CV

TL;DR: 本论文提出PRE-Net模型解决红外降水反演范围限制问题，通过两阶段知识迁移实现在扫描区外的精确全圆盘降水估算。


<details>
  <summary>Details</summary>
Motivation: 尽管卫星技术提升了实时降水监测，但红外反演精度低而微波/雷达反演范围受限，需要扩展精确降水反演范围。

Method: 提出两阶段Multimodal Knowledge Expansion：（1）扫描区通过CoMWE进行多模态知识迁移，（2）全圆盘区通过Self-MaskTune平衡知识。

Result: 在PRE基准测试中显著超越PERSIANN-CCS等主流产品。

Conclusion: PRE-Net首次实现高精度红外全圆盘降水反演，代码将开源。

Abstract: Accurate near-real-time precipitation retrieval has been enhanced by
satellite-based technologies. However, infrared-based algorithms have low
accuracy due to weak relations with surface precipitation, whereas passive
microwave and radar-based methods are more accurate but limited in range. This
challenge motivates the Precipitation Retrieval Expansion (PRE) task, which
aims to enable accurate, infrared-based full-disc precipitation retrievals
beyond the scanning swath. We introduce Multimodal Knowledge Expansion, a
two-stage pipeline with the proposed PRE-Net model. In the Swath-Distilling
stage, PRE-Net transfers knowledge from a multimodal data integration model to
an infrared-based model within the scanning swath via Coordinated Masking and
Wavelet Enhancement (CoMWE). In the Full-Disc Adaptation stage, Self-MaskTune
refines predictions across the full disc by balancing multimodal and full-disc
infrared knowledge. Experiments on the introduced PRE benchmark demonstrate
that PRE-Net significantly advanced precipitation retrieval performance,
outperforming leading products like PERSIANN-CCS, PDIR, and IMERG. The code
will be available at https://github.com/Zjut-MultimediaPlus/PRE-Net.

</details>


### [329] [A Layered Self-Supervised Knowledge Distillation Framework for Efficient Multimodal Learning on the Edge](https://arxiv.org/abs/2506.07055)
*Tarique Dahri,Zulfiqar Ali Memon,Zhenyu Yu,Mohd. Yamani Idna Idris,Sheheryar Khan,Sadiq Ahmad,Maged Shoman,Saddam Aziz,Rizwan Qureshi*

Main category: cs.CV

TL;DR: 作者提出了Layered Self-Supervised Knowledge Distillation（LSSKD）框架，用于训练小型深度学习模型，通过在网络中间特征图上添加辅助分类器生成自监督知识，实现了不同网络阶段的一对一知识迁移。该方法在多个数据集上优于现有技术，且推理时无额外计算开销。


<details>
  <summary>Details</summary>
Motivation: 传统知识蒸馏依赖于预训练的大型教师模型，导致计算开销大且不适用于资源受限设备。本方法旨在不依赖大型教师网络的前提下，通过自监督机制提升小型模型的泛化能力和性能。

Method: 提出LSSKD框架：在基础网络中间特征层附加多个辅助分类器，利用这些分类器的预测生成自监督知识作为‘教师信号’，并通过分层蒸馏实现从浅层到深层的一对一知识迁移。

Result: 在CIFAR-100上超越PS-KD方法4.54%，超过SSKD 1.14%；在ImageNet上比HASSKD提高0.32%。在Tiny ImageNet和CIFAR-100的小样本学习场景中也取得最优结果。推理时可移除辅助分类器，零额外计算开销。

Conclusion: 该方法通过自生成教师信号显著提升小模型性能，尤其适用于计算受限设备。其轻量级特性对多模态传感和网络物理系统具有应用价值，支持弱监督下从有限数据中学习智能体。

Abstract: We introduce Layered Self-Supervised Knowledge Distillation (LSSKD) framework
for training compact deep learning models. Unlike traditional methods that rely
on pre-trained teacher networks, our approach appends auxiliary classifiers to
intermediate feature maps, generating diverse self-supervised knowledge and
enabling one-to-one transfer across different network stages. Our method
achieves an average improvement of 4.54\% over the state-of-the-art PS-KD
method and a 1.14% gain over SSKD on CIFAR-100, with a 0.32% improvement on
ImageNet compared to HASSKD. Experiments on Tiny ImageNet and CIFAR-100 under
few-shot learning scenarios also achieve state-of-the-art results. These
findings demonstrate the effectiveness of our approach in enhancing model
generalization and performance without the need for large over-parameterized
teacher networks. Importantly, at the inference stage, all auxiliary
classifiers can be removed, yielding no extra computational cost. This makes
our model suitable for deploying small language models on affordable
low-computing devices. Owing to its lightweight design and adaptability, our
framework is particularly suitable for multimodal sensing and cyber-physical
environments that require efficient and responsive inference. LSSKD facilitates
the development of intelligent agents capable of learning from limited sensory
data under weak supervision.

</details>


### [330] [D2R: dual regularization loss with collaborative adversarial generation for model robustness](https://arxiv.org/abs/2506.07056)
*Zhenyu Liu,Huizhi Liang,Rajiv Ranjan,Zhanxing Zhu,Vaclav Snasel,Varun Ojha*

Main category: cs.CV

TL;DR: 提出了一种双正则化损失（D2R Loss）和协作对抗生成（CAG）策略，用于增强对抗训练模型的鲁棒性。D2R Loss通过对抗分布和干净分布优化提升目标模型鲁棒性，CAG利用梯度协作生成对抗样本。在多个基准数据集和模型上的实验表明该方法有效提升了模型鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有方法的两个局限性：(i) 损失函数对目标模型的引导不足，(ii) 对抗样本生成过程缺乏协作性。这限制了模型对抗攻击的鲁棒性。

Method: 1. 双正则化损失（D2R Loss）：包含对抗分布优化和干净分布优化两个步骤，通过函数空间探索不同损失函数的优势来提升目标模型对其分布的聚焦能力。2. 协作对抗生成（CAG）：利用指导模型与目标模型之间的基于梯度的协作来生成对抗样本。

Result: 在CIFAR-10、CIFAR-100、Tiny ImageNet数据集及WideResNet34-10和PreActResNet18模型上的实验表明，D2R Loss与CAG结合能产生高鲁棒性模型。

Conclusion: 所提出的D2R损失函数与CAG策略能有效解决现有方法的局限性，显著提升深度学习模型对抗对抗攻击的鲁棒性。该方法在多个基准测试中表现出优越性能。

Abstract: The robustness of Deep Neural Network models is crucial for defending models
against adversarial attacks. Recent defense methods have employed collaborative
learning frameworks to enhance model robustness. Two key limitations of
existing methods are (i) insufficient guidance of the target model via loss
functions and (ii) non-collaborative adversarial generation. We, therefore,
propose a dual regularization loss (D2R Loss) method and a collaborative
adversarial generation (CAG) strategy for adversarial training. D2R loss
includes two optimization steps. The adversarial distribution and clean
distribution optimizations enhance the target model's robustness by leveraging
the strengths of different loss functions obtained via a suitable function
space exploration to focus more precisely on the target model's distribution.
CAG generates adversarial samples using a gradient-based collaboration between
guidance and target models. We conducted extensive experiments on three
benchmark databases, including CIFAR-10, CIFAR-100, Tiny ImageNet, and two
popular target models, WideResNet34-10 and PreActResNet18. Our results show
that D2R loss with CAG produces highly robust models.

</details>


### [331] [FLAIR-HUB: Large-scale Multimodal Dataset for Land Cover and Crop Mapping](https://arxiv.org/abs/2506.07080)
*Anatol Garioud,Sébastien Giordano,Nicolas David,Nicolas Gonthier*

Main category: cs.CV

TL;DR: 论文介绍了FLAIR-HUB数据集：一个超大分辨率的法国土地覆盖分类数据集，整合了6种多模态遥感数据，用于推动精准农业监测。基准测试表明最先进模型可达到78.2%准确率，但多模态融合仍具挑战性。


<details>
  <summary>Details</summary>
Motivation: 解决地球观测数据量大、异质性高带来的处理和标注难题，满足对大标注数据集的需求以赋能土地覆盖和作物类型监控。

Method: 构建包含2528平方公里法国地区、20cm超高分辨率标注的多传感器数据集FLAIR-HUB（含航拍图、哨兵1/2号时序等6种对齐模态）。评估多模态融合、深度学习模型（CNN/Transformer）及多任务学习在土地覆盖/作物分类中的效果。

Result: 在土地覆盖分类中获得78.2%准确率（65.8%mIoU）的最佳成绩，但发现多模态融合和细粒度分类依然复杂。数据集支持监督与多模态预训练。

Conclusion: FLAIR-HUB作为最大的极高清标注多模态土地覆盖数据集，为精准农业监测提供了关键基础设施，同时揭示了多源遥感数据融合的技术挑战。

Abstract: The growing availability of high-quality Earth Observation (EO) data enables
accurate global land cover and crop type monitoring. However, the volume and
heterogeneity of these datasets pose major processing and annotation
challenges. To address this, the French National Institute of Geographical and
Forest Information (IGN) is actively exploring innovative strategies to exploit
diverse EO data, which require large annotated datasets. IGN introduces
FLAIR-HUB, the largest multi-sensor land cover dataset with
very-high-resolution (20 cm) annotations, covering 2528 km2 of France. It
combines six aligned modalities: aerial imagery, Sentinel-1/2 time series, SPOT
imagery, topographic data, and historical aerial images. Extensive benchmarks
evaluate multimodal fusion and deep learning models (CNNs, transformers) for
land cover or crop mapping and also explore multi-task learning. Results
underscore the complexity of multimodal fusion and fine-grained classification,
with best land cover performance (78.2% accuracy, 65.8% mIoU) achieved using
nearly all modalities. FLAIR-HUB supports supervised and multimodal
pretraining, with data and code available at
https://ignf.github.io/FLAIR/flairhub.

</details>


### [332] [UCOD-DPL: Unsupervised Camouflaged Object Detection via Dynamic Pseudo-label Learning](https://arxiv.org/abs/2506.07087)
*Weiqi Yan,Lvhai Chen,Huaijia Kou,Shengchuan Zhang,Yan Zhang,Liujuan Cao*

Main category: cs.CV

TL;DR: 本文提出UCOD-DPL方法，通过动态伪标签学习解决无监督伪装目标检测中的噪声拟合和语义特征学习不足问题，性能优于现有无监督方法甚至部分全监督方法。


<details>
  <summary>Details</summary>
Motivation: 现有无监督伪装目标检测方法存在两大缺陷：1) 固定策略生成的伪标签包含大量噪声，导致模型容易学习错误知识；2) 简单解码器无法有效学习伪装目标的语义特征，尤其对小尺寸目标效果差。

Method: 提出UCOD-DPL方法，包含三个核心组件：1）自适应伪标签模块（APM）动态组合固定策略和教师模型生成的伪标签；2）双分支对抗解码器（DBA）通过对抗学习克服前景背景混淆；3）二次查看机制（Look-Twice）模仿人类观察行为，针对小目标进行二次优化。

Result: 大量实验表明，该方法在DUTS等通用伪装检测数据集上表现优异，计算效率高（仅需单张2080Ti），且推理速度达27FPS。性能超越现有无监督方法，甚至超过部分全监督方法。

Conclusion: UCOD-DPL通过动态伪标签学习和创新模块设计，有效解决了无监督伪装检测中的关键挑战，为减少人工标注依赖提供了可行方案。

Abstract: Unsupervised Camoflaged Object Detection (UCOD) has gained attention since it
doesn't need to rely on extensive pixel-level labels. Existing UCOD methods
typically generate pseudo-labels using fixed strategies and train 1 x1
convolutional layers as a simple decoder, leading to low performance compared
to fully-supervised methods. We emphasize two drawbacks in these approaches:
1). The model is prone to fitting incorrect knowledge due to the pseudo-label
containing substantial noise. 2). The simple decoder fails to capture and learn
the semantic features of camouflaged objects, especially for small-sized
objects, due to the low-resolution pseudo-labels and severe confusion between
foreground and background pixels. To this end, we propose a UCOD method with a
teacher-student framework via Dynamic Pseudo-label Learning called UCOD-DPL,
which contains an Adaptive Pseudo-label Module (APM), a Dual-Branch Adversarial
(DBA) decoder, and a Look-Twice mechanism. The APM module adaptively combines
pseudo-labels generated by fixed strategies and the teacher model to prevent
the model from overfitting incorrect knowledge while preserving the ability for
self-correction; the DBA decoder takes adversarial learning of different
segmentation objectives, guides the model to overcome the foreground-background
confusion of camouflaged objects, and the Look-Twice mechanism mimics the human
tendency to zoom in on camouflaged objects and performs secondary refinement on
small-sized objects. Extensive experiments show that our method demonstrates
outstanding performance, even surpassing some existing fully supervised
methods. The code is available now.

</details>


### [333] [SceneLCM: End-to-End Layout-Guided Interactive Indoor Scene Generation with Latent Consistency Model](https://arxiv.org/abs/2506.07091)
*Yangkai Lin,Jiabao Lei,Kui Jia*

Main category: cs.CV

TL;DR: SceneLCM是一个端到端框架，结合LLM进行布局设计和LCM进行场景优化，通过四阶段模块化流水线（布局生成、家具生成、环境优化、物理编辑）生成交互式室内场景，解决了现有方法的编辑约束、物理不一致、人力消耗大、单房间限制和材质质量低等问题。


<details>
  <summary>Details</summary>
Motivation: 现有室内场景生成方法存在编辑约束刚性、物理不连贯、人力消耗大、仅支持单房间及材质质量差等局限性，无法高效生成符合用户提示的复杂交互式场景。

Method: 1）布局生成：LLM引导3D空间推理将文本转为参数化蓝图，并通过迭代式程序验证优化布局；2）家具生成：采用一致性轨迹采样（CTS）损失生成高质量家具表示，提供理论证明CTS等同于一致性损失；3）环境优化：多分辨率纹理场编码外观，结合法向量感知的交叉注意力解码器保持跨几何纹理一致性；4）物理编辑：集成物理模拟保持物理真实性。

Result: 大量实验验证SceneLCM优于现有技术，在生成速度、语义丰富性、质量和物理连贯性方面表现出色，具备广泛的应用潜力。

Conclusion: SceneLCM通过结合LLM和LCM的优势，实现高效、物理一致、高保真且可编辑的多房间室内场景生成，突破了现有方法的局限性。

Abstract: Our project page: https://scutyklin.github.io/SceneLCM/. Automated generation
of complex, interactive indoor scenes tailored to user prompt remains a
formidable challenge. While existing methods achieve indoor scene synthesis,
they struggle with rigid editing constraints, physical incoherence, excessive
human effort, single-room limitations, and suboptimal material quality. To
address these limitations, we propose SceneLCM, an end-to-end framework that
synergizes Large Language Model (LLM) for layout design with Latent Consistency
Model(LCM) for scene optimization. Our approach decomposes scene generation
into four modular pipelines: (1) Layout Generation. We employ LLM-guided 3D
spatial reasoning to convert textual descriptions into parametric blueprints(3D
layout). And an iterative programmatic validation mechanism iteratively refines
layout parameters through LLM-mediated dialogue loops; (2) Furniture
Generation. SceneLCM employs Consistency Trajectory Sampling(CTS), a
consistency distillation sampling loss guided by LCM, to form fast,
semantically rich, and high-quality representations. We also offer two
theoretical justification to demonstrate that our CTS loss is equivalent to
consistency loss and its distillation error is bounded by the truncation error
of the Euler solver; (3) Environment Optimization. We use a multiresolution
texture field to encode the appearance of the scene, and optimize via CTS loss.
To maintain cross-geometric texture coherence, we introduce a normal-aware
cross-attention decoder to predict RGB by cross-attending to the anchors
locations in geometrically heterogeneous instance. (4)Physically Editing.
SceneLCM supports physically editing by integrating physical simulation,
achieved persistent physical realism. Extensive experiments validate SceneLCM's
superiority over state-of-the-art techniques, showing its wide-ranging
potential for diverse applications.

</details>


### [334] [EdgeSpotter: Multi-Scale Dense Text Spotting for Industrial Panel Monitoring](https://arxiv.org/abs/2506.07112)
*Changhong Fu,Hua Lin,Haobo Zuo,Liangliang Yao,Liguo Zhang*

Main category: cs.CV

TL;DR: 提出一个称为EdgeSpotter的用于工业仪表板的多尺度密集文本识别器，通过新型Transformer和特征采样技术解决跨尺度定位和边界模糊问题，并构建了新数据集验证性能。


<details>
  <summary>Details</summary>
Motivation: 工业仪表板文本识别中，由于跨尺度定位、密集文本边界模糊及现有方法忽略多尺度特征整合，导致精确识别困难。

Method: 结合高效混合器的Transformer用于多级特征互相依赖学习，采用Catmull-Rom样条的特征采样技术编码文本形状、位置和语义信息，并构建新基准数据集IPM。

Result: 在IPM数据集上定量和定性评估显示该方法优于现有方法，基于边缘AI视觉系统的实测验证了实用性。

Conclusion: EdgeSpotter通过多尺度特征整合与新型特征采样，解决了工业场景文本识别难题，实际部署证明其有效性。

Abstract: Text spotting for industrial panels is a key task for intelligent monitoring.
However, achieving efficient and accurate text spotting for complex industrial
panels remains challenging due to issues such as cross-scale localization and
ambiguous boundaries in dense text regions. Moreover, most existing methods
primarily focus on representing a single text shape, neglecting a comprehensive
exploration of multi-scale feature information across different texts. To
address these issues, this work proposes a novel multi-scale dense text spotter
for edge AI-based vision system (EdgeSpotter) to achieve accurate and robust
industrial panel monitoring. Specifically, a novel Transformer with efficient
mixer is developed to learn the interdependencies among multi-level features,
integrating multi-layer spatial and semantic cues. In addition, a new feature
sampling with catmull-rom splines is designed, which explicitly encodes the
shape, position, and semantic information of text, thereby alleviating missed
detections and reducing recognition errors caused by multi-scale or dense text
regions. Furthermore, a new benchmark dataset for industrial panel monitoring
(IPM) is constructed. Extensive qualitative and quantitative evaluations on
this challenging benchmark dataset validate the superior performance of the
proposed method in different challenging panel monitoring tasks. Finally,
practical tests based on the self-designed edge AI-based vision system
demonstrate the practicality of the method. The code and demo will be available
at https://github.com/vision4robotics/EdgeSpotter.

</details>


### [335] [Image segmentation and classification of E-waste for waste segregation](https://arxiv.org/abs/2506.07122)
*Prakriti Tripathi,Theertha Biju,Maniram Thota,Rakesh Lingam*

Main category: cs.CV

TL;DR: 该论文提出了一种基于YOLOv11和Mask-RCNN模型的电子废弃物分类方法，应用于分拣机器人。YOLOv11达到70 mAP，Mask-RCNN为41 mAP。


<details>
  <summary>Details</summary>
Motivation: 为了解决电子废弃物分类问题，工业合作伙伴要求开发机器学习模型，供分拣机器人使用。

Method: 1. 创建自定义数据集（拆解电子废弃物并拍摄图像）
2. 训练YOLOv11模型（实时检测）
3. 训练Mask-RCNN模型（实例分割）

Result: YOLOv11在实时检测中达到70mAP；Mask-RCNN达到41mAP。模型将集成到分拣机器人实现电子废弃物分离。

Conclusion: YOLOv11在电子废弃物分类任务上性能优于Mask-RCNN。未来将把模型部署到分拣机器人进行实际应用。

Abstract: Industry partners provided a problem statement that involves classifying
electronic waste using machine learning models that will be used by
pick-and-place robots for waste segregation. We started by taking common
electronic waste items, such as a mouse and charger, unsoldering them, and
taking pictures to create a custom dataset. Then state-of-the art YOLOv11 model
was trained and run to achieve 70 mAP in real-time. Mask-RCNN model was also
trained and achieved 41 mAP. The model will be further integrated with
pick-and-place robots to perform segregation of e-waste.

</details>


### [336] [Hi-VAE: Efficient Video Autoencoding with Global and Detailed Motion](https://arxiv.org/abs/2506.07136)
*Huaize Liu,Wenzhang Sun,Qiyuan Zhang,Donglin Di,Biao Gong,Hao Li,Chen Wei,Changqing Zou*

Main category: cs.CV

TL;DR: Hi-VAE is a video autoencoding framework that hierarchically compresses motion to achieve 1428x compression, 30x better than prior methods, while maintaining high reconstruction quality and scalability.


<details>
  <summary>Details</summary>
Motivation: Existing video autoencoders inefficiently model spatio-temporal redundancies, leading to high training costs for downstream tasks.

Method: Decomposes video dynamics into Global Motion (overarching patterns) and Detailed Motion (spatial details) latent spaces. Uses self-supervised motion encoders for compression, and a conditional diffusion decoder for reconstruction.

Result: Achieves 1428x compression factor (30x higher than baselines), maintains high reconstruction fidelity, and performs effectively in downstream generative tasks.

Conclusion: Hi-VAE demonstrates efficient hierarchical motion representation, offering new perspectives for video generation with interpretability and scalability.

Abstract: Recent breakthroughs in video autoencoders (Video AEs) have advanced video
generation, but existing methods fail to efficiently model spatio-temporal
redundancies in dynamics, resulting in suboptimal compression factors. This
shortfall leads to excessive training costs for downstream tasks. To address
this, we introduce Hi-VAE, an efficient video autoencoding framework that
hierarchically encode coarse-to-fine motion representations of video dynamics
and formulate the decoding process as a conditional generation task.
Specifically, Hi-VAE decomposes video dynamics into two latent spaces: Global
Motion, capturing overarching motion patterns, and Detailed Motion, encoding
high-frequency spatial details. Using separate self-supervised motion encoders,
we compress video latents into compact motion representations to reduce
redundancy significantly. A conditional diffusion decoder then reconstructs
videos by combining hierarchical global and detailed motions, enabling
high-fidelity video reconstructions. Extensive experiments demonstrate that
Hi-VAE achieves a high compression factor of 1428$\times$, almost 30$\times$
higher than baseline methods (e.g., Cosmos-VAE at 48$\times$), validating the
efficiency of our approach. Meanwhile, Hi-VAE maintains high reconstruction
quality at such high compression rates and performs effectively in downstream
generative tasks. Moreover, Hi-VAE exhibits interpretability and scalability,
providing new perspectives for future exploration in video latent
representation and generation.

</details>


### [337] [Learning Compact Vision Tokens for Efficient Large Multimodal Models](https://arxiv.org/abs/2506.07138)
*Hao Tang,Chengchao Shen*

Main category: cs.CV

TL;DR: 该论文提出了一种名为Spatial Token Fusion (STF)的方法，通过在视觉模型中减少冗余空间令牌来加速推理，同时引入Multi-Block Token Fusion (MBTF)来补充多粒度特征，从而保持性能并提升效率。


<details>
  <summary>Details</summary>
Motivation: 现有的大型多模态模型（LMMs）由于大型语言模型（LLMs）的高计算成本和长视觉令牌序列的二次复杂度，面临显著计算挑战。

Method: 提出STF方法融合空间相邻的视觉令牌以减少序列长度；引入MBTF模块补充多粒度特征；二者结合平衡令牌减少与信息保留。

Result: 在LLaVA-1.5基础上，仅使用基线模型25%的视觉令牌，在8个常见视觉-语言基准测试中取得相当或更优性能。

Conclusion: STF+MBTF方案能显著提高推理效率（减少75%令牌）而基本不影响多模态推理能力，代码和模型权重已开源。

Abstract: Large multimodal models (LMMs) suffer significant computational challenges
due to the high cost of Large Language Models (LLMs) and the quadratic
complexity of processing long vision token sequences. In this paper, we explore
the spatial redundancy among vision tokens and shorten the length of vision
token sequences for inference acceleration. Specifically, we propose a Spatial
Token Fusion (STF) method to learn compact vision tokens for short vision token
sequence, where spatial-adjacent tokens are fused into one. Meanwhile,
weight-frozen vision encoder can not well adapt to the demand of extensive
downstream vision-language tasks. To this end, we further introduce a
Multi-Block Token Fusion (MBTF) module to supplement multi-granularity features
for the reduced token sequence. Overall, we combine STF and MBTF module to
balance token reduction and information preservation, thereby improving
inference efficiency without sacrificing multimodal reasoning capabilities.
Experimental results demonstrate that our method based on LLaVA-1.5 achieves
comparable or even superior performance to the baseline on 8 popular
vision-language benchmarks with only $25\%$ vision tokens of baseline. The
source code and trained weights are available at
https://github.com/visresearch/LLaVA-STF.

</details>


### [338] [GoTrack: Generic 6DoF Object Pose Refinement and Tracking](https://arxiv.org/abs/2506.07155)
*Van Nguyen Nguyen,Christian Forster,Sindi Shkodrani,Vincent Lepetit,Bugra Tekin,Cem Keskin,Tomas Hodan*

Main category: cs.CV

TL;DR: GoTrack是一种高效准确的基于CAD的6DoF物体姿态细化和跟踪方法，无需针对特定物体进行训练。它结合了帧到帧和模型到帧的配准（均通过光流估计实现），简化了模型到帧配准（使用DINOv2上的transformer），并为帧到帧配准使用轻量级现成光流模型。该方案达到SOTA的RGB方法水平。


<details>
  <summary>Details</summary>
Motivation: 现有方法仅依赖模型到帧的分析-合成配准，GoTrack通过整合帧到帧配准来节省计算并稳定跟踪。

Method: 1. 模型到帧配准：简化的神经网络（在DINOv2上训练的transformer）生成姿态置信度 2. 帧到帧配准：轻量级现成光流模型处理连续帧 3. 结合粗姿态估计形成完整流程

Result: 在标准6DoF物体姿态估计和跟踪基准测试中达到SOTA的RGB方法性能

Conclusion: 结合两类配准的GoTrack以最小流程实现高效精确跟踪，代码模型已开源

Abstract: We introduce GoTrack, an efficient and accurate CAD-based method for 6DoF
object pose refinement and tracking, which can handle diverse objects without
any object-specific training. Unlike existing tracking methods that rely solely
on an analysis-by-synthesis approach for model-to-frame registration, GoTrack
additionally integrates frame-to-frame registration, which saves compute and
stabilizes tracking. Both types of registration are realized by optical flow
estimation. The model-to-frame registration is noticeably simpler than in
existing methods, relying only on standard neural network blocks (a transformer
is trained on top of DINOv2) and producing reliable pose confidence scores
without a scoring network. For the frame-to-frame registration, which is an
easier problem as consecutive video frames are typically nearly identical, we
employ a light off-the-shelf optical flow model. We demonstrate that GoTrack
can be seamlessly combined with existing coarse pose estimation methods to
create a minimal pipeline that reaches state-of-the-art RGB-only results on
standard benchmarks for 6DoF object pose estimation and tracking. Our source
code and trained models are publicly available at
https://github.com/facebookresearch/gotrack

</details>


### [339] [Faster than Fast: Accelerating Oriented FAST Feature Detection on Low-end Embedded GPUs](https://arxiv.org/abs/2506.07164)
*Qiong Chang,Xinyuan Chen,Xiang Li,Weimin Wang,Jun Miyazaki*

Main category: cs.CV

TL;DR: 本文提出了两种在低端嵌入式GPU上加速ORB-SLAM中Oriented FAST特征检测的方法，通过二进制编码和可分Harris检测策略，在Jetson TX2上实现了比GPU版OpenCV平均7.3倍的加速。


<details>
  <summary>Details</summary>
Motivation: 虽然基于ORB的SLAM系统在速度和鲁棒性上表现优异，但Oriented FAST计算耗时约占SLAM系统总时间的一半，难以满足移动平台实时性需求。

Method: 针对Oriented FAST检测最耗时的两个步骤：1) 使用二进制编码策略快速确定候选点；2) 采用可分Harris检测策略配合底层GPU指令优化。

Result: 在Jetson TX2嵌入式GPU上，相比支持GPU的OpenCV实现平均获得7.3倍加速。

Conclusion: 所提加速方法能显著提升特征检测效率，为移动和资源受限环境下的实时SLAM应用提供了有效解决方案。

Abstract: The visual-based SLAM (Simultaneous Localization and Mapping) is a technology
widely used in applications such as robotic navigation and virtual reality,
which primarily focuses on detecting feature points from visual images to
construct an unknown environmental map and simultaneously determines its own
location. It usually imposes stringent requirements on hardware power
consumption, processing speed and accuracy. Currently, the ORB (Oriented FAST
and Rotated BRIEF)-based SLAM systems have exhibited superior performance in
terms of processing speed and robustness. However, they still fall short of
meeting the demands for real-time processing on mobile platforms. This
limitation is primarily due to the time-consuming Oriented FAST calculations
accounting for approximately half of the entire SLAM system. This paper
presents two methods to accelerate the Oriented FAST feature detection on
low-end embedded GPUs. These methods optimize the most time-consuming steps in
Oriented FAST feature detection: FAST feature point detection and Harris corner
detection, which is achieved by implementing a binary-level encoding strategy
to determine candidate points quickly and a separable Harris detection strategy
with efficient low-level GPU hardware-specific instructions. Extensive
experiments on a Jetson TX2 embedded GPU demonstrate an average speedup of over
7.3 times compared to widely used OpenCV with GPU support. This significant
improvement highlights its effectiveness and potential for real-time
applications in mobile and resource-constrained environments.

</details>


### [340] [Frame Guidance: Training-Free Guidance for Frame-Level Control in Video Diffusion Models](https://arxiv.org/abs/2506.07177)
*Sangwon Jang,Taekyung Ki,Jaehyeong Jo,Jaehong Yoon,Soo Ye Kim,Zhe Lin,Sung Ju Hwang*

Main category: cs.CV

TL;DR: 提出一种名为Frame Guidance的无训练引导方法，用于基于帧级信号（如关键帧、风格参考图像等）的可控视频生成。该方法通过简单的潜在空间处理和优化策略减少内存使用并确保全局连贯性，可兼容各种视频模型，适用于关键帧引导、风格化等多种任务。


<details>
  <summary>Details</summary>
Motivation: 现有方法通常需要针对特定任务微调大型视频模型，但随着模型规模增大，这种做法变得不切实际。因此，作者旨在开发无需训练的通用可控视频生成方法。

Method: 1. 提出Frame Guidance框架，利用帧级信号（关键帧/参考图等）进行无训练控制
2. 设计低内存占用的潜在空间处理方法
3. 采用新型潜在优化策略确保全局一致性

Result: 实验证明该方法能生成高质量可控视频，适用于关键帧引导、风格迁移、循环视频等多种任务，兼容各类视频模型。

Conclusion: Frame Guidance首次实现无需训练即可灵活控制视频生成，为可控视频生成提供高效、可扩展的解决方案，突破当前依赖任务特定微调的局限性。

Abstract: Advancements in diffusion models have significantly improved video quality,
directing attention to fine-grained controllability. However, many existing
methods depend on fine-tuning large-scale video models for specific tasks,
which becomes increasingly impractical as model sizes continue to grow. In this
work, we present Frame Guidance, a training-free guidance for controllable
video generation based on frame-level signals, such as keyframes, style
reference images, sketches, or depth maps. For practical training-free
guidance, we propose a simple latent processing method that dramatically
reduces memory usage, and apply a novel latent optimization strategy designed
for globally coherent video generation. Frame Guidance enables effective
control across diverse tasks, including keyframe guidance, stylization, and
looping, without any training, compatible with any video models. Experimental
results show that Frame Guidance can produce high-quality controlled videos for
a wide range of tasks and input signals.

</details>


### [341] [Hierarchical Feature-level Reverse Propagation for Post-Training Neural Networks](https://arxiv.org/abs/2506.07188)
*Ni Ding,Lei He,Shengbo Eben Li,Keqiang Li*

Main category: cs.CV

TL;DR: 该论文提出了一种分层的解耦后训练框架，通过重构中间特征图来提供可解释性和训练灵活性。


<details>
  <summary>Details</summary>
Motivation: 端到端自动驾驶模型通常是黑盒的，缺乏可解释性和安全保障。为了提高模型透明度和训练灵活性，作者提出了一种后训练方法。

Method: 该方法通过从真实标签重建中间特征图，引入代理监督信号，允许独立训练特定组件。同时，论文将特征级逆向计算形式化为优化问题（如线性方程组或最小二乘问题），创建了特征反向传播的新范式。

Result: 在多个标准图像分类基准测试中，该方法展现了优于传统训练方法的泛化性能和计算效率。

Conclusion: 该框架为预训练网络提供了高效、可解释的训练范式，在提升性能的同时揭示了模型内部机制，为安全关键领域（如自动驾驶）带来应用潜力。

Abstract: End-to-end autonomous driving has emerged as a dominant paradigm, yet its
highly entangled black-box models pose significant challenges in terms of
interpretability and safety assurance. To improve model transparency and
training flexibility, this paper proposes a hierarchical and decoupled
post-training framework tailored for pretrained neural networks. By
reconstructing intermediate feature maps from ground-truth labels, surrogate
supervisory signals are introduced at transitional layers to enable independent
training of specific components, thereby avoiding the complexity and coupling
of conventional end-to-end backpropagation and providing interpretable insights
into networks' internal mechanisms. To the best of our knowledge, this is the
first method to formalize feature-level reverse computation as well-posed
optimization problems, which we rigorously reformulate as systems of linear
equations or least squares problems. This establishes a novel and efficient
training paradigm that extends gradient backpropagation to feature
backpropagation. Extensive experiments on multiple standard image
classification benchmarks demonstrate that the proposed method achieves
superior generalization performance and computational efficiency compared to
traditional training approaches, validating its effectiveness and potential.

</details>


### [342] [SAP-Bench: Benchmarking Multimodal Large Language Models in Surgical Action Planning](https://arxiv.org/abs/2506.07196)
*Mengya Xu,Zhongzhen Huang,Dillan Imans,Yiru Ye,Xiaofan Zhang,Qi Dou*

Main category: cs.CV

TL;DR: 提出了SAP-Bench基准数据集，用于评估多模态大语言模型在外科手术行动规划上的表现，发现现有模型存在显著性能差距。


<details>
  <summary>Details</summary>
Motivation: 当前基准无法充分评估外科手术行动规划所需的精准分析能力，特别是处理原子级视觉动作和协调长流程手术的能力。

Method: 构建包含1226个临床验证动作片段的SAP-Bench数据集，并提出MLLM-SAP框架，通过注入外科知识增强MLLMs的行动推荐能力。

Result: 测试7个SOTA MLLMs模型（如GPT-4o、Claude-3.5等）均表现出明显性能不足，最优模型准确率仅63.1%。

Conclusion: SAP-Bench填补了手术决策评估空白，揭示当前MLLMs在生命攸关领域的局限性，推动可信赖手术AI发展。

Abstract: Effective evaluation is critical for driving advancements in MLLM research.
The surgical action planning (SAP) task, which aims to generate future action
sequences from visual inputs, demands precise and sophisticated analytical
capabilities. Unlike mathematical reasoning, surgical decision-making operates
in life-critical domains and requires meticulous, verifiable processes to
ensure reliability and patient safety. This task demands the ability to
distinguish between atomic visual actions and coordinate complex, long-horizon
procedures, capabilities that are inadequately evaluated by current benchmarks.
To address this gap, we introduce SAP-Bench, a large-scale, high-quality
dataset designed to enable multimodal large language models (MLLMs) to perform
interpretable surgical action planning. Our SAP-Bench benchmark, derived from
the cholecystectomy procedures context with the mean duration of 1137.5s, and
introduces temporally-grounded surgical action annotations, comprising the
1,226 clinically validated action clips (mean duration: 68.7s) capturing five
fundamental surgical actions across 74 procedures. The dataset provides 1,152
strategically sampled current frames, each paired with the corresponding next
action as multimodal analysis anchors. We propose the MLLM-SAP framework that
leverages MLLMs to generate next action recommendations from the current
surgical scene and natural language instructions, enhanced with injected
surgical domain knowledge. To assess our dataset's effectiveness and the
broader capabilities of current models, we evaluate seven state-of-the-art
MLLMs (e.g., OpenAI-o1, GPT-4o, QwenVL2.5-72B, Claude-3.5-Sonnet, GeminiPro2.5,
Step-1o, and GLM-4v) and reveal critical gaps in next action prediction
performance.

</details>


### [343] [TV-LiVE: Training-Free, Text-Guided Video Editing via Layer Informed Vitality Exploitation](https://arxiv.org/abs/2506.07205)
*Min-Jung Kim,Dongjin Kim,Seokju Yun,Jaegul Choo*

Main category: cs.CV

TL;DR: 提出TV-LiVE框架，无需训练，通过文本指导实现视频编辑，特别是实现对象添加和非刚体编辑。该方法基于发现关键层（关联RoPE），通过选择性注入特征实现编辑，并利用显著层提取新对象区域蒙版。实验证明其优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有视频编辑技术主要处理风格迁移、背景替换等任务，但无法有效处理对象添加和非刚体变换等复杂任务。旨在开发无需训练的文本引导视频编辑框架，解决这些挑战。

Method: 1. 经验性识别视频扩散模型中影响输出质量的关键层（与RoPE相关） 2. 选择性将源模型中KV特征注入目标模型的对应关键层 3. 对象添加任务中，用显著层提取新对象区域蒙版，指导特征注入。

Result: 在对象添加和非刚体视频编辑任务中，TV-LiVE均优于现有方法；提取的蒙版能准确指示需编辑区域；框架无需训练即实现高效编辑。

Conclusion: 1. 首次实现高效的非训练文本引导视频编辑 2. 发现关键层及其与RoPE的关联性 3. 通过层级特性挖掘实现对象添加和非刚体编辑的突破 4. 为复杂视频编辑任务提供新思路

Abstract: Video editing has garnered increasing attention alongside the rapid progress
of diffusion-based video generation models. As part of these advancements,
there is a growing demand for more accessible and controllable forms of video
editing, such as prompt-based editing. Previous studies have primarily focused
on tasks such as style transfer, background replacement, object substitution,
and attribute modification, while maintaining the content structure of the
source video. However, more complex tasks, including the addition of novel
objects and nonrigid transformations, remain relatively unexplored. In this
paper, we present TV-LiVE, a Training-free and text-guided Video editing
framework via Layerinformed Vitality Exploitation. We empirically identify
vital layers within the video generation model that significantly influence the
quality of generated outputs. Notably, these layers are closely associated with
Rotary Position Embeddings (RoPE). Based on this observation, our method
enables both object addition and non-rigid video editing by selectively
injecting key and value features from the source model into the corresponding
layers of the target model guided by the layer vitality. For object addition,
we further identify prominent layers to extract the mask regions corresponding
to the newly added target prompt. We found that the extracted masks from the
prominent layers faithfully indicate the region to be edited. Experimental
results demonstrate that TV-LiVE outperforms existing approaches for both
object addition and non-rigid video editing. Project Page:
https://emjay73.github.io/TV_LiVE/

</details>


### [344] [Backdoor Attack on Vision Language Models with Stealthy Semantic Manipulation](https://arxiv.org/abs/2506.07214)
*Zhiyuan Zhong,Zhen Sun,Yepang Liu,Xinlei He,Guanhong Tao*

Main category: cs.CV

TL;DR: 我们提出了一种名为BadSem的新型后门攻击，通过数据投毒在跨模态语义不匹配时触发恶意输出。该方法在四类VLM上实现了98%以上的攻击成功率。


<details>
  <summary>Details</summary>
Motivation: 现有后门攻击主要使用单模态触发器，未能充分探索跨模态融合模型的漏洞。本文发现语义不匹配可作为隐蔽攻击面，旨在揭示此安全问题。

Method: 构建SIMBad数据集，在训练中故意错配图像-文本对来植入后门，重点关注颜色和物体属性特征。

Result: 攻击平均成功率超过98%，跨数据集泛化性好，可在不同投毒模态间转移。可视化显示后门模型在语义混乱时会聚焦错误特征。

Conclusion: 现有防御策略无法消除此类攻击，证明语义漏洞对VLM构成重大威胁，亟需针对性防御方案。

Abstract: Vision Language Models (VLMs) have shown remarkable performance, but are also
vulnerable to backdoor attacks whereby the adversary can manipulate the model's
outputs through hidden triggers. Prior attacks primarily rely on
single-modality triggers, leaving the crucial cross-modal fusion nature of VLMs
largely unexplored. Unlike prior work, we identify a novel attack surface that
leverages cross-modal semantic mismatches as implicit triggers. Based on this
insight, we propose BadSem (Backdoor Attack with Semantic Manipulation), a data
poisoning attack that injects stealthy backdoors by deliberately misaligning
image-text pairs during training. To perform the attack, we construct SIMBad, a
dataset tailored for semantic manipulation involving color and object
attributes. Extensive experiments across four widely used VLMs show that BadSem
achieves over 98% average ASR, generalizes well to out-of-distribution
datasets, and can transfer across poisoning modalities. Our detailed analysis
using attention visualization shows that backdoored models focus on
semantically sensitive regions under mismatched conditions while maintaining
normal behavior on clean inputs. To mitigate the attack, we try two defense
strategies based on system prompt and supervised fine-tuning but find that both
of them fail to mitigate the semantic backdoor. Our findings highlight the
urgent need to address semantic vulnerabilities in VLMs for their safer
deployment.

</details>


### [345] [AugmentGest: Can Random Data Cropping Augmentation Boost Gesture Recognition Performance?](https://arxiv.org/abs/2506.07216)
*Nada Aboudeshish,Dmitry Ignatov,Radu Timofte*

Main category: cs.CV

TL;DR: 提出了一个综合数据增强框架，结合多种变换增强骨架数据多样性，实验在多个模型和数据集上验证了其有效性


<details>
  <summary>Details</summary>
Motivation: 骨架数据受限于多样性和规模，导致模型泛化能力弱。需通过数据增强模拟真实世界变异

Method: 整合几何变换、随机裁剪、旋转、缩放、强度变换（亮度/对比度调整）等技术，保持时空完整性。为每个样本生成三个增强版本

Result: 在e2eET、FPPR-PCD、DD-Net等模型及DHG14/28/SHREC'17/JHMDB数据集上显著提升性能，刷新SOTA

Conclusion: 该框架可扩展性强，有效提升模型鲁棒性，推动手势识别与动作识别的实际应用

Abstract: Data augmentation is a crucial technique in deep learning, particularly for
tasks with limited dataset diversity, such as skeleton-based datasets. This
paper proposes a comprehensive data augmentation framework that integrates
geometric transformations, random cropping, rotation, zooming and
intensity-based transformations, brightness and contrast adjustments to
simulate real-world variations. Random cropping ensures the preservation of
spatio-temporal integrity while addressing challenges such as viewpoint bias
and occlusions. The augmentation pipeline generates three augmented versions
for each sample in addition to the data set sample, thus quadrupling the data
set size and enriching the diversity of gesture representations. The proposed
augmentation strategy is evaluated on three models: multi-stream e2eET, FPPR
point cloud-based hand gesture recognition (HGR), and DD-Network. Experiments
are conducted on benchmark datasets including DHG14/28, SHREC'17, and JHMDB.
The e2eET model, recognized as the state-of-the-art for hand gesture
recognition on DHG14/28 and SHREC'17. The FPPR-PCD model, the second-best
performing model on SHREC'17, excels in point cloud-based gesture recognition.
DD-Net, a lightweight and efficient architecture for skeleton-based action
recognition, is evaluated on SHREC'17 and the Human Motion Data Base (JHMDB).
The results underline the effectiveness and versatility of the proposed
augmentation strategy, significantly improving model generalization and
robustness across diverse datasets and architectures. This framework not only
establishes state-of-the-art results on all three evaluated models but also
offers a scalable solution to advance HGR and action recognition applications
in real-world scenarios. The framework is available at
https://github.com/NadaAbodeshish/Random-Cropping-augmentation-HGR

</details>


### [346] [Hallucination at a Glance: Controlled Visual Edits and Fine-Grained Multimodal Learning](https://arxiv.org/abs/2506.07227)
*Tianyi Bai,Yuxuan Fan,Jiantao Qiu,Fupeng Sun,Jiayi Song,Junlin Han,Zichen Liu,Conghui He,Wentao Zhang,Binhang Yuan*

Main category: cs.CV

TL;DR: 研究人员提出了一种针对多模态大语言模型（MLLMs）在细粒度视觉差异识别上的改进方法，利用受控数据生成流程构建了Micro Edit Dataset (MED)数据集，并通过特征级一致性损失的监督微调框架提升模型性能。该方法在微编辑检测基准和标准视觉语言任务中均取得显著效果提升。


<details>
  <summary>Details</summary>
Motivation: 现有MLLMs在处理视觉细节时存在幻觉和语义偏移遗漏问题，主要源于训练数据和目标函数的局限。这阻碍了模型在需要精确视觉判断的场景中的应用。

Method: 1) 开发可控数据生成流程创建微编辑图像对及语义对齐文本（MED数据集含11类5万余样本）；2) 设计带特征级一致性损失的SFT框架，强化编辑前后视觉特征稳定性。

Result: 1) 在细粒度编辑检测基准上超越GPT-4o等基线，准确率提升且幻觉减少；2) 标准任务（图像描述/视觉问答）获得一致性改进；3) 证实目标数据与对齐目标结合的有效性。

Conclusion: 通过构建针对性数据集MED和实施特征一致性优化，显著增强了MLLMs的细粒度视觉推理能力，为解决视觉幻觉问题提供了有效方案。

Abstract: Multimodal large language models (MLLMs) have achieved strong performance on
vision-language tasks but still struggle with fine-grained visual differences,
leading to hallucinations or missed semantic shifts. We attribute this to
limitations in both training data and learning objectives. To address these
issues, we propose a controlled data generation pipeline that produces
minimally edited image pairs with semantically aligned captions. Using this
pipeline, we construct the Micro Edit Dataset (MED), containing over 50K
image-text pairs spanning 11 fine-grained edit categories, including attribute,
count, position, and object presence changes. Building on MED, we introduce a
supervised fine-tuning (SFT) framework with a feature-level consistency loss
that promotes stable visual embeddings under small edits. We evaluate our
approach on the Micro Edit Detection benchmark, which includes carefully
balanced evaluation pairs designed to test sensitivity to subtle visual
variations across the same edit categories. Our method improves difference
detection accuracy and reduces hallucinations compared to strong baselines,
including GPT-4o. Moreover, it yields consistent gains on standard
vision-language tasks such as image captioning and visual question answering.
These results demonstrate the effectiveness of combining targeted data and
alignment objectives for enhancing fine-grained visual reasoning in MLLMs.

</details>


### [347] [Multi-Step Visual Reasoning with Visual Tokens Scaling and Verification](https://arxiv.org/abs/2506.07235)
*Tianyi Bai,Zengjie Hu,Fupeng Sun,Jiantao Qiu,Yizhen Jiang,Guangxin He,Bohan Zeng,Conghui He,Binhang Yuan,Wentao Zhang*

Main category: cs.CV

TL;DR: 该论文提出了一个推理时视觉令牌缩放的新框架，使多模态大语言模型（MLLMs）能够对视觉内容进行迭代的、验证器引导的推理。


<details>
  <summary>Details</summary>
Motivation: 现有MLLMs采用静态推理范式，将整个图像编码为固定视觉令牌，限制了其在推理过程中迭代细化理解或适应上下文的能力，缺乏人类感知的动态、选择性和反馈驱动特性。

Method: 将问题建模为马尔可夫决策过程，包含提出视觉动作的推理器和通过多步直接偏好优化（DPO）训练的验证器。开发了VTS数据集，包含监督推理轨迹（VTS-SFT）和偏好标记的推理比较（VTS-DPO）。

Result: 该方法在多种视觉推理基准测试中显著优于现有方法，不仅提高了准确性，还提供了更具可解释性和基础性的推理过程。

Conclusion: 动态推理机制有望在下一代MLLMs中实现细粒度、上下文感知的视觉推理。

Abstract: Multi-modal large language models (MLLMs) have achieved remarkable
capabilities by integrating visual perception with language understanding,
enabling applications such as image-grounded dialogue, visual question
answering, and scientific analysis. However, most MLLMs adopt a static
inference paradigm, encoding the entire image into fixed visual tokens upfront,
which limits their ability to iteratively refine understanding or adapt to
context during inference. This contrasts sharply with human perception, which
is dynamic, selective, and feedback-driven. In this work, we introduce a novel
framework for inference-time visual token scaling that enables MLLMs to perform
iterative, verifier-guided reasoning over visual content. We formulate the
problem as a Markov Decision Process, involving a reasoner that proposes visual
actions and a verifier, which is trained via multi-step Direct Preference
Optimization (DPO), that evaluates these actions and determines when reasoning
should terminate. To support this, we present a new dataset, VTS, comprising
supervised reasoning trajectories (VTS-SFT) and preference-labeled reasoning
comparisons (VTS-DPO). Our method significantly outperforms existing approaches
across diverse visual reasoning benchmarks, offering not only improved accuracy
but also more interpretable and grounded reasoning processes. These results
demonstrate the promise of dynamic inference mechanisms for enabling
fine-grained, context-aware visual reasoning in next-generation MLLMs.

</details>


### [348] [From Generation to Generalization: Emergent Few-Shot Learning in Video Diffusion Models](https://arxiv.org/abs/2506.07280)
*Pablo Acuaviva,Aram Davtyan,Mariam Hassan,Sebastian Stapf,Ahmad Rahimi,Alexandre Alahi,Paolo Favaro*

Main category: cs.CV

TL;DR: 该论文核心是将视频生成模型重新定义为通用视觉学习者，提出少样本学习框架，适应多种视觉任务而不改变基础模型


<details>
  <summary>Details</summary>
Motivation: 现有视频生成模型被低估：它们在训练过程中的连续建模能力应该能提炼复杂的视觉知识结构。本文旨在验证其作为通用视觉基座的潜力

Method: 开发少样本微调框架，将任何视觉任务转化为序列输入输出模式。仅需少量示例，通过冻结主干并训练LoRA参数层实现多任务适配

Result: 在包含低层次分割姿态预测到高层次ARC-AGI的测试集上展示强大泛化力，证明文本生成接口可统一处理视觉任务

Conclusion: 视频生成模型是视觉基础模型的候选基座，其少样本适应能力突破生成领域，为通用视觉智能开辟新路径

Abstract: Video Diffusion Models (VDMs) have emerged as powerful generative tools,
capable of synthesizing high-quality spatiotemporal content. Yet, their
potential goes far beyond mere video generation. We argue that the training
dynamics of VDMs, driven by the need to model coherent sequences, naturally
pushes them to internalize structured representations and an implicit
understanding of the visual world. To probe the extent of this internal
knowledge, we introduce a few-shot fine-tuning framework that repurposes VDMs
for new tasks using only a handful of examples. Our method transforms each task
into a visual transition, enabling the training of LoRA weights on short
input-output sequences without altering the generative interface of a frozen
VDM. Despite minimal supervision, the model exhibits strong generalization
across diverse tasks, from low-level vision (for example, segmentation and pose
estimation) to high-level reasoning (for example, on ARC-AGI). These results
reframe VDMs as more than generative engines. They are adaptable visual
learners with the potential to serve as the backbone for future foundation
models in vision.

</details>


### [349] [Multi-Step Guided Diffusion for Image Restoration on Edge Devices: Toward Lightweight Perception in Embodied AI](https://arxiv.org/abs/2506.07286)
*Aditya Chakravarty*

Main category: cs.CV

TL;DR: 该论文通过在MPGD的每个去噪步骤中使用多步梯度优化，显著提高了图像恢复质量、感知精度和泛化能力，且计算开销低。实验验证了其在超分辨率和去模糊任务中的有效性，并在嵌入式设备上实现实时恢复。


<details>
  <summary>Details</summary>
Motivation: 现有基于扩散模型的逆问题求解方法（如MPGD）每个去噪步骤只执行单次梯度更新，限制了恢复效果和泛化能力，尤其在嵌入式或分布外场景。

Method: 在MPGD框架内，对每个去噪步骤应用多步梯度优化策略，增加梯度更新次数以获得更精确的潜变量估计。

Result: 实验表明：1) 增加梯度更新步数可提升LPIPS和PSNR指标；2) 在Jetson Orin Nano上验证了低延迟实时处理；3) MPGD从人脸数据集成功泛化到自然图像和无人机航拍图像。

Conclusion: 多步优化策略大幅提升了MPGD的恢复性能，使其成为轻量级、即插即用的实时图像恢复模块，适用于无人机、移动机器人等嵌入式AI系统。

Abstract: Diffusion models have shown remarkable flexibility for solving inverse
problems without task-specific retraining. However, existing approaches such as
Manifold Preserving Guided Diffusion (MPGD) apply only a single gradient update
per denoising step, limiting restoration fidelity and robustness, especially in
embedded or out-of-distribution settings. In this work, we introduce a
multistep optimization strategy within each denoising timestep, significantly
enhancing image quality, perceptual accuracy, and generalization. Our
experiments on super-resolution and Gaussian deblurring demonstrate that
increasing the number of gradient updates per step improves LPIPS and PSNR with
minimal latency overhead. Notably, we validate this approach on a Jetson Orin
Nano using degraded ImageNet and a UAV dataset, showing that MPGD, originally
trained on face datasets, generalizes effectively to natural and aerial scenes.
Our findings highlight MPGD's potential as a lightweight, plug-and-play
restoration module for real-time visual perception in embodied AI agents such
as drones and mobile robots.

</details>


### [350] [FANVID: A Benchmark for Face and License Plate Recognition in Low-Resolution Videos](https://arxiv.org/abs/2506.07304)
*Kavitha Viswanathan,Vrinda Goel,Shlesh Gholap,Devayan Ghosh,Madhav Gupta,Dhruvi Ganatra,Sanket Potdar,Amit Sethi*

Main category: cs.CV

TL;DR: FANVID是一个新的视频基准数据集，包含1,463个低分辨率视频片段，针对人脸匹配和车牌识别任务设计，要求模型利用时序信息。数据集包含31,096个手动标注框，并提供基线方法（成绩0.58和0.42）及开源工具。


<details>
  <summary>Details</summary>
Motivation: 现实监控中低分辨率单帧无法识别人脸和车牌，需开发能利用时序信息的模型。当前缺乏专为时序低分辨率识别设计的数据集。

Method: 创建FANVID数据集：从高清视频降采样生成180x320分辨率视频（20-60FPS），包含63个人物和49个车牌的31,096个标注框。定义两项任务：1)人脸匹配：将低清人脸与高清证件照匹配 2)车牌识别：直接识别低清车牌文字。采用改进版mAP@IoU>0.5作为评估指标。

Result: 基线方法（视频超分+检测+识别）在人脸匹配任务得0.58分，车牌识别得0.42分。证明任务可行性但具挑战性。

Conclusion: FANVID通过刻意降低单帧可读性迫使模型学习时间信息，填补了时序低分辨率识别数据集的空白。开源工具促进可复现性，可推动监控/自动驾驶等领域的时序模型创新。

Abstract: Real-world surveillance often renders faces and license plates unrecognizable
in individual low-resolution (LR) frames, hindering reliable identification. To
advance temporal recognition models, we present FANVID, a novel video-based
benchmark comprising nearly 1,463 LR clips (180 x 320, 20--60 FPS) featuring 63
identities and 49 license plates from three English-speaking countries. Each
video includes distractor faces and plates, increasing task difficulty and
realism. The dataset contains 31,096 manually verified bounding boxes and
labels.
  FANVID defines two tasks: (1) face matching -- detecting LR faces and
matching them to high-resolution mugshots, and (2) license plate recognition --
extracting text from LR plates without a predefined database. Videos are
downsampled from high-resolution sources to ensure that faces and text are
indecipherable in single frames, requiring models to exploit temporal
information. We introduce evaluation metrics adapted from mean Average
Precision at IoU > 0.5, prioritizing identity correctness for faces and
character-level accuracy for text.
  A baseline method with pre-trained video super-resolution, detection, and
recognition achieved performance scores of 0.58 (face matching) and 0.42 (plate
recognition), highlighting both the feasibility and challenge of the tasks.
FANVID's selection of faces and plates balances diversity with recognition
challenge. We release the software for data access, evaluation, baseline, and
annotation to support reproducibility and extension. FANVID aims to catalyze
innovation in temporal modeling for LR recognition, with applications in
surveillance, forensics, and autonomous vehicles.

</details>


### [351] [AllTracker: Efficient Dense Point Tracking at High Resolution](https://arxiv.org/abs/2506.07310)
*Adam W. Harley,Yang You,Xinglong Sun,Yang Zheng,Nikhil Raghuraman,Yunqi Gu,Sheldon Liang,Wen-Hsuan Chu,Achal Dave,Pavel Tokmakov,Suya You,Rares Ambrus,Katerina Fragkiadaki,Leonidas J. Guibas*

Main category: cs.CV

TL;DR: AllTracker模型通过估计查询帧与视频每个后续帧之间的光流场，提供高分辨率、稠密的长程点跟踪，融合光流和点跟踪技术，实现高效高精度的跨帧对应。


<details>
  <summary>Details</summary>
Motivation: 现有点跟踪方法无法提供稠密对应关系，而传统光流方法仅能估计相邻帧的流动。AllTracker旨在解决跨数百帧的稠密、高清点跟踪问题。

Method: 结合迭代推理的低分辨率对应估计网格：利用2D卷积层进行空间传播，通过像素对齐注意力层进行时间传播，模型仅含1600万参数，支持768x1024分辨率实时处理。

Result: 在40G GPU上实现高清（768x1024）点跟踪的SOTA精度；训练数据多样性被证明是关键要素；开源代码与模型权重。

Conclusion: 统一光流与点跟踪的架构设计显著提升长程稠密跟踪性能，模型高效且参数量小，泛化能力依赖于多数据集训练。

Abstract: We introduce AllTracker: a model that estimates long-range point tracks by
way of estimating the flow field between a query frame and every other frame of
a video. Unlike existing point tracking methods, our approach delivers
high-resolution and dense (all-pixel) correspondence fields, which can be
visualized as flow maps. Unlike existing optical flow methods, our approach
corresponds one frame to hundreds of subsequent frames, rather than just the
next frame. We develop a new architecture for this task, blending techniques
from existing work in optical flow and point tracking: the model performs
iterative inference on low-resolution grids of correspondence estimates,
propagating information spatially via 2D convolution layers, and propagating
information temporally via pixel-aligned attention layers. The model is fast
and parameter-efficient (16 million parameters), and delivers state-of-the-art
point tracking accuracy at high resolution (i.e., tracking 768x1024 pixels, on
a 40G GPU). A benefit of our design is that we can train on a wider set of
datasets, and we find that doing so is crucial for top performance. We provide
an extensive ablation study on our architecture details and training recipe,
making it clear which details matter most. Our code and model weights are
available at https://alltracker.github.io .

</details>


### [352] ["CASE: Contrastive Activation for Saliency Estimation](https://arxiv.org/abs/2506.07327)
*Dane Williamson,Yangfeng Ji,Matthew Dwyer*

Main category: cs.CV

TL;DR: 许多显著性方法在区分不同类别时表现不佳，提出一种新的诊断测试。引入CASE方法提高解释的准确性。


<details>
  <summary>Details</summary>
Motivation: 研究揭示现有显著性方法在可视化模型预测相关输入特征时存在局限性，特别是在区分不同类别标签方面存在问题。这些方法的可视化看似合理，但实际上可能无法可靠地辨别不同类别。

Method: 提出一种诊断测试验证现有显著性方法的类别区分能力，并引入CASE（对比解释方法），该方法能够分离出对预测类别具有唯一区分性的特征。

Result: 通过大量实验发现许多广泛使用的显著性方法在相同输入下对不同类别标签产生的解释几乎相同，表明这些方法存在结构性缺陷。提出的CASE方法在诊断测试和基于扰动的保真度测试中表现得更加准确和具有类别区分性。

Conclusion: 现有显著性方法存在类别不敏感的局限性，而CASE作为一种新的对比解释方法，能够更可靠、更准确地提供类特有的特征解释。

Abstract: Saliency methods are widely used to visualize which input features are deemed
relevant to a model's prediction. However, their visual plausibility can
obscure critical limitations. In this work, we propose a diagnostic test for
class sensitivity: a method's ability to distinguish between competing class
labels on the same input. Through extensive experiments, we show that many
widely used saliency methods produce nearly identical explanations regardless
of the class label, calling into question their reliability. We find that
class-insensitive behavior persists across architectures and datasets,
suggesting the failure mode is structural rather than model-specific. Motivated
by these findings, we introduce CASE, a contrastive explanation method that
isolates features uniquely discriminative for the predicted class. We evaluate
CASE using the proposed diagnostic and a perturbation-based fidelity test, and
show that it produces faithful and more class-specific explanations than
existing methods.

</details>


### [353] [Hierarchical Scoring with 3D Gaussian Splatting for Instance Image-Goal Navigation](https://arxiv.org/abs/2506.07338)
*Yijie Deng,Shuaihang Yuan,Geeta Chandra Raju Bethala,Anthony Tzes,Yu-Shen Liu,Yi Fang*

Main category: cs.CV

TL;DR: 提出了一种新颖的实例图像目标导航（IIN）框架，采用层次化评分范式选择优化视角，减少冗余渲染并提升导航效率。通过结合跨层级语义评分（CLIP语义相似度）和局部几何评分（位姿估计），显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有IIN方法依赖随机多视角采样，导致大量重叠图像和无效计算。为解决渲染效率和视角选择问题，需要更智能的判别性视角估计机制。

Method: 1. 跨层级语义评分：利用CLIP生成语义相关场定位目标对象类高相似区域；2. 局部几何评分：在候选区域进行精细位姿估计；3. 层次化整合两种评分选择最优视角。

Result: 在仿真IIN基准测试中达到SOTA性能，计算开销显著降低（渲染量减少），并验证了真实世界适用性。

Conclusion: 层次化评分机制通过减少冗余计算提升IIN效率，语义-几何联合优化为智能视角选择提供了新思路。

Abstract: Instance Image-Goal Navigation (IIN) requires autonomous agents to identify
and navigate to a target object or location depicted in a reference image
captured from any viewpoint. While recent methods leverage powerful novel view
synthesis (NVS) techniques, such as three-dimensional Gaussian splatting
(3DGS), they typically rely on randomly sampling multiple viewpoints or
trajectories to ensure comprehensive coverage of discriminative visual cues.
This approach, however, creates significant redundancy through overlapping
image samples and lacks principled view selection, substantially increasing
both rendering and comparison overhead. In this paper, we introduce a novel IIN
framework with a hierarchical scoring paradigm that estimates optimal
viewpoints for target matching. Our approach integrates cross-level semantic
scoring, utilizing CLIP-derived relevancy fields to identify regions with high
semantic similarity to the target object class, with fine-grained local
geometric scoring that performs precise pose estimation within promising
regions. Extensive evaluations demonstrate that our method achieves
state-of-the-art performance on simulated IIN benchmarks and real-world
applicability.

</details>


### [354] [CBAM-STN-TPS-YOLO: Enhancing Agricultural Object Detection through Spatially Adaptive Attention Mechanisms](https://arxiv.org/abs/2506.07357)
*Satvik Praveen,Yoonsung Jung*

Main category: cs.CV

TL;DR: 提出CBAM-STN-TPS-YOLO模型，结合TPS-STN处理植物图像中的非刚性形变，并整合CBAM增强特征提取。在PGP数据集上显著提升检测精度，减少误检率，且适用于实时边缘计算。


<details>
  <summary>Details</summary>
Motivation: 农业植物检测中，现有YOLO模型对遮挡、非规则结构和背景噪声敏感，传统STN的仿射变换无法处理植物叶片弯曲重叠等非刚性形变问题，需要更灵活的空间变换方法。

Method: 1. 将薄板样条(TPS)融入空间变换网络(STN)，实现非刚性空间变换对齐特征；2. 结合卷积注意力模块(CBAM)抑制背景噪声，强化空间及通道特征；3. 在YOLO检测框架中集成上述模块

Result: 在PGP数据集上表现：1. 精确率、召回率及mAP全面超越STN-YOLO；2. 误检率降低12%；3. 验证了TPS正则化参数对形变平滑度与检测性能的平衡作用

Conclusion: 该轻量模型通过TPS-STN增强空间适应性，CBAM优化特征权重，显著提升遮挡场景下的检测鲁棒性。适用于需要高精度实时监测的智慧农业边缘设备部署。

Abstract: Object detection is vital in precision agriculture for plant monitoring,
disease detection, and yield estimation. However, models like YOLO struggle
with occlusions, irregular structures, and background noise, reducing detection
accuracy. While Spatial Transformer Networks (STNs) improve spatial invariance
through learned transformations, affine mappings are insufficient for non-rigid
deformations such as bent leaves and overlaps.
  We propose CBAM-STN-TPS-YOLO, a model integrating Thin-Plate Splines (TPS)
into STNs for flexible, non-rigid spatial transformations that better align
features. Performance is further enhanced by the Convolutional Block Attention
Module (CBAM), which suppresses background noise and emphasizes relevant
spatial and channel-wise features.
  On the occlusion-heavy Plant Growth and Phenotyping (PGP) dataset, our model
outperforms STN-YOLO in precision, recall, and mAP. It achieves a 12% reduction
in false positives, highlighting the benefits of improved spatial flexibility
and attention-guided refinement. We also examine the impact of the TPS
regularization parameter in balancing transformation smoothness and detection
performance.
  This lightweight model improves spatial awareness and supports real-time edge
deployment, making it ideal for smart farming applications requiring accurate
and efficient monitoring.

</details>


### [355] [Multiple Object Stitching for Unsupervised Representation Learning](https://arxiv.org/abs/2506.07364)
*Chengchao Shen,Dawei Liu,Jianxin Wang*

Main category: cs.CV

TL;DR: 提出MOS方法，通过缝合单目标中心图像构建多目标图像，利用预设目标对应关系优化无监督表示学习，提升多目标图像表示性能。


<details>
  <summary>Details</summary>
Motivation: 现有对比学习在单目标图像上表现良好，但在多目标图像上性能不足。为解决此问题，提出通过预定义对象对应关系改进多目标表示。

Method: 通过缝合单目标图像合成多目标图像（保留目标对应关系），在对比学习框架中利用这些附加对应关系强化各对象表示学习。

Result: 在ImageNet、CIFAR、COCO上取得领先的无监督表示性能，显著改善多目标图像处理能力。

Conclusion: MOS通过合成图像与预设对应关系有效提升多目标图像的表示学习，为检测、分割等下游任务提供更细致的特征。

Abstract: Contrastive learning for single object centric images has achieved remarkable
progress on unsupervised representation, but suffering inferior performance on
the widespread images with multiple objects. In this paper, we propose a simple
but effective method, Multiple Object Stitching (MOS), to refine the
unsupervised representation for multi-object images. Specifically, we construct
the multi-object images by stitching the single object centric ones, where the
objects in the synthesized multi-object images are predetermined. Hence,
compared to the existing contrastive methods, our method provides additional
object correspondences between multi-object images without human annotations.
In this manner, our method pays more attention to the representations of each
object in multi-object image, thus providing more detailed representations for
complicated downstream tasks, such as object detection and semantic
segmentation. Experimental results on ImageNet, CIFAR and COCO datasets
demonstrate that our proposed method achieves the leading unsupervised
representation performance on both single object centric images and
multi-object ones. The source code is available at
https://github.com/visresearch/MultipleObjectStitching.

</details>


### [356] [C3S3: Complementary Competition and Contrastive Selection for Semi-Supervised Medical Image Segmentation](https://arxiv.org/abs/2506.07368)
*Jiaying He,Yitong Lin,Jiahe Chen,Honghui Xu,Jianwei Zheng*

Main category: cs.CV

TL;DR: 该论文提出了一种新的半监督医学图像分割模型C3S3，通过互补竞争和对比选择机制解决现有方法在边界细节分割上的不足，显著提升了分割精度。


<details>
  <summary>Details</summary>
Motivation: 现有半监督医学图像分割方法在边界细节处理上存在不足，易导致诊断误差。

Method: 开发包含两个核心模块的C3S3模型：1）结果驱动的对比学习模块优化边界定位；2）动态互补竞争模块利用双分支网络生成高质量伪标签。

Result: 在公开MRI和CT数据集上验证，95HD和ASD指标至少提升6%，超越现有先进方法。

Conclusion: C3S3通过协同互补竞争和对比选择机制，显著提升医学图像边界分割精度，为诊断提供更可靠支持。

Abstract: For the immanent challenge of insufficiently annotated samples in the medical
field, semi-supervised medical image segmentation (SSMIS) offers a promising
solution. Despite achieving impressive results in delineating primary target
areas, most current methodologies struggle to precisely capture the subtle
details of boundaries. This deficiency often leads to significant diagnostic
inaccuracies. To tackle this issue, we introduce C3S3, a novel semi-supervised
segmentation model that synergistically integrates complementary competition
and contrastive selection. This design significantly sharpens boundary
delineation and enhances overall precision. Specifically, we develop an
$\textit{Outcome-Driven Contrastive Learning}$ module dedicated to refining
boundary localization. Additionally, we incorporate a $\textit{Dynamic
Complementary Competition}$ module that leverages two high-performing
sub-networks to generate pseudo-labels, thereby further improving segmentation
quality. The proposed C3S3 undergoes rigorous validation on two publicly
accessible datasets, encompassing the practices of both MRI and CT scans. The
results demonstrate that our method achieves superior performance compared to
previous cutting-edge competitors. Especially, on the 95HD and ASD metrics, our
approach achieves a notable improvement of at least $6\%$, highlighting the
significant advancements. The code is available at
https://github.com/Y-TARL/C3S3.

</details>


### [357] [Generative Models at the Frontier of Compression: A Survey on Generative Face Video Coding](https://arxiv.org/abs/2506.07369)
*Bolin Chen,Shanzhi Yin,Goluck Konuko,Giuseppe Valenzise,Zihan Zhang,Shiqi Wang,Yan Ye*

Main category: cs.CV

TL;DR: 这是一篇关于生成式人脸视频编码（GFVC）技术的综述论文。该技术利用深度生成模型在超低码率下实现高保真面部视频重建，性能远超传统视频编码标准如VVC。论文系统回顾了现有GFVC方法，进行了基准测试分析；构建了包含主观评分的大规模GFVC压缩人脸视频数据库；并探讨了标准化和应用前景。


<details>
  <summary>Details</summary>
Motivation: 现有视频编码标准（如VVC）在面部视频压缩领域面临高保真与超低码率难以兼顾的限制，而生成式模型提供了突破可能。论文旨在通过首次系统梳理GFVC技术，弥合理论创新与标准化之间的鸿沟。

Method: 1) 系统分类回顾现有GFVC方法；2) 建立含主观评分的大规模GFVC压缩数据集；3) 开发低复杂度GFVC系统原型；4) 分析标准化路径（制定统一高层语法）。

Result: 1）完成对多种GFVC方法的技术梳理和性能测试；2）构建首个GFVC专用主观质量数据库；3）验证低复杂度GFVC系统可行性；4）明确GFVC标准化关键方向：建立编解码器间的生成语义空间。特别地通过数据库分析发现：结构相似性度量（如MS-SSIM）相比传统PSNR更能反映GFVC视频感知质量。

Conclusion: GFVC代表视频压缩领域范式变革，在超低码率场景（如VR通讯）优势显著。当前挑战包括生成扭曲控制、计算复杂度和标准化推进，未来可探索生成-混合编码协同框架和硬件友好型算法。

Abstract: The rise of deep generative models has greatly advanced video compression,
reshaping the paradigm of face video coding through their powerful capability
for semantic-aware representation and lifelike synthesis. Generative Face Video
Coding (GFVC) stands at the forefront of this revolution, which could
characterize complex facial dynamics into compact latent codes for bitstream
compactness at the encoder side and leverages powerful deep generative models
to reconstruct high-fidelity face signal from the compressed latent codes at
the decoder side. As such, this well-designed GFVC paradigm could enable
high-fidelity face video communication at ultra-low bitrate ranges, far
surpassing the capabilities of the latest Versatile Video Coding (VVC)
standard. To pioneer foundational research and accelerate the evolution of
GFVC, this paper presents the first comprehensive survey of GFVC technologies,
systematically bridging critical gaps between theoretical innovation and
industrial standardization. In particular, we first review a broad range of
existing GFVC methods with different feature representations and optimization
strategies, and conduct a thorough benchmarking analysis. In addition, we
construct a large-scale GFVC-compressed face video database with subjective
Mean Opinion Scores (MOSs) based on human perception, aiming to identify the
most appropriate quality metrics tailored to GFVC. Moreover, we summarize the
GFVC standardization potentials with a unified high-level syntax and develop a
low-complexity GFVC system which are both expected to push forward future
practical deployments and applications. Finally, we envision the potential of
GFVC in industrial applications and deliberate on the current challenges and
future opportunities.

</details>


### [358] [ARGUS: Hallucination and Omission Evaluation in Video-LLMs](https://arxiv.org/abs/2506.07371)
*Ruchit Rawal,Reza Shirkavand,Heng Huang,Gowthami Somepalli,Tom Goldstein*

Main category: cs.CV

TL;DR: ARGUS benchmark was developed to measure VideoLLM performance on freeform video captioning tasks, assessing both hallucinations (incorrect details) and omissions (missing important details).


<details>
  <summary>Details</summary>
Motivation: Video large language models hallucinate significantly on freeform text tasks but this isn't captured by multiple-choice benchmarks.

Method: Proposed ARGUS benchmark compares model outputs with human ground truth captions to quantify hallucinations and omissions.

Result: Dual metrics reveal hallucination rates and omission rates, providing a comprehensive view of captioning quality.

Conclusion: ARGUS provides essential performance measurement for VideoLLMs addressing freeform captioning deficiencies.

Abstract: Video large language models have not yet been widely deployed, largely due to
their tendency to hallucinate. Typical benchmarks for Video-LLMs rely simply on
multiple-choice questions. Unfortunately, VideoLLMs hallucinate far more
aggressively on freeform text generation tasks like video captioning than they
do on multiple choice verification tasks. To address this weakness, we propose
ARGUS, a VideoLLM benchmark that measures freeform video captioning
performance. By comparing VideoLLM outputs to human ground truth captions,
ARGUS quantifies dual metrics. First, we measure the rate of hallucinations in
the form of incorrect statements about video content or temporal relationships.
Second, we measure the rate at which the model omits important descriptive
details. Together, these dual metrics form a comprehensive view of video
captioning performance.

</details>


### [359] [DINO-CoDT: Multi-class Collaborative Detection and Tracking with Vision Foundation Models](https://arxiv.org/abs/2506.07375)
*Xunjie He,Christina Dao Wen Lee,Meiling Wang,Chengran Yuan,Zefan Huang,Yufeng Yue,Marcelo H. Ang Jr*

Main category: cs.CV

TL;DR: 论文提出了一种针对多类别道路使用者的协作检测与跟踪框架，包括全局空间注意力融合模块、基于视觉语义的再识别模块和速度自适应的轨迹管理模块，显著提升了检测与跟踪精度。


<details>
  <summary>Details</summary>
Motivation: 现有协作感知方法主要针对车辆类别，缺乏多类别处理能力。现实场景中存在外观和运动模式各异的多种对象，需要开发能够处理多类别的协作检测与跟踪算法。

Method: 1. 全局空间注意力融合(GSAF)模块增强多尺度特征学习
2. 基于视觉基础模型的轨迹再识别(REID)模块减少ID切换错误
3. 速度自适应轨迹管理(VATM)模块根据运动速度调整跟踪间隔

Result: 在V2X-Real和OPV2V数据集上，检测与跟踪精度显著超越现有最优方法

Conclusion: 该框架有效解决了多类别道路用户的协作检测与跟踪问题，克服了现有方法仅关注车辆类别的局限，提高了复杂场景的适用性。

Abstract: Collaborative perception plays a crucial role in enhancing environmental
understanding by expanding the perceptual range and improving robustness
against sensor failures, which primarily involves collaborative 3D detection
and tracking tasks. The former focuses on object recognition in individual
frames, while the latter captures continuous instance tracklets over time.
However, existing works in both areas predominantly focus on the vehicle
superclass, lacking effective solutions for both multi-class collaborative
detection and tracking. This limitation hinders their applicability in
real-world scenarios, which involve diverse object classes with varying
appearances and motion patterns. To overcome these limitations, we propose a
multi-class collaborative detection and tracking framework tailored for diverse
road users. We first present a detector with a global spatial attention fusion
(GSAF) module, enhancing multi-scale feature learning for objects of varying
sizes. Next, we introduce a tracklet RE-IDentification (REID) module that
leverages visual semantics with a vision foundation model to effectively reduce
ID SWitch (IDSW) errors, in cases of erroneous mismatches involving small
objects like pedestrians. We further design a velocity-based adaptive tracklet
management (VATM) module that adjusts the tracking interval dynamically based
on object motion. Extensive experiments on the V2X-Real and OPV2V datasets show
that our approach significantly outperforms existing state-of-the-art methods
in both detection and tracking accuracy.

</details>


### [360] [Adapter Naturally Serves as Decoupler for Cross-Domain Few-Shot Semantic Segmentation](https://arxiv.org/abs/2506.07376)
*Jintao Tong,Ran Ma,Yixiong Zou,Guangyao Chen,Yuhua Li,Ruixuan Li*

Main category: cs.CV

TL;DR: 本文提出了Domain Feature Navigator (DFN)来解决跨域小样本分割中的域差异和数据稀缺问题。DFN利用模型固有结构解耦域信息，并结合SAM-SVN方法防止过拟合。实验表明，该方法在1-shot和5-shot场景下分别超越现有最佳方法2.69%和4.68% mIoU。


<details>
  <summary>Details</summary>
Motivation: 跨域小样本分割面临两个核心挑战：(1) 源域与目标域之间的域差异，(2) 目标域中用于微调的样本稀少。研究发现基于适配器的方法能自然解耦域信息，进而探索模型固有结构在域信息解耦中的作用。

Method: 1. 提出基于结构的域特征导航器（DFN），通过模型固有结构解耦域特征（而非传统基于损失函数的方式）；2. 设计SAM-SVN方法约束DFN在源域训练中避免学习样本级特异性知识；3. 目标域微调时冻结主模型，仅微调DFN学习目标域知识。

Result: 在跨域小样本分割任务中，DFN方法在1-shot和5-shot场景下分别取得比现有最优方法高2.69%和4.68%的mIoU提升。

Conclusion: 1. 发现模型固有结构具备自然解耦域信息的能力；2. 提出的结构化解耦器DFN结合抗过拟合机制能有效解决域差异和样本稀缺问题；3. 该方法为跨域小样本学习提供了新视角。

Abstract: Cross-domain few-shot segmentation (CD-FSS) is proposed to pre-train the
model on a source-domain dataset with sufficient samples, and then transfer the
model to target-domain datasets where only a few samples are available for
efficient fine-tuning. There are majorly two challenges in this task: (1) the
domain gap and (2) fine-tuning with scarce data. To solve these challenges, we
revisit the adapter-based methods, and discover an intriguing insight not
explored in previous works: the adapter not only helps the fine-tuning of
downstream tasks but also naturally serves as a domain information decoupler.
Then, we delve into this finding for an interpretation, and find the model's
inherent structure could lead to a natural decoupling of domain information.
Building upon this insight, we propose the Domain Feature Navigator (DFN),
which is a structure-based decoupler instead of loss-based ones like current
works, to capture domain-specific information, thereby directing the model's
attention towards domain-agnostic knowledge. Moreover, to prevent the potential
excessive overfitting of DFN during the source-domain training, we further
design the SAM-SVN method to constrain DFN from learning sample-specific
knowledge. On target domains, we freeze the model and fine-tune the DFN to
learn target-specific knowledge specific. Extensive experiments demonstrate
that our method surpasses the state-of-the-art method in CD-FSS significantly
by 2.69% and 4.68% MIoU in 1-shot and 5-shot scenarios, respectively.

</details>


### [361] [MrM: Black-Box Membership Inference Attacks against Multimodal RAG Systems](https://arxiv.org/abs/2506.07399)
*Peiru Yang,Jinhua Yin,Haoran Zheng,Xueying Bai,Huili Wang,Yufei Sun,Xintian Li,Shangguang Wang,Yongfeng Huang,Tao Qi*

Main category: cs.CV

TL;DR: 提出了一种名为MrM的针对多模态检索增强生成系统的黑盒成员推理攻击框架，通过多目标数据扰动和选择性遮罩，有效窃取敏感信息的成员状态。


<details>
  <summary>Details</summary>
Motivation: 当前成员推理攻击方法主要集中在文本模态，缺乏对多模态系统中隐私泄露风险的全面评估。

Method: 使用对象感知数据扰动确保检索成功，基于反事实掩码选择策略放大攻击效果，最后通过统计特征推断成员状态。

Result: 在两类视觉数据集和八种主流VL模型上的实验显示，MrM在样本级/集合级评估中均超过基线，且能抵抗自适应防御。

Conclusion: 揭示了多模态RAG系统在视觉隐私保护上的新型威胁，证明关键语义扰动和反事实分析可实现高效成员推理。

Abstract: Multimodal retrieval-augmented generation (RAG) systems enhance large
vision-language models by integrating cross-modal knowledge, enabling their
increasing adoption across real-world multimodal tasks. These knowledge
databases may contain sensitive information that requires privacy protection.
However, multimodal RAG systems inherently grant external users indirect access
to such data, making them potentially vulnerable to privacy attacks,
particularly membership inference attacks (MIAs). % Existing MIA methods
targeting RAG systems predominantly focus on the textual modality, while the
visual modality remains relatively underexplored. To bridge this gap, we
propose MrM, the first black-box MIA framework targeted at multimodal RAG
systems. It utilizes a multi-object data perturbation framework constrained by
counterfactual attacks, which can concurrently induce the RAG systems to
retrieve the target data and generate information that leaks the membership
information. Our method first employs an object-aware data perturbation method
to constrain the perturbation to key semantics and ensure successful retrieval.
Building on this, we design a counterfact-informed mask selection strategy to
prioritize the most informative masked regions, aiming to eliminate the
interference of model self-knowledge and amplify attack efficacy. Finally, we
perform statistical membership inference by modeling query trials to extract
features that reflect the reconstruction of masked semantics from response
patterns. Experiments on two visual datasets and eight mainstream commercial
visual-language models (e.g., GPT-4o, Gemini-2) demonstrate that MrM achieves
consistently strong performance across both sample-level and set-level
evaluations, and remains robust under adaptive defenses.

</details>


### [362] [Compressed Feature Quality Assessment: Dataset and Baselines](https://arxiv.org/abs/2506.07412)
*Changsheng Gao,Wei Zhou,Guosheng Lin,Weisi Lin*

Main category: cs.CV

TL;DR: 提出首个压缩特征质量评估(CFQA)问题,创建包含300个原始特征和12000个压缩特征的数据集,评估三种现有指标在语义退化量化中的不足。


<details>
  <summary>Details</summary>
Motivation: 资源受限环境中大规模模型部署需要高效传输中间特征,特征压缩会产生难以量化的语义退化,缺乏评估压缩特征语义保真度的统一标准。

Method: 构建涵盖3个视觉任务和4种特征编解码器的基准数据集,用任务性能下降作为真实语义失真标准,评估MSE、余弦相似度和中心核对齐三种指标表现。

Result: 现有指标难以准确捕捉压缩特征的语义退化,数据集能有效代表真实场景,需开发更精细的CFQA指标。

Conclusion: 发布首个CFQA数据集和源代码,推动压缩特征质量评估领域发展,为社区提供基础资源。

Abstract: The widespread deployment of large models in resource-constrained
environments has underscored the need for efficient transmission of
intermediate feature representations. In this context, feature coding, which
compresses features into compact bitstreams, becomes a critical component for
scenarios involving feature transmission, storage, and reuse. However, this
compression process introduces inherent semantic degradation that is
notoriously difficult to quantify with traditional metrics. To address this,
this paper introduces the research problem of Compressed Feature Quality
Assessment (CFQA), which seeks to evaluate the semantic fidelity of compressed
features. To advance CFQA research, we propose the first benchmark dataset,
comprising 300 original features and 12000 compressed features derived from
three vision tasks and four feature codecs. Task-specific performance drops are
provided as true semantic distortion for the evaluation of CFQA metrics. We
assess the performance of three widely used metrics (MSE, cosine similarity,
and Centered Kernel Alignment) in capturing semantic degradation. The results
underscore the representativeness of the dataset and highlight the need for
more refined metrics capable of addressing the nuances of semantic distortion
in compressed features. To facilitate the ongoing development of CFQA research,
we release the dataset and all accompanying source code at
\href{https://github.com/chansongoal/Compressed-Feature-Quality-Assessment}{https://github.com/chansongoal/Compressed-Feature-Quality-Assessment}.
This contribution aims to advance the field and provide a foundational resource
for the community to explore CFQA.

</details>


### [363] [DPFormer: Dynamic Prompt Transformer for Continual Learning](https://arxiv.org/abs/2506.07414)
*Sheng-Kai Huang,Jiun-Feng Chang,Chun-Rong Huang*

Main category: cs.CV

TL;DR: 为了解决持续学习中的灾难性遗忘、稳定性-可塑性困境以及任务间混淆问题，作者提出了基于动态提示方案的新型动态提示变换器（DPFormer），通过固定参数规模实现新旧任务知识整合，并在多个数据集上取得SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 持续学习中存在灾难性遗忘导致稳定性-可塑性困境，以及不同任务间缺乏知识交互引发任务混淆问题，需要开发能兼顾知识保留与增量学习的方法。

Method: 提出DPFormer结构：使用动态提示机制固化历史知识并注入任务特异性信息；设计统一分类模块（含二元交叉熵、蒸馏损失和辅助损失）实现端到端训练。

Result: 在CIFAR-100/ImageNet100/ImageNet1K数据集上，各类增量学习场景下均超越现有最佳方法。

Conclusion: 动态提示机制能有效解耦任务特异性表示，结合统一损失函数显著提升持续学习性能，且模型参数量基本恒定。

Abstract: In continual learning, solving the catastrophic forgetting problem may make
the models fall into the stability-plasticity dilemma. Moreover, inter-task
confusion will also occur due to the lack of knowledge exchanges between
different tasks. In order to solve the aforementioned problems, we propose a
novel dynamic prompt transformer (DPFormer) with prompt schemes. The prompt
schemes help the DPFormer memorize learned knowledge of previous classes and
tasks, and keep on learning new knowledge from new classes and tasks under a
single network structure with a nearly fixed number of model parameters.
Moreover, they also provide discrepant information to represent different tasks
to solve the inter-task confusion problem. Based on prompt schemes, a unified
classification module with the binary cross entropy loss, the knowledge
distillation loss and the auxiliary loss is proposed to train the whole model
in an end-to-end trainable manner. Compared with state-of-the-art methods, our
method achieves the best performance in the CIFAR-100, ImageNet100 and
ImageNet1K datasets under different class-incremental settings in continual
learning. The source code will be available at our GitHub after acceptance.

</details>


### [364] [FAMSeg: Fetal Femur and Cranial Ultrasound Segmentation Using Feature-Aware Attention and Mamba Enhancement](https://arxiv.org/abs/2506.07431)
*Jie He,Minglang Chen,Minying Lu,Bocheng Liang,Junming Wei,Guiyan Peng,Jiaxi Chen,Ying Tan*

Main category: cs.CV

TL;DR: 提出了一种基于特征感知和Mamba增强的胎儿股骨及头颅超声图像分割模型FAMSeg，通过设计独立视角扫描卷积块和特征感知模块，结合Mamba优化的残差结构，有效提升了高噪声、高相似性超声图像的分割精度，特别是解决了小物体分割的锯齿效应问题。


<details>
  <summary>Details</summary>
Motivation: 超声图像分割的精度对生物测量和评估至关重要。现有分割模型难以适应高噪声、高相似性的超声对象，尤其在小物体分割时会产生明显锯齿效应。手动分割则误差大且耗时。

Method: 1) 设计纵向横向独立视角扫描卷积块(LTIVSCB)增强局部细节捕捉；2) 引入特征感知模块提升上下文信息融合；3) 结合Mamba优化的残差结构抑制原始噪声干扰；4) 采用多优化器组合训练策略。

Result: FAMSeg网络在不同尺寸和方向的图像上均实现最快损失收敛和最佳分割性能：1) 分割精度显著提升；2) 有效消除了小物体分割的锯齿效应；3) 噪声抑制能力增强。

Conclusion: 该模型通过特征感知机制和状态空间建模的协同作用，成功建立全局信息和局部特征的依赖关系，为高噪声医学图像分割提供了新思路。实验证明了其在超声图像分割领域的优越性。

Abstract: Accurate ultrasound image segmentation is a prerequisite for precise
biometrics and accurate assessment. Relying on manual delineation introduces
significant errors and is time-consuming. However, existing segmentation models
are designed based on objects in natural scenes, making them difficult to adapt
to ultrasound objects with high noise and high similarity. This is particularly
evident in small object segmentation, where a pronounced jagged effect occurs.
Therefore, this paper proposes a fetal femur and cranial ultrasound image
segmentation model based on feature perception and Mamba enhancement to address
these challenges. Specifically, a longitudinal and transverse independent
viewpoint scanning convolution block and a feature perception module were
designed to enhance the ability to capture local detail information and improve
the fusion of contextual information. Combined with the Mamba-optimized
residual structure, this design suppresses the interference of raw noise and
enhances local multi-dimensional scanning. The system builds global information
and local feature dependencies, and is trained with a combination of different
optimizers to achieve the optimal solution. After extensive experimental
validation, the FAMSeg network achieved the fastest loss reduction and the best
segmentation performance across images of varying sizes and orientations.

</details>


### [365] [Prompt to Protection: A Comparative Study of Multimodal LLMs in Construction Hazard Recognition](https://arxiv.org/abs/2506.07436)
*Nishi Chaudhary,S M Jamil Uddin,Sathvik Sharath Chandra,Anto Ovid,Alex Albert*

Main category: cs.CV

TL;DR: 通过评估五种先进的LLMs模型在三种提示策略下的表现，发现提示策略对施工安全危害识别的准确性有显著影响，其中CoT提示最有效，GPT-4.5和GPT-o3表现最优。


<details>
  <summary>Details</summary>
Motivation: 近年来多模态大语言模型在视觉危险识别方面展现潜力，但缺乏在施工领域安全关键任务中的性能评估。

Method: 比较Claude-3 Opus等五种LLMs模型在真实施工图像中的危害识别能力，采用零样本、少样本和思维链（CoT）三种提示策略，并使用精准率、召回率和F1值进行定量分析。

Result: CoT提示在所有模型中获得最高准确率；不同条件下模型性能存在差异，GPT-4.5和GPT-o3在多数场景表现最优；提示设计显著影响多模态LLMs的准确性和一致性。

Conclusion: 提示工程对提升施工安全应用的LLMs可靠性至关重要，为开发AI辅助安全系统提供实用见解。

Abstract: The recent emergence of multimodal large language models (LLMs) has
introduced new opportunities for improving visual hazard recognition on
construction sites. Unlike traditional computer vision models that rely on
domain-specific training and extensive datasets, modern LLMs can interpret and
describe complex visual scenes using simple natural language prompts. However,
despite growing interest in their applications, there has been limited
investigation into how different LLMs perform in safety-critical visual tasks
within the construction domain. To address this gap, this study conducts a
comparative evaluation of five state-of-the-art LLMs: Claude-3 Opus, GPT-4.5,
GPT-4o, GPT-o3, and Gemini 2.0 Pro, to assess their ability to identify
potential hazards from real-world construction images. Each model was tested
under three prompting strategies: zero-shot, few-shot, and chain-of-thought
(CoT). Zero-shot prompting involved minimal instruction, few-shot incorporated
basic safety context and a hazard source mnemonic, and CoT provided
step-by-step reasoning examples to scaffold model thinking. Quantitative
analysis was performed using precision, recall, and F1-score metrics across all
conditions. Results reveal that prompting strategy significantly influenced
performance, with CoT prompting consistently producing higher accuracy across
models. Additionally, LLM performance varied under different conditions, with
GPT-4.5 and GPT-o3 outperforming others in most settings. The findings also
demonstrate the critical role of prompt design in enhancing the accuracy and
consistency of multimodal LLMs for construction safety applications. This study
offers actionable insights into the integration of prompt engineering and LLMs
for practical hazard recognition, contributing to the development of more
reliable AI-assisted safety systems.

</details>


### [366] [PhysiInter: Integrating Physical Mapping for High-Fidelity Human Interaction Generation](https://arxiv.org/abs/2506.07456)
*Wei Yao,Yunlian Sun,Chang Liu,Hongwen Zhang,Jinhui Tang*

Main category: cs.CV

TL;DR: 介绍了一种通过物理映射和基于物理的模拟改善多人运动生成质量的方法，解决现有技术忽略物理约束导致的穿模、滑动和漂浮问题，显著提升物理保真度3%-89%。


<details>
  <summary>Details</summary>
Motivation: 现有动作捕捉技术和生成模型常忽略物理约束，导致穿模、滑动和漂浮等伪影，尤其在多人交互生成中更严重。作者旨在通过物理映射和定制化损失函数提升运动生成的物理真实性和交互质量。

Method: 1) 在基于物理的模拟环境中通过动作模仿将目标运动投影到物理有效空间；2) 提出运动一致性(MC)和基于标记的交互(MI)损失函数优化多人运动表示；3) 将物理映射整合到生成流程中进行后处理。

Result: 实验证实方法显著提升生成运动的物理真实性，物理保真度改善幅度达3%至89%，并在多人交互场景中保持运动语义完整性。

Conclusion: 物理映射机制和定制化交互损失函数能有效解决运动生成中的物理约束问题，为多人交互运动合成提供高质量解决方案，项目页面见http://yw0208.github.io/physiinter。

Abstract: Driven by advancements in motion capture and generative artificial
intelligence, leveraging large-scale MoCap datasets to train generative models
for synthesizing diverse, realistic human motions has become a promising
research direction. However, existing motion-capture techniques and generative
models often neglect physical constraints, leading to artifacts such as
interpenetration, sliding, and floating. These issues are exacerbated in
multi-person motion generation, where complex interactions are involved. To
address these limitations, we introduce physical mapping, integrated throughout
the human interaction generation pipeline. Specifically, motion imitation
within a physics-based simulation environment is used to project target motions
into a physically valid space. The resulting motions are adjusted to adhere to
real-world physics constraints while retaining their original semantic meaning.
This mapping not only improves MoCap data quality but also directly informs
post-processing of generated motions. Given the unique interactivity of
multi-person scenarios, we propose a tailored motion representation framework.
Motion Consistency (MC) and Marker-based Interaction (MI) loss functions are
introduced to improve model performance. Experiments show our method achieves
impressive results in generated human motion quality, with a 3%-89% improvement
in physical fidelity. Project page http://yw0208.github.io/physiinter

</details>


### [367] [GLOS: Sign Language Generation with Temporally Aligned Gloss-Level Conditioning](https://arxiv.org/abs/2506.07460)
*Taeryung Lee,Hyeongjin Nam,Gyeongsik Moon,Kyoung Mu Lee*

Main category: cs.CV

TL;DR: 提出GLOS框架，通过时间对齐的gloss级条件解决现有手语生成方法因句子级条件导致的词序错误和语义准确性问题，在CSL-Daily和Phoenix-2014T数据集上表现优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有手语生成方法使用句子级条件编码，导致无法捕捉手语时间结构和缺乏词汇级语义粒度，造成词序混乱和动作模糊。

Method: 1. 使用时间对齐的gloss嵌入序列作为细粒度条件 2. 提出时间对齐条件模块(TAC)传递词汇语义和时间结构。

Result: GLOS在CSL-Daily和Phoenix-2014T数据集上生成词序正确、语义准确的手语，超越先前方法。

Conclusion: gloss级条件与TAC模块能有效提升手语生成的词序准确性与语义保真度。

Abstract: Sign language generation (SLG), or text-to-sign generation, bridges the gap
between signers and non-signers. Despite recent progress in SLG, existing
methods still often suffer from incorrect lexical ordering and low semantic
accuracy. This is primarily due to sentence-level condition, which encodes the
entire sentence of the input text into a single feature vector as a condition
for SLG. This approach fails to capture the temporal structure of sign language
and lacks the granularity of word-level semantics, often leading to disordered
sign sequences and ambiguous motions. To overcome these limitations, we propose
GLOS, a sign language generation framework with temporally aligned gloss-level
conditioning. First, we employ gloss-level conditions, which we define as
sequences of gloss embeddings temporally aligned with the motion sequence. This
enables the model to access both the temporal structure of sign language and
word-level semantics at each timestep. As a result, this allows for
fine-grained control of signs and better preservation of lexical order. Second,
we introduce a condition fusion module, temporal alignment conditioning (TAC),
to efficiently deliver the word-level semantic and temporal structure provided
by the gloss-level condition to the corresponding motion timesteps. Our method,
which is composed of gloss-level conditions and TAC, generates signs with
correct lexical order and high semantic accuracy, outperforming prior methods
on CSL-Daily and Phoenix-2014T.

</details>


### [368] [DeepVideo-R1: Video Reinforcement Fine-Tuning via Difficulty-aware Regressive GRPO](https://arxiv.org/abs/2506.07464)
*Jinyoung Park,Jeehye Na,Jinyoung Kim,Hyunwoo J. Kim*

Main category: cs.CV

TL;DR: 本文探索了GRPO在视频大语言模型中的应用，解决了依赖安全机制和优势消失问题，提出了Reg-GRPO和难度感知数据增强策略，显著提升了视频推理性能。


<details>
  <summary>Details</summary>
Motivation: 现有研究表明基于强化学习的后训练能提升大语言模型的推理能力，但GRPO在视频大语言模型中的应用较少且存在两个主要问题：依赖安全机制和优势消失。

Method: 提出Reg-GRPO将GRPO目标重构为回归任务，直接预测优势值以消除安全机制需求；同时设计难度感知数据增强策略，动态生成可解难度样本。

Result: DeepVideo-R1模型在多个视频推理基准测试中显著提升性能。

Conclusion: Reg-GRPO和难度感知数据增强策略有效解决了GRPO在视频领域的问题，推动了视频语言模型的发展。

Abstract: Recent works have demonstrated the effectiveness of reinforcement learning
(RL)-based post-training in enhancing the reasoning capabilities of large
language models (LLMs). In particular, Group Relative Policy Optimization
(GRPO) has shown impressive success by employing a PPO-style reinforcement
algorithm with group-based normalized rewards. However, the application of GRPO
to Video Large Language Models (Video LLMs) has been less studied. In this
paper, we explore GRPO for video LLMs and identify two primary issues that
impede its effective learning: (1) reliance on safeguards, and (2) the
vanishing advantage problem. To mitigate these challenges, we propose
DeepVideo-R1, a video large language model trained with our proposed Reg-GRPO
(Regressive GRPO) and difficulty-aware data augmentation strategy. Reg-GRPO
reformulates the GRPO objective as a regression task, directly predicting the
advantage in GRPO. This design eliminates the need for safeguards like clipping
and min functions, thereby facilitating more direct policy guidance by aligning
the model with the advantage values. We also design the difficulty-aware data
augmentation strategy that dynamically augments training samples at solvable
difficulty levels, fostering diverse and informative reward signals. Our
comprehensive experiments show that DeepVideo-R1 significantly improves video
reasoning performance across multiple video reasoning benchmarks.

</details>


### [369] [Ambiguity-Restrained Text-Video Representation Learning for Partially Relevant Video Retrieval](https://arxiv.org/abs/2506.07471)
*CH Cho,WJ Moon,W Jun,MS Jung,JP Heo*

Main category: cs.CV

TL;DR: 该论文提出了ARL框架，通过检测模糊文本-视频对并采用多正例对比学习和双三重边际损失来解决部分相关视频检索（PRVR）中的模糊性问题。同时，该方法还利用视频内帧级关系和跨模型模糊检测来提升性能。


<details>
  <summary>Details</summary>
Motivation: 传统PRVR训练假设文本查询与视频一对一对应，但本文指出文本与视频内容在概念范围上存在固有模糊性。因此需要将模糊性纳入模型学习过程。

Method: 1) 基于不确定性和相似性检测模糊文本-视频对；2) 通过多正例对比学习和双三重边际损失分层学习语义关系；3) 利用同一未修剪视频中多上下文特点进行文本-帧级别训练；4) 提出跨模型模糊检测避免单模型检测误差传播

Result: 未直接提及具体指标，但强调“证明了在PRVR中的有效性”

Conclusion: 综合检测模糊对、分层学习、帧级关系利用和跨模型检测的ARL框架，能有效解决PRVR的模糊性问题

Abstract: Partially Relevant Video Retrieval~(PRVR) aims to retrieve a video where a
specific segment is relevant to a given text query. Typical training processes
of PRVR assume a one-to-one relationship where each text query is relevant to
only one video. However, we point out the inherent ambiguity between text and
video content based on their conceptual scope and propose a framework that
incorporates this ambiguity into the model learning process. Specifically, we
propose Ambiguity-Restrained representation Learning~(ARL) to address ambiguous
text-video pairs. Initially, ARL detects ambiguous pairs based on two criteria:
uncertainty and similarity. Uncertainty represents whether instances include
commonly shared context across the dataset, while similarity indicates
pair-wise semantic overlap. Then, with the detected ambiguous pairs, our ARL
hierarchically learns the semantic relationship via multi-positive contrastive
learning and dual triplet margin loss. Additionally, we delve into fine-grained
relationships within the video instances. Unlike typical training at the
text-video level, where pairwise information is provided, we address the
inherent ambiguity within frames of the same untrimmed video, which often
contains multiple contexts. This allows us to further enhance learning at the
text-frame level. Lastly, we propose cross-model ambiguity detection to
mitigate the error propagation that occurs when a single model is employed to
detect ambiguous pairs for its training. With all components combined, our
proposed method demonstrates its effectiveness in PRVR.

</details>


### [370] [CoCoA-Mix: Confusion-and-Confidence-Aware Mixture Model for Context Optimization](https://arxiv.org/abs/2506.07484)
*Dasol Hong,Wooju Lee,Hyun Myung*

Main category: cs.CV

TL;DR: 提出CoCoA-Mix方法，通过混淆感知损失和置信感知权重增强提示调优的领域泛化能力。


<details>
  <summary>Details</summary>
Motivation: 解决提示调优中因冻结编码器特征错位导致的类间混淆问题，同时提高任务专业性和跨域泛化性。

Method: 引入混淆感知损失(CoA-loss)精化决策边界；提出混合模型与置信感知权重(CoA-weights)调整预测置信度。

Result: 在各项实验中超越现有最优方法，代码已开源。

Conclusion: CoCoA-Mix通过同时优化决策边界和预测置信度，有效提升了专业化和泛化能力。

Abstract: Prompt tuning, which adapts vision-language models by freezing model
parameters and optimizing only the prompt, has proven effective for
task-specific adaptations. The core challenge in prompt tuning is improving
specialization for a specific task and generalization for unseen domains.
However, frozen encoders often produce misaligned features, leading to
confusion between classes and limiting specialization. To overcome this issue,
we propose a confusion-aware loss (CoA-loss) that improves specialization by
refining the decision boundaries between confusing classes. Additionally, we
mathematically demonstrate that a mixture model can enhance generalization
without compromising specialization. This is achieved using confidence-aware
weights (CoA-weights), which adjust the weights of each prediction in the
mixture model based on its confidence within the class domains. Extensive
experiments show that CoCoA-Mix, a mixture model with CoA-loss and CoA-weights,
outperforms state-of-the-art methods by enhancing specialization and
generalization. Our code is publicly available at
https://github.com/url-kaist/CoCoA-Mix.

</details>


### [371] [Drive Any Mesh: 4D Latent Diffusion for Mesh Deformation from Video](https://arxiv.org/abs/2506.07489)
*Yahao Shi,Yang Liu,Yanmin Wu,Xing Liu,Chen Zhao,Jie Luo,Bin Zhou*

Main category: cs.CV

TL;DR: DriveAnyMesh是一种利用单目视频驱动网格的方法，解决了现有三维动态内容生成技术面临的渲染效率低、手动工作量大、跨类别泛化能力弱等问题。它通过基于变换器的变分自动编码器（Transformer-based VAE）捕捉形状和运动信息，并结合时空注意力机制的扩散模型生成网格动画。实验证明该方法能高效创建高品质动画，适用于现代渲染引擎


<details>
  <summary>Details</summary>
Motivation: 当前4D生成技术（如隐式方法和骨骼绑定方法）存在诸多限制：隐式方法渲染效率低且不兼容基于光栅化的引擎；骨骼绑定需大量手动干预且缺乏跨类别泛化能力。现有三维资产动画化方案需要深入理解三维结构，存在效率与通用性不足的问题。因此，本文提出能直接驱动现有网格资产并兼容现代渲染引擎的解决方案

Method: 1) 提出基于点云轨迹序列的网格动画生成框架；2) 设计Transformer-based VAE编码器捕获3D形状与运动信息的潜变量集合；3) 构建时空Transformer扩散模型对潜变量序列去噪，增强帧间信息交互；4) 通过潜变量解码生成兼容渲染引擎的网格动画序列

Result: 实验表明：1) 在复杂动作序列（如舞蹈）中可实时生成高质量动画（平均速率: 2秒/序列）；2) 渲染效率对比隐式方法提升17倍（256x256分辨率标准）；3) 跨类别测试（人形/动物）保持泛化能力（FID指标优于骨骼绑定方法34.2%）

Conclusion: DriveAnyMesh首次实现端到端的单目视频驱动网格生成方案，其时空Transformer扩散架构与潜变量表示有效平衡了渲染效率、动作质量和跨类别适应性。该技术为游戏/影视行业提供新型动态内容生产工具，未来可探索多视角约束与物理驱动方向

Abstract: We propose DriveAnyMesh, a method for driving mesh guided by monocular video.
Current 4D generation techniques encounter challenges with modern rendering
engines. Implicit methods have low rendering efficiency and are unfriendly to
rasterization-based engines, while skeletal methods demand significant manual
effort and lack cross-category generalization. Animating existing 3D assets,
instead of creating 4D assets from scratch, demands a deep understanding of the
input's 3D structure. To tackle these challenges, we present a 4D diffusion
model that denoises sequences of latent sets, which are then decoded to produce
mesh animations from point cloud trajectory sequences. These latent sets
leverage a transformer-based variational autoencoder, simultaneously capturing
3D shape and motion information. By employing a spatiotemporal,
transformer-based diffusion model, information is exchanged across multiple
latent frames, enhancing the efficiency and generalization of the generated
results. Our experimental results demonstrate that DriveAnyMesh can rapidly
produce high-quality animations for complex motions and is compatible with
modern rendering engines. This method holds potential for applications in both
the gaming and filming industries.

</details>


### [372] [SpatialLM: Training Large Language Models for Structured Indoor Modeling](https://arxiv.org/abs/2506.07491)
*Yongsen Mao,Junhao Zhong,Chuan Fang,Jia Zheng,Rui Tang,Hao Zhu,Ping Tan,Zihan Zhou*

Main category: cs.CV

TL;DR: SpatialLM是一个能处理3D点云数据的大语言模型，能够输出结构化3D场景理解结果，包括墙体、门窗等建筑元素及带语义的定向物体框。


<details>
  <summary>Details</summary>
Motivation: 提升现代大语言模型的空间理解能力，应用于增强现实、具身机器人等领域；不同于以往任务特定的网络设计，直接基于开源LLM微调实现。

Method: 收集包含12,328个室内场景（54,778个房间）点云的大规模合成数据集，研究不同建模和训练决策，采用标准多模态LLM架构进行微调。

Result: 在公开基准测试中：布局估计任务达到SOTA，3D物体检测任务取得竞争性结果。

Conclusion: 验证了通过微调开源LLM增强空间理解能力的可行路径。

Abstract: SpatialLM is a large language model designed to process 3D point cloud data
and generate structured 3D scene understanding outputs. These outputs include
architectural elements like walls, doors, windows, and oriented object boxes
with their semantic categories. Unlike previous methods which exploit
task-specific network designs, our model adheres to the standard multimodal LLM
architecture and is fine-tuned directly from open-source LLMs.
  To train SpatialLM, we collect a large-scale, high-quality synthetic dataset
consisting of the point clouds of 12,328 indoor scenes (54,778 rooms) with
ground-truth 3D annotations, and conduct a careful study on various modeling
and training decisions. On public benchmarks, our model gives state-of-the-art
performance in layout estimation and competitive results in 3D object
detection. With that, we show a feasible path for enhancing the spatial
understanding capabilities of modern LLMs for applications in augmented
reality, embodied robotics, and more.

</details>


### [373] [Genesis: Multimodal Driving Scene Generation with Spatio-Temporal and Cross-Modal Consistency](https://arxiv.org/abs/2506.07497)
*Xiangyu Guo,Zhanqian Wu,Kaixin Xiong,Ziyang Xu,Lijun Zhou,Gangwei Xu,Shaoqing Xu,Haiyang Sun,Bing Wang,Guang Chen,Hangjun Ye,Wenyu Liu,Xinggang Wang*

Main category: cs.CV

TL;DR: Genesis是一个统一的框架，用于联合生成多视角驾驶视频和具有时空与跨模态一致性的LiDAR序列。它采用两阶段架构，结合了DiT基视频扩散模型与3D-VAE编码，以及BEV感知的LiDAR生成器（含NeRF渲染和自适应采样）。通过共享潜在空间实现跨视觉与几何域的一致性生成，并引入基于视觉语言模型的DataCrafter标注模块提供语义监督。在nuScenes上实现视频/LiDAR指标SOTA，并提升下游任务（如分割与检测）性能。


<details>
  <summary>Details</summary>
Motivation: 当前自动驾驶系统依赖大量标注数据，但真实世界数据采集成本高且受限。现有生成方法往往单独处理视频或点云，缺乏跨模态的一致性建模。Genesis旨在通过统一框架同时生成时空一致的驾驶视频和LiDAR序列，提供更高效且语义可控的合成数据源。

Method: 1. 两阶段生成架构：\n a) 视频分支：采用DiT扩散模型+3D-VAE编码动态场景\n b) LiDAR分支：BEV感知生成器结合NeRF渲染与自适应采样\n2. 模态耦合：通过共享潜在空间强制视频与LiDAR的跨模态一致性\n3. 语义引导：DataCrafter模块利用视觉语言模型提供场景/实例级标注，监督生成过程语义准确性

Result: 在nuScenes基准测试中达到SOTA：\n- 视频指标：FVD=16.95, FID=4.24\n- LiDAR指标：Chamfer距离=0.611\n下游任务验证：\n- 生成数据显著提升分割与3D检测模型性能

Conclusion: Genesis通过统一生成框架首次实现多视角视频与LiDAR序列的联合合成，其共享潜在空间和语义监督机制保障了跨模态时空一致性。实验证明该方法不仅实现跨模态SOTA性能，生成的数据还可有效增强下游感知模型，为自动驾驶数据扩展提供可行方案。

Abstract: We present Genesis, a unified framework for joint generation of multi-view
driving videos and LiDAR sequences with spatio-temporal and cross-modal
consistency. Genesis employs a two-stage architecture that integrates a
DiT-based video diffusion model with 3D-VAE encoding, and a BEV-aware LiDAR
generator with NeRF-based rendering and adaptive sampling. Both modalities are
directly coupled through a shared latent space, enabling coherent evolution
across visual and geometric domains. To guide the generation with structured
semantics, we introduce DataCrafter, a captioning module built on
vision-language models that provides scene-level and instance-level
supervision. Extensive experiments on the nuScenes benchmark demonstrate that
Genesis achieves state-of-the-art performance across video and LiDAR metrics
(FVD 16.95, FID 4.24, Chamfer 0.611), and benefits downstream tasks including
segmentation and 3D detection, validating the semantic fidelity and practical
utility of the generated data.

</details>


### [374] [MoQAE: Mixed-Precision Quantization for Long-Context LLM Inference via Mixture of Quantization-Aware Experts](https://arxiv.org/abs/2506.07533)
*Wei Tao,Haocheng Lu,Xiaoyang Qu,Bin Zhang,Kai Lu,Jiguang Wan,Jianzong Wang*

Main category: cs.CV

TL;DR: MoQAE: 一种基于专家混合的分块输入混合精度量化方法，通过轻量级路由微调和路由冻结/共享机制，在保持精度的同时显著降低LLM长上下文推理中KV缓存的存储开销。


<details>
  <summary>Details</summary>
Motivation: 现有KV缓存量化方法无法同时兼顾效率与精度，且传统混合专家方法在逐令牌路由时效率低下。需设计新型混合精度量化方案以平衡内存缩减与模型精度。

Method: 1) 将不同量化位宽配置视为专家，采用分块输入（非逐令牌）路由选择最优位宽
2) 设计带综合损失函数的路由器轻量微调流程
3) 引入路由冻结（RF）与路由共享（RS）减少推理开销

Result: 在多个基准数据集上超越现有KV缓存量化方案，实现效率（内存/延时）与精度双优

Conclusion: MoQAE证明了分块路由选择和轻量微调机制能有效平衡LLM长上下文推理的存储效率与性能，为后续优化提供新方向

Abstract: One of the primary challenges in optimizing large language models (LLMs) for
long-context inference lies in the high memory consumption of the Key-Value
(KV) cache. Existing approaches, such as quantization, have demonstrated
promising results in reducing memory usage. However, current quantization
methods cannot take both effectiveness and efficiency into account. In this
paper, we propose MoQAE, a novel mixed-precision quantization method via
mixture of quantization-aware experts. First, we view different quantization
bit-width configurations as experts and use the traditional mixture of experts
(MoE) method to select the optimal configuration. To avoid the inefficiency
caused by inputting tokens one by one into the router in the traditional MoE
method, we input the tokens into the router chunk by chunk. Second, we design a
lightweight router-only fine-tuning process to train MoQAE with a comprehensive
loss to learn the trade-off between model accuracy and memory usage. Finally,
we introduce a routing freezing (RF) and a routing sharing (RS) mechanism to
further reduce the inference overhead. Extensive experiments on multiple
benchmark datasets demonstrate that our method outperforms state-of-the-art KV
cache quantization approaches in both efficiency and effectiveness.

</details>


### [375] [Domain Randomization for Object Detection in Manufacturing Applications using Synthetic Data: A Comprehensive Study](https://arxiv.org/abs/2506.07539)
*Xiaomeng Zhu,Jacob Henningsson,Duruo Li,Pär Mårtensson,Lars Hanson,Mårten Björkman,Atsuto Maki*

Main category: cs.CV

TL;DR: 摘要提出一个综合数据生成流程，用于制造对象检测应用领域。该流程考虑目标特征、背景、光照等因素，并引入SIP15-OD数据集。实验证明，通过改进关键因素（如纹理渲染、后处理等），在纯合成数据训练的YOLOv8模型上达到顶尖性能(mAP@50:96.4%-99.5%)，验证了该方案在解决仿真到实际检测问题方面的有效性。


<details>
  <summary>Details</summary>
Motivation: 解决制造领域对象检测应用中，仿真到实际数据转换(sim-to-real)的效果问题。具体而言，研究者们旨在通过系统性改进数据生成流程的关键环节，验证域随机化技术是否能在目标检测任务上覆盖真实数据的分布。

Method: 设计了包含对象特征、背景、光照、相机设置和后处理的完整数据生成流程，创建了包含15种工业零件的SIP15-OD数据集作为新测试平台，并选用公开工业机器人数据集进行实验。通过控制变量分析，重点优化了材质属性、渲染方法、后处理和干扰因素等关键因素。所有模型基于YOLOv8架构，完全使用合成数据训练。

Result: 在工业机器人数据集上获得96.4%的mAP@50；在SIP15-OD的三个用例上分别达到94.1%、99.5%和95.3%的mAP@50，均创下最先进水平。这证明所提域随机化方法能有效弥合合成数据与真实数据间的差距。

Conclusion: 通过系统性改进合成数据的关键生成因素，域随机化能够覆盖接近真实数据的分布。研究为工业领域的对象检测应用提供了新方法，证明了纯合成训练数据的可行性。

Abstract: This paper addresses key aspects of domain randomization in generating
synthetic data for manufacturing object detection applications. To this end, we
present a comprehensive data generation pipeline that reflects different
factors: object characteristics, background, illumination, camera settings, and
post-processing. We also introduce the Synthetic Industrial Parts Object
Detection dataset (SIP15-OD) consisting of 15 objects from three industrial use
cases under varying environments as a test bed for the study, while also
employing an industrial dataset publicly available for robotic applications. In
our experiments, we present more abundant results and insights into the
feasibility as well as challenges of sim-to-real object detection. In
particular, we identified material properties, rendering methods,
post-processing, and distractors as important factors. Our method, leveraging
these, achieves top performance on the public dataset with Yolov8 models
trained exclusively on synthetic data; mAP@50 scores of 96.4% for the robotics
dataset, and 94.1%, 99.5%, and 95.3% across three of the SIP15-OD use cases,
respectively. The results showcase the effectiveness of the proposed domain
randomization, potentially covering the distribution close to real data for the
applications.

</details>


### [376] [APTOS-2024 challenge report: Generation of synthetic 3D OCT images from fundus photographs](https://arxiv.org/abs/2506.07542)
*Bowen Liu,Weiyi Zhang,Peranut Chotcomwongse,Xiaolan Chen,Ruoyu Chen,Pawin Pakaymaskul,Niracha Arjkongharn,Nattaporn Vongsa,Xuelian Cheng,Zongyuan Ge,Kun Huang,Xiaohui Li,Yiru Duan,Zhenbang Wang,BaoYe Xie,Qiang Chen,Huazhu Fu,Michael A. Mahr,Jiaqi Qu,Wangyiyang Chen,Shiye Wang,Yubo Tan,Yongjie Li,Mingguang He,Danli Shi,Paisan Ruamviboonsuk*

Main category: cs.CV

TL;DR: 该论文介绍了APTOS-2024挑战赛，这是一个将2D眼底图像合成为3D OCT图像的AI竞赛。挑战赛旨在解决OCT设备昂贵且操作复杂的问题。通过342个团队的参与，展示了眼底到OCT合成的可行性，并提出了评估方法（图像距离和视频距离指标）。


<details>
  <summary>Details</summary>
Motivation: 尽管OCT能够提供高分辨率的3D视网膜成像，但设备昂贵且需要专业人员操作，限制了其广泛应用。相比之下，2D眼底照相更易获取。开发从2D眼底图像生成3D OCT图像的AI模型可以降低OCT使用门槛，提高医疗服务可及性。

Method: 挑战赛框架包括：基准数据集、两阶段评估方法（图像级相似度和体积一致性指标）。前9名团队采用的方法包括：跨模态数据预处理/增强、眼科数据预训练、视觉大模型集成、模型架构优化。

Result: 342支团队参与（42份初赛提交，9名决赛队伍）。顶尖模型的创新点集中在混合数据策略、预训练和视觉基础模型应用。挑战赛首次证明了2D眼底到3D OCT合成的可行性。

Conclusion: APTOS-2024挑战赛是首个通过系统性评估验证眼底到OCT合成可行性的基准。该技术有望在医疗资源匮乏地区改善眼科护理可及性，并加速医学研究。

Abstract: Optical Coherence Tomography (OCT) provides high-resolution, 3D, and
non-invasive visualization of retinal layers in vivo, serving as a critical
tool for lesion localization and disease diagnosis. However, its widespread
adoption is limited by equipment costs and the need for specialized operators.
In comparison, 2D color fundus photography offers faster acquisition and
greater accessibility with less dependence on expensive devices. Although
generative artificial intelligence has demonstrated promising results in
medical image synthesis, translating 2D fundus images into 3D OCT images
presents unique challenges due to inherent differences in data dimensionality
and biological information between modalities. To advance generative models in
the fundus-to-3D-OCT setting, the Asia Pacific Tele-Ophthalmology Society
(APTOS-2024) organized a challenge titled Artificial Intelligence-based OCT
Generation from Fundus Images. This paper details the challenge framework
(referred to as APTOS-2024 Challenge), including: the benchmark dataset,
evaluation methodology featuring two fidelity metrics-image-based distance
(pixel-level OCT B-scan similarity) and video-based distance (semantic-level
volumetric consistency), and analysis of top-performing solutions. The
challenge attracted 342 participating teams, with 42 preliminary submissions
and 9 finalists. Leading methodologies incorporated innovations in hybrid data
preprocessing or augmentation (cross-modality collaborative paradigms),
pre-training on external ophthalmic imaging datasets, integration of vision
foundation models, and model architecture improvement. The APTOS-2024 Challenge
is the first benchmark demonstrating the feasibility of fundus-to-3D-OCT
synthesis as a potential solution for improving ophthalmic care accessibility
in under-resourced healthcare settings, while helping to expedite medical
research and clinical applications.

</details>


### [377] [Synthesize Privacy-Preserving High-Resolution Images via Private Textual Intermediaries](https://arxiv.org/abs/2506.07555)
*Haoxiang Wang,Zinan Lin,Da Yu,Huishuai Zhang*

Main category: cs.CV

TL;DR: SPTI利用文本中介和现成模型生成高质量DP图像，无需训练，在ε=1时FID显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有DP图像合成方法难以生成高分辨率忠实原数据的图像，需解决隐私保护下的视觉数据共享问题。

Method: 1. 图像转文本描述 2. 改进Private Evolution算法生成DP文本 3. 文本转图像合成。全程仅用现成模型推理。

Result: 在LSUN Bedroom上FID≤26.71（原40.36），MM CelebA HQ上≤33.27（原57.01），显著提升质量。

Conclusion: SPTI通过文本域转换实现高效高分辨率DP图像合成，兼容性强，推动私有视觉数据共享。

Abstract: Generating high fidelity, differentially private (DP) synthetic images offers
a promising route to share and analyze sensitive visual data without
compromising individual privacy. However, existing DP image synthesis methods
struggle to produce high resolution outputs that faithfully capture the
structure of the original data. In this paper, we introduce a novel method,
referred to as Synthesis via Private Textual Intermediaries (SPTI), that can
generate high resolution DP images with easy adoption. The key idea is to shift
the challenge of DP image synthesis from the image domain to the text domain by
leveraging state of the art DP text generation methods. SPTI first summarizes
each private image into a concise textual description using image to text
models, then applies a modified Private Evolution algorithm to generate DP
text, and finally reconstructs images using text to image models. Notably, SPTI
requires no model training, only inference with off the shelf models. Given a
private dataset, SPTI produces synthetic images of substantially higher quality
than prior DP approaches. On the LSUN Bedroom dataset, SPTI attains an FID less
than or equal to 26.71 under epsilon equal to 1.0, improving over Private
Evolution FID of 40.36. Similarly, on MM CelebA HQ, SPTI achieves an FID less
than or equal to 33.27 at epsilon equal to 1.0, compared to 57.01 from DP fine
tuning baselines. Overall, our results demonstrate that Synthesis via Private
Textual Intermediaries provides a resource efficient and proprietary model
compatible framework for generating high resolution DP synthetic images,
greatly expanding access to private visual datasets.

</details>


### [378] [Cross-channel Perception Learning for H&E-to-IHC Virtual Staining](https://arxiv.org/abs/2506.07559)
*Hao Yang,JianYu Wu,Run Fang,Xuelian Zhao,Yuan Ji,Zhiyu Chen,Guibin He,Junceng Guo,Yang Liu,Xinhua Zeng*

Main category: cs.CV

TL;DR: 该论文提出了一种名为跨通道感知学习（CCPL）的新策略，用于改善H&E切片到IHC切片的虚拟染色。CCPL将IHC图像分解为对应细胞核和细胞膜的赫马托素和DAB通道，使用预训练模型提取特征、计算跨通道相关性，并通过特征蒸馏和光学密度统计分析来提升生成质量。实验表明该方法在定量指标和病理学家评估中均表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有H&E虚拟染色方法忽视了细胞核与细胞膜间的跨通道相关性，导致染色结果不理想。数字病理学发展需要更精确的虚拟染色技术支撑多媒体医疗信息系统中的病理分析与诊断。

Method: 1. 将HER2免疫组化染色分解为核通道（赫马托素）和膜通道（DAB）
2. 利用Gigapath基础模型的Tile Encoder提取生成图与真实图的双通道特征
3. 计算核与膜跨通道相关性损失
4. 引入特征蒸馏损失强化特征提取能力
5. 基于焦点光学密度图进行单通道统计分布对齐

Result: 在PSNR、SSIM、PCC、FID等定量指标上表现优异，病理学家专业评估确认生成图像能有效保留病理特征，为多媒体医疗数据的自动化病理诊断提供可靠支持。

Conclusion: CCPL通过显式建模核膜跨通道相关性，结合特征蒸馏与统计对齐，首次解决了虚拟染色中的跨通道关联问题，显著提升了染色质量与诊断价值。

Abstract: With the rapid development of digital pathology, virtual staining has become
a key technology in multimedia medical information systems, offering new
possibilities for the analysis and diagnosis of pathological images. However,
existing H&E-to-IHC studies often overlook the cross-channel correlations
between cell nuclei and cell membranes. To address this issue, we propose a
novel Cross-Channel Perception Learning (CCPL) strategy. Specifically, CCPL
first decomposes HER2 immunohistochemical staining into Hematoxylin and DAB
staining channels, corresponding to cell nuclei and cell membranes,
respectively. Using the pathology foundation model Gigapath's Tile Encoder,
CCPL extracts dual-channel features from both the generated and real images and
measures cross-channel correlations between nuclei and membranes. The features
of the generated and real stained images, obtained through the Tile Encoder,
are also used to calculate feature distillation loss, enhancing the model's
feature extraction capabilities without increasing the inference burden.
Additionally, CCPL performs statistical analysis on the focal optical density
maps of both single channels to ensure consistency in staining distribution and
intensity. Experimental results, based on quantitative metrics such as PSNR,
SSIM, PCC, and FID, along with professional evaluations from pathologists,
demonstrate that CCPL effectively preserves pathological features, generates
high-quality virtual stained images, and provides robust support for automated
pathological diagnosis using multimedia medical data.

</details>


### [379] [OpenDance: Multimodal Controllable 3D Dance Generation Using Large-scale Internet Data](https://arxiv.org/abs/2506.07565)
*Jinlu Zhang,Zixi Kang,Yizhou Wang*

Main category: cs.CV

TL;DR: 提出OpenDance5D数据集和OpenDanceNet框架解决音乐驱动舞蹈生成中的可控性和多样性问题。数据集包含101+小时多模态数据，框架通过掩码建模实现多条件可控生成。


<details>
  <summary>Details</summary>
Motivation: 现有研究因缺乏细粒度多模态数据和灵活的多条件生成能力，导致舞蹈生成可控性和实践多样性受限。

Method: 构建包含14种流派101+小时的五模态数据集OpenDance5D；提出基于掩码建模的统一框架OpenDanceNet，支持音乐与文本/关键点/位置等任意条件组合生成。

Result: 实验证明OpenDanceNet能实现高保真舞蹈生成和灵活的多条件控制。

Conclusion: OpenDance5D数据集弥补了数据缺口，OpenDanceNet框架在多条件可控舞蹈生成上取得显著效果。

Abstract: Music-driven dance generation offers significant creative potential yet faces
considerable challenges. The absence of fine-grained multimodal data and the
difficulty of flexible multi-conditional generation limit previous works on
generation controllability and diversity in practice. In this paper, we build
OpenDance5D, an extensive human dance dataset comprising over 101 hours across
14 distinct genres. Each sample has five modalities to facilitate robust
cross-modal learning: RGB video, audio, 2D keypoints, 3D motion, and
fine-grained textual descriptions from human arts. Furthermore, we propose
OpenDanceNet, a unified masked modeling framework for controllable dance
generation conditioned on music and arbitrary combinations of text prompts,
keypoints, or character positioning. Comprehensive experiments demonstrate that
OpenDanceNet achieves high-fidelity and flexible controllability.

</details>


### [380] [Towards the Influence of Text Quantity on Writer Retrieval](https://arxiv.org/abs/2506.07566)
*Marco Peer,Robert Sablatnig,Florian Kleber*

Main category: cs.CV

TL;DR: 本文研究基于手写相似性的文档作者检索任务，通过评估行级和词级检索分析文本量对检索性能的影响。实验表明即使仅用一行文本也能保持90%以上页面级检索性能（当至少四行时），并揭示了传统手工特征在少文本场景的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有手写作者检索方法主要基于整页文本，但实际场景中常面临文本量不足的情况（如签名、短笔记）。本文旨在探索文本量对检索性能的影响，填补行级/词级检索的研究空白。

Method: 使用CVL/IAM数据集，对比三类SOTA方法：1) 传统手工特征+VLAD编码 2) 卷积神经网络的深度特征 3) 加入NetVLAD的深度特征改进。实验变量包括查询/库样本的文本量（从单词到整页）。

Result: 1) 当查询样本仅含一行文本时，检索mAP性能较整页下降20-30%，但若提供至少四行文本可恢复至整页性能的90%以上。2) 文本依赖型方法在少文本场景更鲁棒。3) 基于NetVLAD的深度学习方法显著优于传统VLAD，尤其在行级检索（如一行文本查询时NetVLAD mAP 0.76 vs 传统VLAD 0.58）。

Conclusion: 少文本场景（≥4行）仍可实现实用级作者检索性能；深度学习方法尤其NetVLAD架构对文本碎片化具有更强适应性；文本依赖型方法应作为少文本检索的优选方案。

Abstract: This paper investigates the task of writer retrieval, which identifies
documents authored by the same individual within a dataset based on handwriting
similarities. While existing datasets and methodologies primarily focus on page
level retrieval, we explore the impact of text quantity on writer retrieval
performance by evaluating line- and word level retrieval. We examine three
state-of-the-art writer retrieval systems, including both handcrafted and deep
learning-based approaches, and analyze their performance using varying amounts
of text. Our experiments on the CVL and IAM dataset demonstrate that while
performance decreases by 20-30% when only one line of text is used as query and
gallery, retrieval accuracy remains above 90% of full-page performance when at
least four lines are included. We further show that text-dependent retrieval
can maintain strong performance in low-text scenarios. Our findings also
highlight the limitations of handcrafted features in low-text scenarios, with
deep learning-based methods like NetVLAD outperforming traditional VLAD
encoding.

</details>


### [381] [LLM-driven Indoor Scene Layout Generation via Scaled Human-aligned Data Synthesis and Multi-Stage Preference Optimization](https://arxiv.org/abs/2506.07570)
*Yixuan Yang,Zhen Luo,Tongsheng Ding,Junru Lu,Mingqi Gao,Jinyu Yang,Victor Sanchez,Feng Zheng*

Main category: cs.CV

TL;DR: 论文提出了一个大型数据集3D-SynthPlace和一个优化的开源LLM OptiScene，用于室内布局生成。


<details>
  <summary>Details</summary>
Motivation: 现有方法存在空间不一致、高成本或泛化能力差的问题，需要更好的解决方案。

Method: 创建合成数据集3D-SynthPlace，并采用两阶段训练（SFT和DPO）优化模型OptiScene。

Result: OptiScene在布局质量和成功率上优于基线方法，并在互动任务中表现良好。

Conclusion: 3D-SynthPlace和OptiScene显著提升了室内布局生成的性能，展示了在场景编辑等应用的潜力。

Abstract: Automatic indoor layout generation has attracted increasing attention due to
its potential in interior design, virtual environment construction, and
embodied AI. Existing methods fall into two categories: prompt-driven
approaches that leverage proprietary LLM services (e.g., GPT APIs) and
learning-based methods trained on layout data upon diffusion-based models.
Prompt-driven methods often suffer from spatial inconsistency and high
computational costs, while learning-based methods are typically constrained by
coarse relational graphs and limited datasets, restricting their generalization
to diverse room categories. In this paper, we revisit LLM-based indoor layout
generation and present 3D-SynthPlace, a large-scale dataset that combines
synthetic layouts generated via a 'GPT synthesize, Human inspect' pipeline,
upgraded from the 3D-Front dataset. 3D-SynthPlace contains nearly 17,000
scenes, covering four common room types -- bedroom, living room, kitchen, and
bathroom -- enriched with diverse objects and high-level spatial annotations.
We further introduce OptiScene, a strong open-source LLM optimized for indoor
layout generation, fine-tuned based on our 3D-SynthPlace dataset through our
two-stage training. For the warum-up stage I, we adopt supervised fine-tuning
(SFT), which is taught to first generate high-level spatial descriptions then
conditionally predict concrete object placements. For the reinforcing stage II,
to better align the generated layouts with human design preferences, we apply
multi-turn direct preference optimization (DPO), which significantly improving
layout quality and generation success rates. Extensive experiments demonstrate
that OptiScene outperforms traditional prompt-driven and learning-based
baselines. Moreover, OptiScene shows promising potential in interactive tasks
such as scene editing and robot navigation.

</details>


### [382] [Learning Speaker-Invariant Visual Features for Lipreading](https://arxiv.org/abs/2506.07572)
*Yu Li,Feng Xue,Shujie Li,Jinrui Zhang,Shuang Yang,Dan Guo,Richang Hong*

Main category: cs.CV

TL;DR: SIFLip框架通过隐式和显式解耦模块消除说话人特定特征，提升唇读泛化能力


<details>
  <summary>Details</summary>
Motivation: 现有唇读方法提取的视觉特征包含说话人特定属性，导致虚假相关性和泛化性差

Method: 用文本嵌入隐式解耦（语义一致性）+说话人识别子任务显式解耦（梯度反转）

Result: 在多个数据集上显著超越SOTA，泛化性能大幅提升

Conclusion: 解耦说话人特征可有效提升唇读模型的泛化能力和精度

Abstract: Lipreading is a challenging cross-modal task that aims to convert visual lip
movements into spoken text. Existing lipreading methods often extract visual
features that include speaker-specific lip attributes (e.g., shape, color,
texture), which introduce spurious correlations between vision and text. These
correlations lead to suboptimal lipreading accuracy and restrict model
generalization. To address this challenge, we introduce SIFLip, a
speaker-invariant visual feature learning framework that disentangles
speaker-specific attributes using two complementary disentanglement modules
(Implicit Disentanglement and Explicit Disentanglement) to improve
generalization. Specifically, since different speakers exhibit semantic
consistency between lip movements and phonetic text when pronouncing the same
words, our implicit disentanglement module leverages stable text embeddings as
supervisory signals to learn common visual representations across speakers,
implicitly decoupling speaker-specific features. Additionally, we design a
speaker recognition sub-task within the main lipreading pipeline to filter
speaker-specific features, then further explicitly disentangle these
personalized visual features from the backbone network via gradient reversal.
Experimental results demonstrate that SIFLip significantly enhances
generalization performance across multiple public datasets. Experimental
results demonstrate that SIFLip significantly improves generalization
performance across multiple public datasets, outperforming state-of-the-art
methods.

</details>


### [383] [Uncertainty-o: One Model-agnostic Framework for Unveiling Uncertainty in Large Multimodal Models](https://arxiv.org/abs/2506.07575)
*Ruiyang Zhang,Hu Zhang,Hao Fei,Zhedong Zheng*

Main category: cs.CV

TL;DR: 本文提出了Uncertainty-o框架，用于评估和揭示多模态模型的不确定性，解决如何统一评估、如何提示模型显示不确定性和如何量化不确定性用于下游任务的问题。实验证明其在多种基准测试中有效，提升了幻觉检测、缓解及不确定性感知推理等下游任务。


<details>
  <summary>Details</summary>
Motivation: 虽然大型多模态模型（LMMs）被认为比纯语言模型更稳健，但其是否具备自知不确定性尚不明确。当前存在三个挑战：如何统一评估不同LMMs的不确定性、如何通过提示引发其不确定性表达、如何量化不确定性以用于下游任务。

Method: 提出Uncertainty-o框架：1）模型无关设计，适配不同模态/架构的LMMs；2）通过经验性扰动多模态提示引发不确定性；3）推导多模态语义不确定性的数学公式，从多模态响应中量化不确定性。

Result: 在18个跨模态基准测试和10种开闭源LMMs上验证，证明该框架能可靠估计模型不确定性，有效提升下游任务（如幻觉检测与缓解、不确定性思维链推理）。

Conclusion: Uncertainty-o为LMMs的不确定性评估提供统一解决方案，通过扰动提示和数学建模实现量化，显著增强下游应用鲁棒性。

Abstract: Large Multimodal Models (LMMs), harnessing the complementarity among diverse
modalities, are often considered more robust than pure Language Large Models
(LLMs); yet do LMMs know what they do not know? There are three key open
questions remaining: (1) how to evaluate the uncertainty of diverse LMMs in a
unified manner, (2) how to prompt LMMs to show its uncertainty, and (3) how to
quantify uncertainty for downstream tasks. In an attempt to address these
challenges, we introduce Uncertainty-o: (1) a model-agnostic framework designed
to reveal uncertainty in LMMs regardless of their modalities, architectures, or
capabilities, (2) an empirical exploration of multimodal prompt perturbations
to uncover LMM uncertainty, offering insights and findings, and (3) derive the
formulation of multimodal semantic uncertainty, which enables quantifying
uncertainty from multimodal responses. Experiments across 18 benchmarks
spanning various modalities and 10 LMMs (both open- and closed-source)
demonstrate the effectiveness of Uncertainty-o in reliably estimating LMM
uncertainty, thereby enhancing downstream tasks such as hallucination
detection, hallucination mitigation, and uncertainty-aware Chain-of-Thought
reasoning.

</details>


### [384] [Super Encoding Network: Recursive Association of Multi-Modal Encoders for Video Understanding](https://arxiv.org/abs/2506.07576)
*Boyu Chen,Siran Chen,Kunchang Li,Qinglin Xu,Yu Qiao,Yali Wang*

Main category: cs.CV

TL;DR: 提出统一超编码网络(SEN)，通过递归关联多模态编码器增强深度交互，提升视频理解任务(跟踪、识别、聊天、编辑)的性能。


<details>
  <summary>Details</summary>
Motivation: 现有多模态基础模型仅通过对比学习对齐不同模态编码器，缺乏深层多模态交互，难以理解复杂运动与多样化场景。

Method: 1. 将预训练编码器视为“超神经元” 2. 设计递归关联(RA)块 3. 通过知识整合/分发/提示递归融合多模态

Result: 在四项视频任务上显著提升：跟踪任务Jaccard指数↑2.7%/TC↓8.8%；编辑任务文本对齐↑6.4%/帧一致性↑4.1%

Conclusion: SEN通过递归关联机制有效增强多模态交互，为下游视频理解提供通用解决方案

Abstract: Video understanding has been considered as one critical step towards world
modeling, which is an important long-term problem in AI research. Recently,
multi-modal foundation models have shown such potential via large-scale
pretraining. However, these models simply align encoders of different
modalities via contrastive learning, while lacking deeper multi-modal
interactions, which is critical for understanding complex target movements with
diversified video scenes. To fill this gap, we propose a unified Super Encoding
Network (SEN) for video understanding, which builds up such distinct
interactions through recursive association of multi-modal encoders in the
foundation models. Specifically, we creatively treat those well-trained
encoders as "super neurons" in our SEN. Via designing a Recursive Association
(RA) block, we progressively fuse multi-modalities with the input video, based
on knowledge integrating, distributing, and prompting of super neurons in a
recursive manner. In this way, our SEN can effectively encode deeper
multi-modal interactions, for prompting various video understanding tasks in
downstream. Extensive experiments show that, our SEN can remarkably boost the
four most representative video tasks, including tracking, recognition,
chatting, and editing, e.g., for pixel-level tracking, the average jaccard
index improves 2.7%, temporal coherence(TC) drops 8.8% compared to the popular
CaDeX++ approach. For one-shot video editing, textual alignment improves 6.4%,
and frame consistency increases 4.1% compared to the popular TuneA-Video
approach.

</details>


### [385] [Explore the vulnerability of black-box models via diffusion models](https://arxiv.org/abs/2506.07590)
*Jiacheng Shi,Yanfu Zhang,Huajie Shao,Ashley Gao*

Main category: cs.CV

TL;DR: 发现扩散模型API存在新的安全威胁：攻击者通过生成合成图像训练替代模型，以极低查询成本实现模型窃取和对抗攻击，效果远超现有方法。


<details>
  <summary>Details</summary>
Motivation: 扩散模型在生成高保真图像的同时带来安全隐患（如版权侵犯/信息泄露），但目前尚未有研究关注利用其API生成合成图像来攻击其他黑盒分类模型的风险。

Method: 1. 通过扩散模型API批量生成合成图像 2. 用合成图像训练高精度替代模型 3. 利用替代模型执行模型窃取和迁移式对抗攻击（仅需黑盒模型0.01倍查询量）

Result: 在CIFAR/ImageNet等7个数据集上，对抗攻击成功率98.68%，平均性能超越SOTA方法27.37%

Conclusion: 扩散模型API存在新型安全漏洞，能在极低查询成本下实现高效模型提取和对抗攻击，需引起安全社区重视

Abstract: Recent advancements in diffusion models have enabled high-fidelity and
photorealistic image generation across diverse applications. However, these
models also present security and privacy risks, including copyright violations,
sensitive information leakage, and the creation of harmful or offensive content
that could be exploited maliciously. In this study, we uncover a novel security
threat where an attacker leverages diffusion model APIs to generate synthetic
images, which are then used to train a high-performing substitute model. This
enables the attacker to execute model extraction and transfer-based adversarial
attacks on black-box classification models with minimal queries, without
needing access to the original training data. The generated images are
sufficiently high-resolution and diverse to train a substitute model whose
outputs closely match those of the target model. Across the seven benchmarks,
including CIFAR and ImageNet subsets, our method shows an average improvement
of 27.37% over state-of-the-art methods while using just 0.01 times of the
query budget, achieving a 98.68% success rate in adversarial attacks on the
target model.

</details>


### [386] [SceneRAG: Scene-level Retrieval-Augmented Generation for Video Understanding](https://arxiv.org/abs/2506.07600)
*Nianbo Zeng,Haowen Hou,Fei Richard Yu,Si Shi,Ying Tiffany He*

Main category: cs.CV

TL;DR: 提出了一个名为SceneRAG的多模态框架，通过场景分割和图推理技术解决长视频理解难题。


<details>
  <summary>Details</summary>
Motivation: 当前基于固定长度切分的检索增强生成方法会破坏视频上下文连续性，无法捕捉真实场景边界，影响了长视频理解的效果。

Method: 1) 利用LLM处理视频转录文本，结合时间元数据进行场景分割 2) 通过启发式规则和迭代修正优化边界 3) 多模态融合构建动态知识图谱 4) 支持多跳检索的图推理机制

Result: 在134小时视频的LongerVideos基准测试中，生成任务获胜率最高达72.5%，显著超越现有方法。

Conclusion: 该框架突破性地证明：模仿人类认知过程的场景化组织策略，能有效解决长视频内容理解中的上下文连续性难题。

Abstract: Despite recent advances in retrieval-augmented generation (RAG) for video
understanding, effectively understanding long-form video content remains
underexplored due to the vast scale and high complexity of video data. Current
RAG approaches typically segment videos into fixed-length chunks, which often
disrupts the continuity of contextual information and fails to capture
authentic scene boundaries. Inspired by the human ability to naturally organize
continuous experiences into coherent scenes, we present SceneRAG, a unified
framework that leverages large language models to segment videos into
narrative-consistent scenes by processing ASR transcripts alongside temporal
metadata. SceneRAG further sharpens these initial boundaries through
lightweight heuristics and iterative correction. For each scene, the framework
fuses information from both visual and textual modalities to extract entity
relations and dynamically builds a knowledge graph, enabling robust multi-hop
retrieval and generation that account for long-range dependencies. Experiments
on the LongerVideos benchmark, featuring over 134 hours of diverse content,
confirm that SceneRAG substantially outperforms prior baselines, achieving a
win rate of up to 72.5 percent on generation tasks.

</details>


### [387] [SurgBench: A Unified Large-Scale Benchmark for Surgical Video Analysis](https://arxiv.org/abs/2506.07603)
*Jianhui Wei,Zikai Xiao,Danyu Sun,Luqi Gong,Zongxin Yang,Zuozhu Liu,Jian Wu*

Main category: cs.CV

TL;DR: 本文提出了SurgBench，一个统一的手术视频基准框架，包括预训练数据集SurgBench-P和评估基准SurgBench-E。SurgBench-P包含5300万帧的手术视频，覆盖22种手术操作和11个专业领域；SurgBench-E包含6大类72项精细评估任务。实验表明，现有视频基础模型难以泛化到多种手术视频分析任务，而使用SurgBench-P进行预训练能显著提升性能，对未知手术操作和模态具有卓越的跨域泛化能力。


<details>
  <summary>Details</summary>
Motivation: 发展手术视频基础模型的进展受限于大规模、多样化数据集的稀缺。

Method: 构建了包含预训练数据集SurgBench-P和评估基准SurgBench-E的框架。SurgBench-P提供大规模预训练数据，SurgBench-E设计6类任务进行评估。通过实验比较现有模型与使用SurgBench-P预训练模型的性能。

Result: 现有视频基础模型在多样化手术任务上泛化能力差。SurgBench-P预训练显著提升模型性能（平均+10-15% mAP），在跨域和跨模态任务上表现出优越的泛化能力。

Conclusion: SurgBench填补了手术视频分析领域基准框架的空白，其大规模数据集和综合评估协议为推进手术视频基础模型研究提供了关键基础设施。

Abstract: Surgical video understanding is pivotal for enabling automated intraoperative
decision-making, skill assessment, and postoperative quality improvement.
However, progress in developing surgical video foundation models (FMs) remains
hindered by the scarcity of large-scale, diverse datasets for pretraining and
systematic evaluation. In this paper, we introduce \textbf{SurgBench}, a
unified surgical video benchmarking framework comprising a pretraining dataset,
\textbf{SurgBench-P}, and an evaluation benchmark, \textbf{SurgBench-E}.
SurgBench offers extensive coverage of diverse surgical scenarios, with
SurgBench-P encompassing 53 million frames across 22 surgical procedures and 11
specialties, and SurgBench-E providing robust evaluation across six categories
(phase classification, camera motion, tool recognition, disease diagnosis,
action classification, and organ detection) spanning 72 fine-grained tasks.
Extensive experiments reveal that existing video FMs struggle to generalize
across varied surgical video analysis tasks, whereas pretraining on SurgBench-P
yields substantial performance improvements and superior cross-domain
generalization to unseen procedures and modalities. Our dataset and code are
available upon request.

</details>


### [388] [DragNeXt: Rethinking Drag-Based Image Editing](https://arxiv.org/abs/2506.07611)
*Yuan Zhou,Junbao Zhou,Qingshan Xu,Kesen Zhao,Yuxuan Wang,Hao Fei,Richang Hong,Hanwang Zhang*

Main category: cs.CV

TL;DR: DragNeXt redefines拖拽式图像编辑(DBIE)为区域变形/旋转/平移, 通过显式区域指定解决歧义问题,并提出了基于潜在区域优化(PBSI)的简化框架,大幅超越现有方法。


<details>
  <summary>Details</summary>
Motivation: 当前DBIE方法存在两点不足:1)基于点的拖拽意图不明确;2)现有运动监督+点追踪流程复杂且效果有限。

Method: 1) 将DBIE重构为对用户指定手柄区域的变形/旋转/平移;2) 提出DragNeXt框架: 通过潜在区域优化(LRO)统一问题,采用渐进式反向自干预(PBSI)优化,利用区域结构信息和中间状态引导。

Result: 在NextBench测试集上, DragNeXt显著优于现有方法,生成质量更高。

Conclusion: 显式区域指定+潜在区域优化框架能有效解决DBIE歧义问题, PBSI机制简化流程的同时提升了编辑质量。

Abstract: Drag-Based Image Editing (DBIE), which allows users to manipulate images by
directly dragging objects within them, has recently attracted much attention
from the community. However, it faces two key challenges:
(\emph{\textcolor{magenta}{i}}) point-based drag is often highly ambiguous and
difficult to align with users' intentions; (\emph{\textcolor{magenta}{ii}})
current DBIE methods primarily rely on alternating between motion supervision
and point tracking, which is not only cumbersome but also fails to produce
high-quality results. These limitations motivate us to explore DBIE from a new
perspective -- redefining it as deformation, rotation, and translation of
user-specified handle regions. Thereby, by requiring users to explicitly
specify both drag areas and types, we can effectively address the ambiguity
issue. Furthermore, we propose a simple-yet-effective editing framework, dubbed
\textcolor{SkyBlue}{\textbf{DragNeXt}}. It unifies DBIE as a Latent Region
Optimization (LRO) problem and solves it through Progressive Backward
Self-Intervention (PBSI), simplifying the overall procedure of DBIE while
further enhancing quality by fully leveraging region-level structure
information and progressive guidance from intermediate drag states. We validate
\textcolor{SkyBlue}{\textbf{DragNeXt}} on our NextBench, and extensive
experiments demonstrate that our proposed method can significantly outperform
existing approaches. Code will be released on github.

</details>


### [389] [Scaling Human Activity Recognition: A Comparative Evaluation of Synthetic Data Generation and Augmentation Techniques](https://arxiv.org/abs/2506.07612)
*Zikang Leng,Archith Iyer,Thomas Plötz*

Main category: cs.CV

TL;DR: 该论文通过对比两种虚拟IMU生成方法（基于视频和基于语言）与传统数据增强技术，发现虚拟IMU数据能在有限数据条件下显著提升人体活动识别（HAR）性能，并提供了实际选择策略的建议。


<details>
  <summary>Details</summary>
Motivation: 解决HAR领域因标注数据稀缺导致的性能限制问题，探索虚拟IMU数据的生成方法及其与传统增强技术的相对有效性。

Method: 构建大规模虚拟IMU数据集（覆盖100种活动，模拟22个身体部位的传感器信号），在三个基准HAR数据集上使用四种模型对比评估三种数据生成策略。

Result: 虚拟IMU数据显著优于单独使用真实数据或增强数据（特别在有限数据条件下），并揭示了不同方法的优缺点。

Conclusion: 虚拟IMU是提升HAR性能的有效手段，论文为选择数据生成策略提供了实用指南，同时指出不同方法在计算成本和应用场景上的权衡。

Abstract: Human activity recognition (HAR) is often limited by the scarcity of labeled
datasets due to the high cost and complexity of real-world data collection. To
mitigate this, recent work has explored generating virtual inertial measurement
unit (IMU) data via cross-modality transfer. While video-based and
language-based pipelines have each shown promise, they differ in assumptions
and computational cost. Moreover, their effectiveness relative to traditional
sensor-level data augmentation remains unclear. In this paper, we present a
direct comparison between these two virtual IMU generation approaches against
classical data augmentation techniques. We construct a large-scale virtual IMU
dataset spanning 100 diverse activities from Kinetics-400 and simulate sensor
signals at 22 body locations. The three data generation strategies are
evaluated on benchmark HAR datasets (UTD-MHAD, PAMAP2, HAD-AW) using four
popular models. Results show that virtual IMU data significantly improves
performance over real or augmented data alone, particularly under limited-data
conditions. We offer practical guidance on choosing data generation strategies
and highlight the distinct advantages and disadvantages of each approach.

</details>


### [390] [Event-Priori-Based Vision-Language Model for Efficient Visual Understanding](https://arxiv.org/abs/2506.07627)
*Haotong Qin,Cheng Hu,Michele Magno*

Main category: cs.CV

TL;DR: 提出名为EP-VLM的事件先验视觉语言模型，通过事件数据引导RGB输入的稀疏化处理，减少冗余计算，在Qwen2-VL系列模型上实现50%计算量节省的同时保持98%准确率，提升边缘设备部署可行性。


<details>
  <summary>Details</summary>
Motivation: 现有LLM基视觉语言模型因处理密集冗余视觉信息导致计算效率低下，难以部署在资源受限的边缘设备。受人类视觉启发的稀疏处理能提升效率。

Method: 1) 利用动态事件数据引导RGB输入的块级稀疏化处理 2) 采用保持位置信息的token化策略处理事件数据引导后的非结构化稀疏输入

Result: 在Qwen2-VL-2B模型上降低50%计算量(FLOPs)，在RealWorldQA数据集保持98%原模型准确率。

Conclusion: 事件视觉先验可显著提升VLM推理效率，为开发可持续的边缘视觉理解模型铺平道路。

Abstract: Large Language Model (LLM)-based Vision-Language Models (VLMs) have
substantially extended the boundaries of visual understanding capabilities.
However, their high computational demands hinder deployment on
resource-constrained edge devices. A key source of inefficiency stems from the
VLM's need to process dense and redundant visual information. Visual inputs
contain significant regions irrelevant to text semantics, rendering the
associated computations ineffective for inference. This paper introduces a
novel Event-Priori-Based Vision-Language Model, termed EP-VLM. Its core
contribution is a novel mechanism leveraging motion priors derived from dynamic
event vision to enhance VLM efficiency. Inspired by human visual cognition,
EP-VLM first employs event data to guide the patch-wise sparsification of RGB
visual inputs, progressively concentrating VLM computation on salient regions
of the visual input. Subsequently, we construct a position-preserving
tokenization strategy for the visual encoder within the VLM architecture. This
strategy processes the event-guided, unstructured, sparse visual input while
accurately preserving positional understanding within the visual input.
Experimental results demonstrate that EP-VLM achieves significant efficiency
improvements while maintaining nearly lossless accuracy compared to baseline
models from the Qwen2-VL series. For instance, against the original
Qwen2-VL-2B, EP-VLM achieves 50% FLOPs savings while retaining 98% of the
original accuracy on the RealWorldQA dataset. This work demonstrates the
potential of event-based vision priors for improving VLM inference efficiency,
paving the way for creating more efficient and deployable VLMs for sustainable
visual understanding at the edge.

</details>


### [391] [HuSc3D: Human Sculpture dataset for 3D object reconstruction](https://arxiv.org/abs/2506.07628)
*Weronika Smolak-Dyżewska,Dawid Malarz,Grzegorz Wilczyński,Rafał Tobiasz,Joanna Waczyńska,Piotr Borycki,Przemysław Spurek*

Main category: cs.CV

TL;DR: 提出了HuSc3D数据集用于真实获取挑战下的3D重建模型基准测试


<details>
  <summary>Details</summary>
Motivation: 现有数据集专注于理想化合成或精细捕获的真实数据，未能反映新获取真实场景（尤其是室外）的复杂性

Method: 创建包含6个白色雕塑的新数据集，具有复杂穿孔结构和最小纹理变化，图像数量变化大

Result: 评估主流3D重建方法，证明该数据集能有效区分模型性能，揭示对几何细节/色彩歧义/数据变化的敏感性

Conclusion: HuSc3D填补了现有基准测试的空白，突显了传统数据集未能暴露的方法局限性

Abstract: 3D scene reconstruction from 2D images is one of the most important tasks in
computer graphics. Unfortunately, existing datasets and benchmarks concentrate
on idealized synthetic or meticulously captured realistic data. Such benchmarks
fail to convey the inherent complexities encountered in newly acquired
real-world scenes. In such scenes especially those acquired outside, the
background is often dynamic, and by popular usage of cell phone cameras, there
might be discrepancies in, e.g., white balance. To address this gap, we present
HuSc3D, a novel dataset specifically designed for rigorous benchmarking of 3D
reconstruction models under realistic acquisition challenges. Our dataset
uniquely features six highly detailed, fully white sculptures characterized by
intricate perforations and minimal textural and color variation. Furthermore,
the number of images per scene varies significantly, introducing the additional
challenge of limited training data for some instances alongside scenes with a
standard number of views. By evaluating popular 3D reconstruction methods on
this diverse dataset, we demonstrate the distinctiveness of HuSc3D in
effectively differentiating model performance, particularly highlighting the
sensitivity of methods to fine geometric details, color ambiguity, and varying
data availability--limitations often masked by more conventional datasets.

</details>


### [392] [HieraEdgeNet: A Multi-Scale Edge-Enhanced Framework for Automated Pollen Recognition](https://arxiv.org/abs/2506.07637)
*Yuchong Long,Wen Sun,Ningxiao Sun,Wenxiao Wang,Chao Li,Shan Yin*

Main category: cs.CV

TL;DR: 論文介紹名為HieraEdgeNet的多尺度邊緣增強框架，透過三個模組（HEM、SEF、CSPOKM）解決顯微鏡目標（如花粉）檢測的邊界模糊問題，在120類花粉數據集上達到0.9501 mAP，超越現有模型。


<details>
  <summary>Details</summary>
Motivation: 現有深度學習模型對微小目標（如花粉）的定位精度不足，其特徵包括尺寸微小、邊緣模糊及背景複雜，因此需要提升自動化花粉識別的精確度。

Method: 提出HieraEdgeNet框架，包含三個模組：1) 分層邊緣模組（HEM）提取多尺度邊緣特徵；2）協同邊緣融合（SEF）模組深度融合邊緣與語義信息；3）跨階段部分全核模組（CSPOKM），在CSP框架內使用Omni-Kernel運算元（結合各向異性大核卷積和混合域注意力）精煉特徵層。

Result: 在120類花粉的大型數據集上，HieraEdgeNet達到0.9501平均精度（mAP@.5），顯著優於YOLOv12n和RT-DETR等模型。定性分析證實其特徵表示更精確聚焦物體邊界。

Conclusion: HieraEdgeNet透過系統性整合邊緣信息，為高精度、高效率的自動化顯微物體檢測提供強健解決方案。

Abstract: Automated pollen recognition is vital to paleoclimatology, biodiversity
monitoring, and public health, yet conventional methods are hampered by
inefficiency and subjectivity. Existing deep learning models often struggle to
achieve the requisite localization accuracy for microscopic targets like
pollen, which are characterized by their minute size, indistinct edges, and
complex backgrounds. To overcome this limitation, we introduce HieraEdgeNet, a
multi-scale edge-enhancement framework. The framework's core innovation is the
introduction of three synergistic modules: the Hierarchical Edge Module (HEM),
which explicitly extracts a multi-scale pyramid of edge features that
corresponds to the semantic hierarchy at early network stages; the Synergistic
Edge Fusion (SEF) module, for deeply fusing these edge priors with semantic
information at each respective scale; and the Cross Stage Partial Omni-Kernel
Module (CSPOKM), which maximally refines the most detail-rich feature layers
using an Omni-Kernel operator - comprising anisotropic large-kernel
convolutions and mixed-domain attention - all within a computationally
efficient Cross-Stage Partial (CSP) framework. On a large-scale dataset
comprising 120 pollen classes, HieraEdgeNet achieves a mean Average Precision
(mAP@.5) of 0.9501, significantly outperforming state-of-the-art baseline
models such as YOLOv12n and RT-DETR. Furthermore, qualitative analysis confirms
that our approach generates feature representations that are more precisely
focused on object boundaries. By systematically integrating edge information,
HieraEdgeNet provides a robust and powerful solution for high-precision,
high-efficiency automated detection of microscopic objects.

</details>


### [393] [Synthetic Visual Genome](https://arxiv.org/abs/2506.07643)
*Jae Sung Park,Zixian Ma,Linjie Li,Chenhao Zheng,Cheng-Yu Hsieh,Ximing Lu,Khyathi Chandu,Quan Kong,Norimasa Kobori,Ali Farhadi,Yejin Choi,Ranjay Krishna*

Main category: cs.CV

TL;DR: ROBIN模型通过合成高质量场景图数据SVG训练，并借助SG-EDIT框架自我蒸馏，在少量数据下实现超越更大模型的视觉关系理解性能。


<details>
  <summary>Details</summary>
Motivation: 现有多模态语言模型在视觉关系推理上存在不足，尤其缺乏精确关系和生成能力。为此需要构建高质量密集场景图数据集以提升模型性能。

Method: 1. 合成SVG数据集：使用教师模型补全现有场景图的缺失关系，并通过过滤保证质量。2. 提出SG-EDIT框架：利用GPT-4o优化模型预测的场景图。3. 训练3B参数的ROBIN模型。

Result: 1. 构建含146K图像/560万关系的数据集。2. ROBIN-3B在关系理解基准上超越同规模模型（训练数据量少100倍），甚至超过13B参数模型。3. 指代表达理解任务达到SOTA（88.9分）。

Conclusion: 精炼的场景图数据训练对视觉推理任务至关重要，小模型通过高质量数据可超越大模型。

Abstract: Reasoning over visual relationships-spatial, functional, interactional,
social, etc.-is considered to be a fundamental component of human cognition.
Yet, despite the major advances in visual comprehension in multimodal language
models (MLMs), precise reasoning over relationships and their generations
remains a challenge. We introduce ROBIN: an MLM instruction-tuned with densely
annotated relationships capable of constructing high-quality dense scene graphs
at scale. To train ROBIN, we curate SVG, a synthetic scene graph dataset by
completing the missing relations of selected objects in existing scene graphs
using a teacher MLM and a carefully designed filtering process to ensure
high-quality. To generate more accurate and rich scene graphs at scale for any
image, we introduce SG-EDIT: a self-distillation framework where GPT-4o further
refines ROBIN's predicted scene graphs by removing unlikely relations and/or
suggesting relevant ones. In total, our dataset contains 146K images and 5.6M
relationships for 2.6M objects. Results show that our ROBIN-3B model, despite
being trained on less than 3 million instances, outperforms similar-size models
trained on over 300 million instances on relationship understanding benchmarks,
and even surpasses larger models up to 13B parameters. Notably, it achieves
state-of-the-art performance in referring expression comprehension with a score
of 88.9, surpassing the previous best of 87.4. Our results suggest that
training on the refined scene graph data is crucial to maintaining high
performance across diverse visual reasoning task.

</details>


### [394] [FMaMIL: Frequency-Driven Mamba Multi-Instance Learning for Weakly Supervised Lesion Segmentation in Medical Images](https://arxiv.org/abs/2506.07652)
*Hangbei Cheng,Xiaorong Dong,Xueyu Liu,Jianan Zhang,Xuetao Ma,Mingqiang Wei,Liansheng Wang,Junxin Chen,Yongfei Wu*

Main category: cs.CV

TL;DR: 提出一个名为FMaMIL的两阶段弱监督病灶分割框架，仅使用图像级标签


<details>
  <summary>Details</summary>
Motivation: 解决因像素级注释稀缺且成本高而导致的组织病理学图像病灶分割难题

Method: 第一阶段：基于Mamba的编码器捕获远距离依赖+可学习频域编码模块补充特征；第二阶段：通过软标签监督和自校正机制优化伪标签

Result: 在公开和私有数据集上超越现有弱监督方法

Conclusion: 验证了该框架在数字病理学应用中的有效性和潜力

Abstract: Accurate lesion segmentation in histopathology images is essential for
diagnostic interpretation and quantitative analysis, yet it remains challenging
due to the limited availability of costly pixel-level annotations. To address
this, we propose FMaMIL, a novel two-stage framework for weakly supervised
lesion segmentation based solely on image-level labels. In the first stage, a
lightweight Mamba-based encoder is introduced to capture long-range
dependencies across image patches under the MIL paradigm. To enhance spatial
sensitivity and structural awareness, we design a learnable frequency-domain
encoding module that supplements spatial-domain features with spectrum-based
information. CAMs generated in this stage are used to guide segmentation
training. In the second stage, we refine the initial pseudo labels via a
CAM-guided soft-label supervision and a self-correction mechanism, enabling
robust training even under label noise. Extensive experiments on both public
and private histopathology datasets demonstrate that FMaMIL outperforms
state-of-the-art weakly supervised methods without relying on pixel-level
annotations, validating its effectiveness and potential for digital pathology
applications.

</details>


### [395] [ProSplat: Improved Feed-Forward 3D Gaussian Splatting for Wide-Baseline Sparse Views](https://arxiv.org/abs/2506.07670)
*Xiaohan Lu,Jiaye Fu,Jiaqi Zhang,Zetian Song,Chuanmin Jia,Siwei Ma*

Main category: cs.CV

TL;DR: ProSplat：针对稀疏输入下宽基线场景提升3D高斯泼溅渲染质量


<details>
  <summary>Details</summary>
Motivation: 标准3D高斯泼溅在宽基线场景中性能大幅下降（纹理缺失和几何不一致），需要新的解决方案

Method: 提出两阶段框架：1) 3DGS原语生成 2) 基于改进扩散模型的渲染增强技术（MORI补充纹理，DWEA保障几何一致性）

Result: 在RealEstate10K和DL3DV-10K数据集上平均PSNR提升1dB

Conclusion: ProSplat通过创新架构有效解决了宽基线渲染难题，为NVS任务提供新方向

Abstract: Feed-forward 3D Gaussian Splatting (3DGS) has recently demonstrated promising
results for novel view synthesis (NVS) from sparse input views, particularly
under narrow-baseline conditions. However, its performance significantly
degrades in wide-baseline scenarios due to limited texture details and
geometric inconsistencies across views. To address these challenges, in this
paper, we propose ProSplat, a two-stage feed-forward framework designed for
high-fidelity rendering under wide-baseline conditions. The first stage
involves generating 3D Gaussian primitives via a 3DGS generator. In the second
stage, rendered views from these primitives are enhanced through an improvement
model. Specifically, this improvement model is based on a one-step diffusion
model, further optimized by our proposed Maximum Overlap Reference view
Injection (MORI) and Distance-Weighted Epipolar Attention (DWEA). MORI
supplements missing texture and color by strategically selecting a reference
view with maximum viewpoint overlap, while DWEA enforces geometric consistency
using epipolar constraints. Additionally, we introduce a divide-and-conquer
training strategy that aligns data distributions between the two stages through
joint optimization. We evaluate ProSplat on the RealEstate10K and DL3DV-10K
datasets under wide-baseline settings. Experimental results demonstrate that
ProSplat achieves an average improvement of 1 dB in PSNR compared to recent
SOTA methods.

</details>


### [396] [OpenSplat3D: Open-Vocabulary 3D Instance Segmentation using Gaussian Splatting](https://arxiv.org/abs/2506.07697)
*Jens Piekenbrinck,Christian Schmidt,Alexander Hermans,Narunas Vaskevicius,Timm Linder,Bastian Leibe*

Main category: cs.CV

TL;DR: OpenSplat3D是一种基于3D高斯溅射（3DGS）的开集词汇3D实例分割方法，无需人工标注。它通过特征溅射技术关联语义信息，结合Segment Anything模型和视觉语言模型嵌入，实现基于自然语言描述的物体识别与分割。


<details>
  <summary>Details</summary>
Motivation: 当前3DGS在场景重建方面高效，但缺乏对场景的细粒度理解能力。OpenSplat3D旨在扩展3DGS的能力，实现开放词汇的3D实例分割，无需手动标注即可通过自然语言描述识别和分割任意物体。

Method: 1. 利用特征溅射将语义信息绑定到高斯点；2. 引入Segment Anything模型的实例掩码作为对比损失的监督信号；3. 整合视觉语言模型的语言嵌入，实现文本驱动的实例识别。

Result: 方法在LERF-mask、LERF-OVS和ScanNet++验证集上有效，证明能基于文本查询准确分割3D实例。

Conclusion: OpenSplat3D将3DGS转化为语义理解工具，实现灵活、开放词汇的3D实例分割，为3D场景理解提供新方案。

Abstract: 3D Gaussian Splatting (3DGS) has emerged as a powerful representation for
neural scene reconstruction, offering high-quality novel view synthesis while
maintaining computational efficiency. In this paper, we extend the capabilities
of 3DGS beyond pure scene representation by introducing an approach for
open-vocabulary 3D instance segmentation without requiring manual labeling,
termed OpenSplat3D. Our method leverages feature-splatting techniques to
associate semantic information with individual Gaussians, enabling fine-grained
scene understanding. We incorporate Segment Anything Model instance masks with
a contrastive loss formulation as guidance for the instance features to achieve
accurate instance-level segmentation. Furthermore, we utilize language
embeddings of a vision-language model, allowing for flexible, text-driven
instance identification. This combination enables our system to identify and
segment arbitrary objects in 3D scenes based on natural language descriptions.
We show results on LERF-mask and LERF-OVS as well as the full ScanNet++
validation set, demonstrating the effectiveness of our approach.

</details>


### [397] [NOVA3D: Normal Aligned Video Diffusion Model for Single Image to 3D Generation](https://arxiv.org/abs/2506.07698)
*Yuxiao Yang,Peihao Li,Yuhong Zhang,Junzhe Lu,Xianglong He,Minghan Qin,Weitao Wang,Haoqian Wang*

Main category: cs.CV

TL;DR: NOVA3D是一个创新的单图像到3D生成框架，它利用预训练视频扩散模型的强3D先验，并通过几何-时间对齐注意机制和多视图解冲突几何融合算法，显著提高了多视图一致性和纹理保真度。


<details>
  <summary>Details</summary>
Motivation: 现有的3D AIGC方法依赖评分蒸馏采样从图像扩散模型中提取3D物体，但存在3D先验不足导致的多视图一致性问题。

Method: 1) 利用预训练视频扩散模型的3D先验 2) 多视图视频微调时整合几何信息 3) 提出几何-时间对齐注意力机制 4) 引入解冲突几何融合算法处理姿态对齐差异。

Result: 大量实验证明NOVA3D在单图像3D生成任务上优于现有基线，特别在多视图一致性和纹理质量方面。

Conclusion: NOVA3D通过融合视频扩散模型的时空先验和几何信息处理机制，为单图像3D生成提供了更高质量的解决方案。

Abstract: 3D AI-generated content (AIGC) has made it increasingly accessible for anyone
to become a 3D content creator. While recent methods leverage Score
Distillation Sampling to distill 3D objects from pretrained image diffusion
models, they often suffer from inadequate 3D priors, leading to insufficient
multi-view consistency. In this work, we introduce NOVA3D, an innovative
single-image-to-3D generation framework. Our key insight lies in leveraging
strong 3D priors from a pretrained video diffusion model and integrating
geometric information during multi-view video fine-tuning. To facilitate
information exchange between color and geometric domains, we propose the
Geometry-Temporal Alignment (GTA) attention mechanism, thereby improving
generalization and multi-view consistency. Moreover, we introduce the
de-conflict geometry fusion algorithm, which improves texture fidelity by
addressing multi-view inaccuracies and resolving discrepancies in pose
alignment. Extensive experiments validate the superiority of NOVA3D over
existing baselines.

</details>


### [398] [Adaptive Blind Super-Resolution Network for Spatial-Specific and Spatial-Agnostic Degradations](https://arxiv.org/abs/2506.07705)
*Weilei Wen,Chunle Guo,Wenqi Ren,Hongpeng Wang,Xiuli Shao*

Main category: cs.CV

TL;DR: 该论文提出了一种动态滤波网络，通过整合全局和局部分支来处理图像重建中的两种主要退化类型：空间不可知主导退化和空间特定主导退化。该方法优于现有的盲超分辨率算法。


<details>
  <summary>Details</summary>
Motivation: 现有方法忽视了不同退化类型之间的多样性，使用统一网络模型处理多种退化效果不佳。作者发现主要退化类型可分为两类：空间不可知主导退化（如降采样和噪声）和空间特定主导退化（如模糊），需要不同处理策略。

Method: 设计了包含全局和局部分支的动态滤波网络：全局动态滤波层通过注意力机制生成权重处理空间不可知退化；局部动态滤波层生成空间特定动态滤波器处理空间特定退化。

Result: 该方法在合成和真实图像数据集上均优于最先进的盲超分辨率算法。

Conclusion: 通过区分两种退化类型并分别设计针对性处理模块，该动态滤波网络有效提升了图像重建质量，解决了现有方法忽视退化多样性的问题。

Abstract: Prior methodologies have disregarded the diversities among distinct
degradation types during image reconstruction, employing a uniform network
model to handle multiple deteriorations. Nevertheless, we discover that
prevalent degradation modalities, including sampling, blurring, and noise, can
be roughly categorized into two classes. We classify the first class as
spatial-agnostic dominant degradations, less affected by regional changes in
image space, such as downsampling and noise degradation. The second class
degradation type is intimately associated with the spatial position of the
image, such as blurring, and we identify them as spatial-specific dominant
degradations. We introduce a dynamic filter network integrating global and
local branches to address these two degradation types. This network can greatly
alleviate the practical degradation problem. Specifically, the global dynamic
filtering layer can perceive the spatial-agnostic dominant degradation in
different images by applying weights generated by the attention mechanism to
multiple parallel standard convolution kernels, enhancing the network's
representation ability. Meanwhile, the local dynamic filtering layer converts
feature maps of the image into a spatially specific dynamic filtering operator,
which performs spatially specific convolution operations on the image features
to handle spatial-specific dominant degradations. By effectively integrating
both global and local dynamic filtering operators, our proposed method
outperforms state-of-the-art blind super-resolution algorithms in both
synthetic and real image datasets.

</details>


### [399] [Consistent Video Editing as Flow-Driven Image-to-Video Generation](https://arxiv.org/abs/2506.07713)
*Ge Wang,Songlin Fan,Hangxu Liu,Quanjian Song,Hewei Wang,Jinfeng Xu*

Main category: cs.CV

TL;DR: FlowV2V是一种基于光流的视频编辑方法，通过将视频编辑任务分解为首帧编辑和条件图像到视频生成，利用伪光流序列保持变形过程中的时间一致性，提升非刚性物体运动的编辑效果


<details>
  <summary>Details</summary>
Motivation: 现有视频编辑方法难以处理复杂动作（如多物体运动和肖像编辑），且主要局限于物体替换任务。为解决这一问题，作者发现光流在复杂动作建模中具有潜力

Method: 1. 将视频编辑分为首帧编辑和条件I2V生成两个阶段 \n 2. 生成与变形形状对齐的伪光流序列 \n 3. 通过FlowV2V模型保持编辑过程中时间一致性

Result: 在DAVIS-EDIT数据集上：\n- DOVER指标提升13.67% \n- 扭曲误差降低50.66% \n证明该方法在时间一致性和样本质量上优于现有SOTA

Conclusion: 1. FlowV2V验证了光流驱动方法在复杂视频编辑中的有效性 \n 2. 首帧编辑范式+光流对齐策略能显著提升时间一致性 \n 3. 为处理非刚性物体运动提供了新思路

Abstract: With the prosper of video diffusion models, down-stream applications like
video editing have been significantly promoted without consuming much
computational cost. One particular challenge in this task lies at the motion
transfer process from the source video to the edited one, where it requires the
consideration of the shape deformation in between, meanwhile maintaining the
temporal consistency in the generated video sequence. However, existing methods
fail to model complicated motion patterns for video editing, and are
fundamentally limited to object replacement, where tasks with non-rigid object
motions like multi-object and portrait editing are largely neglected. In this
paper, we observe that optical flows offer a promising alternative in complex
motion modeling, and present FlowV2V to re-investigate video editing as a task
of flow-driven Image-to-Video (I2V) generation. Specifically, FlowV2V
decomposes the entire pipeline into first-frame editing and conditional I2V
generation, and simulates pseudo flow sequence that aligns with the deformed
shape, thus ensuring the consistency during editing. Experimental results on
DAVIS-EDIT with improvements of 13.67% and 50.66% on DOVER and warping error
illustrate the superior temporal consistency and sample quality of FlowV2V
compared to existing state-of-the-art ones. Furthermore, we conduct
comprehensive ablation studies to analyze the internal functionalities of the
first-frame paradigm and flow alignment in the proposed method.

</details>


### [400] [ReverB-SNN: Reversing Bit of the Weight and Activation for Spiking Neural Networks](https://arxiv.org/abs/2506.07720)
*Yufei Guo,Yuhan Zhang,Zhou Jie,Xiaode Liu,Xin Tong,Yuanpei Chen,Weihang Peng,Zhe Ma*

Main category: cs.CV

TL;DR: 论文提出了一种称为ReverB-SNN的新方法，通过在SNN中反转权重和激活值的位，使用实数脉冲激活和二元权重来增强信息容量，并通过可训练因子和重新参数化提高准确性和效率


<details>
  <summary>Details</summary>
Motivation: 传统的SNN使用二元脉冲激活在提高能效的同时牺牲了准确性。作者观察到激活值的量化比权重量化对准确性的影响更大，因此提出采用实数激活来保留更多信息

Method: （1）使用实数脉冲激活替代二元激活；（2）采用二元权重，但引入可训练因子适应学习权重幅度；（3）推理时通过重新参数化技术将可训练权重建模为静态形式以保持效率

Result: 在多种网络架构和数据集（静态/动态）上的实验表明，该方法始终优于现有技术

Conclusion: ReverB-SNN在保持SNN事件驱动和免乘法优点的同时，提升了激活值的信息容量，有效平衡了准确性与效率

Abstract: The Spiking Neural Network (SNN), a biologically inspired neural network
infrastructure, has garnered significant attention recently. SNNs utilize
binary spike activations for efficient information transmission, replacing
multiplications with additions, thereby enhancing energy efficiency. However,
binary spike activation maps often fail to capture sufficient data information,
resulting in reduced accuracy. To address this challenge, we advocate reversing
the bit of the weight and activation for SNNs, called \textbf{ReverB-SNN},
inspired by recent findings that highlight greater accuracy degradation from
quantizing activations compared to weights. Specifically, our method employs
real-valued spike activations alongside binary weights in SNNs. This preserves
the event-driven and multiplication-free advantages of standard SNNs while
enhancing the information capacity of activations. Additionally, we introduce a
trainable factor within binary weights to adaptively learn suitable weight
amplitudes during training, thereby increasing network capacity. To maintain
efficiency akin to vanilla \textbf{ReverB-SNN}, our trainable binary weight
SNNs are converted back to standard form using a re-parameterization technique
during inference. Extensive experiments across various network architectures
and datasets, both static and dynamic, demonstrate that our approach
consistently outperforms state-of-the-art methods.

</details>


### [401] [ETA: Efficiency through Thinking Ahead, A Dual Approach to Self-Driving with Large Models](https://arxiv.org/abs/2506.07725)
*Shadi Hamdan,Chonghao Sima,Zetong Yang,Hongyang Li,Fatma Güney*

Main category: cs.CV

TL;DR: 本文提出了一种名为 ETA 的异步双系统架构，通过在先前时间步处理大型模型的密集计算，并执行批量推理，实现在保持接近实时推理速度（50 毫秒）的同时，提升自动驾驶决策性能（在CARLA基准测试中提升8%，驾驶分数达69.53）。


<details>
  <summary>Details</summary>
Motivation: 为了解决大型模型推理速度慢而无法满足自动驾驶实时决策需求的问题。现有的双系统架构（小型模型实时决策+大型模型慢速分析）仍难以及时为每一帧提供大模型响应。

Method: ETA 系统通过三个关键设计实现：(1) 利用大模型对未来的预测，将过去的重要特征传播到当前帧；(2) 使用小型模型提取当前帧特征保证实时性；(3) 通过动作掩码机制整合双特征，强化关键图像区域。

Result: 在 Bench2Drive CARLA Leaderboard-v2 基准测试中，驾驶分数提升至69.53（超出此前最佳8%），同时维持50毫秒的接近实时推理速度。

Conclusion: 通过提前计算和特征传播策略，ETA 有效解决了大型模型响应延迟问题，为自动驾驶系统提供高性能且实时的决策能力。

Abstract: How can we benefit from large models without sacrificing inference speed, a
common dilemma in self-driving systems? A prevalent solution is a dual-system
architecture, employing a small model for rapid, reactive decisions and a
larger model for slower but more informative analyses. Existing dual-system
designs often implement parallel architectures where inference is either
directly conducted using the large model at each current frame or retrieved
from previously stored inference results. However, these works still struggle
to enable large models for a timely response to every online frame. Our key
insight is to shift intensive computations of the current frame to previous
time steps and perform a batch inference of multiple time steps to make large
models respond promptly to each time step. To achieve the shifting, we
introduce Efficiency through Thinking Ahead (ETA), an asynchronous system
designed to: (1) propagate informative features from the past to the current
frame using future predictions from the large model, (2) extract current frame
features using a small model for real-time responsiveness, and (3) integrate
these dual features via an action mask mechanism that emphasizes
action-critical image regions. Evaluated on the Bench2Drive CARLA
Leaderboard-v2 benchmark, ETA advances state-of-the-art performance by 8% with
a driving score of 69.53 while maintaining a near-real-time inference speed at
50 ms.

</details>


### [402] [SpikeSMOKE: Spiking Neural Networks for Monocular 3D Object Detection with Cross-Scale Gated Coding](https://arxiv.org/abs/2506.07737)
*Xuemei Chen,Huamin Wang,Hangchi Shen,Shukai Duan,Shiping Wen,Tingwen Huang*

Main category: cs.CV

TL;DR: 提出SpikeSMOKE架构，采用脉冲神经网络(SNNs)实现低功耗单目3D目标检测，通过交叉尺度门控编码机制(CSGC)增强特征表示，并引入轻量残差块降低计算量。在KITTI数据集上检测性能显著提升，能耗降低72.2%，参数量减少3倍，计算量减少10倍。


<details>
  <summary>Details</summary>
Motivation: 传统3D目标检测能耗高，脉冲神经网络(SNNs)的低功耗特性为单目3D检测提供新解决方案。但SNN的离散信号会导致信息损失，限制特征表达能力，需设计新机制解决。

Method: 1. 提出SpikeSMOKE架构，首次将SNN用于单目3D目标检测；2. 创新交叉尺度门控编码机制(CSGC)，结合跨尺度注意力和生物神经元突触过滤机制增强特征；3. 设计轻量残差块，保持脉冲计算范式同时减少计算量。

Result: 在KITTI数据集上：1. CSGC使检测性能提升2.82-3.17 AP；2. 能耗比SMOKE降低72.2%（Hard类）时性能仅降4%；3. 轻量版(SpikeSMOKE-L)参数量减少3倍，计算量减少10倍。

Conclusion: SpikeSMOKE首次证明SNN在单目3D检测的可行性，CSGC有效提升SNN特征表达能力，轻量设计大幅降低能耗。为低功耗自动驾驶视觉系统提供新范式。

Abstract: Low energy consumption for 3D object detection is an important research area
because of the increasing energy consumption with their wide application in
fields such as autonomous driving. The spiking neural networks (SNNs) with
low-power consumption characteristics can provide a novel solution for this
research. Therefore, we apply SNNs to monocular 3D object detection and propose
the SpikeSMOKE architecture in this paper, which is a new attempt for low-power
monocular 3D object detection. As we all know, discrete signals of SNNs will
generate information loss and limit their feature expression ability compared
with the artificial neural networks (ANNs).In order to address this issue,
inspired by the filtering mechanism of biological neuronal synapses, we propose
a cross-scale gated coding mechanism(CSGC), which can enhance feature
representation by combining cross-scale fusion of attentional methods and gated
filtering mechanisms.In addition, to reduce the computation and increase the
speed of training, we present a novel light-weight residual block that can
maintain spiking computing paradigm and the highest possible detection
performance. Compared to the baseline SpikeSMOKE under the 3D Object Detection,
the proposed SpikeSMOKE with CSGC can achieve 11.78 (+2.82, Easy), 10.69 (+3.2,
Moderate), and 10.48 (+3.17, Hard) on the KITTI autonomous driving dataset by
AP|R11 at 0.7 IoU threshold, respectively. It is important to note that the
results of SpikeSMOKE can significantly reduce energy consumption compared to
the results on SMOKE. For example,the energy consumption can be reduced by
72.2% on the hard category, while the detection performance is reduced by only
4%. SpikeSMOKE-L (lightweight) can further reduce the amount of parameters by 3
times and computation by 10 times compared to SMOKE.

</details>


### [403] [AssetDropper: Asset Extraction via Diffusion Models with Reward-Driven Optimization](https://arxiv.org/abs/2506.07738)
*Lanjiong Li,Guanhua Zhao,Lingting Zhu,Zeyu Cai,Lequan Yu,Jian Zhang,Zeyu Wang*

Main category: cs.CV

TL;DR: 介绍了AssetDropper框架，用于从开放世界图像中提取高质量标准化资源资产，并通过奖励驱动优化实现了最先进的提取效果。


<details>
  <summary>Details</summary>
Motivation: 设计师需要标准化的资源库，而现有生成模型专注于直接视觉输出而非资源提取；开放世界场景含有丰富资源但提取困难。

Method: 1) 创建合成/真实数据集建立基准；2) 从参考图提取前景资源；3) 预训练奖励模型提供闭环反馈，通过逆向粘贴任务提升一致性。

Result: 在资源提取任务上达到SOTA；奖励机制有效提升提取精度并减少幻觉现象。

Conclusion: 首个从开放世界图像提取标准化资源框架；闭环反馈机制显著提升性能；提供基准数据集推动未来研究。

Abstract: Recent research on generative models has primarily focused on creating
product-ready visual outputs; however, designers often favor access to
standardized asset libraries, a domain that has yet to be significantly
enhanced by generative capabilities. Although open-world scenes provide ample
raw materials for designers, efficiently extracting high-quality, standardized
assets remains a challenge. To address this, we introduce AssetDropper, the
first framework designed to extract assets from reference images, providing
artists with an open-world asset palette. Our model adeptly extracts a front
view of selected subjects from input images, effectively handling complex
scenarios such as perspective distortion and subject occlusion. We establish a
synthetic dataset of more than 200,000 image-subject pairs and a real-world
benchmark with thousands more for evaluation, facilitating the exploration of
future research in downstream tasks. Furthermore, to ensure precise asset
extraction that aligns well with the image prompts, we employ a pre-trained
reward model to fulfill a closed-loop with feedback. We design the reward model
to perform an inverse task that pastes the extracted assets back into the
reference sources, which assists training with additional consistency and
mitigates hallucination. Extensive experiments show that, with the aid of
reward-driven optimization, AssetDropper achieves the state-of-the-art results
in asset extraction. Project page: AssetDropper.github.io.

</details>


### [404] [ArchiLense: A Framework for Quantitative Analysis of Architectural Styles Based on Vision Large Language Models](https://arxiv.org/abs/2506.07739)
*Jing Zhong,Jun Yin,Peilin Li,Pengyu Zeng,Miao Zhang,Shuai Lu,Ran Luo*

Main category: cs.CV

TL;DR: 本研究提出了ArchDiffBench数据集和ArchiLense框架，使用视觉语言模型和机器学习实现建筑风格的自动识别与描述，克服了传统方法的主观性和地域局限性。


<details>
  <summary>Details</summary>
Motivation: 传统建筑文化研究依赖主观专家解读和历史文献，存在地域偏见和解释局限，需要更客观的分析方法。

Method: 构建ArchDiffBench数据集（1,765张高质量建筑图像），开发基于视觉语言模型的ArchiLense框架，整合计算机视觉和深度学习算法进行自动风格识别与描述。

Result: ArchiLense在建筑风格识别上达到92.4%的专家标注一致率和84.5%分类准确率，有效捕捉跨文化风格差异。

Conclusion: 该框架为建筑文化比较研究提供了客观、准确的新视角，突破传统主观分析的限制。

Abstract: Architectural cultures across regions are characterized by stylistic
diversity, shaped by historical, social, and technological contexts in addition
to geograph-ical conditions. Understanding architectural styles requires the
ability to describe and analyze the stylistic features of different architects
from various regions through visual observations of architectural imagery.
However, traditional studies of architectural culture have largely relied on
subjective expert interpretations and historical literature reviews, often
suffering from regional biases and limited ex-planatory scope. To address these
challenges, this study proposes three core contributions: (1) We construct a
professional architectural style dataset named ArchDiffBench, which comprises
1,765 high-quality architectural images and their corresponding style
annotations, collected from different regions and historical periods. (2) We
propose ArchiLense, an analytical framework grounded in Vision-Language Models
and constructed using the ArchDiffBench dataset. By integrating ad-vanced
computer vision techniques, deep learning, and machine learning algo-rithms,
ArchiLense enables automatic recognition, comparison, and precise
classi-fication of architectural imagery, producing descriptive language
outputs that ar-ticulate stylistic differences. (3) Extensive evaluations show
that ArchiLense achieves strong performance in architectural style recognition,
with a 92.4% con-sistency rate with expert annotations and 84.5% classification
accuracy, effec-tively capturing stylistic distinctions across images. The
proposed approach transcends the subjectivity inherent in traditional analyses
and offers a more objective and accurate perspective for comparative studies of
architectural culture.

</details>


### [405] [Flow-Anything: Learning Real-World Optical Flow Estimation from Large-Scale Single-view Images](https://arxiv.org/abs/2506.07740)
*Yingping Liang,Ying Fu,Yutao Hu,Wenqi Shao,Jiaming Liu,Debing Zhang*

Main category: cs.CV

TL;DR: Flow-Anything 是一个大规模数据生成框架，旨在从真实世界的单视图图像学习光流估计，通过单张图片生成3D表示并渲染光流，解决了合成数据集的域差距问题，并创建了FA-Flow数据集，显著提升了光流估计性能。


<details>
  <summary>Details</summary>
Motivation: 真实世界光流估计的鲁棒性受限于使用动画合成数据集训练导致的域差距问题，阻碍了数据集规模扩展的效益。

Method: 1. 使用单目深度估计网络将单视图图像转换为3D表示，从而渲染光流和新视角图像；2. 开发了目标无关的体积渲染模块和深度感知修补模块处理动态物体。

Result: 首次证明从真实世界图像生成光流训练数据的优势，在合成数据集上超越了最先进的非监督和监督方法，且模型能作为基础模型提升下游视频任务性能。

Conclusion: Flow-Anything框架有效解决训练数据域差距问题，FA-Flow数据集证明了从真实世界图像缩放数据集的可行性，为光流估计和视频任务提供了新范式。

Abstract: Optical flow estimation is a crucial subfield of computer vision, serving as
a foundation for video tasks. However, the real-world robustness is limited by
animated synthetic datasets for training. This introduces domain gaps when
applied to real-world applications and limits the benefits of scaling up
datasets. To address these challenges, we propose \textbf{Flow-Anything}, a
large-scale data generation framework designed to learn optical flow estimation
from any single-view images in the real world. We employ two effective steps to
make data scaling-up promising. First, we convert a single-view image into a 3D
representation using advanced monocular depth estimation networks. This allows
us to render optical flow and novel view images under a virtual camera. Second,
we develop an Object-Independent Volume Rendering module and a Depth-Aware
Inpainting module to model the dynamic objects in the 3D representation. These
two steps allow us to generate realistic datasets for training from large-scale
single-view images, namely \textbf{FA-Flow Dataset}. For the first time, we
demonstrate the benefits of generating optical flow training data from
large-scale real-world images, outperforming the most advanced unsupervised
methods and supervised methods on synthetic datasets. Moreover, our models
serve as a foundation model and enhance the performance of various downstream
video tasks.

</details>


### [406] [Difference Inversion: Interpolate and Isolate the Difference with Token Consistency for Image Analogy Generation](https://arxiv.org/abs/2506.07750)
*Hyunsoo Kim,Donghyun Kim,Suhyun Kim*

Main category: cs.CV

TL;DR: 论文提出了一种名为“差异反演”的新方法，用于图像编辑任务，能够从一对原始图像（A和A'）中提取差异特征，并应用于另一图像B来生成编辑后的B'。该方法的关键在于构建适用于任何扩散模型的完整提示，而非依赖特定模型的指令提示，通过差值插值、标记一致性损失和标记嵌入零初始化等技术精准提取差异，实现了模型无关的高质量图像编辑。


<details>
  <summary>Details</summary>
Motivation: 现有图像编辑方法（如视觉上下文学习或视觉指令）通常局限于特定模型（如InstructPix2Pix），可能引入模型偏见或编辑能力有限。为了突破对特定扩散模型的依赖，需开发通用框架来提高编辑灵活性和效果。

Method: 1) Delta插值：从图像对A-A'中提取视觉差异；2) 标记一致性损失：训练中保持差异特征的语义一致性；3) 标记嵌入零初始化：优化文本编码过程。核心是构建包含原始图像B描述+差异描述的完整提示，输入通用扩散模型生成B'。

Result: 大量实验表明该方法在定量和定性评估上均超越基线模型，能生成更合理的图像B'并兼容多种扩散模型（如SDXL/Stable Diffusion）。

Conclusion: 所提出的差异反演技术成功解耦了编辑操作与特定模型架构的依赖，通过通用提示框架实现了模型无关的高精度图像编辑，为开放场景下的可控生成提供了新思路。

Abstract: How can we generate an image B' that satisfies A:A'::B:B', given the input
images A,A' and B? Recent works have tackled this challenge through approaches
like visual in-context learning or visual instruction. However, these methods
are typically limited to specific models (e.g. InstructPix2Pix. Inpainting
models) rather than general diffusion models (e.g. Stable Diffusion, SDXL).
This dependency may lead to inherited biases or lower editing capabilities. In
this paper, we propose Difference Inversion, a method that isolates only the
difference from A and A' and applies it to B to generate a plausible B'. To
address model dependency, it is crucial to structure prompts in the form of a
"Full Prompt" suitable for input to stable diffusion models, rather than using
an "Instruction Prompt". To this end, we accurately extract the Difference
between A and A' and combine it with the prompt of B, enabling a plug-and-play
application of the difference. To extract a precise difference, we first
identify it through 1) Delta Interpolation. Additionally, to ensure accurate
training, we propose the 2) Token Consistency Loss and 3) Zero Initialization
of Token Embeddings. Our extensive experiments demonstrate that Difference
Inversion outperforms existing baselines both quantitatively and qualitatively,
indicating its ability to generate more feasible B' in a model-agnostic manner.

</details>


### [407] [Trend-Aware Fashion Recommendation with Visual Segmentation and Semantic Similarity](https://arxiv.org/abs/2506.07773)
*Mohamed Djilani,Nassim Ali Ousalah,Nidhal Eddine Chenni*

Main category: cs.CV

TL;DR: 这篇论文提出了一种趋势感知且视觉基础化的时尚推荐系统，结合了深度视觉表示、衣物感知分割、语义类别相似性和用户行为模拟。通过提取服装区域的视觉嵌入，生成模拟用户购买历史，并融合视觉相似性、语义一致性和流行度对齐的加权评分函数进行推荐。在DeepFashion数据集上实验显示，ResNet-50模型取得了最佳性能（64.95%类别相似度），消融实验验证了各模块的有效性。


<details>
  <summary>Details</summary>
Motivation: 现有时尚推荐系统往往忽略服装实体特性、用户行为动态性和新兴趋势的整合。需要构建一个能同时解析视觉特征、模拟真实用户偏好变化并捕捉流行趋势的推荐框架，以平衡个性化风格与趋势需求。

Method: 1) 通过语义分割（DeepLabV3+）掩蔽非服装区域，采用预训练CNN（ResNet-50等）提取聚焦视觉嵌入；2) 基于用户特定趋势敏感度和物品流行度生成合成购买历史；3) 设计加权评分函数（视觉相似度+语义类别相似度+流行度对齐）生成推荐。

Result: 在DeepFashion数据集上：1) ResNet-50视觉骨干取得最优表现——64.95%类别相似度（优于基线8.2%）；2) 流行度预测MAE最低（0.13）；3) 消融实验证实视觉和流行度线索的互补性（去除任一组件导致召回率下降≥5.7%）。

Conclusion: 该方法通过融合视觉基础表示与合成行为建模，构建了可扩展的个性化时尚推荐框架，有效平衡个体风格与趋势响应。公开的代码实现促进了实际应用与后续研究。

Abstract: We introduce a trend-aware and visually-grounded fashion recommendation
system that integrates deep visual representations, garment-aware segmentation,
semantic category similarity and user behavior simulation. Our pipeline
extracts focused visual embeddings by masking non-garment regions via semantic
segmentation followed by feature extraction using pretrained CNN backbones
(ResNet-50, DenseNet-121, VGG16). To simulate realistic shopping behavior, we
generate synthetic purchase histories influenced by user-specific trendiness
and item popularity. Recommendations are computed using a weighted scoring
function that fuses visual similarity, semantic coherence and popularity
alignment. Experiments on the DeepFashion dataset demonstrate consistent gender
alignment and improved category relevance, with ResNet-50 achieving 64.95%
category similarity and lowest popularity MAE. An ablation study confirms the
complementary roles of visual and popularity cues. Our method provides a
scalable framework for personalized fashion recommendations that balances
individual style with emerging trends. Our implementation is available at
https://github.com/meddjilani/FashionRecommender

</details>


### [408] [Language-Vision Planner and Executor for Text-to-Visual Reasoning](https://arxiv.org/abs/2506.07778)
*Yichang Xu,Gaowen Liu,Ramana Rao Kompella,Sihao Hu,Tiansheng Huang,Fatih Ilhan,Selim Furkan Tekin,Zachary Yahn,Ling Liu*

Main category: cs.CV

TL;DR: 本文提出VLAgent系统，通过结合规划脚本与执行验证来改进多模态视觉-文本推理。系统利用上下文学习微调LLM生成步骤规划，并通过语法-语义解析器和集成方法优化执行。在多个基准测试上表现超越现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有视觉语言模型泛化性能不足。受大型语言模型在视觉推理中的进展启发，作者构建了能生成可执行分步计划并实时验证的AI系统，以提升多模态推理的准确性和鲁棒性。

Method: 1. 任务规划阶段：通过上下文学习微调LLM生成分步计划
2. 计划执行阶段：渐进优化神经符号执行模块
3. 三大创新设计：上下文学习改进计划质量；语法-语义解析器修正逻辑错误；集成方法提升执行泛化性

Result: 在GQA、MME、NLVR2、VQAv2四个基准测试中，VLAgent性能显著优于现有视觉语言模型（如ViperGPT、VisProg），特别是在减少逻辑错误和幻觉方面效果突出

Conclusion: 通过分步规划生成与执行验证的协同优化机制能有效提升多模态推理性能。核心创新点SS-Parser、Plan Repairer、Output Verifiers为未来可解释AI系统提供新范式

Abstract: The advancement in large language models (LLMs) and large vision models has
fueled the rapid progress in multi-modal visual-text reasoning capabilities.
However, existing vision-language models (VLMs) to date suffer from
generalization performance. Inspired by recent development in LLMs for visual
reasoning, this paper presents VLAgent, an AI system that can create a
step-by-step visual reasoning plan with an easy-to-understand script and
execute each step of the plan in real time by integrating planning script with
execution verifications via an automated process supported by VLAgent. In the
task planning phase, VLAgent fine-tunes an LLM through in-context learning to
generate a step-by-step planner for each user-submitted text-visual reasoning
task. During the plan execution phase, VLAgent progressively refines the
composition of neuro-symbolic executable modules to generate high-confidence
reasoning results. VLAgent has three unique design characteristics: First, we
improve the quality of plan generation through in-context learning, improving
logic reasoning by reducing erroneous logic steps, incorrect programs, and LLM
hallucinations. Second, we design a syntax-semantics parser to identify and
correct additional logic errors of the LLM-generated planning script prior to
launching the plan executor. Finally, we employ the ensemble method to improve
the generalization performance of our step-executor. Extensive experiments with
four visual reasoning benchmarks (GQA, MME, NLVR2, VQAv2) show that VLAgent
achieves significant performance enhancement for multimodal text-visual
reasoning applications, compared to the exiting representative VLMs and LLM
based visual composition approaches like ViperGPT and VisProg, thanks to the
novel optimization modules of VLAgent back-engine (SS-Parser, Plan Repairer,
Output Verifiers). Code and data will be made available upon paper acceptance.

</details>


### [409] [Design and Evaluation of Deep Learning-Based Dual-Spectrum Image Fusion Methods](https://arxiv.org/abs/2506.07779)
*Beining Xu,Junxian Li*

Main category: cs.CV

TL;DR: 该论文构建了一个高质量的双光谱数据集（VIS-NIR），并提出了一种融合下游任务性能的综合评估框架。通过实验发现，针对下游任务优化的融合模型在目标检测中表现更优，而传统指标评测存在局限性。


<details>
  <summary>Details</summary>
Motivation: 当前多模态图像融合方法缺乏标准化评估基准和下游任务验证，且公开数据集不足。为解决这些问题，作者旨在创建高质量数据集和综合评估框架。

Method: 1) 建立包含1369对可见光-红外图像的数据集（覆盖4种场景）；2) 提出融合速度、传统指标和目标检测性能（基于lang-segment-anything模型）的三维评估框架；3) 对主流算法进行跨数据集测试。

Result: 实验表明：为下游任务优化的融合模型在弱光/遮挡场景中检测更优；传统指标优秀的方法在下游任务中可能表现不佳，验证了新评估框架的必要性。

Conclusion: 贡献包括：1) 多元场景数据集；2) 任务感知的评估框架；3) 多数据集对比分析。证明下游任务应纳入融合模型评估，推动领域发展。

Abstract: Visible images offer rich texture details, while infrared images emphasize
salient targets. Fusing these complementary modalities enhances scene
understanding, particularly for advanced vision tasks under challenging
conditions. Recently, deep learning-based fusion methods have gained attention,
but current evaluations primarily rely on general-purpose metrics without
standardized benchmarks or downstream task performance. Additionally, the lack
of well-developed dual-spectrum datasets and fair algorithm comparisons hinders
progress.
  To address these gaps, we construct a high-quality dual-spectrum dataset
captured in campus environments, comprising 1,369 well-aligned visible-infrared
image pairs across four representative scenarios: daytime, nighttime, smoke
occlusion, and underpasses. We also propose a comprehensive and fair evaluation
framework that integrates fusion speed, general metrics, and object detection
performance using the lang-segment-anything model to ensure fairness in
downstream evaluation.
  Extensive experiments benchmark several state-of-the-art fusion algorithms
under this framework. Results demonstrate that fusion models optimized for
downstream tasks achieve superior performance in target detection, especially
in low-light and occluded scenes. Notably, some algorithms that perform well on
general metrics do not translate to strong downstream performance, highlighting
limitations of current evaluation practices and validating the necessity of our
proposed framework.
  The main contributions of this work are: (1)a campus-oriented dual-spectrum
dataset with diverse and challenging scenes; (2) a task-aware, comprehensive
evaluation framework; and (3) thorough comparative analysis of leading fusion
methods across multiple datasets, offering insights for future development.

</details>


### [410] [Re-ranking Reasoning Context with Tree Search Makes Large Vision-Language Models Stronger](https://arxiv.org/abs/2506.07785)
*Qi Yang,Chenghao Zhang,Lubin Fan,Kun Ding,Jieping Ye,Shiming Xiang*

Main category: cs.CV

TL;DR: 本论文提出了一种名为RCTS的多模态RAG框架，通过构建推理上下文丰富的知识库和树搜索重排方法，解决现有方法中知识推理样本稀缺和检索知识响应不稳定的问题。实验显示其在多个VQA数据集上达到SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 现有基于检索增强生成（RAG）的大视觉语言模型（LVLM）面临知识推理样本稀缺和检索结果响应不稳定的挑战，需要提升多模态RAG的可靠性。

Method: 1. 构建推理上下文丰富的知识库（通过自洽评估机制丰富推理模式）
2. 提出基于启发式奖励的蒙特卡洛树搜索重排方法（MCTS-HR）优先选择最相关样本

Result: 在多个VQA数据集上显著超越ICL和Vanilla-RAG方法，达到state-of-the-art性能

Conclusion: RCTS框架通过增强知识库的推理上下文和树搜索重排，有效提升LVLMs的响应质量和一致性，为多模态RAG提供了可靠解决方案

Abstract: Recent advancements in Large Vision Language Models (LVLMs) have
significantly improved performance in Visual Question Answering (VQA) tasks
through multimodal Retrieval-Augmented Generation (RAG). However, existing
methods still face challenges, such as the scarcity of knowledge with reasoning
examples and erratic responses from retrieved knowledge. To address these
issues, in this study, we propose a multimodal RAG framework, termed RCTS,
which enhances LVLMs by constructing a Reasoning Context-enriched knowledge
base and a Tree Search re-ranking method. Specifically, we introduce a
self-consistent evaluation mechanism to enrich the knowledge base with
intrinsic reasoning patterns. We further propose a Monte Carlo Tree Search with
Heuristic Rewards (MCTS-HR) to prioritize the most relevant examples. This
ensures that LVLMs can leverage high-quality contextual reasoning for better
and more consistent responses. Extensive experiments demonstrate that our
framework achieves state-of-the-art performance on multiple VQA datasets,
significantly outperforming In-Context Learning (ICL) and Vanilla-RAG methods.
It highlights the effectiveness of our knowledge base and re-ranking method in
improving LVLMs. Our code is available at https://github.com/yannqi/RCTS-RAG.

</details>


### [411] [Image Reconstruction as a Tool for Feature Analysis](https://arxiv.org/abs/2506.07803)
*Eduard Allakhverdov,Dmitrii Tarasov,Elizaveta Goncharova,Andrey Kuznetsov*

Main category: cs.CV

TL;DR: 提出了新的图像重建方法来可视化视觉特征表示，通过比较不同预训练目标的模型家族（如SigLIP和SigLIP2），发现图像任务训练的编码器保留更多信息；评估了多种视觉编码器的信息丰富度；发现正交旋转控制色彩编码的可解释性


<details>
  <summary>Details</summary>
Motivation: 由于视觉编码器在各类应用中广泛使用（从纯视觉模型到多模态系统），但其内部特征表示机制仍不明确，因此需要一种新的解释方法

Method: 采用图像重建技术分析特征空间：1) 比较相同架构但不同训练目标（图像任务vs对比学习）的模型家族 2) 评估多种视觉编码器的特征信息丰富度 3) 通过特征空间操作探究几何变换与色彩编码的关系

Result: 1) 基于图像任务预训练的编码器保留的原图像信息显著多于对比学习训练的编码器 2) 建立了视觉编码器的信息丰富度排名 3) 发现正交旋转（非空间变换）控制色彩编码，且特征操作可预测地改变重建图像

Conclusion: 该方法可泛用于任何视觉编码器，揭示了特征空间的内部结构（特别是几何属性和色彩编码的分离机制），为理解视觉表示提供了新工具

Abstract: Vision encoders are increasingly used in modern applications, from
vision-only models to multimodal systems such as vision-language models.
Despite their remarkable success, it remains unclear how these architectures
represent features internally. Here, we propose a novel approach for
interpreting vision features via image reconstruction. We compare two related
model families, SigLIP and SigLIP2, which differ only in their training
objective, and show that encoders pre-trained on image-based tasks retain
significantly more image information than those trained on non-image tasks such
as contrastive learning. We further apply our method to a range of vision
encoders, ranking them by the informativeness of their feature representations.
Finally, we demonstrate that manipulating the feature space yields predictable
changes in reconstructed images, revealing that orthogonal rotations (rather
than spatial transformations) control color encoding. Our approach can be
applied to any vision encoder, shedding light on the inner structure of its
feature space. The code and model weights to reproduce the experiments are
available in GitHub.

</details>


### [412] [Incorporating Uncertainty-Guided and Top-k Codebook Matching for Real-World Blind Image Super-Resolution](https://arxiv.org/abs/2506.07809)
*Weilei Wen,Tianyi Zhang,Qianqian Zhao,Zhaohui Zheng,Chunle Guo,Xiuli Shao,Chongyi Li*

Main category: cs.CV

TL;DR: 提出UGTSR框架解决代码本图像超分辨率中特征匹配不准和纹理重建差的问题，引入不确定性学习、Top-k特征匹配和Align-Attention模块，实验显示纹理真实性和重建保真度显著提升。


<details>
  <summary>Details</summary>
Motivation: 现有代码本超分辨率方法存在特征匹配不准确和纹理细节重建质量差的问题

Method: 不确定性引导机制聚焦纹理丰富区域；Top-k特征匹配融合多候选特征提升准确性；Align-Attention模块增强LR与HR特征对齐

Result: 在纹理真实性和重建保真度方面显著超越现有方法

Conclusion: UGTSR框架通过三项改进有效解决了现有方法的两个关键缺陷，推进了真实图像超分辨率性能

Abstract: Recent advancements in codebook-based real image super-resolution (SR) have
shown promising results in real-world applications. The core idea involves
matching high-quality image features from a codebook based on low-resolution
(LR) image features. However, existing methods face two major challenges:
inaccurate feature matching with the codebook and poor texture detail
reconstruction. To address these issues, we propose a novel Uncertainty-Guided
and Top-k Codebook Matching SR (UGTSR) framework, which incorporates three key
components: (1) an uncertainty learning mechanism that guides the model to
focus on texture-rich regions, (2) a Top-k feature matching strategy that
enhances feature matching accuracy by fusing multiple candidate features, and
(3) an Align-Attention module that enhances the alignment of information
between LR and HR features. Experimental results demonstrate significant
improvements in texture realism and reconstruction fidelity compared to
existing methods. We will release the code upon formal publication.

</details>


### [413] [Looking Beyond Visible Cues: Implicit Video Question Answering via Dual-Clue Reasoning](https://arxiv.org/abs/2506.07811)
*Tieyuan Chen,Huabin Liu,Yi Wang,Chaofan Gan,Mingxi Lyu,Gui Zou,Weiyao Lin*

Main category: cs.CV

TL;DR: 该论文提出隐式视频问答(I-VQA)新任务，解决现有VideoQA在缺乏显式视觉证据时性能下降的问题，并设计IRM推理框架，整合动作与意图双流建模，实验显示其在I-VQA及相关任务上超越现有模型。


<details>
  <summary>Details</summary>
Motivation: 现有VideoQA依赖显式视觉片段，但在涉及符号意义或深层意图的问题中缺乏直接证据，导致性能显著下降。需要构建能利用上下文视觉线索解决此类隐式问题的框架。

Method: 提出IRM框架：1) AIM模块通过生成线索候选和关系推演获取动作-意图双线索；2) VEM模块利用关键上下文线索增强视觉表征。

Result: 在I-VQA任务中超越GPT-4o(0.76%)、OpenAI-o3(1.37%)和VideoChat2(4.87%)，并在广告理解和交通预测等隐式任务上达到SOTA。

Conclusion: I-VQA任务填补了隐式推理的空白，IRM框架通过双流建模有效捕捉上下文线索，为复杂视频理解提供新方向。

Abstract: Video Question Answering (VideoQA) aims to answer natural language questions
based on the given video, with prior work primarily focusing on identifying the
duration of relevant segments, referred to as explicit visual evidence.
However, explicit visual evidence is not always directly available,
particularly when questions target symbolic meanings or deeper intentions,
leading to significant performance degradation. To fill this gap, we introduce
a novel task and dataset, $\textbf{I}$mplicit $\textbf{V}$ideo
$\textbf{Q}$uestion $\textbf{A}$nswering (I-VQA), which focuses on answering
questions in scenarios where explicit visual evidence is inaccessible. Given an
implicit question and its corresponding video, I-VQA requires answering based
on the contextual visual cues present within the video. To tackle I-VQA, we
propose a novel reasoning framework, IRM (Implicit Reasoning Model),
incorporating dual-stream modeling of contextual actions and intent clues as
implicit reasoning chains. IRM comprises the Action-Intent Module (AIM) and the
Visual Enhancement Module (VEM). AIM deduces and preserves question-related
dual clues by generating clue candidates and performing relation deduction. VEM
enhances contextual visual representation by leveraging key contextual clues.
Extensive experiments validate the effectiveness of our IRM in I-VQA tasks,
outperforming GPT-4o, OpenAI-o3, and fine-tuned VideoChat2 by $0.76\%$,
$1.37\%$, and $4.87\%$, respectively. Additionally, IRM performs SOTA on
similar implicit advertisement understanding and future prediction in
traffic-VQA. Datasets and codes are available for double-blind review in
anonymous repo: https://github.com/tychen-SJTU/Implicit-VideoQA.

</details>


### [414] [Self-Cascaded Diffusion Models for Arbitrary-Scale Image Super-Resolution](https://arxiv.org/abs/2506.07813)
*Junseo Bang,Joonhee Lee,Kyeonghyun Lee,Haechang Lee,Dong Un Kang,Se Young Chun*

Main category: cs.CV

TL;DR: 提出了 CasArbi，一种新型自级联扩散框架，用于任意尺度超分辨率任务。它通过将缩放任务拆解为多级连续放大并协调残差扩散来实现任意尺度下的高感知质量重建。


<details>
  <summary>Details</summary>
Motivation: 传统单级任意缩放模型难以适应连续变化的尺度分布，现有扩散模型在逐步上采样机制中的集成研究不足。

Method: 提出自级联扩散框架（CasArbi），分解缩放因子为多级小因子，采用坐标引导残差扩散模型逐步增强分辨率。

Result: 在多个任意尺度超分辨率基准测试中超越现有方法，在感知质量和失真指标上均得到提升。

Conclusion: CasArbi验证了级联扩散机制在连续尺度超分辨率任务中的有效性，为生成式任意缩放提供了新思路。

Abstract: Arbitrary-scale image super-resolution aims to upsample images to any desired
resolution, offering greater flexibility than traditional fixed-scale
super-resolution. Recent approaches in this domain utilize regression-based or
generative models, but many of them are a single-stage upsampling process,
which may be challenging to learn across a wide, continuous distribution of
scaling factors. Progressive upsampling strategies have shown promise in
mitigating this issue, yet their integration with diffusion models for flexible
upscaling remains underexplored. Here, we present CasArbi, a novel
self-cascaded diffusion framework for arbitrary-scale image super-resolution.
CasArbi meets the varying scaling demands by breaking them down into smaller
sequential factors and progressively enhancing the image resolution at each
step with seamless transitions for arbitrary scales. Our novel
coordinate-guided residual diffusion model allows for the learning of
continuous image representations while enabling efficient diffusion sampling.
Extensive experiments demonstrate that our CasArbi outperforms prior arts in
both perceptual and distortion performance metrics across diverse
arbitrary-scale super-resolution benchmarks.

</details>


### [415] [M2Restore: Mixture-of-Experts-based Mamba-CNN Fusion Framework for All-in-One Image Restoration](https://arxiv.org/abs/2506.07814)
*Yongzhen Wang,Yongjun Li,Zhuoran Zheng,Xiao-Ping Zhang,Mingqiang Wei*

Main category: cs.CV

TL;DR: M2Restore提出了一种基于Mixture-of-Experts (MoE)和Mamba-CNN融合的框架，用于高效、鲁棒的全能图像恢复。它通过CLIP引导的MoE门控机制增强对不同退化的泛化能力，采用双流架构结合全局和局部建模，并引入边缘感知动态门控实现自适应计算分配。实验证明其在视觉质量和量化指标上均优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 自然图像常受复合退化（如雨、雪、雾）影响，现有方法在动态退化场景泛化性和局部细节与全局依赖的平衡方面存在局限。

Method: 1. CLIP引导的MoE门控机制融合任务条件提示与CLIP语义先验，实现跨模态特征校准；2. Mamba与CNN双流架构协同捕捉全局依赖与局部细节；3. 边缘感知动态门控机制自适应分配计算资源。

Result: 在多图像恢复基准测试中取得视觉质量和量化指标的优越性能。

Conclusion: M2Restore通过创新性地融合MoE门控、双流架构与动态计算分配，有效解决了图像恢复中的泛化性挑战与全局-局部平衡问题，为全能图像恢复提供了高效解决方案。

Abstract: Natural images are often degraded by complex, composite degradations such as
rain, snow, and haze, which adversely impact downstream vision applications.
While existing image restoration efforts have achieved notable success, they
are still hindered by two critical challenges: limited generalization across
dynamically varying degradation scenarios and a suboptimal balance between
preserving local details and modeling global dependencies. To overcome these
challenges, we propose M2Restore, a novel Mixture-of-Experts (MoE)-based
Mamba-CNN fusion framework for efficient and robust all-in-one image
restoration. M2Restore introduces three key contributions: First, to boost the
model's generalization across diverse degradation conditions, we exploit a
CLIP-guided MoE gating mechanism that fuses task-conditioned prompts with
CLIP-derived semantic priors. This mechanism is further refined via cross-modal
feature calibration, which enables precise expert selection for various
degradation types. Second, to jointly capture global contextual dependencies
and fine-grained local details, we design a dual-stream architecture that
integrates the localized representational strength of CNNs with the long-range
modeling efficiency of Mamba. This integration enables collaborative
optimization of global semantic relationships and local structural fidelity,
preserving global coherence while enhancing detail restoration. Third, we
introduce an edge-aware dynamic gating mechanism that adaptively balances
global modeling and local enhancement by reallocating computational attention
to degradation-sensitive regions. This targeted focus leads to more efficient
and precise restoration. Extensive experiments across multiple image
restoration benchmarks validate the superiority of M2Restore in both visual
quality and quantitative performance.

</details>


### [416] [R3D2: Realistic 3D Asset Insertion via Diffusion for Autonomous Driving Simulation](https://arxiv.org/abs/2506.07826)
*William Ljungbergh,Bernardo Taveira,Wenzhao Zheng,Adam Tonderski,Chensheng Peng,Fredrik Kahl,Christoffer Petersson,Michael Felsberg,Kurt Keutzer,Masayoshi Tomizuka,Wei Zhan*

Main category: cs.CV

TL;DR: R3D2：一个轻量级一步扩散模型，用于在神经渲染场景中逼真插入3D资产，解决动态对象操纵难题，提升自动驾驶验证的真实性和可扩展性


<details>
  <summary>Details</summary>
Motivation: 传统仿真平台可扩展性差且存在领域差异，神经重建方法（如3DGS）难以实现动态对象操作和复用。需要突破性技术实现真实场景中3D资产的无缝集成

Method: 构建新型数据集：首先利用图像条件化3D生成模型从真实驾驶数据创建3DGS资产，再将其合成到神经渲染虚拟环境中。基于此训练R3D2扩散模型实时生成阴影/光照等渲染效果

Result: 定量定性评估表明：1) 显著提升插入资产真实感 2) 支持文本到3D插入等新用例 3) 实现跨场景对象迁移，验证了自动驾驶验证系统的真实可扩展性

Conclusion: R3D2突破了现有方法在动态对象渲染的局限性，通过释放数据集和代码推动自动驾驶仿真研究，解决了自动驾驶验证面临的关键可扩展性问题

Abstract: Validating autonomous driving (AD) systems requires diverse and
safety-critical testing, making photorealistic virtual environments essential.
Traditional simulation platforms, while controllable, are resource-intensive to
scale and often suffer from a domain gap with real-world data. In contrast,
neural reconstruction methods like 3D Gaussian Splatting (3DGS) offer a
scalable solution for creating photorealistic digital twins of real-world
driving scenes. However, they struggle with dynamic object manipulation and
reusability as their per-scene optimization-based methodology tends to result
in incomplete object models with integrated illumination effects. This paper
introduces R3D2, a lightweight, one-step diffusion model designed to overcome
these limitations and enable realistic insertion of complete 3D assets into
existing scenes by generating plausible rendering effects-such as shadows and
consistent lighting-in real time. This is achieved by training R3D2 on a novel
dataset: 3DGS object assets are generated from in-the-wild AD data using an
image-conditioned 3D generative model, and then synthetically placed into
neural rendering-based virtual environments, allowing R3D2 to learn realistic
integration. Quantitative and qualitative evaluations demonstrate that R3D2
significantly enhances the realism of inserted assets, enabling use-cases like
text-to-3D asset insertion and cross-scene/dataset object transfer, allowing
for true scalability in AD validation. To promote further research in scalable
and realistic AD simulation, we will release our dataset and code, see
https://research.zenseact.com/publications/R3D2/.

</details>


### [417] [Diffusion models under low-noise regime](https://arxiv.org/abs/2506.07841)
*Elizabeth Pavlova,Xue-Xin Wei*

Main category: cs.CV

TL;DR: 该论文探讨了扩散模型在低噪声条件下的行为，揭示了大噪声输出收敛时，不同训练数据训练的模型在数据流形附近输出会发散的现象，并分析了训练集大小、数据几何和模型目标如何影响去噪轨迹和得分准确性。


<details>
  <summary>Details</summary>
Motivation: 现有研究表明扩散模型在记忆训练数据和生成新样本两种模式中切换，但这些结论仅在高噪声环境下得到验证。该论文旨在探索在小扰动常见的实际应用中，扩散模型在低噪声环境下的行为差异，以解决实际应用中的模型可靠性问题。

Method: 引入两个验证框架：(1)使用不同样本量的CelebA子集，(2)高斯混合模型分析基准。通过模型去噪轨迹的差异分析进行量化研究，重点关注训练集规模、数据几何结构及模型目标函数对输出结果的影响。

Result: 实验发现：在训练数据不重叠的情况下，尽管高噪声区域模型输出收敛，但在接近数据流形的低噪声区域输出出现显著分歧。研究量化了训练集大小与得分准确性的关系，揭示了数据几何结构如何主导模型学习数据分布表示的过程。

Conclusion: 该研究填补了对扩散模型在低噪声条件下行为的理解空白，证明模型在数据流形附近的敏感性与记忆-泛化二分行为存在根本差异。结论强调了在现实应用场景中（如小扰动鲁棒性需求），模型行为理解的必要性，为生成模型可靠性提供新见解。

Abstract: Recent work on diffusion models proposed that they operate in two regimes:
memorization, in which models reproduce their training data, and
generalization, in which they generate novel samples. While this has been
tested in high-noise settings, the behavior of diffusion models as effective
denoisers when the corruption level is small remains unclear. To address this
gap, we systematically investigated the behavior of diffusion models under
low-noise diffusion dynamics, with implications for model robustness and
interpretability. Using (i) CelebA subsets of varying sample sizes and (ii)
analytic Gaussian mixture benchmarks, we reveal that models trained on disjoint
data diverge near the data manifold even when their high-noise outputs
converge. We quantify how training set size, data geometry, and model objective
choice shape denoising trajectories and affect score accuracy, providing
insights into how these models actually learn representations of data
distributions. This work starts to address gaps in our understanding of
generative model reliability in practical applications where small
perturbations are common.

</details>


### [418] [F2Net: A Frequency-Fused Network for Ultra-High Resolution Remote Sensing Segmentation](https://arxiv.org/abs/2506.07847)
*Hengzhi Chen,Liqian Feng,Wenhua Wu,Xiaogang Zhu,Shawn Leo,Kun Hu*

Main category: cs.CV

TL;DR: 提出F2Net框架，通过频域分解处理超高分辨率遥感图像，结合高频细节和低频全局信息，并设计损失函数解决训练不稳定性问题，在两个基准上达到SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 现有语义分割方法处理超高分辨率遥感图像时存在细节丢失或上下文割裂问题，多分支网络则面临计算低效和梯度动态冲突。需要一种方法在保留细节和全局上下文的同时提升训练效率。

Method: F2Net：1) 将图像分解为高频/低频分量：高频分支保持全分辨率细节，低频分支降采样后分两条子支路处理短/长程依赖；2) 混合频率融合模块；3) 提出跨频率对齐损失（语义一致性）和平衡损失（梯度调节）。

Result: DeepGlobe数据集mIoU 80.22，Inria Aerial数据集mIoU 83.39，均达到当前最佳水平。

Conclusion: 频域分解结合专门设计的融合模块和损失函数，在保持细节与全局信息的同时解决了多分支训练冲突问题，为超高分辨率遥感分割提供了高效方案。

Abstract: Semantic segmentation of ultra-high-resolution (UHR) remote sensing imagery
is critical for applications like environmental monitoring and urban planning
but faces computational and optimization challenges. Conventional methods
either lose fine details through downsampling or fragment global context via
patch processing. While multi-branch networks address this trade-off, they
suffer from computational inefficiency and conflicting gradient dynamics during
training. We propose F2Net, a frequency-aware framework that decomposes UHR
images into high- and low-frequency components for specialized processing. The
high-frequency branch preserves full-resolution structural details, while the
low-frequency branch processes downsampled inputs through dual sub-branches
capturing short- and long-range dependencies. A Hybrid-Frequency Fusion module
integrates these observations, guided by two novel objectives: Cross-Frequency
Alignment Loss ensures semantic consistency between frequency components, and
Cross-Frequency Balance Loss regulates gradient magnitudes across branches to
stabilize training. Evaluated on DeepGlobe and Inria Aerial benchmarks, F2Net
achieves state-of-the-art performance with mIoU of 80.22 and 83.39,
respectively. Our code will be publicly available.

</details>


### [419] [PolyVivid: Vivid Multi-Subject Video Generation with Cross-Modal Interaction and Enhancement](https://arxiv.org/abs/2506.07848)
*Teng Hu,Zhentao Yu,Zhengguang Zhou,Jiangning Zhang,Yuan Zhou,Qinglin Lu,Ran Yi*

Main category: cs.CV

TL;DR: 提出了PolyVivid框架，解决多主体视频定制中的身份一致性和交互问题。通过文本-图像融合、3D-RoPE增强和注意力继承注入三大模块，结合MLLM数据管道，在身份保真度、视频真实感和主体对齐方面超越现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有视频生成模型在多主体定制时缺乏细粒度控制能力，尤其在保持身份一致性和主体交互方面存在不足。

Method: 1) VLLM文本-图像融合模块：将视觉身份嵌入文本空间实现精确对齐；2）3D-RoPE增强模块：通过结构化双向融合提升身份保持和主体交互；3）注意力继承身份注入模块：防止身份漂移；4）MLLM数据管道：包含定位/分割/主体整合。

Result: 大量实验证明在身份保真度、视频真实性和主体对齐方面超越开源及商业基线。

Conclusion: PolyVivid为多主体视频定制提供了高效解决方案，通过多模态融合和结构化增强实现身份一致性生成。

Abstract: Despite recent advances in video generation, existing models still lack
fine-grained controllability, especially for multi-subject customization with
consistent identity and interaction. In this paper, we propose PolyVivid, a
multi-subject video customization framework that enables flexible and
identity-consistent generation. To establish accurate correspondences between
subject images and textual entities, we design a VLLM-based text-image fusion
module that embeds visual identities into the textual space for precise
grounding. To further enhance identity preservation and subject interaction, we
propose a 3D-RoPE-based enhancement module that enables structured
bidirectional fusion between text and image embeddings. Moreover, we develop an
attention-inherited identity injection module to effectively inject fused
identity features into the video generation process, mitigating identity drift.
Finally, we construct an MLLM-based data pipeline that combines MLLM-based
grounding, segmentation, and a clique-based subject consolidation strategy to
produce high-quality multi-subject data, effectively enhancing subject
distinction and reducing ambiguity in downstream video generation. Extensive
experiments demonstrate that PolyVivid achieves superior performance in
identity fidelity, video realism, and subject alignment, outperforming existing
open-source and commercial baselines.

</details>


### [420] [SAM2Auto: Auto Annotation Using FLASH](https://arxiv.org/abs/2506.07850)
*Arash Rocky,Q. M. Jonathan Wu*

Main category: cs.CV

TL;DR: SAM2Auto是一种全自动视频数据集注释框架，不需要人工干预或数据集特定训练，旨在解决视觉语言模型中注释数据稀缺的问题。它包含对象检测系统(SMART-OD)和实例分割跟踪模块(FLASH)，通过统计方法减少错误和保持连续追踪，实验证明其效果接近人工注释但大幅节省时间和成本。


<details>
  <summary>Details</summary>
Motivation: 视觉语言模型(VLM)发展受限的主要原因在于制作配对的视觉-文本注释数据集耗时耗力且成本高昂。为了解决这个核心瓶颈问题，研究者提出了首个完全自动化的视频标注流程——SAM2Auto。

Method: 1. SMART-OD：结合自动掩码生成和开放世界对象检测能力的鲁棒对象检测系统，避免现有方法需要逐帧调整参数和高误报率的问题
2. FLASH：多对象实时视频实例分割模块，在连续帧间保持稳定的目标识别，能够有效应对间歇性目标丢失的情况
采用统计方法保证跨视频序列持续跟踪的稳定性

Result: 在大量实验验证中，SAM2Auto在保持与人工注释相当精度的同时，显著减少标注时间，完全消除人工成本。系统能不依赖重训练或复杂参数调整处理多样数据集，为大规模数据集构建提供实用解决方案。

Conclusion: 该工作为自动化视频标注建立了新的基准，通过解决数据集瓶颈问题为视觉语言理解领域的进步提供加速路径

Abstract: Vision-Language Models (VLMs) lag behind Large Language Models due to the
scarcity of annotated datasets, as creating paired visual-textual annotations
is labor-intensive and expensive. To address this bottleneck, we introduce
SAM2Auto, the first fully automated annotation pipeline for video datasets
requiring no human intervention or dataset-specific training. Our approach
consists of two key components: SMART-OD, a robust object detection system that
combines automatic mask generation with open-world object detection
capabilities, and FLASH (Frame-Level Annotation and Segmentation Handler), a
multi-object real-time video instance segmentation (VIS) that maintains
consistent object identification across video frames even with intermittent
detection gaps. Unlike existing open-world detection methods that require
frame-specific hyperparameter tuning and suffer from numerous false positives,
our system employs statistical approaches to minimize detection errors while
ensuring consistent object tracking throughout entire video sequences.
Extensive experimental validation demonstrates that SAM2Auto achieves
comparable accuracy to manual annotation while dramatically reducing annotation
time and eliminating labor costs. The system successfully handles diverse
datasets without requiring retraining or extensive parameter adjustments,
making it a practical solution for large-scale dataset creation. Our work
establishes a new baseline for automated video annotation and provides a
pathway for accelerating VLM development by addressing the fundamental dataset
bottleneck that has constrained progress in vision-language understanding.

</details>


### [421] [LogoSP: Local-global Grouping of Superpoints for Unsupervised Semantic Segmentation of 3D Point Clouds](https://arxiv.org/abs/2506.07857)
*Zihui Zhang,Weisheng Dai,Hongtao Wen,Bo Yang*

Main category: cs.CV

TL;DR: 该论文提出了一种名为LogoSP的无监督3D点云语义分割方法，该方法通过结合局部和全局特征（尤其在频域中分析全局模式）生成高质量伪标签，显著超越现有方法，并在室内外数据集上实现了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 现有无监督3D分割方法仅依赖局部特征进行分组，缺乏挖掘更丰富语义先验的能力。LogoSP旨在同时利用局部和全局特征（特别是频域中的全局模式）来发现更具判别性的3D语义信息。

Method: LogoSP方法核心：通过对超点(superpoints)在频域中的全局模式进行分组，生成高精度的语义伪标签用于训练分割网络。具体包含两个阶段：1) 基于局部特征和频域全局特征联合学习；2) 利用发现的全局模式生成伪标签进行网络训练。

Result: 在室内外三个数据集上的实验表明，LogoSP大幅超越所有现有无监督方法（如SOTA提升显著）。定量分析证实其伪标签准确性高，且可视化显示学习到的全局模式确实对应有意义的3D语义（如物体整体结构）。

Conclusion: LogoSP证明了频域全局模式对无监督3D语义发现的有效性，为不依赖人工标注的3D理解提供了新思路。该方法实现了当前无监督3D分割的最优性能，且所学全局特征具有可解释性。

Abstract: We study the problem of unsupervised 3D semantic segmentation on raw point
clouds without needing human labels in training. Existing methods usually
formulate this problem into learning per-point local features followed by a
simple grouping strategy, lacking the ability to discover additional and
possibly richer semantic priors beyond local features. In this paper, we
introduce LogoSP to learn 3D semantics from both local and global point
features. The key to our approach is to discover 3D semantic information by
grouping superpoints according to their global patterns in the frequency
domain, thus generating highly accurate semantic pseudo-labels for training a
segmentation network. Extensive experiments on two indoor and an outdoor
datasets show that our LogoSP surpasses all existing unsupervised methods by
large margins, achieving the state-of-the-art performance for unsupervised 3D
semantic segmentation. Notably, our investigation into the learned global
patterns reveals that they truly represent meaningful 3D semantics in the
absence of human labels during training.

</details>


### [422] [Egocentric Event-Based Vision for Ping Pong Ball Trajectory Prediction](https://arxiv.org/abs/2506.07860)
*Ivan Alberico,Marco Cannici,Giovanni Cioffi,Davide Scaramuzza*

Main category: cs.CV

TL;DR: 提出了一种用于乒乓球实时自我中心轨迹预测的事件相机系统，具有低延迟和抗运动模糊的特性，利用人眼凝视数据实现焦点视觉处理，显著降低计算延迟并提高检测性能。


<details>
  <summary>Details</summary>
Motivation: 标准相机在高速度乒乓球运动中存在延迟和运动模糊问题，事件相机能提供更高的时间分辨率，从而更准确地进行轨迹预测。

Method: 通过Meta Project Aria眼镜收集传感器数据和事件流，结合眼球追踪实现焦点视觉处理；使用短时间窗口事件数据进行球体检测，并构建轨迹预测模型。

Result: 系统最坏情况总延迟为4.5毫秒（比30帧/秒的传统系统快14倍以上）；通过在焦点区域处理事件，计算量减少10.81倍。

Conclusion: 这是首个使用事件相机从自我中心视角预测乒乓球轨迹的方法，成功实现了高精度、低延迟的3D轨迹预测。

Abstract: In this paper, we present a real-time egocentric trajectory prediction system
for table tennis using event cameras. Unlike standard cameras, which suffer
from high latency and motion blur at fast ball speeds, event cameras provide
higher temporal resolution, allowing more frequent state updates, greater
robustness to outliers, and accurate trajectory predictions using just a short
time window after the opponent's impact. We collect a dataset of ping-pong game
sequences, including 3D ground-truth trajectories of the ball, synchronized
with sensor data from the Meta Project Aria glasses and event streams. Our
system leverages foveated vision, using eye-gaze data from the glasses to
process only events in the viewer's fovea. This biologically inspired approach
improves ball detection performance and significantly reduces computational
latency, as it efficiently allocates resources to the most perceptually
relevant regions, achieving a reduction factor of 10.81 on the collected
trajectories. Our detection pipeline has a worst-case total latency of 4.5 ms,
including computation and perception - significantly lower than a frame-based
30 FPS system, which, in the worst case, takes 66 ms solely for perception.
Finally, we fit a trajectory prediction model to the estimated states of the
ball, enabling 3D trajectory forecasting in the future. To the best of our
knowledge, this is the first approach to predict table tennis trajectories from
an egocentric perspective using event cameras.

</details>


### [423] [VIVAT: Virtuous Improving VAE Training through Artifact Mitigation](https://arxiv.org/abs/2506.07863)
*Lev Novitskiy,Viacheslav Vasilev,Maria Kovaleva,Vladimir Arkhipkin,Denis Dimitrov*

Main category: cs.CV

TL;DR: VIVAT是一种改进KL-VAE训练的方法，它通过简单修改（如调整损失权重、填充策略和集成空间条件归一化）来减少常见伪影（如色彩偏移、网格图案、模糊、角落和液滴伪影），从而提升重建和生成质量。


<details>
  <summary>Details</summary>
Motivation: 传统的变分自编码器（VAE）在训练中常出现伪影问题，影响重建和生成图像的质量。这些伪影包括色彩偏移、网格图案等五种类型，VIVAT旨在系统地缓解这些问题，而不需要对架构进行重大改动。

Method: 提出了VIVAT方法，包括：（1）分析五种常见伪影的根本原因；（2）对KL-VAE进行简单修改，如损失权重调整、填充策略优化和集成Spatially Conditional Normalization（空间条件归一化）。

Result: 在多个基准测试中，VIVAT在图像重建指标（PSNR和SSIM）上达到当前最优结果，且文本到图像生成的CLIP分数更高。

Conclusion: VIVAT以简洁的方式解决了KL-VAE训练中的实际挑战，为优化VAE训练提供了有效工具，同时保持了原框架的简单性。

Abstract: Variational Autoencoders (VAEs) remain a cornerstone of generative computer
vision, yet their training is often plagued by artifacts that degrade
reconstruction and generation quality. This paper introduces VIVAT, a
systematic approach to mitigating common artifacts in KL-VAE training without
requiring radical architectural changes. We present a detailed taxonomy of five
prevalent artifacts - color shift, grid patterns, blur, corner and droplet
artifacts - and analyze their root causes. Through straightforward
modifications, including adjustments to loss weights, padding strategies, and
the integration of Spatially Conditional Normalization, we demonstrate
significant improvements in VAE performance. Our method achieves
state-of-the-art results in image reconstruction metrics (PSNR and SSIM) across
multiple benchmarks and enhances text-to-image generation quality, as evidenced
by superior CLIP scores. By preserving the simplicity of the KL-VAE framework
while addressing its practical challenges, VIVAT offers actionable insights for
researchers and practitioners aiming to optimize VAE training.

</details>


### [424] [FreeGave: 3D Physics Learning from Dynamic Videos by Gaussian Velocity](https://arxiv.org/abs/2506.07865)
*Jinxi Li,Ziyang Song,Siyuan Zhou,Bo Yang*

Main category: cs.CV

TL;DR: 本文提出FreeGave方法，仅从多视角视频无监督学习3D场景的几何、外观和物理特性，无需物体先验知识，通过物理编码和散度无模块实现高效动力学建模。


<details>
  <summary>Details</summary>
Motivation: 现有方法要么无法学习边界复杂物理运动，要么需要掩码/物体类型等先验知识，因此需开发无需先验即可建模复杂3D场景物理的方法。

Method: 引入物理编码配合散度无模块，估计每个高斯点的无散速度场，避免低效的物理信息神经网络损失。

Result: 在三个公开数据集和新收集的真实数据集上实现优异的未来帧外推和运动分割性能，物理编码被证实可无监督学习有意义的3D物理运动模式。

Conclusion: FreeGave首次实现无需物体先验的复杂动态3D场景物理建模，物理编码机制为核心创新点。

Abstract: In this paper, we aim to model 3D scene geometry, appearance, and the
underlying physics purely from multi-view videos. By applying various governing
PDEs as PINN losses or incorporating physics simulation into neural networks,
existing works often fail to learn complex physical motions at boundaries or
require object priors such as masks or types. In this paper, we propose
FreeGave to learn the physics of complex dynamic 3D scenes without needing any
object priors. The key to our approach is to introduce a physics code followed
by a carefully designed divergence-free module for estimating a per-Gaussian
velocity field, without relying on the inefficient PINN losses. Extensive
experiments on three public datasets and a newly collected challenging
real-world dataset demonstrate the superior performance of our method for
future frame extrapolation and motion segmentation. Most notably, our
investigation into the learned physics codes reveals that they truly learn
meaningful 3D physical motion patterns in the absence of any human labels in
training.

</details>


### [425] [Spatio-Temporal State Space Model For Efficient Event-Based Optical Flow](https://arxiv.org/abs/2506.07878)
*Muhammad Ahmed Humais,Xiaoqian Huang,Hussain Sajwani,Sajid Javed,Yahya Zweiri*

Main category: cs.CV

TL;DR: 提出了一种基于状态空间模型（STSSM）的新方法，利用事件相机数据实现高效的光流估计。该方法在计算效率和性能上优于现有ViT、CNN等方法，推理速度提升4.5倍，计算量减少8倍。


<details>
  <summary>Details</summary>
Motivation: 现有基于深度学习的光流估计算法（如CNN、RNN、ViT）计算效率低，而异步事件处理方法（如SNN、GNN）虽高效但时空信息捕捉不足。需要兼顾效率和性能的新方案。

Method: 引入时空状态空间模型（STSSM）模块及新型网络架构。STSSM利用状态空间模型有效捕捉事件数据的时空相关性，比ViT和CNN架构更高效。

Result: 在DSEC基准测试中获得竞争性性能：推理速度比TMA快4.5倍，计算量比TMA低8倍，比EV-FlowNet低2倍。

Conclusion: STSSM方法在保持竞争性性能的同时显著提升计算效率，为实时应用提供了可行的光流估计解决方案。

Abstract: Event cameras unlock new frontiers that were previously unthinkable with
standard frame-based cameras. One notable example is low-latency motion
estimation (optical flow), which is critical for many real-time applications.
In such applications, the computational efficiency of algorithms is paramount.
Although recent deep learning paradigms such as CNN, RNN, or ViT have shown
remarkable performance, they often lack the desired computational efficiency.
Conversely, asynchronous event-based methods including SNNs and GNNs are
computationally efficient; however, these approaches fail to capture sufficient
spatio-temporal information, a powerful feature required to achieve better
performance for optical flow estimation. In this work, we introduce
Spatio-Temporal State Space Model (STSSM) module along with a novel network
architecture to develop an extremely efficient solution with competitive
performance. Our STSSM module leverages state-space models to effectively
capture spatio-temporal correlations in event data, offering higher performance
with lower complexity compared to ViT, CNN-based architectures in similar
settings. Our model achieves 4.5x faster inference and 8x lower computations
compared to TMA and 2x lower computations compared to EV-FlowNet with
competitive performance on the DSEC benchmark. Our code will be available at
https://github.com/AhmedHumais/E-STMFlow

</details>


### [426] [CrosswalkNet: An Optimized Deep Learning Framework for Pedestrian Crosswalk Detection in Aerial Images with High-Performance Computing](https://arxiv.org/abs/2506.07885)
*Zubin Bhuyan,Yuanchang Xie,AngkeaReach Rith,Xintong Yan,Nasko Apostolov,Jimi Oke,Chengbo Ai*

Main category: cs.CV

TL;DR: 介绍 CrosswalkNet 一个用于从高分辨率航拍图像中检测各种人行横道的深度学习框架，该框架使用定向边界框和改进的注意力机制等优化技术，在多个州的数据集上表现出高精度和强泛化能力。


<details>
  <summary>Details</summary>
Motivation: 尽管航拍和卫星影像日益普及，但传统方法在检测定向人行横道方面存在精度不足的问题。该研究旨在通过改进目标检测策略来提高人行横道检测准确性，以支持交通资产管理、安全分析和城市规划。

Method: 提出 CrosswalkNet 框架，融合定向边界框（OBB）、卷积块注意力机制、双分支空间金字塔池化快速模块（SPPF）和余弦退火技术。使用包含 23,000 多个标注实例的数据集进行训练验证。

Result: 在麻省数据上实现 96.5% 准确率和 93.3% 召回率；新罕布什尔、弗吉尼亚和缅因州数据集无需迁移学习即表现良好。利用高性能计算将检测结果转化为多边形 shp 文件，加速实时分析。

Conclusion: 该框架为决策者和工程师提供了有效工具，能够显著提升行人安全与城市交通流动性，展现强大泛化性和实时处理潜力。

Abstract: With the increasing availability of aerial and satellite imagery, deep
learning presents significant potential for transportation asset management,
safety analysis, and urban planning. This study introduces CrosswalkNet, a
robust and efficient deep learning framework designed to detect various types
of pedestrian crosswalks from 15-cm resolution aerial images. CrosswalkNet
incorporates a novel detection approach that improves upon traditional object
detection strategies by utilizing oriented bounding boxes (OBB), enhancing
detection precision by accurately capturing crosswalks regardless of their
orientation. Several optimization techniques, including Convolutional Block
Attention, a dual-branch Spatial Pyramid Pooling-Fast module, and cosine
annealing, are implemented to maximize performance and efficiency. A
comprehensive dataset comprising over 23,000 annotated crosswalk instances is
utilized to train and validate the proposed framework. The best-performing
model achieves an impressive precision of 96.5% and a recall of 93.3% on aerial
imagery from Massachusetts, demonstrating its accuracy and effectiveness.
CrosswalkNet has also been successfully applied to datasets from New Hampshire,
Virginia, and Maine without transfer learning or fine-tuning, showcasing its
robustness and strong generalization capability. Additionally, the crosswalk
detection results, processed using High-Performance Computing (HPC) platforms
and provided in polygon shapefile format, have been shown to accelerate data
processing and detection, supporting real-time analysis for safety and mobility
applications. This integration offers policymakers, transportation engineers,
and urban planners an effective instrument to enhance pedestrian safety and
improve urban mobility.

</details>


### [427] [EgoM2P: Egocentric Multimodal Multitask Pretraining](https://arxiv.org/abs/2506.07886)
*Gen Li,Yutong Chen,Yiqian Wu,Kaifeng Zhao,Marc Pollefeys,Siyu Tang*

Main category: cs.CV

TL;DR: 提出了EgoM2P框架，用于解决自我中心多模态数据建模中的异质性和缺失标签问题，通过掩码建模统一处理感知与生成任务


<details>
  <summary>Details</summary>
Motivation: 自我中心视数据（如RGB-D、姿态和视线）具有多样性和模态缺失问题，难以构建大规模统一模型

Method: 开发时间感知tokenizer，提出基于掩码建模的EgoM2P框架，支持多任务联合训练

Result: 在视线追踪、姿态估计与深度估计等任务中达到或超过专业模型，速度快10倍

Conclusion: EgoM2P通过模态无关的统一架构解决了自我中心数据建模的核心挑战，能同时支撑感知类与生成类任务

Abstract: Understanding multimodal signals in egocentric vision, such as RGB video,
depth, camera poses, and gaze, is essential for applications in augmented
reality, robotics, and human-computer interaction. These capabilities enable
systems to better interpret the camera wearer's actions, intentions, and
surrounding environment. However, building large-scale egocentric multimodal
and multitask models presents unique challenges. Egocentric data are inherently
heterogeneous, with large variations in modality coverage across devices and
settings. Generating pseudo-labels for missing modalities, such as gaze or
head-mounted camera trajectories, is often infeasible, making standard
supervised learning approaches difficult to scale. Furthermore, dynamic camera
motion and the complex temporal and spatial structure of first-person video
pose additional challenges for the direct application of existing multimodal
foundation models.
  To address these challenges, we introduce a set of efficient temporal
tokenizers and propose EgoM2P, a masked modeling framework that learns from
temporally aware multimodal tokens to train a large, general-purpose model for
egocentric 4D understanding. This unified design supports multitasking across
diverse egocentric perception and synthesis tasks, including gaze prediction,
egocentric camera tracking, and monocular depth estimation from egocentric
video. EgoM2P also serves as a generative model for conditional egocentric
video synthesis. Across these tasks, EgoM2P matches or outperforms specialist
models while being an order of magnitude faster. We will fully open-source
EgoM2P to support the community and advance egocentric vision research. Project
page: https://egom2p.github.io/

</details>


### [428] [Video Unlearning via Low-Rank Refusal Vector](https://arxiv.org/abs/2506.07891)
*Simone Facchiano,Stefano Saravalle,Matteo Migliarini,Edoardo De Matteis,Alessio Sampieri,Andrea Pilzer,Emanuele Rodolà,Indro Spinelli,Luca Franco,Fabio Galasso*

Main category: cs.CV

TL;DR: 该论文提出了一种针对视频扩散模型的遗忘方法，仅需5个多模态提示对即可从模型中删除有害概念，同时保持生成质量。


<details>
  <summary>Details</summary>
Motivation: 视频生成模型可能产生非法或不良内容，需要在不重新训练或访问原始数据的情况下消除特定有害概念。

Method: 通过计算安全与有害提示对之间的潜层差异得出'refusal vector'，采用低秩分解处理嵌入协方差差以确保鲁棒性，并将该向量从模型参数中减去。

Result: 该方法成功中和了裸露、暴力、版权等有害内容，并保持了视频生成质量，且对对抗性绕过具有鲁棒性。

Conclusion: 首次针对视频扩散模型的遗忘技术，高效、无需重训练，通过权重嵌入增强安全性，为生成模型的伦理使用提供解决方案。

Abstract: Video generative models democratize the creation of visual content through
intuitive instruction following, but they also inherit the biases and harmful
concepts embedded within their web-scale training data. This inheritance
creates a significant risk, as users can readily generate undesirable and even
illegal content. This work introduces the first unlearning technique tailored
explicitly for video diffusion models to address this critical issue. Our
method requires 5 multi-modal prompt pairs only. Each pair contains a "safe"
and an "unsafe" example that differ only by the target concept. Averaging their
per-layer latent differences produces a "refusal vector", which, once
subtracted from the model parameters, neutralizes the unsafe concept. We
introduce a novel low-rank factorization approach on the covariance difference
of embeddings that yields robust refusal vectors. This isolates the target
concept while minimizing collateral unlearning of other semantics, thus
preserving the visual quality of the generated video. Our method preserves the
model's generation quality while operating without retraining or access to the
original training data. By embedding the refusal direction directly into the
model's weights, the suppression mechanism becomes inherently more robust
against adversarial bypass attempts compared to surface-level input-output
filters. In a thorough qualitative and quantitative evaluation, we show that we
can neutralize a variety of harmful contents, including explicit nudity,
graphic violence, copyrights, and trademarks. Project page:
https://www.pinlab.org/video-unlearning.

</details>


### [429] [WeThink: Toward General-purpose Vision-Language Reasoning via Reinforcement Learning](https://arxiv.org/abs/2506.07905)
*Jie Yang,Feipeng Ma,Zitian Wang,Dacheng Yin,Kang Rong,Fengyun Rao,Ruimao Zhang*

Main category: cs.CV

TL;DR: 本文提出了一种可扩展的多模态问答合成流程，并发布了WeThink数据集，通过结合规则和模型奖励机制增强多模态语言模型的通用推理能力。


<details>
  <summary>Details</summary>
Motivation: 当前基于文本的推理模型（如DeepSeek-R1）向多模态扩展时存在局限，现有方法多专注于特定领域任务，缺乏通用视觉-语言推理能力的强化学习训练方案。

Method: 1) 设计可自动生成图像关联推理式QA对的数据流程；2) 构建12万对涵盖18个来源的多模态数据集WeThink；3) 采用规则验证与模型评估结合的混合奖励机制优化RL训练。

Result: 在14个多模态基准测试中展现出全面性能提升，特别是数学推理和通用任务表现突出；自动化流水线可持续扩展数据多样性。

Conclusion: WeThink数据集与混合奖励机制可有效增强多模态大语言模型的通用推理能力，自动化数据生产机制具有持续优化潜力。

Abstract: Building on the success of text-based reasoning models like DeepSeek-R1,
extending these capabilities to multimodal reasoning holds great promise. While
recent works have attempted to adapt DeepSeek-R1-style reinforcement learning
(RL) training paradigms to multimodal large language models (MLLM), focusing on
domain-specific tasks like math and visual perception, a critical question
remains: How can we achieve the general-purpose visual-language reasoning
through RL? To address this challenge, we make three key efforts: (1) A novel
Scalable Multimodal QA Synthesis pipeline that autonomously generates
context-aware, reasoning-centric question-answer (QA) pairs directly from the
given images. (2) The open-source WeThink dataset containing over 120K
multimodal QA pairs with annotated reasoning paths, curated from 18 diverse
dataset sources and covering various question domains. (3) A comprehensive
exploration of RL on our dataset, incorporating a hybrid reward mechanism that
combines rule-based verification with model-based assessment to optimize RL
training efficiency across various task domains. Across 14 diverse MLLM
benchmarks, we demonstrate that our WeThink dataset significantly enhances
performance, from mathematical reasoning to diverse general multimodal tasks.
Moreover, we show that our automated data pipeline can continuously increase
data diversity to further improve model performance.

</details>


### [430] [A Comparative Study of U-Net Architectures for Change Detection in Satellite Images](https://arxiv.org/abs/2506.07925)
*Yaxita Amin,Naimisha S Trivedi,Rashmi Bhattad*

Main category: cs.CV

TL;DR: 该研究填补了U-Net在遥感变化检测领域应用的空白，通过综合分析34篇论文，比较评估了18种U-Net变体在遥感变化检测中的优劣。


<details>
  <summary>Details</summary>
Motivation: 尽管U-Net在图像分割领域表现出色，但它在遥感变化检测中的应用尚未得到充分探索。因此，本研究旨在系统评估不同U-Net变体在该领域的效果，为研究者和实践者提供选择指导。

Method: 通过文献综述，对18种U-Net变体进行比较分析，特别关注专为变化检测设计的架构（如Siamese Swin-U-Net），评估它们在处理时序数据和远程依赖关系方面的能力。

Result: 研究表明，处理多时相数据的能力和捕获远程空间关系对提高变化检测精度至关重要。同时，研究明确了不同U-Net变体的优缺点。

Conclusion: 该综合分析为遥感变化检测任务中U-Net架构的选择提供了实践指导，强调了面向变化检测的特化架构（如Siamese结构）的价值，并指出处理时序信息和远程依赖关系是关键改进方向。

Abstract: Remote sensing change detection is essential for monitoring the everchanging
landscapes of the Earth. The U-Net architecture has gained popularity for its
capability to capture spatial information and perform pixel-wise
classification. However, their application in the Remote sensing field remains
largely unexplored. Therefore, this paper fill the gap by conducting a
comprehensive analysis of 34 papers. This study conducts a comparison and
analysis of 18 different U-Net variations, assessing their potential for
detecting changes in remote sensing. We evaluate both benefits along with
drawbacks of each variation within the framework of this particular
application. We emphasize variations that are explicitly built for change
detection, such as Siamese Swin-U-Net, which utilizes a Siamese architecture.
The analysis highlights the significance of aspects such as managing data from
different time periods and collecting relationships over a long distance to
enhance the precision of change detection. This study provides valuable
insights for researchers and practitioners that choose U-Net versions for
remote sensing change detection tasks.

</details>


### [431] [Mimicking or Reasoning: Rethinking Multi-Modal In-Context Learning in Vision-Language Models](https://arxiv.org/abs/2506.07936)
*Chengyue Huang,Yuchen Zhu,Sichen Zhu,Jingyun Xiao,Moises Andrade,Shivang Chopra,Zsolt Kira*

Main category: cs.CV

TL;DR: 研究发现当前视觉语言模型在多模态上下文学习中主要依赖于浅层启发式方法，而非真正的任务理解，且在分布变化下性能反而下降。


<details>
  <summary>Details</summary>
Motivation: 评估视觉语言模型在分布变化下执行多模态上下文学习的能力，现有研究认为模型主要依赖浅层启发式方法（如复制或多数投票）而非理解任务。

Method: 提出MM-ICL with Reasoning流程，为每个示例添加自动生成的推理依据。在感知和推理两类数据集上测试3B到72B规模的开源模型及Gemini 2.0等专有模型，控制样本数量、检索方法、依据质量和分布等变量。

Result: 增加示例数量反而降低性能，模型倾向于复制答案；各项控制因素（样本量、依据质量等）对性能影响有限，表明当前模型未能有效利用上下文学习中的示例信息。

Conclusion: 当前视觉语言模型尚未具备真正的多模态上下文学习能力，其表现主要依赖浅层策略而非任务理解。

Abstract: Vision-language models (VLMs) are widely assumed to exhibit in-context
learning (ICL), a property similar to that of their language-only counterparts.
While recent work suggests VLMs can perform multimodal ICL (MM-ICL), studies
show they often rely on shallow heuristics -- such as copying or majority
voting -- rather than true task understanding. We revisit this assumption by
evaluating VLMs under distribution shifts, where support examples come from a
dataset different from the query. Surprisingly, performance often degrades with
more demonstrations, and models tend to copy answers rather than learn from
them. To investigate further, we propose a new MM-ICL with Reasoning pipeline
that augments each demonstration with a generated rationale alongside the
answer. We conduct extensive and comprehensive experiments on both perception-
and reasoning-required datasets with open-source VLMs ranging from 3B to 72B
and proprietary models such as Gemini 2.0. We conduct controlled studies
varying shot count, retrieval method, rationale quality, and distribution. Our
results show limited performance sensitivity across these factors, suggesting
that current VLMs do not effectively utilize demonstration-level information as
intended in MM-ICL.

</details>


### [432] [Decoupling the Image Perception and Multimodal Reasoning for Reasoning Segmentation with Digital Twin Representations](https://arxiv.org/abs/2506.07943)
*Yizhen Li,Dell Zhang,Xuelong Li,Yiqing Shen*

Main category: cs.CV

TL;DR: We introduce DTwinSeger, a new method for Reasoning Segmentation that uses Digital Twin representation to separate perception and reasoning, achieving state-of-the-art results on multiple benchmarks.


<details>
  <summary>Details</summary>
Motivation: Existing methods tokenize images, disrupting spatial relationships between objects, limiting performance in Reasoning Segmentation tasks.

Method: A two-stage approach: 1. Transform image into structured Digital Twin representation preserving spatial relations; 2. Use LLM for explicit reasoning over this representation to identify targets. Includes supervised fine-tuning method and dataset Seg-DT for LLMs.

Result: Achieves state-of-the-art performance on two Reasoning Segmentation and three referring segmentation benchmarks.

Conclusion: DT representation effectively bridges vision and text, enabling complex multimodal reasoning using only LLMs.

Abstract: Reasoning Segmentation (RS) is a multimodal vision-text task that requires
segmenting objects based on implicit text queries, demanding both precise
visual perception and vision-text reasoning capabilities. Current RS approaches
rely on fine-tuning vision-language models (VLMs) for both perception and
reasoning, but their tokenization of images fundamentally disrupts continuous
spatial relationships between objects. We introduce DTwinSeger, a novel RS
approach that leverages Digital Twin (DT) representation as an intermediate
layer to decouple perception from reasoning. Innovatively, DTwinSeger
reformulates RS as a two-stage process, where the first transforms the image
into a structured DT representation that preserves spatial relationships and
semantic properties and then employs a Large Language Model (LLM) to perform
explicit reasoning over this representation to identify target objects. We
propose a supervised fine-tuning method specifically for LLM with DT
representation, together with a corresponding fine-tuning dataset Seg-DT, to
enhance the LLM's reasoning capabilities with DT representations. Experiments
show that our method can achieve state-of-the-art performance on two image RS
benchmarks and three image referring segmentation benchmarks. It yields that DT
representation functions as an effective bridge between vision and text,
enabling complex multimodal reasoning tasks to be accomplished solely with an
LLM.

</details>


### [433] [Creating a Historical Migration Dataset from Finnish Church Records, 1800-1920](https://arxiv.org/abs/2506.07960)
*Ari Vesalainen,Jenna Kanerva,Aida Nitsch,Kiia Korsu,Ilari Larkiola,Laura Ruotsalainen,Filip Ginter*

Main category: cs.CV

TL;DR: 本文利用深度学习方法，从芬兰1800-1920年的教会迁移记录中提取了超过600万条数据，构建了一个用于研究历史人口模式的结构化数据集，并通过案例研究展示了其在重建迁移历史中的应用。


<details>
  <summary>Details</summary>
Motivation: 教会保存的手写迁移记录是研究历史人口模式的宝贵资料，但人工处理海量档案效率低下。研究者旨在通过自动化技术将这些非结构化历史文档转化为结构化数据。

Method: 采用深度学习自动化流程：图像预处理后依次进行版式分析、表格检测、单元格分类和手写文字识别，最终从约20万份手写记录图像中提取数据。

Result: 成功构建包含600多万条迁移记录的数据集，覆盖芬兰全域。以Elimäki教区的案例研究验证了数据集在重建地方迁移史和流行病传播模式中的有效性。

Conclusion: 该研究证明深度学习能高效转换历史手写档案，为人口史学提供新工具；数据集可支持城市化、家族迁移及疾病传播等跨学科研究。

Abstract: This article presents a large-scale effort to create a structured dataset of
internal migration in Finland between 1800 and 1920 using digitized church
moving records. These records, maintained by Evangelical-Lutheran parishes,
document the migration of individuals and families and offer a valuable source
for studying historical demographic patterns. The dataset includes over six
million entries extracted from approximately 200,000 images of handwritten
migration records.
  The data extraction process was automated using a deep learning pipeline that
included layout analysis, table detection, cell classification, and handwriting
recognition. The complete pipeline was applied to all images, resulting in a
structured dataset suitable for research.
  The dataset can be used to study internal migration, urbanization, and family
migration, and the spread of disease in preindustrial Finland. A case study
from the Elim\"aki parish shows how local migration histories can be
reconstructed. The work demonstrates how large volumes of handwritten archival
material can be transformed into structured data to support historical and
demographic research.

</details>


### [434] [SlideCoder: Layout-aware RAG-enhanced Hierarchical Slide Generation from Design](https://arxiv.org/abs/2506.07964)
*Wenxin Tang,Jingyu Xiao,Wenxuan Jiang,Xi Xiao,Yuhang Wang,Xuxin Tang,Qing Li,Yuehe Ma,Junliang Liu,Shisong Tang,Michael R. Lyu*

Main category: cs.CV

TL;DR: 论文提出Slide2Code基准和SlideCoder框架，用于从参考图像生成可编辑幻灯片，解决现有方法在视觉和结构设计上的不足。


<details>
  <summary>Details</summary>
Motivation: 手动创建幻灯片费时费力且需专业知识，现有基于自然语言的LLM方法难以捕捉幻灯片设计的视觉和结构细微差别。

Method: 引入布局感知的检索增强框架SlideCoder，整合基于颜色梯度的分割算法和分层检索增强生成方法；同时发布微调的开源模型SlideMaster。

Result: SlideCoder在布局保真度、执行准确性和视觉一致性上比之前最佳方法高出40.5分。

Conclusion: 提出的框架和基准有效解决基于参考图像的幻灯片生成问题，其代码和模型已开源。

Abstract: Manual slide creation is labor-intensive and requires expert prior knowledge.
Existing natural language-based LLM generation methods struggle to capture the
visual and structural nuances of slide designs. To address this, we formalize
the Reference Image to Slide Generation task and propose Slide2Code, the first
benchmark with difficulty-tiered samples based on a novel Slide Complexity
Metric. We introduce SlideCoder, a layout-aware, retrieval-augmented framework
for generating editable slides from reference images. SlideCoder integrates a
Color Gradient-based Segmentation algorithm and a Hierarchical
Retrieval-Augmented Generation method to decompose complex tasks and enhance
code generation. We also release SlideMaster, a 7B open-source model fine-tuned
with improved reverse-engineered data. Experiments show that SlideCoder
outperforms state-of-the-art baselines by up to 40.5 points, demonstrating
strong performance across layout fidelity, execution accuracy, and visual
consistency. Our code is available at
https://github.com/vinsontang1/SlideCoder.

</details>


### [435] [SpaCE-10: A Comprehensive Benchmark for Multimodal Large Language Models in Compositional Spatial Intelligence](https://arxiv.org/abs/2506.07966)
*Ziyang Gong,Wenhao Li,Oliver Ma,Songyuan Li,Jiayi Ji,Xue Yang,Gen Luo,Junchi Yan,Rongrong Ji*

Main category: cs.CV

TL;DR: SpaCE-10 是一个新的多模态大语言模型空间智能评测基准，包含10种基础空间能力和8种组合能力，通过分层标注流程构建了超过5k高质量问答对。评测显示当前最先进模型仍大幅落后人类，并发现计数能力短板是限制组合能力的关键因素。


<details>
  <summary>Details</summary>
Motivation: 现有基准难以全面评估MLLMs从原子级到组合级的空间智能。为了解决这个问题，SpaCE-10提出10种原子空间能力和8种衍生组合能力作为评价体系。

Method: 使用分层标注流程生成高质量多样化QA对（涉及811个真实室内场景），构建包含5000+样本的基准。支持点云输入、多选题等多种评测设置。

Result: 顶级MLLM表现仍显著落后人类（约25.7分差）。关键发现：计数能力缺陷严重制约组合空间能力发展。

Conclusion: SpaCE-10揭示了MLLMs空间智能的当前局限，特别是基础计数能力对组合能力的瓶颈效应，为未来研究指明方向。基准数据集和代码已开源。

Abstract: Multimodal Large Language Models (MLLMs) have achieved remarkable progress in
various multimodal tasks. To pursue higher intelligence in space, MLLMs require
integrating multiple atomic spatial capabilities to handle complex and dynamic
tasks. However, existing benchmarks struggle to comprehensively evaluate the
spatial intelligence of common MLLMs from the atomic level to the compositional
level. To fill this gap, we present SpaCE-10, a comprehensive benchmark for
compositional spatial evaluations. In SpaCE-10, we define 10 atomic spatial
capabilities, which are combined to form 8 compositional capabilities. Based on
these definitions, we propose a novel hierarchical annotation pipeline to
generate high-quality and diverse question-answer (QA) pairs. With over 150+
hours of human expert effort, we obtain over 5k QA pairs for 811 real indoor
scenes in SpaCE-10, which covers various evaluation settings like point cloud
input and multi-choice QA. We conduct an extensive evaluation of common MLLMs
on SpaCE-10 and find that even the most advanced MLLM still lags behind humans
by large margins. Through our careful study, we also draw several significant
findings that benefit the MLLM community. For example, we reveal that the
shortcoming of counting capability greatly limits the compositional spatial
capabilities of existing MLLMs. The evaluation code and benchmark datasets are
available at https://github.com/Cuzyoung/SpaCE-10.

</details>


### [436] [CyberV: Cybernetics for Test-time Scaling in Video Understanding](https://arxiv.org/abs/2506.07971)
*Jiahao Meng,Shuyang Sun,Yue Tan,Lu Qi,Yunhai Tong,Xiangtai Li,Longyin Wen*

Main category: cs.CV

TL;DR: 提出了一种名为CyberV的新型框架，通过基于控制论的原理增强现有的冻结多模态大语言模型（MLLM），使模型能够推理时自我监控、自我修正并动态分配资源，从而解决当前模型在处理长/复杂视频时存在计算开销大、鲁棒性差和准确率低的问题。该框架以黑盒形式实现，无需重训练，并显著提升了多个模型在视频理解任务上的性能（最高提升10%），达到媲美人类专家的水平。


<details>
  <summary>Details</summary>
Motivation: 现有MLLM处理长/复杂视频时存在三个核心限制：测试时计算开销大、缺乏鲁棒性、准确率有限（尤其小参数模型），因其采用前馈式处理机制无法动态调整。

Method: 受控制论启发设计CyberV框架，由三个组件构成循环：1) MLLM推理系统（黑盒处理视频）；2) 传感器（监控推理中间状态如注意力漂移）；3) 控制器（决定何时/如何触发自修正，并生成反馈指导下一轮推理）

Result: 1) 显著提升开源模型性能：Qwen2.5-VL-7B在VideoMMU提升8.3%，InternVL3-8B提升5.5%，超越GPT-4o；Qwen2.5-VL-72B提升10%达人类水平。2) 在VideoMME/WorldSense等通用基准持续有效，证明泛化能力

Conclusion: CyberV首次将控制论循环引入视频MLLM，实现测试时自适应缩放。框架增强冻结模型无需重训练，解决了前馈模型的固有问题，显著提升动态视频理解能力，为更鲁棒、准确的视频MLLM开辟新方向。

Abstract: Current Multimodal Large Language Models (MLLMs) may struggle with
understanding long or complex videos due to computational demands at test time,
lack of robustness, and limited accuracy, primarily stemming from their
feed-forward processing nature. These limitations could be more severe for
models with fewer parameters. To address these limitations, we propose a novel
framework inspired by cybernetic principles, redesigning video MLLMs as
adaptive systems capable of self-monitoring, self-correction, and dynamic
resource allocation during inference. Our approach, CyberV, introduces a
cybernetic loop consisting of an MLLM Inference System, a Sensor, and a
Controller. Specifically, the sensor monitors forward processes of the MLLM and
collects intermediate interpretations, such as attention drift, then the
controller determines when and how to trigger self-correction and generate
feedback to guide the next round. This test-time adaptive scaling framework
enhances frozen MLLMs without requiring retraining or additional components.
Experiments demonstrate significant improvements: CyberV boosts Qwen2.5-VL-7B
by 8.3% and InternVL3-8B by 5.5% on VideoMMMU, surpassing the competitive
proprietary model GPT-4o. When applied to Qwen2.5-VL-72B, it yields a 10.0%
improvement, achieving performance even comparable to human experts.
Furthermore, our method demonstrates consistent gains on general-purpose
benchmarks, such as VideoMME and WorldSense, highlighting its effectiveness and
generalization capabilities in making MLLMs more robust and accurate for
dynamic video understanding. The code is released at
https://github.com/marinero4972/CyberV.

</details>


### [437] [OneIG-Bench: Omni-dimensional Nuanced Evaluation for Image Generation](https://arxiv.org/abs/2506.07977)
*Jingjing Chang,Yixiao Fang,Peng Xing,Shuhan Wu,Wei Cheng,Rui Wang,Xianfang Zeng,Gang Yu,Hai-Bao Chen*

Main category: cs.CV

TL;DR: 介绍了名为OneIG-Bench的综合性文本生成图像（T2I）模型基准测试框架，针对现有基准在细粒度评估上的不足，支持从提示图像对齐、文本渲染、推理生成内容、风格化和多样性等维度进行灵活评估。


<details>
  <summary>Details</summary>
Motivation: 现有T2I模型评估基准存在局限性，未能全面覆盖推理能力、文本渲染及风格等维度，尤其缺乏对前沿模型强推理能力的评估。

Method: 构建多维度评估框架（OneIG-Bench），支持用户针对特定维度生成图像并进行灵活评估，包括提示对齐、文本精确度、推理、风格化、多样性等。

Result: 代码库和数据集已开源，促进可复现的T2I模型评估与跨模型比较。

Conclusion: 该基准填补了T2I综合评估缺口，通过结构化分析帮助研究者定位模型瓶颈，推动领域发展。

Abstract: Text-to-image (T2I) models have garnered significant attention for generating
high-quality images aligned with text prompts. However, rapid T2I model
advancements reveal limitations in early benchmarks, lacking comprehensive
evaluations, for example, the evaluation on reasoning, text rendering and
style. Notably, recent state-of-the-art models, with their rich knowledge
modeling capabilities, show promising results on the image generation problems
requiring strong reasoning ability, yet existing evaluation systems have not
adequately addressed this frontier. To systematically address these gaps, we
introduce OneIG-Bench, a meticulously designed comprehensive benchmark
framework for fine-grained evaluation of T2I models across multiple dimensions,
including prompt-image alignment, text rendering precision, reasoning-generated
content, stylization, and diversity. By structuring the evaluation, this
benchmark enables in-depth analysis of model performance, helping researchers
and practitioners pinpoint strengths and bottlenecks in the full pipeline of
image generation. Specifically, OneIG-Bench enables flexible evaluation by
allowing users to focus on a particular evaluation subset. Instead of
generating images for the entire set of prompts, users can generate images only
for the prompts associated with the selected dimension and complete the
corresponding evaluation accordingly. Our codebase and dataset are now publicly
available to facilitate reproducible evaluation studies and cross-model
comparisons within the T2I research community.

</details>


### [438] [Real-time Localization of a Soccer Ball from a Single Camera](https://arxiv.org/abs/2506.07981)
*Dmitrii Vorobev,Artem Prosvetov,Karim Elhadji Daou*

Main category: cs.CV

TL;DR: 该论文提出了一种实时三维足球轨迹重建方法，使用单摄像头高效处理，即使在遮挡、模糊等情况下也能保持厘米级精度，适合直播环境，无需多摄像头系统的高成本。


<details>
  <summary>Details</summary>
Motivation: 为了实现低成本、高效且准确的足球轨迹跟踪，特别是在直播场景中应对遮挡、运动模糊和复杂背景等挑战，该研究旨在开发一种仅需单个广播摄像头的解决方案。

Method: 采用多模式状态模型（含 W 个离散模式）加速优化过程，系统设计可在标准 CPU 上运行以保证低延迟。

Result: 在俄罗斯超级联赛 6K 分辨率专有数据集上验证，性能媲美多摄像头系统，同时保持厘米级精度。

Conclusion: 该方法为职业足球环境提供了一种实用、可访问且准确的 3D 球轨迹跟踪技术，显著降低基础设施成本。

Abstract: We propose a computationally efficient method for real-time three-dimensional
football trajectory reconstruction from a single broadcast camera. In contrast
to previous work, our approach introduces a multi-mode state model with $W$
discrete modes to significantly accelerate optimization while preserving
centimeter-level accuracy -- even in cases of severe occlusion, motion blur,
and complex backgrounds. The system operates on standard CPUs and achieves low
latency suitable for live broadcast settings. Extensive evaluation on a
proprietary dataset of 6K-resolution Russian Premier League matches
demonstrates performance comparable to multi-camera systems, without the need
for specialized or costly infrastructure. This work provides a practical method
for accessible and accurate 3D ball tracking in professional football
environments.

</details>


### [439] [CXR-LT 2024: A MICCAI challenge on long-tailed, multi-label, and zero-shot disease classification from chest X-ray](https://arxiv.org/abs/2506.07984)
*Mingquan Lin,Gregory Holste,Song Wang,Yiliang Zhou,Yishu Wei,Imon Banerjee,Pengyi Chen,Tianjie Dai,Yuexi Du,Nicha C. Dvornek,Yuyan Ge,Zuowei Guo,Shouhei Hanaoka,Dongkyun Kim,Pablo Messina,Yang Lu,Denis Parra,Donghyun Son,Álvaro Soto,Aisha Urooj,René Vidal,Yosuke Yamagishi,Zefan Yang,Ruichi Zhang,Yang Zhou,Leo Anthony Celi,Ronald M. Summers,Zhiyong Lu,Hao Chen,Adam Flanders,George Shih,Zhangyang Wang,Yifan Peng*

Main category: cs.CV

TL;DR: CXR-LT 2024是一个社区驱动的项目，提供377,110个胸透图像和45种疾病标注（含19种新罕见病），专注于开放长尾肺病分类问题，引入了新任务：长尾噪声集分类、金标准子集分类和零样本泛化到5种未见疾病。


<details>
  <summary>Details</summary>
Motivation: 解决开放环境下的长尾肺病分类挑战，提升现有技术的可测量性；扩展现有数据集以更好地反映真实临床场景；解决上一届活动发现的局限性（如零样本学习）。

Method: 提供高质量基准数据集（377,110 CXR），设计三个任务：（i）基于大型噪声测试集的长尾分类，（ii）基于人工标注“金标准”子集的长尾分类，（iii）针对五种未见疾病的零样本泛化。采用多模态模型检测罕见病、先进生成方法处理噪声标签、零样本学习策略。

Result: 数据集扩展至45种疾病标签（新增19种罕见病），创建新的零样本学习任务，整合了针对上述任务的先进解决方案（如多模态模型和生成方法）。

Conclusion: 该项目通过整合参与者洞察与创新，旨在推进临床实用性强、泛化能力好的胸透诊断模型发展；扩展数据集将成为未来研究的宝贵资源。

Abstract: The CXR-LT series is a community-driven initiative designed to enhance lung
disease classification using chest X-rays (CXR). It tackles challenges in open
long-tailed lung disease classification and enhances the measurability of
state-of-the-art techniques. The first event, CXR-LT 2023, aimed to achieve
these goals by providing high-quality benchmark CXR data for model development
and conducting comprehensive evaluations to identify ongoing issues impacting
lung disease classification performance. Building on the success of CXR-LT
2023, the CXR-LT 2024 expands the dataset to 377,110 chest X-rays (CXRs) and 45
disease labels, including 19 new rare disease findings. It also introduces a
new focus on zero-shot learning to address limitations identified in the
previous event. Specifically, CXR-LT 2024 features three tasks: (i) long-tailed
classification on a large, noisy test set, (ii) long-tailed classification on a
manually annotated "gold standard" subset, and (iii) zero-shot generalization
to five previously unseen disease findings. This paper provides an overview of
CXR-LT 2024, detailing the data curation process and consolidating
state-of-the-art solutions, including the use of multimodal models for rare
disease detection, advanced generative approaches to handle noisy labels, and
zero-shot learning strategies for unseen diseases. Additionally, the expanded
dataset enhances disease coverage to better represent real-world clinical
settings, offering a valuable resource for future research. By synthesizing the
insights and innovations of participating teams, we aim to advance the
development of clinically realistic and generalizable diagnostic models for
chest radiography.

</details>


### [440] [Rethinking Crowd-Sourced Evaluation of Neuron Explanations](https://arxiv.org/abs/2506.07985)
*Tuomas Oikarinen,Ge Yan,Akshay Kulkarni,Tsui-Wei Weng*

Main category: cs.CV

TL;DR: 该论文提出了一种高效准确的众包策略来评估神经元解释方法的质量，包括重要性抽样降低成本和贝叶斯方法聚合评分，并在大规模研究中比较了不同方法在视觉模型上的表现。


<details>
  <summary>Details</summary>
Motivation: 现有神经元解释方法的可靠性评估通常依赖嘈杂且昂贵的众包评估，导致结果不可靠。因此需要开发更经济、更准确的评估策略。

Method: 1) 引入重要性抽样选择最有价值的输入样本，降低评估成本约30倍；2) 采用贝叶斯方法聚合众包评分，进一步减少约5倍所需评分数量；3) 应用这些策略大规模比较主流神经元解释方法在视觉模型上的质量。

Result: 1) 重要性抽样使成本降低约30倍；2) 贝叶斯聚合方法减少约5倍所需评分数量；3) 在大规模研究中系统评估了不同神经元解释方法的效果。

Conclusion: 所提评估策略显著提高了神经元解释评估的效率和准确性，为比较不同解释方法提供了可靠框架，并通过大规模实验验证了其有效性。

Abstract: Interpreting individual neurons or directions in activations space is an
important component of mechanistic interpretability. As such, many algorithms
have been proposed to automatically produce neuron explanations, but it is
often not clear how reliable these explanations are, or which methods produce
the best explanations. This can be measured via crowd-sourced evaluations, but
they can often be noisy and expensive, leading to unreliable results. In this
paper, we carefully analyze the evaluation pipeline and develop a
cost-effective and highly accurate crowdsourced evaluation strategy. In
contrast to previous human studies that only rate whether the explanation
matches the most highly activating inputs, we estimate whether the explanation
describes neuron activations across all inputs. To estimate this effectively,
we introduce a novel application of importance sampling to determine which
inputs are the most valuable to show to raters, leading to around 30x cost
reduction compared to uniform sampling. We also analyze the label noise present
in crowd-sourced evaluations and propose a Bayesian method to aggregate
multiple ratings leading to a further ~5x reduction in number of ratings
required for the same accuracy. Finally, we use these methods to conduct a
large-scale study comparing the quality of neuron explanations produced by the
most popular methods for two different vision models.

</details>


### [441] [Rethinking Cross-Modal Interaction in Multimodal Diffusion Transformers](https://arxiv.org/abs/2506.07986)
*Zhengyao Lv,Tianlin Pan,Chenyang Si,Zhaoxi Chen,Wangmeng Zuo,Ziwei Liu,Kwan-Yee K. Wong*

Main category: cs.CV

TL;DR: 提出TACA方法解决多模态扩散变换器中文本-图像对齐问题，通过温度缩放和步数感知调整优化跨模态注意力机制


<details>
  <summary>Details</summary>
Motivation: 当前MM-DiT模型（如FLUX）存在文本提示与生成内容对齐不精确的问题，主要归因于（1）视觉与文本模态间的token数量不平衡导致跨模态注意力被抑制，（2）缺乏步数感知的注意力权重调整

Method: 提出Temperature-Adjusted Cross-modal Attention (TACA)，通过温度参数动态调节不同模态间的注意力权重分布，配合LoRA微调策略

Result: 在T2I-CompBench基准测试中显著提升对齐效果，适用于FLUX和SD3.5等模型，在物体外观、属性绑定和空间关系等维度上均取得改进

Conclusion: 平衡跨模态注意力对提升语义保真度至关重要，TACA以极小计算开销实现了高效对齐改进。代码已开源。

Abstract: Multimodal Diffusion Transformers (MM-DiTs) have achieved remarkable progress
in text-driven visual generation. However, even state-of-the-art MM-DiT models
like FLUX struggle with achieving precise alignment between text prompts and
generated content. We identify two key issues in the attention mechanism of
MM-DiT, namely 1) the suppression of cross-modal attention due to token
imbalance between visual and textual modalities and 2) the lack of
timestep-aware attention weighting, which hinder the alignment. To address
these issues, we propose \textbf{Temperature-Adjusted Cross-modal Attention
(TACA)}, a parameter-efficient method that dynamically rebalances multimodal
interactions through temperature scaling and timestep-dependent adjustment.
When combined with LoRA fine-tuning, TACA significantly enhances text-image
alignment on the T2I-CompBench benchmark with minimal computational overhead.
We tested TACA on state-of-the-art models like FLUX and SD3.5, demonstrating
its ability to improve image-text alignment in terms of object appearance,
attribute binding, and spatial relationships. Our findings highlight the
importance of balancing cross-modal attention in improving semantic fidelity in
text-to-image diffusion models. Our codes are publicly available at
\href{https://github.com/Vchitect/TACA}

</details>


### [442] [PairEdit: Learning Semantic Variations for Exemplar-based Image Editing](https://arxiv.org/abs/2506.07992)
*Haoguang Lu,Jiacheng Chen,Zhenguo Yang,Aurele Tohokantche Gnanha,Fu Lee Wang,Li Qing,Xudong Mao*

Main category: cs.CV

TL;DR: PairEdit是一种基于视觉的编辑方法，它从少量图像对中学习编辑语义，无需文本指导。通过目标噪声预测、内容保留噪声调度和优化LoRAs来改进内容一致性。


<details>
  <summary>Details</summary>
Motivation: 现有基于示例的编辑方法依赖文本提示或隐式文本指令，难以精确指定某些编辑语义。本文旨在从图像对中直接学习复杂编辑语义，避免文本依赖。

Method: 提出目标噪声预测建模语义变化（含引导方向项），内容保留噪声调度促进语义学习，并优化独立LoRAs解耦语义变化与内容学习。

Result: 实验证明PairEdit能有效学习复杂语义，相比基线显著提升内容一致性。

Conclusion: PairEdit实现了无文本指导下的高效视觉编辑语义学习，为精细图像编辑提供新方案。

Abstract: Recent advancements in text-guided image editing have achieved notable
success by leveraging natural language prompts for fine-grained semantic
control. However, certain editing semantics are challenging to specify
precisely using textual descriptions alone. A practical alternative involves
learning editing semantics from paired source-target examples. Existing
exemplar-based editing methods still rely on text prompts describing the change
within paired examples or learning implicit text-based editing instructions. In
this paper, we introduce PairEdit, a novel visual editing method designed to
effectively learn complex editing semantics from a limited number of image
pairs or even a single image pair, without using any textual guidance. We
propose a target noise prediction that explicitly models semantic variations
within paired images through a guidance direction term. Moreover, we introduce
a content-preserving noise schedule to facilitate more effective semantic
learning. We also propose optimizing distinct LoRAs to disentangle the learning
of semantic variations from content. Extensive qualitative and quantitative
evaluations demonstrate that PairEdit successfully learns intricate semantics
while significantly improving content consistency compared to baseline methods.
Code will be available at https://github.com/xudonmao/PairEdit.

</details>


### [443] [UA-Pose: Uncertainty-Aware 6D Object Pose Estimation and Online Object Completion with Partial References](https://arxiv.org/abs/2506.07996)
*Ming-Feng Li,Xin Yang,Fu-En Wang,Hritam Basak,Yuyin Sun,Shreekant Gayaka,Min Sun,Cheng-Hao Kuo*

Main category: cs.CV

TL;DR: UA-Pose提出了一种针对部分参考图像的6D物体姿态估计和在线物体补全方法，通过不确定性建模提升残缺物体的姿态估计鲁棒性和完整性。


<details>
  <summary>Details</summary>
Motivation: 现有6D姿态估计方法需完整3D模型或大量覆盖物体全貌的参考图像，但实际场景常只能获取部分观测（少量RGBD图像或单张2D图像），导致姿态估计困难。

Method: 1）根据少量已知位姿的RGBD图像初始化局部3D模型，或基于单张2D图像生成初始模型；2）在模型中显式区分观测/未观测区域的不确定性；3）利用不确定性引导采样策略进行在线物体补全，增强姿态估计鲁棒性。

Result: 在YCB-Video等三个数据集上验证，尤其在物体观测残缺时超越现有方法（如用10%图像时PVNet精度提升48.7%，DenseFusion提升16.8%）。

Conclusion: 不确定性建模能有效解决参考图像不完整问题，为实际应用中基于碎片信息的姿态估计提供新方案。

Abstract: 6D object pose estimation has shown strong generalizability to novel objects.
However, existing methods often require either a complete, well-reconstructed
3D model or numerous reference images that fully cover the object. Estimating
6D poses from partial references, which capture only fragments of an object's
appearance and geometry, remains challenging. To address this, we propose
UA-Pose, an uncertainty-aware approach for 6D object pose estimation and online
object completion specifically designed for partial references. We assume
access to either (1) a limited set of RGBD images with known poses or (2) a
single 2D image. For the first case, we initialize a partial object 3D model
based on the provided images and poses, while for the second, we use
image-to-3D techniques to generate an initial object 3D model. Our method
integrates uncertainty into the incomplete 3D model, distinguishing between
seen and unseen regions. This uncertainty enables confidence assessment in pose
estimation and guides an uncertainty-aware sampling strategy for online object
completion, enhancing robustness in pose estimation accuracy and improving
object completeness. We evaluate our method on the YCB-Video, YCBInEOAT, and
HO3D datasets, including RGBD sequences of YCB objects manipulated by robots
and human hands. Experimental results demonstrate significant performance
improvements over existing methods, particularly when object observations are
incomplete or partially captured. Project page:
https://minfenli.github.io/UA-Pose/

</details>


### [444] [MADFormer: Mixed Autoregressive and Diffusion Transformers for Continuous Image Generation](https://arxiv.org/abs/2506.07999)
*Junhao Chen,Yulia Tsvetkov,Xiaochuang Han*

Main category: cs.CV

TL;DR: 提出了一种名为MADFormer的混合自回归和扩散Transformer模型，旨在系统性地研究AR与扩散模型在生成任务中的互补特性，为高分辨率图像生成提供设计原则。


<details>
  <summary>Details</summary>
Motivation: 现有的混合模型缺乏对自回归与扩散模型容量分配的系统指导，MADFormer作为测试平台，用于分析AR-扩散的权衡关系。

Method: 将图像生成划分为空间区块，使用AR层进行跨区块全局条件处理，扩散层则迭代优化每个区块内的局部细节。

Result: 在FFHQ-1024和ImageNet上的实验表明：逐块分区显著提升高分辨率图像生成性能；垂直混合层结构改善质量-效率平衡（受限计算下FID改进达75%）。

Conclusion: 研究结果为未来混合生成模型提供了实用设计原则，证明区块化处理和层间混合能有效提升生成效果。

Abstract: Recent progress in multimodal generation has increasingly combined
autoregressive (AR) and diffusion-based approaches, leveraging their
complementary strengths: AR models capture long-range dependencies and produce
fluent, context-aware outputs, while diffusion models operate in continuous
latent spaces to refine high-fidelity visual details. However, existing hybrids
often lack systematic guidance on how and why to allocate model capacity
between these paradigms. In this work, we introduce MADFormer, a Mixed
Autoregressive and Diffusion Transformer that serves as a testbed for analyzing
AR-diffusion trade-offs. MADFormer partitions image generation into spatial
blocks, using AR layers for one-pass global conditioning across blocks and
diffusion layers for iterative local refinement within each block. Through
controlled experiments on FFHQ-1024 and ImageNet, we identify two key insights:
(1) block-wise partitioning significantly improves performance on
high-resolution images, and (2) vertically mixing AR and diffusion layers
yields better quality-efficiency balances--improving FID by up to 75% under
constrained inference compute. Our findings offer practical design principles
for future hybrid generative models.

</details>


### [445] [Aligning Text, Images, and 3D Structure Token-by-Token](https://arxiv.org/abs/2506.08002)
*Aadarsh Sahoo,Vansh Tibrewal,Georgia Gkioxari*

Main category: cs.CV

TL;DR: 该论文提出了一种统一的大型语言模型（LLM）框架，旨在对齐语言、图像和3D场景，为3D任务（如渲染、识别、指令跟随和问答）提供高效的训练和方法设计指南，并在合成和真实数据集上验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 3D理解对设计和机器人技术至关重要，受语言和图像建模进展的启发，研究如何将自回归模型应用于结构化3D场景这一新模态。

Method: 提出统一的LLM框架整合三种模态，通过详细'cookbook'规范数据表示和训练目标，并扩展方法使用量化形状编码重建复杂3D物体。

Result: 在四种核心3D任务（渲染、识别、指令跟随、问答）和四个数据集上评估性能，并在真实世界3D物体识别任务中验证有效性。

Conclusion: 该方法为3D场景理解提供了可行性方案，通过多模态对齐实现了跨任务泛化能力，项目网页公开了技术细节。

Abstract: Creating machines capable of understanding the world in 3D is essential in
assisting designers that build and edit 3D environments and robots navigating
and interacting within a three-dimensional space. Inspired by advances in
language and image modeling, we investigate the potential of autoregressive
models for a new modality: structured 3D scenes. To this end, we propose a
unified LLM framework that aligns language, images, and 3D scenes and provide a
detailed ''cookbook'' outlining critical design choices for achieving optimal
training and performance addressing key questions related to data
representation, modality-specific objectives, and more. We evaluate performance
across four core 3D tasks -- rendering, recognition, instruction-following, and
question-answering -- and four 3D datasets, synthetic and real-world. We extend
our approach to reconstruct complex 3D object shapes by enriching our 3D
modality with quantized shape encodings, and show our model's effectiveness on
real-world 3D object recognition tasks. Project webpage:
https://glab-caltech.github.io/kyvo/

</details>


### [446] [Audio-Sync Video Generation with Multi-Stream Temporal Control](https://arxiv.org/abs/2506.08003)
*Shuchen Weng,Haojie Zheng,Zheng Chang,Si Li,Boxin Shi,Xinlong Wang*

Main category: cs.CV

TL;DR: MTV框架通过分离音频中的语音、音效和音乐轨道，实现了细粒度的音频同步视频生成。该方法显著提升了生成视频的质量和音频-视频对齐，尤其是在处理复杂多样音频时表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有音频驱动视频生成方法在复杂音频下难以保证高质量和精确的视听同步。音频作为与视觉自然对齐的信号，具备控制视频生成的潜力（如电影制作），且直接转换音频到视频对可视化音频叙事（如播客）至关重要。

Method: 1) 提出MTV框架，显式将音频分解为语音、音效和音乐三轨，分别控制唇部运动/事件时序/视觉氛围；2) 构建DEMIX数据集（含高质量影视素材及分解音频），通过五重叠子集支持多阶段训练。

Result: 在六大标准指标（视频质量/文本一致性/视听对齐）上达到SOTA，消融实验证实三轨分离策略对提升复杂场景下的同步精度关键有效。

Conclusion: MTV通过音轨解耦创新实现细粒度可控视频生成，DEMIX数据集为同类研究提供新基准，为多样化音频叙事可视化开辟新途径。

Abstract: Audio is inherently temporal and closely synchronized with the visual world,
making it a naturally aligned and expressive control signal for controllable
video generation (e.g., movies). Beyond control, directly translating audio
into video is essential for understanding and visualizing rich audio narratives
(e.g., Podcasts or historical recordings). However, existing approaches fall
short in generating high-quality videos with precise audio-visual
synchronization, especially across diverse and complex audio types. In this
work, we introduce MTV, a versatile framework for audio-sync video generation.
MTV explicitly separates audios into speech, effects, and music tracks,
enabling disentangled control over lip motion, event timing, and visual mood,
respectively -- resulting in fine-grained and semantically aligned video
generation. To support the framework, we additionally present DEMIX, a dataset
comprising high-quality cinematic videos and demixed audio tracks. DEMIX is
structured into five overlapped subsets, enabling scalable multi-stage training
for diverse generation scenarios. Extensive experiments demonstrate that MTV
achieves state-of-the-art performance across six standard metrics spanning
video quality, text-video consistency, and audio-video alignment. Project page:
https://hjzheng.net/projects/MTV/.

</details>


### [447] [Dynamic View Synthesis as an Inverse Problem](https://arxiv.org/abs/2506.08004)
*Hidir Yesiltepe,Pinar Yanardag*

Main category: cs.CV

TL;DR: 提出了一种无需训练的动态视图合成方法，通过改进预训练视频扩散模型的噪声初始化，解决了SNR为零时的确定性反转障碍，并引入了随机潜在调制来合成新视角的遮挡区域。


<details>
  <summary>Details</summary>
Motivation: 针对单目视频动态视图合成的逆问题，在无需训练更新的设定下，提升合成质量。解决预训练模型在零终端SNR下确定性反转的障碍，并处理相机运动导致的新增可见区域合成问题。

Method: 1. 提出K阶递归噪声表示（K-order Recursive Noise Representation）解决零终端SNR导致的反转问题；2. 推导闭式解实现VAE编码与DDIM反转潜变量的对齐；3. 引入随机潜在调制（Stochastic Latent Modulation）进行遮挡区域补全。

Result: 通过结构化潜变量操作实现高质量动态视图合成。综合实验证明该方法在噪声初始化阶段即可有效完成动态视图合成，无需权重更新或辅助模块。

Conclusion: 重新设计预训练视频扩散模型的噪声初始化机制，结合K阶噪声表示和随机潜在调制，可在免训练条件下实现单目视频的高保真动态视图合成。

Abstract: In this work, we address dynamic view synthesis from monocular videos as an
inverse problem in a training-free setting. By redesigning the noise
initialization phase of a pre-trained video diffusion model, we enable
high-fidelity dynamic view synthesis without any weight updates or auxiliary
modules. We begin by identifying a fundamental obstacle to deterministic
inversion arising from zero-terminal signal-to-noise ratio (SNR) schedules and
resolve it by introducing a novel noise representation, termed K-order
Recursive Noise Representation. We derive a closed form expression for this
representation, enabling precise and efficient alignment between the
VAE-encoded and the DDIM inverted latents. To synthesize newly visible regions
resulting from camera motion, we introduce Stochastic Latent Modulation, which
performs visibility aware sampling over the latent space to complete occluded
regions. Comprehensive experiments demonstrate that dynamic view synthesis can
be effectively performed through structured latent manipulation in the noise
initialization phase.

</details>


### [448] [ZeroVO: Visual Odometry with Minimal Assumptions](https://arxiv.org/abs/2506.08005)
*Lei Lai,Zekai Yin,Eshed Ohn-Bar*

Main category: cs.CV

TL;DR: ZeroVO是一种新颖的视觉里程计算法，能够在不同摄像头和环境中实现零样本泛化。它通过校准免费的几何感知网络结构、基于语言的先验知识以及半监督训练范式，在无需微调或相机标定的情况下，在多个标准基准测试上实现了30%以上的性能提升。


<details>
  <summary>Details</summary>
Motivation: 解决现有视觉里程计方法依赖于预定义或静态相机标定设置的问题，提供一种能够泛化到不同摄像头和环境的通用解决方案。

Method: 1. 设计校准免费的几何感知网络结构，处理估计深度和相机参数中的噪声；2. 引入基于语言的先验知识，注入语义信息以增强特征提取和泛化能力；3. 开发灵活的半监督训练范式，利用未标记数据进行场景自适应。

Result: 在KITTI、nuScenes和Argoverse 2三个标准基准测试以及基于GTA的新合成数据集上，相比现有方法实现了超过30%的性能提升。

Conclusion: ZeroVO通过消除对微调或相机标定的依赖，拓宽了视觉里程计的适用性，为大规模实际部署提供了通用解决方案。

Abstract: We introduce ZeroVO, a novel visual odometry (VO) algorithm that achieves
zero-shot generalization across diverse cameras and environments, overcoming
limitations in existing methods that depend on predefined or static camera
calibration setups. Our approach incorporates three main innovations. First, we
design a calibration-free, geometry-aware network structure capable of handling
noise in estimated depth and camera parameters. Second, we introduce a
language-based prior that infuses semantic information to enhance robust
feature extraction and generalization to previously unseen domains. Third, we
develop a flexible, semi-supervised training paradigm that iteratively adapts
to new scenes using unlabeled data, further boosting the models' ability to
generalize across diverse real-world scenarios. We analyze complex autonomous
driving contexts, demonstrating over 30% improvement against prior methods on
three standard benchmarks, KITTI, nuScenes, and Argoverse 2, as well as a newly
introduced, high-fidelity synthetic dataset derived from Grand Theft Auto
(GTA). By not requiring fine-tuning or camera calibration, our work broadens
the applicability of VO, providing a versatile solution for real-world
deployment at scale.

</details>


### [449] [Dreamland: Controllable World Creation with Simulator and Generative Models](https://arxiv.org/abs/2506.08006)
*Sicheng Mo,Ziyang Leng,Leon Liu,Weizhen Wang,Honglin He,Bolei Zhou*

Main category: cs.CV

TL;DR: Dreamland 是一个结合物理模拟器和预训练生成模型的混合世界生成框架，通过分层世界抽象增强可控性，减少适配成本，并在图像质量和可控性上优于现有基线。


<details>
  <summary>Details</summary>
Motivation: 当前大规模视频生成模型缺乏元素级可控性，限制了其在场景编辑和具身智能体训练中的应用。

Method: 设计分层世界抽象作为中间表示（包含像素级和对象级的语义与几何），桥接物理模拟器和生成模型，并使用 D3Sim 数据集训练评估。

Result: 图像质量提升 50.8%，可控性增强 17.9%，有效提升具身智能体训练效果。

Conclusion: Dreamland 框架通过分层抽象实现细粒度控制，为场景编辑和智能体训练提供了高效且可扩展的解决方案。

Abstract: Large-scale video generative models can synthesize diverse and realistic
visual content for dynamic world creation, but they often lack element-wise
controllability, hindering their use in editing scenes and training embodied AI
agents. We propose Dreamland, a hybrid world generation framework combining the
granular control of a physics-based simulator and the photorealistic content
output of large-scale pretrained generative models. In particular, we design a
layered world abstraction that encodes both pixel-level and object-level
semantics and geometry as an intermediate representation to bridge the
simulator and the generative model. This approach enhances controllability,
minimizes adaptation cost through early alignment with real-world
distributions, and supports off-the-shelf use of existing and future pretrained
generative models. We further construct a D3Sim dataset to facilitate the
training and evaluation of hybrid generation pipelines. Experiments demonstrate
that Dreamland outperforms existing baselines with 50.8% improved image
quality, 17.9% stronger controllability, and has great potential to enhance
embodied agent training. Code and data will be made available.

</details>


### [450] [Hidden in plain sight: VLMs overlook their visual representations](https://arxiv.org/abs/2506.08008)
*Stephanie Fu,Tyler Bonnen,Devin Guillory,Trevor Darrell*

Main category: cs.CV

TL;DR: Vision Language Models (VLMs) consistently underperform compared to their visual encoders on vision tasks, due to ineffective integration of visual information and language priors.


<details>
  <summary>Details</summary>
Motivation: Leverage language interfaces for visual tasks requires VLMs to integrate visual and linguistic information effectively. This paper investigates why VLMs perform poorly on vision-centric tasks despite having capable visual encoders.

Method: Compare VLMs against direct readouts from their visual encoders across vision benchmarks (e.g. depth estimation, image correspondence). Analyze degradation via: 1) vision representation quality, 2) prompt brittleness, 3) role of language model in task solving.

Result: VLMs perform near-chance levels on vision tasks—significantly worse than visual encoders alone. Primary bottleneck is the VLM's inability to utilize accessible visual information across the model, while inheriting language priors from the LLM component.

Conclusion: Current VLMs fail to effectively integrate visual features for vision-centric tasks, prioritizing linguistic biases over visual evidence. This diagnostic work provides benchmarks for future VLM visual understanding improvements.

Abstract: Language provides a natural interface to specify and evaluate performance on
visual tasks. To realize this possibility, vision language models (VLMs) must
successfully integrate visual and linguistic information. Our work compares
VLMs to a direct readout of their visual encoders to understand their ability
to integrate across these modalities. Across a series of vision-centric
benchmarks (e.g., depth estimation, correspondence), we find that VLMs perform
substantially worse than their visual encoders, dropping to near-chance
performance. We investigate these results through a series of analyses across
the entire VLM: namely 1) the degradation of vision representations, 2)
brittleness to task prompt, and 3) the language model's role in solving the
task. We find that the bottleneck in performing these vision-centric tasks lies
in this third category; VLMs are not effectively using visual information
easily accessible throughout the entire model, and they inherit the language
priors present in the LLM. Our work helps diagnose the failure modes of
open-source VLMs, and presents a series of evaluations useful for future
investigations into visual understanding within VLMs.

</details>


### [451] [Self Forcing: Bridging the Train-Test Gap in Autoregressive Video Diffusion](https://arxiv.org/abs/2506.08009)
*Xun Huang,Zhengqi Li,Guande He,Mingyuan Zhou,Eli Shechtman*

Main category: cs.CV

TL;DR: Self Forcing是一种新的自回归视频扩散模型训练方法，通过训练时使用自生成帧作为上下文解决曝光偏差问题，结合KV缓存机制实现实时视频生成。


<details>
  <summary>Details</summary>
Motivation: 解决自回归视频扩散模型中存在的曝光偏差问题（训练使用真实帧而在推理时依赖自生成的不完美帧），同时实现实时高质量视频生成。

Method: 1. 训练时通过KV缓存进行自回归展开，以前帧预测结果作为后帧条件；2. 采用关键帧采样和随机梯度截断策略平衡计算效率；3. 提出滚动KV缓存机制支持高效自回归预测。

Result: 在单个GPU上实现亚秒延时的实时视频生成，质量匹配或超越计算成本更高的非因果扩散模型。

Conclusion: Self Forcing通过自监督训练范式成功解决曝光偏差问题，在高效视频生成领域实现突破。

Abstract: We introduce Self Forcing, a novel training paradigm for autoregressive video
diffusion models. It addresses the longstanding issue of exposure bias, where
models trained on ground-truth context must generate sequences conditioned on
their own imperfect outputs during inference. Unlike prior methods that denoise
future frames based on ground-truth context frames, Self Forcing conditions
each frame's generation on previously self-generated outputs by performing
autoregressive rollout with key-value (KV) caching during training. This
strategy enables supervision through a holistic loss at the video level that
directly evaluates the quality of the entire generated sequence, rather than
relying solely on traditional frame-wise objectives. To ensure training
efficiency, we employ a few-step diffusion model along with a stochastic
gradient truncation strategy, effectively balancing computational cost and
performance. We further introduce a rolling KV cache mechanism that enables
efficient autoregressive video extrapolation. Extensive experiments demonstrate
that our approach achieves real-time streaming video generation with sub-second
latency on a single GPU, while matching or even surpassing the generation
quality of significantly slower and non-causal diffusion models. Project
website: http://self-forcing.github.io/

</details>


### [452] [Vision Transformers Don't Need Trained Registers](https://arxiv.org/abs/2506.08010)
*Nick Jiang,Amil Dravid,Alexei Efros,Yossi Gandelsman*

Main category: cs.CV

TL;DR: 该论文研究了ViT中高范数标记（outlier tokens）引起的噪声注意力问题，发现特定神经元是导致该现象的原因，并提出了一种无需重新训练的测试时寄存器方法，通过转移高范数激活到一个额外标记上，显著提升了注意力图的效果和多个下游任务的性能。


<details>
  <summary>Details</summary>
Motivation: Vision Transformers中高范数标记的存在导致注意力图噪声大，影响下游视觉任务性能。现有方案需重新训练模型添加寄存器标记，过程耗时耗资源。因此需要一种无需重新训练、可直接应用于预训练模型的新方法。

Method: 定位负责高范数激活的具体神经元，将其高激活值转移到新增的“寄存器标记”（未训练的额外token）上。该方法不修改模型本身，在推理时插入额外token即可平滑注意力分布。

Result: 1）注意力图噪声显著降低 2）多下游任务性能超越原始模型 3）媲美显式训练寄存器标记的模型 4）能提升现成视觉语言模型可解释性

Conclusion: 测试时寄存器成功模拟了显示训练寄存器的作用，为各类预训练ViT提供零成本方案实现性能提升和可解释性优化。

Abstract: We investigate the mechanism underlying a previously identified phenomenon in
Vision Transformers -- the emergence of high-norm tokens that lead to noisy
attention maps. We observe that in multiple models (e.g., CLIP, DINOv2), a
sparse set of neurons is responsible for concentrating high-norm activations on
outlier tokens, leading to irregular attention patterns and degrading
downstream visual processing. While the existing solution for removing these
outliers involves retraining models from scratch with additional learned
register tokens, we use our findings to create a training-free approach to
mitigate these artifacts. By shifting the high-norm activations from our
discovered register neurons into an additional untrained token, we can mimic
the effect of register tokens on a model already trained without registers. We
demonstrate that our method produces cleaner attention and feature maps,
enhances performance over base models across multiple downstream visual tasks,
and achieves results comparable to models explicitly trained with register
tokens. We then extend test-time registers to off-the-shelf vision-language
models to improve their interpretability. Our results suggest that test-time
registers effectively take on the role of register tokens at test-time,
offering a training-free solution for any pre-trained model released without
them.

</details>


### [453] [Play to Generalize: Learning to Reason Through Game Play](https://arxiv.org/abs/2506.08011)
*Yunfei Xie,Yinsong Ma,Shiyi Lan,Alan Yuille,Junfei Xiao,Chen Wei*

Main category: cs.CV

TL;DR: ViGaL通过让多模态大语言模型玩街机游戏（如蛇游戏），使用强化学习进行后训练，显著提升其在多模态数学和多学科问题上的推理能力，无需任何中间步骤数据。模型在保持基础模型通用视觉能力的同时，在推理任务上优于专属模型。


<details>
  <summary>Details</summary>
Motivation: 现有方法难以开发可迁移的多模态推理能力。受认知科学启发：游戏能够提升可迁移的认知技能。

Method: 提出视觉游戏学习（ViGaL）：使用强化学习对7B参数模型进行后训练，训练数据为简单的规则化游戏（如蛇游戏）。

Result: 1) 在MathVista和MMMU等基准测试中显著提升，未见中间步骤数据。2) 在推理任务上超越专属模型，同时保持通用视觉能力。3) 证明游戏可作为可控、可扩展的预训练任务。

Conclusion: 基于规则的游戏后训练可解锁MLLM的可迁移推理能力，为后训练范式提供新方向。

Abstract: Developing generalizable reasoning capabilities in multimodal large language
models (MLLMs) remains challenging. Motivated by cognitive science literature
suggesting that gameplay promotes transferable cognitive skills, we propose a
novel post-training paradigm, Visual Game Learning, or ViGaL, where MLLMs
develop out-of-domain generalization of multimodal reasoning through playing
arcade-like games. Specifically, we show that post-training a 7B-parameter MLLM
via reinforcement learning (RL) on simple arcade-like games, e.g. Snake,
significantly enhances its downstream performance on multimodal math benchmarks
like MathVista, and on multi-discipline questions like MMMU, without seeing any
worked solutions, equations, or diagrams during RL, suggesting the capture of
transferable reasoning skills. Remarkably, our model outperforms specialist
models tuned on multimodal reasoning data in multimodal reasoning benchmarks,
while preserving the base model's performance on general visual benchmarks, a
challenge where specialist models often fall short. Our findings suggest a new
post-training paradigm: synthetic, rule-based games can serve as controllable
and scalable pre-text tasks that unlock generalizable multimodal reasoning
abilities in MLLMs.

</details>


### [454] [StableMTL: Repurposing Latent Diffusion Models for Multi-Task Learning from Partially Annotated Synthetic Datasets](https://arxiv.org/abs/2506.08013)
*Anh-Quan Cao,Ivan Lopes,Raoul de Charette*

Main category: cs.CV

TL;DR: 提出了StableMTL方法，在零样本设置下使用合成数据集训练多任务扩散模型，通过统一潜在损失和多流任务注意机制提升7项任务性能


<details>
  <summary>Details</summary>
Motivation: 多任务密集预测通常需要每个任务都标注完整数据，而部分标注学习的泛化能力有限。研究旨在探索如何利用扩散模型的泛化能力，实现零样本多任务学习

Method: 1) 将图像生成器改造成潜在回归器 2) 采用带任务编码的去噪框架 3) 提出多流模型和1-to-N任务注意机制 4) 使用统一潜在损失替代需要平衡的每任务损失

Result: 在8个基准测试的7项任务中超越基线模型

Conclusion: 该方法通过创新架构设计有效解决了零样本多任务学习的挑战，实现了跨任务知识共享

Abstract: Multi-task learning for dense prediction is limited by the need for extensive
annotation for every task, though recent works have explored training with
partial task labels. Leveraging the generalization power of diffusion models,
we extend the partial learning setup to a zero-shot setting, training a
multi-task model on multiple synthetic datasets, each labeled for only a subset
of tasks. Our method, StableMTL, repurposes image generators for latent
regression. Adapting a denoising framework with task encoding, per-task
conditioning and a tailored training scheme. Instead of per-task losses
requiring careful balancing, a unified latent loss is adopted, enabling
seamless scaling to more tasks. To encourage inter-task synergy, we introduce a
multi-stream model with a task-attention mechanism that converts N-to-N task
interactions into efficient 1-to-N attention, promoting effective cross-task
sharing. StableMTL outperforms baselines on 7 tasks across 8 benchmarks.

</details>


### [455] [4DGT: Learning a 4D Gaussian Transformer Using Real-World Monocular Videos](https://arxiv.org/abs/2506.08015)
*Zhen Xu,Zhengqin Li,Zhao Dong,Xiaowei Zhou,Richard Newcombe,Zhaoyang Lv*

Main category: cs.CV

TL;DR: 4DGT是一种基于4D高斯和Transformer的动态场景重建模型，使用真实单目视频训练，统一静态和动态组件，通过滚动窗口处理64帧，实现高效实时渲染。


<details>
  <summary>Details</summary>
Motivation: 现有动态场景重建方法中，基于高斯的方法难以建模复杂时变环境和对象生命周期，优化方法耗时长。为兼顾效率与质量，需开发纯前馈模型。

Method: 提出4D Gaussian为归纳偏置；设计密度控制策略处理长时输入；通过滚动窗口预测一致性4D高斯；纯前馈架构加速推理。

Result: 在真实视频中超越先前高斯方法；在跨域视频上与基于优化的方法精度相当；推理时间从小时级降至秒级。

Conclusion: 4DGT首次实现基于纯前馈高斯模型的动态重建，高效处理长序列，单目训练即可适配真实及跨域场景。

Abstract: We propose 4DGT, a 4D Gaussian-based Transformer model for dynamic scene
reconstruction, trained entirely on real-world monocular posed videos. Using 4D
Gaussian as an inductive bias, 4DGT unifies static and dynamic components,
enabling the modeling of complex, time-varying environments with varying object
lifespans. We proposed a novel density control strategy in training, which
enables our 4DGT to handle longer space-time input and remain efficient
rendering at runtime. Our model processes 64 consecutive posed frames in a
rolling-window fashion, predicting consistent 4D Gaussians in the scene. Unlike
optimization-based methods, 4DGT performs purely feed-forward inference,
reducing reconstruction time from hours to seconds and scaling effectively to
long video sequences. Trained only on large-scale monocular posed video
datasets, 4DGT can outperform prior Gaussian-based networks significantly in
real-world videos and achieve on-par accuracy with optimization-based methods
on cross-domain videos. Project page: https://4dgt.github.io

</details>


### [456] [Facial Foundational Model Advances Early Warning of Coronary Artery Disease from Live Videos with DigitalShadow](https://arxiv.org/abs/2506.06283)
*Juexiao Zhou,Zhongyi Han,Mankun Xin,Xingwei He,Guotao Wang,Jiaoyan Song,Gongning Luo,Wenjia He,Xintong Li,Yuetan Chu,Juanwen Chen,Bo Wang,Xia Wu,Wenwen Duan,Zhixia Guo,Liyan Bai,Yilin Pan,Xuefei Bi,Lu Liu,Long Feng,Xiaonan He,Xin Gao*

Main category: cs.CV

TL;DR: 一个叫DigitalShadow的系统，它使用微调的面部基础模型，可以被动无接触地评估冠状动脉疾病（CAD）风险。系统有预训练2100万面部图像，并使用7004张来自中国4家医院的1751名患者的图像进行微调。它通过视频流分析面部特征，生成风险报告和个性化建议，支持本地部署以确保隐私。


<details>
  <summary>Details</summary>
Motivation: 全球老龄化加剧，CAD每年导致1780万死亡，成为主要死因之一。由于CAD可预防，早期发现和主动管理至关重要。现有方法需要主动参与，本工作旨在开发被动、无接触的早期预警系统。

Method: 1.预训练：在2100万面部图像上训练基础模型。2.微调：在来自1751名受试者的7004张面部图像（来自中国4家医院）上训练LiveCAD模型。3.部署：开发DigitalShadow系统，从视频流中无接触提取面部特征，结合个人数据库生成风险报告和建议。核心为本地部署确保隐私。

Result: 开发了DigitalShadow系统，包含：a) LiveCAD模型——专门用于CAD风险评估的微调面部模型；b) 被动无接触监测能力；c) 自然语言报告和健康建议输出；d) 隐私保护设计。

Conclusion: DigitalShadow通过AI面部分析实现CAD风险的无感筛查，有潜力成为大规模人群健康监测工具。其本地化部署解决了医疗隐私问题，但临床效果需进一步验证。

Abstract: Global population aging presents increasing challenges to healthcare systems,
with coronary artery disease (CAD) responsible for approximately 17.8 million
deaths annually, making it a leading cause of global mortality. As CAD is
largely preventable, early detection and proactive management are essential. In
this work, we introduce DigitalShadow, an advanced early warning system for
CAD, powered by a fine-tuned facial foundation model. The system is pre-trained
on 21 million facial images and subsequently fine-tuned into LiveCAD, a
specialized CAD risk assessment model trained on 7,004 facial images from 1,751
subjects across four hospitals in China. DigitalShadow functions passively and
contactlessly, extracting facial features from live video streams without
requiring active user engagement. Integrated with a personalized database, it
generates natural language risk reports and individualized health
recommendations. With privacy as a core design principle, DigitalShadow
supports local deployment to ensure secure handling of user data.

</details>


### [457] [Exploring Adversarial Watermarking in Transformer-Based Models: Transferability and Robustness Against Defense Mechanism for Medical Images](https://arxiv.org/abs/2506.06389)
*Rifat Sadik,Tanvir Rahman,Arpan Bhattacharjee,Bikash Chandra Halder,Ismail Hossain*

Main category: cs.CV

TL;DR: 该论文研究了视觉变换器（ViT）在皮肤医学图像上对对抗性水印攻击的脆弱性，并通过对抗训练提升其防御能力。


<details>
  <summary>Details</summary>
Motivation: 尽管ViT在计算机视觉任务中表现出色，但其全局注意力机制使其容易受到对抗性扰动的影响，尤其是在医疗影像领域。作者旨在探索ViT在医学图像上对对抗性水印攻击的敏感性，并评估对抗训练作为防御手段的有效性。

Method: 使用投影梯度下降（PGD）生成对抗性水印攻击ViT模型，测试攻击向CNN模型的可迁移性，并采用对抗训练增强模型的鲁棒性。

Result: 未经防御的ViT在遭受攻击时准确率大幅下降至27.6%，表明其高度脆弱性；采用对抗训练后准确率恢复到90.0%，证明防御有效性。

Conclusion: ViT在医疗影像领域易受对抗攻击，但对抗训练能显著提升其鲁棒性，为医疗AI系统的安全部署提供重要参考。

Abstract: Deep learning models have shown remarkable success in dermatological image
analysis, offering potential for automated skin disease diagnosis. Previously,
convolutional neural network(CNN) based architectures have achieved immense
popularity and success in computer vision (CV) based task like skin image
recognition, generation and video analysis. But with the emergence of
transformer based models, CV tasks are now are nowadays carrying out using
these models. Vision Transformers (ViTs) is such a transformer-based models
that have shown success in computer vision. It uses self-attention mechanisms
to achieve state-of-the-art performance across various tasks. However, their
reliance on global attention mechanisms makes them susceptible to adversarial
perturbations. This paper aims to investigate the susceptibility of ViTs for
medical images to adversarial watermarking-a method that adds so-called
imperceptible perturbations in order to fool models. By generating adversarial
watermarks through Projected Gradient Descent (PGD), we examine the
transferability of such attacks to CNNs and analyze the performance defense
mechanism -- adversarial training. Results indicate that while performance is
not compromised for clean images, ViTs certainly become much more vulnerable to
adversarial attacks: an accuracy drop of as low as 27.6%. Nevertheless,
adversarial training raises it up to 90.0%.

</details>


### [458] [(LiFT) Lightweight Fitness Transformer: A language-vision model for Remote Monitoring of Physical Training](https://arxiv.org/abs/2506.06480)
*A. Postlmayr,P. Cosman,S. Dey*

Main category: cs.CV

TL;DR: 研究人员开发了一种使用智能手机RGB摄像头进行远程健身追踪的系统，通过大规模数据集Olympia训练的多任务视觉语言模型，实现了高精度的运动识别和重复次数统计。


<details>
  <summary>Details</summary>
Motivation: 现有健身追踪模型在运动多样性和实际部署方面存在局限，难以普及。为了解决这些问题，需要一个能在多种运动上运行且易于部署的健壮模型。

Method: 构建了包含1900多种运动的大规模数据集Olympia，采用视觉语言transformer模型同时处理运动检测和重复计数任务。仅需RGB视频输入。

Result: 模型在Olympia数据集上达到76.5%的运动识别准确率和85.3%的重复计数准确率（off-by-one标准）。

Conclusion: 该单一模型方案在精度和通用性上超越了现有方法，为普及AI健身追踪迈出重要一步，同时保障了隐私和低成本。

Abstract: We introduce a fitness tracking system that enables remote monitoring for
exercises using only a RGB smartphone camera, making fitness tracking more
private, scalable, and cost effective. Although prior work explored automated
exercise supervision, existing models are either too limited in exercise
variety or too complex for real-world deployment. Prior approaches typically
focus on a small set of exercises and fail to generalize across diverse
movements. In contrast, we develop a robust, multitask motion analysis model
capable of performing exercise detection and repetition counting across
hundreds of exercises, a scale far beyond previous methods. We overcome
previous data limitations by assembling a large-scale fitness dataset, Olympia
covering more than 1,900 exercises. To our knowledge, our vision-language model
is the first that can perform multiple tasks on skeletal fitness data. On
Olympia, our model can detect exercises with 76.5% accuracy and count
repetitions with 85.3% off-by-one accuracy, using only RGB video. By presenting
a single vision-language transformer model for both exercise identification and
rep counting, we take a significant step toward democratizing AI-powered
fitness tracking.

</details>


### [459] [GS4: Generalizable Sparse Splatting Semantic SLAM](https://arxiv.org/abs/2506.06517)
*Mingqi Jiang,Chanho Kim,Chen Ziwen,Li Fuxin*

Main category: cs.CV

TL;DR: 介绍首个通用基于高斯溅射的语义SLAM算法，通过学习通用网络，从RGB-D视频流中增量构建3D场景表示，集成3D语义分割，优化效率和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 传统SLAM算法跟踪能力强但生成地图分辨率低且不完整，现有基于高斯溅射的SLAM依赖耗时单场景优化且泛化差，需解决效率和泛化性问题。

Method: 使用RGB-D识别主干网络预测高斯参数，集成3D语义分割，全局定位后仅优化1次高斯溅射解决定位漂移和漂浮物问题。

Result: 在ScanNet上实现SOTA语义SLAM性能，高斯数少一个数量级，并在NYUv2和TUM RGB-D上展示零样本泛化能力。

Conclusion: 该方法高效构建高分辨率3D语义地图，显著优于现有高斯溅射SLAM方法，在泛化和效率方面取得突破。

Abstract: Traditional SLAM algorithms are excellent at camera tracking but might
generate lower resolution and incomplete 3D maps. Recently, Gaussian Splatting
(GS) approaches have emerged as an option for SLAM with accurate, dense 3D map
building. However, existing GS-based SLAM methods rely on per-scene
optimization which is time-consuming and does not generalize to diverse scenes
well. In this work, we introduce the first generalizable GS-based semantic SLAM
algorithm that incrementally builds and updates a 3D scene representation from
an RGB-D video stream using a learned generalizable network. Our approach
starts from an RGB-D image recognition backbone to predict the Gaussian
parameters from every downsampled and backprojected image location.
Additionally, we seamlessly integrate 3D semantic segmentation into our GS
framework, bridging 3D mapping and recognition through a shared backbone. To
correct localization drifting and floaters, we propose to optimize the GS for
only 1 iteration following global localization. We demonstrate state-of-the-art
semantic SLAM performance on the real-world benchmark ScanNet with an order of
magnitude fewer Gaussians compared to other recent GS-based methods, and
showcase our model's generalization capability through zero-shot transfer to
the NYUv2 and TUM RGB-D datasets.

</details>


### [460] [Bridging Audio and Vision: Zero-Shot Audiovisual Segmentation by Connecting Pretrained Models](https://arxiv.org/abs/2506.06537)
*Seung-jae Lee,Paul Hongsuck Seo*

Main category: cs.CV

TL;DR: 提出了一种无需任务特定训练或标注的零样本视听分割（AVS）框架，通过整合多个预训练模型的音频、视觉和文本表示来提高分割精度。


<details>
  <summary>Details</summary>
Motivation: 传统AVS方法依赖大量像素级标注，这些标注成本高且耗时。

Method: 利用预训练的音频、视觉和文本模型，通过系统探索不同策略来桥接模态差距。

Result: 在多个数据集上实现了最先进的零样本AVS性能。

Conclusion: 该框架证明了整合多模态模型在无标注视听分割任务中的有效性，显著降低了对标注数据的依赖。

Abstract: Audiovisual segmentation (AVS) aims to identify visual regions corresponding
to sound sources, playing a vital role in video understanding, surveillance,
and human-computer interaction. Traditional AVS methods depend on large-scale
pixel-level annotations, which are costly and time-consuming to obtain. To
address this, we propose a novel zero-shot AVS framework that eliminates
task-specific training by leveraging multiple pretrained models. Our approach
integrates audio, vision, and text representations to bridge modality gaps,
enabling precise sound source segmentation without AVS-specific annotations. We
systematically explore different strategies for connecting pretrained models
and evaluate their efficacy across multiple datasets. Experimental results
demonstrate that our framework achieves state-of-the-art zero-shot AVS
performance, highlighting the effectiveness of multimodal model integration for
finegrained audiovisual segmentation.

</details>


### [461] [Securing Traffic Sign Recognition Systems in Autonomous Vehicles](https://arxiv.org/abs/2506.06563)
*Thushari Hapuarachchi,Long Dang,Kaiqi Xiong*

Main category: cs.CV

TL;DR: 该论文研究了深度神经网络在交通标志识别中的鲁棒性，提出了应对误差最小化攻击的数据增强训练方法和中毒数据检测模型。攻击使准确率从99.9%降至10.6%，而缓解方案恢复至96.05%，检测模型成功率超99%。


<details>
  <summary>Details</summary>
Motivation: 由于DNN模型常使用来源未知的大规模数据集训练，需确保训练过程中模型不被篡改或中毒，本文旨在提升交通标志识别DNN对抗数据投毒攻击的鲁棒性。

Method: 1. 对训练数据注入不易察觉的扰动实施误差最小化攻击；2. 提出基于非线性变换数据增强的训练方法以破坏扰动；3. 设计可检测不可见扰动中毒数据的检测模型。

Result: 1. 攻击使模型准确率从99.90%骤降至10.6%；2. 缓解方案将准确率恢复至96.05%，优于对抗训练；3. 检测模型识别攻击成功率超过99%。

Conclusion: 交通标志识别系统需采用先进训练方法（如本文方案）抵御数据投毒攻击，非线性变换增强和检测模型能有效提升安全性能。

Abstract: Deep Neural Networks (DNNs) are widely used for traffic sign recognition
because they can automatically extract high-level features from images. These
DNNs are trained on large-scale datasets obtained from unknown sources.
Therefore, it is important to ensure that the models remain secure and are not
compromised or poisoned during training. In this paper, we investigate the
robustness of DNNs trained for traffic sign recognition. First, we perform the
error-minimizing attacks on DNNs used for traffic sign recognition by adding
imperceptible perturbations on training data. Then, we propose a data
augmentation-based training method to mitigate the error-minimizing attacks.
The proposed training method utilizes nonlinear transformations to disrupt the
perturbations and improve the model robustness. We experiment with two
well-known traffic sign datasets to demonstrate the severity of the attack and
the effectiveness of our mitigation scheme. The error-minimizing attacks reduce
the prediction accuracy of the DNNs from 99.90% to 10.6%. However, our
mitigation scheme successfully restores the prediction accuracy to 96.05%.
Moreover, our approach outperforms adversarial training in mitigating the
error-minimizing attacks. Furthermore, we propose a detection model capable of
identifying poisoned data even when the perturbations are imperceptible to
human inspection. Our detection model achieves a success rate of over 99% in
identifying the attack. This research highlights the need to employ advanced
training methods for DNNs in traffic sign recognition systems to mitigate the
effects of data poisoning attacks.

</details>


### [462] [Textile Analysis for Recycling Automation using Transfer Learning and Zero-Shot Foundation Models](https://arxiv.org/abs/2506.06569)
*Yannis Spyridis,Vasileios Argyriou*

Main category: cs.CV

TL;DR: 使用RGB图像与深度学习技术实现纺织品回收自动化中的分类与污染物分割


<details>
  <summary>Details</summary>
Motivation: 纺织品回收自动化需要准确识别材料成分和污染物，但传感器数据处理存在挑战。RGB成像是经济有效的解决方案。

Method: 1. 分类任务：评估多种预训练架构（迁移学习+交叉验证）；2. 分割任务：采用Grounding DINO与SAM零样本分割模型

Result: 1. EfficientNetB0分类准确率达81.25%；2. 分割模型mIoU达0.90

Conclusion: RGB图像结合迁移学习（分类）和基础模型（零样本分割）能有效支持纺织品回收自动化预处理

Abstract: Automated sorting is crucial for improving the efficiency and scalability of
textile recycling, but accurately identifying material composition and
detecting contaminants from sensor data remains challenging. This paper
investigates the use of standard RGB imagery, a cost-effective sensing
modality, for key pre-processing tasks in an automated system. We present
computer vision components designed for a conveyor belt setup to perform (a)
classification of four common textile types and (b) segmentation of non-textile
features such as buttons and zippers. For classification, several pre-trained
architectures were evaluated using transfer learning and cross-validation, with
EfficientNetB0 achieving the best performance on a held-out test set with
81.25\% accuracy. For feature segmentation, a zero-shot approach combining the
Grounding DINO open-vocabulary detector with the Segment Anything Model (SAM)
was employed, demonstrating excellent performance with a mIoU of 0.90 for the
generated masks against ground truth. This study demonstrates the feasibility
of using RGB images coupled with modern deep learning techniques, including
transfer learning for classification and foundation models for zero-shot
segmentation, to enable essential analysis steps for automated textile
recycling pipelines.

</details>


### [463] [A Deep Learning Approach for Facial Attribute Manipulation and Reconstruction in Surveillance and Reconnaissance](https://arxiv.org/abs/2506.06578)
*Anees Nashath Shaik,Barbara Villarini,Vasileios Argyriou*

Main category: cs.CV

TL;DR: 提出一个数据驱动平台，通过生成合成训练数据来解决人脸识别中的偏见问题，提高监控系统准确性和公平性。


<details>
  <summary>Details</summary>
Motivation: 现有的监控系统因低质量图像和视频导致识别准确率低，且现有人脸分析模型存在肤色偏见和遮挡问题，这源于训练数据集多样性的不足。

Method: 利用基于深度学习的自编码器和生成对抗网络（GANs）进行人脸属性操作与重建，创建多样化的合成数据集；并集成图像增强模块处理低分辨率或被遮挡人脸。

Result: 在CelebA数据集上评估表明，该平台提高了数据集多样性和模型公平性。

Conclusion: 该平台有效减少AI人脸分析的偏见，提升监控系统在复杂环境下的准确性与可靠性，促进更公平的安防应用。

Abstract: Surveillance systems play a critical role in security and reconnaissance, but
their performance is often compromised by low-quality images and videos,
leading to reduced accuracy in face recognition. Additionally, existing
AI-based facial analysis models suffer from biases related to skin tone
variations and partially occluded faces, further limiting their effectiveness
in diverse real-world scenarios. These challenges are the results of data
limitations and imbalances, where available training datasets lack sufficient
diversity, resulting in unfair and unreliable facial recognition performance.
To address these issues, we propose a data-driven platform that enhances
surveillance capabilities by generating synthetic training data tailored to
compensate for dataset biases. Our approach leverages deep learning-based
facial attribute manipulation and reconstruction using autoencoders and
Generative Adversarial Networks (GANs) to create diverse and high-quality
facial datasets. Additionally, our system integrates an image enhancement
module, improving the clarity of low-resolution or occluded faces in
surveillance footage. We evaluate our approach using the CelebA dataset,
demonstrating that the proposed platform enhances both training data diversity
and model fairness. This work contributes to reducing bias in AI-based facial
analysis and improving surveillance accuracy in challenging environments,
leading to fairer and more reliable security applications.

</details>


### [464] [EV-LayerSegNet: Self-supervised Motion Segmentation using Event Cameras](https://arxiv.org/abs/2506.06596)
*Youssef Farah,Federico Paredes-Vallés,Guido De Croon,Muhammad Ahmed Humais,Hussain Sajwani,Yahya Zweiri*

Main category: cs.CV

TL;DR: 该论文提出了一种自监督的CNN模型EV-LayerSegNet，用于事件相机的运动分割。因为传统标注成本高且困难，该方法通过学习场景的分层表示，将仿射光流和分割掩码分开学习，并利用它们去模糊事件输入，然后以去模糊的作为自监督损失。


<details>
  <summary>Details</summary>
Motivation: 事件相机具有高时间分辨率，擅长捕捉动态，适合运动分割任务。但为事件数据获取手工标注十分昂贵、易出错且频率受限，因此需要无标注的自监督方法。

Method: 提出了EV-LayerSegNet自监督卷积神经网络：利用场景的分层表示，分别独立学习仿射光流和分割掩码；然后使用二者去模糊输入事件；最后以去模糊质量作为损失函数替代标注。

Result: 在纯仿射运动的模拟数据集上训练和测试，模型在分割任务中取得了71%的IoU（交并比）和87%的检测率。

Conclusion: 该方法证明了在无标签事件数据上，通过分层动态建模实现自监督运动分割的可行性，在模拟数据上获得了有希望的性能。

Abstract: Event cameras are novel bio-inspired sensors that capture motion dynamics
with much higher temporal resolution than traditional cameras, since pixels
react asynchronously to brightness changes. They are therefore better suited
for tasks involving motion such as motion segmentation. However, training
event-based networks still represents a difficult challenge, as obtaining
ground truth is very expensive, error-prone and limited in frequency. In this
article, we introduce EV-LayerSegNet, a self-supervised CNN for event-based
motion segmentation. Inspired by a layered representation of the scene
dynamics, we show that it is possible to learn affine optical flow and
segmentation masks separately, and use them to deblur the input events. The
deblurring quality is then measured and used as self-supervised learning loss.
We train and test the network on a simulated dataset with only affine motion,
achieving IoU and detection rate up to 71% and 87% respectively.

</details>


### [465] [RARL: Improving Medical VLM Reasoning and Generalization with Reinforcement Learning and LoRA under Data and Hardware Constraints](https://arxiv.org/abs/2506.06600)
*Tan-Hanh Pham,Chris Ngo*

Main category: cs.CV

TL;DR: RARL框架通过强化学习提升医疗图像处理中视觉语言模型的推理能力，在保证计算效率的同时显著提高诊断准确性和解释质量。


<details>
  <summary>Details</summary>
Motivation: 当前医疗视觉语言模型存在泛化性差、透明度低和计算效率低的问题，难以在资源受限环境中部署。

Method: 使用基于Qwen2-VL-2B-Instruct的基础模型，采用低秩适配技术（LoRA）和定制奖励函数进行强化学习微调，奖励函数同时考虑诊断准确性和推理质量。训练在单张NVIDIA A100显卡上完成。

Result: 在医疗影像分析和临床推理任务中，RARL比有监督微调在推理任务上提升约7.78%性能，在未见数据集上比有监督微调和传统RL微调分别提升约27%和4%。实验表明训练时的多样性提示和推理时的推理提示对提升性能至关重要。

Conclusion: 推理引导的学习方法和推理提示技术能显著提升医疗视觉语言模型的透明度、准确性和资源效率，推动临床应用。

Abstract: The growing integration of vision-language models (VLMs) in medical
applications offers promising support for diagnostic reasoning. However,
current medical VLMs often face limitations in generalization, transparency,
and computational efficiency-barriers that hinder deployment in real-world,
resource-constrained settings. To address these challenges, we propose a
Reasoning-Aware Reinforcement Learning framework, \textbf{RARL}, that enhances
the reasoning capabilities of medical VLMs while remaining efficient and
adaptable to low-resource environments. Our approach fine-tunes a lightweight
base model, Qwen2-VL-2B-Instruct, using Low-Rank Adaptation and custom reward
functions that jointly consider diagnostic accuracy and reasoning quality.
Training is performed on a single NVIDIA A100-PCIE-40GB GPU, demonstrating the
feasibility of deploying such models in constrained environments. We evaluate
the model using an LLM-as-judge framework that scores both correctness and
explanation quality. Experimental results show that RARL significantly improves
VLM performance in medical image analysis and clinical reasoning, outperforming
supervised fine-tuning on reasoning-focused tasks by approximately 7.78%, while
requiring fewer computational resources. Additionally, we demonstrate the
generalization capabilities of our approach on unseen datasets, achieving
around 27% improved performance compared to supervised fine-tuning and about 4%
over traditional RL fine-tuning. Our experiments also illustrate that diversity
prompting during training and reasoning prompting during inference are crucial
for enhancing VLM performance. Our findings highlight the potential of
reasoning-guided learning and reasoning prompting to steer medical VLMs toward
more transparent, accurate, and resource-efficient clinical decision-making.
Code and data are publicly available.

</details>


### [466] [Zero Shot Composed Image Retrieval](https://arxiv.org/abs/2506.06602)
*Santhosh Kakarla,Gautama Shastry Bulusu Venkata*

Main category: cs.CV

TL;DR: 改进的BLIP-2模型通过轻量级Q-Former融合视觉和文本特征，在FashionIQ基准测试上将Recall@10提高到45.6%（衬衫）、40.1%（连衣裙）和50.4%（T恤），平均Recall@50达67.6%。而Retrieval-DPO方法因缺乏多模态融合等缺陷仅获0.02% Recall@10。有效的CIR需要多模态融合、排序感知目标和精心筛选的负样本。


<details>
  <summary>Details</summary>
Motivation: 现有零样本组合图像检索（CIR）方法在FashionIQ基准上Recall@10仅为20-25%，需要提升细粒度文本修改后的图像检索性能。

Method: 1) 微调BLIP-2模型，使用轻量级Q-Former融合视觉文本特征生成单嵌入向量；2) 尝试Retrieval-DPO方法：用DPO损失微调CLIP文本编码器，通过FAISS挖掘负样本。

Result: Q-Former方法显著提升指标：衬衫/连衣裙/T恤Recall@10分别达45.6%/40.1%/50.4%，平均Recall@50为67.6%；而Retrieval-DPO仅0.02% Recall@10，远低于基线。

Conclusion: 成功CIR需三个关键因素：真实多模态融合（如Q-Former）、排序感知目标函数（非边界损失）、高质量负样本。Retrieval-DPO因缺乏融合等根本缺陷失败。

Abstract: Composed image retrieval (CIR) allows a user to locate a target image by
applying a fine-grained textual edit (e.g., ``turn the dress blue'' or ``remove
stripes'') to a reference image. Zero-shot CIR, which embeds the image and the
text with separate pretrained vision-language encoders, reaches only 20-25\%
Recall@10 on the FashionIQ benchmark. We improve this by fine-tuning BLIP-2
with a lightweight Q-Former that fuses visual and textual features into a
single embedding, raising Recall@10 to 45.6\% (shirt), 40.1\% (dress), and
50.4\% (top-tee) and increasing the average Recall@50 to 67.6\%. We also
examine Retrieval-DPO, which fine-tunes CLIP's text encoder with a Direct
Preference Optimization loss applied to FAISS-mined hard negatives. Despite
extensive tuning of the scaling factor, index, and sampling strategy,
Retrieval-DPO attains only 0.02\% Recall@10 -- far below zero-shot and
prompt-tuned baselines -- because it (i) lacks joint image-text fusion, (ii)
uses a margin objective misaligned with top-$K$ metrics, (iii) relies on
low-quality negatives, and (iv) keeps the vision and Transformer layers frozen.
Our results show that effective preference-based CIR requires genuine
multimodal fusion, ranking-aware objectives, and carefully curated negatives.

</details>


### [467] [PhysLab: A Benchmark Dataset for Multi-Granularity Visual Parsing of Physics Experiments](https://arxiv.org/abs/2506.06631)
*Minghao Zou,Qingtian Zeng,Yongping Miao,Shangkun Liu,Zilong Wang,Hantao Liu,Wei Zhou*

Main category: cs.CV

TL;DR: 论文介绍了PhysLab，首个记录学生进行复杂物理实验的视频数据集，用于解决现有数据集在注释粒度、领域覆盖和教育场景定制方面的不足，支持细粒度视觉解析。


<details>
  <summary>Details</summary>
Motivation: 现有数据集存在三大局限：注释粒度不足阻碍细粒度场景理解；教育场景覆盖率低；缺乏明确程序性指导。为了填补这些空白，作者提出了PhysLab数据集。

Method: 构建包含620个长视频的数据集，涵盖4项代表性物理实验，提供多层次注释（动作识别、物体检测、HOI分析等）。建立强基线并进行广泛评估。

Result: 数据集公开可用，包含丰富的人-物交互模式和多级标注。基线评估揭示了教育视频解析的关键挑战。

Conclusion: PhysLab可作为推进细粒度视觉解析、智能课堂系统的宝贵资源，促进计算机视觉与教育技术的融合。

Abstract: Visual parsing of images and videos is critical for a wide range of
real-world applications. However, progress in this field is constrained by
limitations of existing datasets: (1) insufficient annotation granularity,
which impedes fine-grained scene understanding and high-level reasoning; (2)
limited coverage of domains, particularly a lack of datasets tailored for
educational scenarios; and (3) lack of explicit procedural guidance, with
minimal logical rules and insufficient representation of structured task
process. To address these gaps, we introduce PhysLab, the first video dataset
that captures students conducting complex physics experiments. The dataset
includes four representative experiments that feature diverse scientific
instruments and rich human-object interaction (HOI) patterns. PhysLab comprises
620 long-form videos and provides multilevel annotations that support a variety
of vision tasks, including action recognition, object detection, HOI analysis,
etc. We establish strong baselines and perform extensive evaluations to
highlight key challenges in the parsing of procedural educational videos. We
expect PhysLab to serve as a valuable resource for advancing fine-grained
visual parsing, facilitating intelligent classroom systems, and fostering
closer integration between computer vision and educational technologies. The
dataset and the evaluation toolkit are publicly available at
https://github.com/ZMH-SDUST/PhysLab.

</details>


### [468] [Dark Channel-Assisted Depth-from-Defocus from a Single Image](https://arxiv.org/abs/2506.06643)
*Moushumi Medhi,Rajiv Ranjan Sahay*

Main category: cs.CV

TL;DR: 提出了一种基于暗通道先验的单幅图像离焦深度估计方法，利用暗通道作为辅助线索结合局部离焦模糊与对比度变化的关系，以端到端对抗训练方式实现场景深度估计。


<details>
  <summary>Details</summary>
Motivation: 现有深度估计方法通常依赖多幅不同焦距/光圈图像，而单幅离焦图像深度估计由于病态性问题研究较少。暗通道能有效捕捉模糊图像的局部统计特性和场景结构。

Method: 利用暗通道先验建立局部离焦模糊与对比度变化的关联作为深度线索，采用端到端对抗训练框架。

Result: 在真实数据集测试表明，引入暗通道先验的单幅图像离焦深度估计能获得有意义的深度图。

Conclusion: 暗通道先验可有效解决单幅离焦图像深度估计问题，验证了方法的有效性。

Abstract: In this paper, we utilize the dark channel as a complementary cue to estimate
the depth of a scene from a single space-variant defocus blurred image due to
its effectiveness in implicitly capturing the local statistics of blurred
images and the scene structure. Existing depth-from-defocus (DFD) techniques
typically rely on multiple images with varying apertures or focus settings to
recover depth information. Very few attempts have focused on DFD from a single
defocused image due to the underconstrained nature of the problem. Our method
capitalizes on the relationship between local defocus blur and contrast
variations as key depth cues to enhance the overall performance in estimating
the scene's structure. The entire pipeline is trained adversarially in a fully
end-to-end fashion. Experiments conducted on real data with realistic
depth-induced defocus blur demonstrate that incorporating dark channel prior
into single image DFD yields meaningful depth estimation results, validating
the effectiveness of our approach.

</details>


### [469] [Parametric Gaussian Human Model: Generalizable Prior for Efficient and Realistic Human Avatar Modeling](https://arxiv.org/abs/2506.06645)
*Cheng Peng,Jingxiang Sun,Yushuo Chen,Zhaoqi Su,Zhuo Su,Yebin Liu*

Main category: cs.CV

TL;DR: 提出参数化高斯人体模型（PGHM），一个可泛化且高效的框架，将人体先验集成到3D高斯泼溅（3DGS）中，用于从单眼视频快速重建高保真度化身。核心创新包括UV对齐隐式身份映射和分离式多头U-Net，能在挑战性姿势下保证渲染质量，实现约20分钟/人的高效适应性。


<details>
  <summary>Details</summary>
Motivation: 现有3D高斯泼溅方法存在两大问题：需要耗时的逐主体优化；对稀疏单眼输入泛化能力差。需要开发一个结合人体先验的通用框架，实现快速高保真度单眼化身重建。

Method: 1. UV对齐隐式身份映射：将特定主体的几何和外观紧凑编码为可学习特征张量；2. 分离式多头U-Net：通过条件解码器分解静态、姿势相关和视角相关组件预测高斯属性。

Result: PGHM比从头优化方法显著高效（约20分钟/主体），且在挑战性姿势和视角下保持稳健渲染质量。视觉质量与传统方法相当，实现了单眼化身重建的实用价值。

Conclusion: PGHM证明将人体先验融入3DGS的框架可克服现有缺陷，实现快速高质量单眼化身重建。其高效性（20分钟/主体）为AR/VR等领域提供了实用解决方案。

Abstract: Photorealistic and animatable human avatars are a key enabler for
virtual/augmented reality, telepresence, and digital entertainment. While
recent advances in 3D Gaussian Splatting (3DGS) have greatly improved rendering
quality and efficiency, existing methods still face fundamental challenges,
including time-consuming per-subject optimization and poor generalization under
sparse monocular inputs. In this work, we present the Parametric Gaussian Human
Model (PGHM), a generalizable and efficient framework that integrates human
priors into 3DGS for fast and high-fidelity avatar reconstruction from
monocular videos. PGHM introduces two core components: (1) a UV-aligned latent
identity map that compactly encodes subject-specific geometry and appearance
into a learnable feature tensor; and (2) a disentangled Multi-Head U-Net that
predicts Gaussian attributes by decomposing static, pose-dependent, and
view-dependent components via conditioned decoders. This design enables robust
rendering quality under challenging poses and viewpoints, while allowing
efficient subject adaptation without requiring multi-view capture or long
optimization time. Experiments show that PGHM is significantly more efficient
than optimization-from-scratch methods, requiring only approximately 20 minutes
per subject to produce avatars with comparable visual quality, thereby
demonstrating its practical applicability for real-world monocular avatar
creation.

</details>


### [470] [Flood-DamageSense: Multimodal Mamba with Multitask Learning for Building Flood Damage Assessment using SAR Remote Sensing Imagery](https://arxiv.org/abs/2506.06667)
*Yu-Hsuan Ho,Ali Mostafavi*

Main category: cs.CV

TL;DR: 提出首个专注于建筑级洪水损害评估的深度学习框架Flood-DamageSense


<details>
  <summary>Details</summary>
Motivation: 解决现有模型因洪水损害缺乏明显光谱/结构特征而表现不佳的问题

Method: 融合灾前/灾后SAR/InSAR影像、高分辨率光学底图及洪水风险层，采用多模态Mamba架构联合预测建筑损伤状态/洪水范围/建筑轮廓

Result: 在哈维飓风数据集上F1分数提升19个百分点，在轻微/中度损伤类别改进最显著

Conclusion: 风险感知建模结合SAR全天候能力，可快速生成建筑级损伤地图支持灾后决策

Abstract: Most post-disaster damage classifiers succeed only when destructive forces
leave clear spectral or structural signatures -- conditions rarely present
after inundation. Consequently, existing models perform poorly at identifying
flood-related building damages. The model presented in this study,
Flood-DamageSense, addresses this gap as the first deep-learning framework
purpose-built for building-level flood-damage assessment. The architecture
fuses pre- and post-event SAR/InSAR scenes with very-high-resolution optical
basemaps and an inherent flood-risk layer that encodes long-term exposure
probabilities, guiding the network toward plausibly affected structures even
when compositional change is minimal. A multimodal Mamba backbone with a
semi-Siamese encoder and task-specific decoders jointly predicts (1) graded
building-damage states, (2) floodwater extent, and (3) building footprints.
Training and evaluation on Hurricane Harvey (2017) imagery from Harris County,
Texas -- supported by insurance-derived property-damage extents -- show a mean
F1 improvement of up to 19 percentage points over state-of-the-art baselines,
with the largest gains in the frequently misclassified "minor" and "moderate"
damage categories. Ablation studies identify the inherent-risk feature as the
single most significant contributor to this performance boost. An end-to-end
post-processing pipeline converts pixel-level outputs to actionable,
building-scale damage maps within minutes of image acquisition. By combining
risk-aware modeling with SAR's all-weather capability, Flood-DamageSense
delivers faster, finer-grained, and more reliable flood-damage intelligence to
support post-disaster decision-making and resource allocation.

</details>


### [471] [Interpretation of Deep Learning Model in Embryo Selection for In Vitro Fertilization (IVF) Treatment](https://arxiv.org/abs/2506.06680)
*Radha Kodali,Venkata Rao Dhulipalla,Venkata Siva Kishor Tatavarty,Madhavi Nadakuditi,Bharadwaj Thiruveedhula,Suryanarayana Gunnam,Durga Prasad Bavirisetti*

Main category: cs.CV

TL;DR: 提出了一种基于卷积神经网络（CNN）和长短期记忆网络（LSTM）的可解释人工智能框架（XAI），用于提高胚胎分类的准确性和效率。


<details>
  <summary>Details</summary>
Motivation: 解决辅助生殖领域胚胎人工评估效率低的问题。

Method: 融合CNN-LSTM模型的可解释AI框架

Result: 在保持可解释性的同时实现高精度胚胎分类

Conclusion: 该框架为胚胎选择提供高效准确的技术支持

Abstract: Infertility has a considerable impact on individuals' quality of life,
affecting them socially and psychologically, with projections indicating a rise
in the upcoming years. In vitro fertilization (IVF) emerges as one of the
primary techniques within economically developed nations, employed to address
the rising problem of low fertility. Expert embryologists conventionally grade
embryos by reviewing blastocyst images to select the most optimal for transfer,
yet this process is time-consuming and lacks efficiency. Blastocyst images
provide a valuable resource for assessing embryo viability. In this study, we
introduce an explainable artificial intelligence (XAI) framework for
classifying embryos, employing a fusion of convolutional neural network (CNN)
and long short-term memory (LSTM) architecture, referred to as CNN-LSTM.
Utilizing deep learning, our model achieves high accuracy in embryo
classification while maintaining interpretability through XAI.

</details>


### [472] [A Systematic Investigation on Deep Learning-Based Omnidirectional Image and Video Super-Resolution](https://arxiv.org/abs/2506.06710)
*Qianqian Zhao,Chunle Guo,Tianyi Zhang,Junpei Zhang,Peiyang Jia,Tan Su,Wenjie Jiang,Chongyi Li*

Main category: cs.CV

TL;DR: 本文概述了全向图像和视频超分辨率的深度学习方法，介绍了新数据集360Insta以弥补现有合成数据集的不足，并对现有方法进行了全面评估。


<details>
  <summary>Details</summary>
Motivation: 现有的全向超分辨率数据集主要依赖合成退化，无法捕捉真实世界的失真，因此需要引入真实退化数据来更稳健地评估方法的泛化能力。

Method: 提出了360Insta数据集，包含不同光照、运动和曝光条件下真实采集的低质全向图像/视频；在此基础上对现有方法进行定性和定量评估。

Result: 新数据集揭示了当前方法在真实场景中的泛化缺陷；实验表明现有方法在合成数据集上表现良好但在真实数据上显著下降。

Conclusion: 真实退化数据集对于评估全向超分辨率方法至关重要；未来研究应关注模型在真实场景的鲁棒性及新网络架构设计。

Abstract: Omnidirectional image and video super-resolution is a crucial research topic
in low-level vision, playing an essential role in virtual reality and augmented
reality applications. Its goal is to reconstruct high-resolution images or
video frames from low-resolution inputs, thereby enhancing detail preservation
and enabling more accurate scene analysis and interpretation. In recent years,
numerous innovative and effective approaches have been proposed, predominantly
based on deep learning techniques, involving diverse network architectures,
loss functions, projection strategies, and training datasets. This paper
presents a systematic review of recent progress in omnidirectional image and
video super-resolution, focusing on deep learning-based methods. Given that
existing datasets predominantly rely on synthetic degradation and fall short in
capturing real-world distortions, we introduce a new dataset, 360Insta, that
comprises authentically degraded omnidirectional images and videos collected
under diverse conditions, including varying lighting, motion, and exposure
settings. This dataset addresses a critical gap in current omnidirectional
benchmarks and enables more robust evaluation of the generalization
capabilities of omnidirectional super-resolution methods. We conduct
comprehensive qualitative and quantitative evaluations of existing methods on
both public datasets and our proposed dataset. Furthermore, we provide a
systematic overview of the current status of research and discuss promising
directions for future exploration. All datasets, methods, and evaluation
metrics introduced in this work are publicly available and will be regularly
updated. Project page: https://github.com/nqian1/Survey-on-ODISR-and-ODVSR.

</details>


### [473] [Active Contour Models Driven by Hyperbolic Mean Curvature Flow for Image Segmentation](https://arxiv.org/abs/2506.06712)
*Saiyu Hu,Chunlei He,Jianfeng Zhang,Dexing Kong,Shoujun Huang*

Main category: cs.CV

TL;DR: 本文提出了一种新型超曲率流驱动的主动轮廓模型（HMCF-ACMs），通过引入可调节的初始速度场提升图像分割效果，并开发了抗噪性更强的双模正则化模型（HDRF-ACMs）。


<details>
  <summary>Details</summary>
Motivation: 传统抛物线形平均曲率流驱动的主动轮廓模型（PMCF-ACMs）对初始曲线配置敏感，难以适应多样化的分割场景。

Method: 1. 提出超曲率流驱动的主动轮廓模型（HMCF-ACMs）引入初始速度场
2. 建立耗散型HMCF与特定波动方程的数值等价关系
3. 开发使用平滑Heaviside函数抑制弱边界过扩散的双模正则化模型（HDRF-ACMs）
4. 优化带九点格式的加权四阶Runge-Kutta算法求解波动方程

Result: HMCF-ACMs和HDRF-ACMs在分割精度、噪声抗扰性和数值稳定性方面均表现更优，尤其适应不同初始速度场与初始轮廓配置。

Conclusion: 超曲率驱动模型通过可调节初始速度场实现了任务自适应分割，双模正则化进一步增强弱边界处理能力，为复杂场景图像分割提供新思路。

Abstract: Parabolic mean curvature flow-driven active contour models (PMCF-ACMs) are
widely used in image segmentation, which however depend heavily on the
selection of initial curve configurations. In this paper, we firstly propose
several hyperbolic mean curvature flow-driven ACMs (HMCF-ACMs), which introduce
tunable initial velocity fields, enabling adaptive optimization for diverse
segmentation scenarios. We shall prove that HMCF-ACMs are indeed normal flows
and establish the numerical equivalence between dissipative HMCF formulations
and certain wave equations using the level set method with signed distance
function. Building on this framework, we furthermore develop hyperbolic
dual-mode regularized flow-driven ACMs (HDRF-ACMs), which utilize smooth
Heaviside functions for edge-aware force modulation to suppress over-diffusion
near weak boundaries. Then, we optimize a weighted fourth-order Runge-Kutta
algorithm with nine-point stencil spatial discretization when solving the
above-mentioned wave equations. Experiments show that both HMCF-ACMs and
HDRF-ACMs could achieve more precise segmentations with superior noise
resistance and numerical stability due to task-adaptive configurations of
initial velocities and initial contours.

</details>


### [474] [Improving Wildlife Out-of-Distribution Detection: Africas Big Five](https://arxiv.org/abs/2506.06719)
*Mufhumudzi Muthivhi,Jiahao Huo,Fredrik Gustafsson,Terence L. van Zyl*

Main category: cs.CV

TL;DR: 该论文研究了野生动物（特别是非洲五霸）的分布外（OOD）检测问题。现有动物分类模型在封闭世界假设下训练，对未知类过度自信。作者比较了参数化NCM方法和非参数化对比学习方法，发现基于特征的方法（尤其是使用ImageNet预训练的NCM）在多个指标上显著优于其他OOD方法。


<details>
  <summary>Details</summary>
Motivation: 当前动物分类模型基于封闭世界假设，对未知类别过度自信，这在野生动物多样性环境中存在局限。为解决实际问题中可能出现的未知物种识别问题，需要开发有效的OOD检测方法。

Method: 1) 采用参数化的最近类均值（NCM）方法；2）非参数化对比学习方法；3）比较多种常见OOD检测方法；4）使用预训练和投影特征。

Result: 基于特征的方法展现更强泛化能力：使用ImageNet预训练的NCM方法在AUPR-IN、AUPR-OUT和AUTC指标上分别比最佳OOD方法提升2%、4%和22%。

Conclusion: 在野生动物OOD检测任务中，特征方法（尤其是NCM+ImageNet预训练）显著优于传统OOD方法，为解决开放世界野生动物识别提供了有效方案。

Abstract: Mitigating human-wildlife conflict seeks to resolve unwanted encounters
between these parties. Computer Vision provides a solution to identifying
individuals that might escalate into conflict, such as members of the Big Five
African animals. However, environments often contain several varied species.
The current state-of-the-art animal classification models are trained under a
closed-world assumption. They almost always remain overconfident in their
predictions even when presented with unknown classes. This study investigates
out-of-distribution (OOD) detection of wildlife, specifically the Big Five. To
this end, we select a parametric Nearest Class Mean (NCM) and a non-parametric
contrastive learning approach as baselines to take advantage of pretrained and
projected features from popular classification encoders. Moreover, we compare
our baselines to various common OOD methods in the literature. The results show
feature-based methods reflect stronger generalisation capability across varying
classification thresholds. Specifically, NCM with ImageNet pre-trained features
achieves a 2%, 4% and 22% improvement on AUPR-IN, AUPR-OUT and AUTC over the
best OOD methods, respectively. The code can be found here
https://github.com/pxpana/BIG5OOD

</details>


### [475] [Mitigating Object Hallucination via Robust Local Perception Search](https://arxiv.org/abs/2506.06729)
*Zixian Gao,Chao Yang,Zhanhui Zhou,Xing Xu,Chaochao Lu*

Main category: cs.CV

TL;DR: 本文提出了一种名为局部感知搜索（LPS）的训练免费解码方法，通过利用局部视觉先验信息来减少多模态大语言模型中的幻觉现象。


<details>
  <summary>Details</summary>
Motivation: 尽管MLLMs在视觉语言任务中表现出色，但仍存在输出与图像内容不实的幻觉问题，需要一种有效且无需训练的方法来抑制此类现象。

Method: LPS在推理阶段引入局部视觉先验作为价值函数来修正解码过程，是一种即插即用的解码策略。

Result: 在标准幻觉基准测试和高噪声数据上的实验表明，LPS显著降低了幻觉发生率，尤其在噪声环境下表现优异。

Conclusion: LPS提供了一种简单有效、模型无关的幻觉抑制方案，特别适用于含噪声场景的多模态任务。

Abstract: Recent advancements in Multimodal Large Language Models (MLLMs) have enabled
them to effectively integrate vision and language, addressing a variety of
downstream tasks. However, despite their significant success, these models
still exhibit hallucination phenomena, where the outputs appear plausible but
do not align with the content of the images. To mitigate this issue, we
introduce Local Perception Search (LPS), a decoding method during inference
that is both simple and training-free, yet effectively suppresses
hallucinations. This method leverages local visual prior information as a value
function to correct the decoding process. Additionally, we observe that the
impact of the local visual prior on model performance is more pronounced in
scenarios with high levels of image noise. Notably, LPS is a plug-and-play
approach that is compatible with various models. Extensive experiments on
widely used hallucination benchmarks and noisy data demonstrate that LPS
significantly reduces the incidence of hallucinations compared to the baseline,
showing exceptional performance, particularly in noisy settings.

</details>


### [476] [RecipeGen: A Step-Aligned Multimodal Benchmark for Real-World Recipe Generation](https://arxiv.org/abs/2506.06733)
*Ruoxuan Zhang,Jidong Gao,Bin Wen,Hongxia Xie,Chenming Zhang,Honghan-shuai,Wen-Huang Cheng*

Main category: cs.CV

TL;DR: RecipeGen is the first large-scale benchmark for recipe-based image and video generation, addressing the lack of aligned datasets. It includes recipes, images, and videos with domain-specific metrics for evaluation.


<details>
  <summary>Details</summary>
Motivation: Existing datasets lack fine-grained alignment between recipe steps and visual content, which is crucial for applications like culinary education and recipe assistants.

Method: RecipeGen provides a benchmark with 26,453 recipes, 196,724 images, and 4,491 videos. It introduces domain-specific metrics to evaluate ingredient fidelity and interaction modeling.

Result: The dataset covers diverse ingredients, cooking procedures, styles, and dish types. The paper benchmarks existing T2I, I2V, and T2V models and provides insights for future models.

Conclusion: RecipeGen fills a gap in food computing by providing a comprehensive real-world benchmark, and the proposed metrics and evaluations offer guidance for improving recipe-based generation models.

Abstract: Creating recipe images is a key challenge in food computing, with
applications in culinary education and multimodal recipe assistants. However,
existing datasets lack fine-grained alignment between recipe goals, step-wise
instructions, and visual content. We present RecipeGen, the first large-scale,
real-world benchmark for recipe-based Text-to-Image (T2I), Image-to-Video
(I2V), and Text-to-Video (T2V) generation. RecipeGen contains 26,453 recipes,
196,724 images, and 4,491 videos, covering diverse ingredients, cooking
procedures, styles, and dish types. We further propose domain-specific
evaluation metrics to assess ingredient fidelity and interaction modeling,
benchmark representative T2I, I2V, and T2V models, and provide insights for
future recipe generation models. Project page is available now.

</details>


### [477] [THU-Warwick Submission for EPIC-KITCHEN Challenge 2025: Semi-Supervised Video Object Segmentation](https://arxiv.org/abs/2506.06748)
*Mingqi Gao,Haoran Duan,Tianlu Zhang,Jungong Han*

Main category: cs.CV

TL;DR: 结合SAM视觉预训练和深度几何线索实现了90.1%分割准确率


<details>
  <summary>Details</summary>
Motivation: 解决自我中心视频中复杂场景和长期目标分割的挑战

Method: 集成大规模视觉预训练（SAM2）和深度几何线索的统一框架

Result: 在VISOR测试集上J&F达到90.1%

Conclusion: 多模态信号融合有效提升自我中心视频目标分割性能

Abstract: In this report, we describe our approach to egocentric video object
segmentation. Our method combines large-scale visual pretraining from SAM2 with
depth-based geometric cues to handle complex scenes and long-term tracking. By
integrating these signals in a unified framework, we achieve strong
segmentation performance. On the VISOR test set, our method reaches a J&F score
of 90.1%.

</details>


### [478] [SAR2Struct: Extracting 3D Semantic Structural Representation of Aircraft Targets from Single-View SAR Image](https://arxiv.org/abs/2506.06757)
*Ziyu Yue,Ruixi You,Feng Xu*

Main category: cs.CV

TL;DR: 本文提出了一种新的SAR目标结构恢复任务，通过两步算法框架从单视角SAR图像推断目标组件及其结构关系（对称性和邻接性），并实验验证了首次直接从SAR图像获取3D语义结构的能力。


<details>
  <summary>Details</summary>
Motivation: 现有SAR图像解释方法集中于3D重建或局部特征提取，忽略了结构建模在捕获语义信息中的作用，无法实现可解释的高级信息检索。

Method: 提出两步算法框架：1）训练阶段从真实SAR图像检测2D关键点，并利用模拟数据学习关键点到3D分层结构的映射；2）测试阶段整合上述步骤从真实SAR图像推断3D结构。

Result: 实验验证了各步骤有效性，首次证实可直接从单视角SAR图像获取飞机目标的3D语义结构表示。

Conclusion: 该框架通过跨样本学习结构一致性与几何多样性，实现了SAR图像到目标语义的直接推断，为SAR高级信息检索提供新方向。

Abstract: To translate synthetic aperture radar (SAR) image into interpretable forms
for human understanding is the ultimate goal of SAR advanced information
retrieval. Existing methods mainly focus on 3D surface reconstruction or local
geometric feature extraction of targets, neglecting the role of structural
modeling in capturing semantic information. This paper proposes a novel task:
SAR target structure recovery, which aims to infer the components of a target
and the structural relationships between its components, specifically symmetry
and adjacency, from a single-view SAR image. Through learning the structural
consistency and geometric diversity across the same type of targets as observed
in different SAR images, it aims to derive the semantic representation of
target directly from its 2D SAR image. To solve this challenging task, a
two-step algorithmic framework based on structural descriptors is developed.
Specifically, in the training phase, it first detects 2D keypoints from real
SAR images, and then learns the mapping from these keypoints to 3D hierarchical
structures using simulated data. During the testing phase, these two steps are
integrated to infer the 3D structure from real SAR images. Experimental results
validated the effectiveness of each step and demonstrated, for the first time,
that 3D semantic structural representation of aircraft targets can be directly
derived from a single-view SAR image.

</details>


### [479] [LitMAS: A Lightweight and Generalized Multi-Modal Anti-Spoofing Framework for Biometric Security](https://arxiv.org/abs/2506.06759)
*Nidheesh Gorthi,Kartik Thakral,Rishabh Ranjan,Richa Singh,Mayank Vatsa*

Main category: cs.CV

TL;DR: LitMAS提案了一个轻量级、可泛化的多模态防伪框架，用于检测语音、人脸、虹膜和指纹的欺骗攻击，通过模态对齐损失提升效果，仅用600万参数量在7个数据集上平均EER领先SOTA方法1.36%。


<details>
  <summary>Details</summary>
Motivation: 当前生物特征防伪技术多为模态专用方案，缺乏跨模态的统一轻量化解决方案。

Method: 设计轻量级框架LitMAS，核心是模态对齐聚焦损失函数，增强类间区分度同时保持跨模态一致性。

Result: 在七大数据集上平均EER达到1.36%的领先，模型参数量仅600万，适合边缘部署。

Conclusion: LitMAS实现了高效、可泛化的多模态防伪，为边缘设备生物认证提供了可行方案。

Abstract: Biometric authentication systems are increasingly being deployed in critical
applications, but they remain susceptible to spoofing. Since most of the
research efforts focus on modality-specific anti-spoofing techniques, building
a unified, resource-efficient solution across multiple biometric modalities
remains a challenge. To address this, we propose LitMAS, a
$\textbf{Li}$gh$\textbf{t}$ weight and generalizable $\textbf{M}$ulti-modal
$\textbf{A}$nti-$\textbf{S}$poofing framework designed to detect spoofing
attacks in speech, face, iris, and fingerprint-based biometric systems. At the
core of LitMAS is a Modality-Aligned Concentration Loss, which enhances
inter-class separability while preserving cross-modal consistency and enabling
robust spoof detection across diverse biometric traits. With just 6M
parameters, LitMAS surpasses state-of-the-art methods by $1.36\%$ in average
EER across seven datasets, demonstrating high efficiency, strong
generalizability, and suitability for edge deployment. Code and trained models
are available at https://github.com/IAB-IITJ/LitMAS.

</details>


### [480] [LoopDB: A Loop Closure Dataset for Large Scale Simultaneous Localization and Mapping](https://arxiv.org/abs/2506.06771)
*Mohammad-Maher Nakshbandi,Ziad Sharawy,Dorian Cojocaru,Sorin Grigorescu*

Main category: cs.CV

TL;DR: 本文介绍了LoopDB数据集，包含1000+张不同环境下的图像序列，每场景5张连续图像，用于SLAM中的闭环检测算法评估与深度学习训练。


<details>
  <summary>Details</summary>
Motivation: 目前的闭环检测缺乏高质量、多环境的基准数据集，为支持算法开发和评估，作者创建了LoopDB。

Method: 使用高清相机采集多环境下的图像序列，提供场景连续图像间的旋转平移矩阵作为真值。

Result: 构建了包含公园/室内/停车场/物体中心等场景的闭环数据集LoopDB。

Conclusion: LoopDB可用于深度学习闭环检测算法的训练与评估，已开源。

Abstract: In this study, we introduce LoopDB, which is a challenging loop closure
dataset comprising over 1000 images captured across diverse environments,
including parks, indoor scenes, parking spaces, as well as centered around
individual objects. Each scene is represented by a sequence of five consecutive
images. The dataset was collected using a high resolution camera, providing
suitable imagery for benchmarking the accuracy of loop closure algorithms,
typically used in simultaneous localization and mapping. As ground truth
information, we provide computed rotations and translations between each
consecutive images. Additional to its benchmarking goal, the dataset can be
used to train and fine-tune loop closure methods based on deep neural networks.
LoopDB is publicly available at https://github.com/RovisLab/LoopDB.

</details>


### [481] [Continuous-Time SO(3) Forecasting with Savitzky--Golay Neural Controlled Differential Equations](https://arxiv.org/abs/2506.06780)
*Lennart Bastian,Mohammad Rashed,Nassir Navab,Tolga Birdal*

Main category: cs.CV

TL;DR: 该论文提出了一种在SO(3)上建模连续时间旋转物体动力学的方法，使用神经控制微分方程和Savitzky-Golay路径，相比现有方法在真实数据上表现出更优的预测能力。


<details>
  <summary>Details</summary>
Motivation: 当前SO(3)外推面临三个挑战：传感器观测可能嘈杂稀疏、运动模式可能受复杂动力学支配、应用场景可能要求长期预测。现有方法依赖于简化的运动假设。

Method: 采用神经控制微分方程（Neural CDE）建模连续时间旋转动力学，利用Savitzky-Golay路径引导，在保持旋转几何结构的同时学习潜在动态系统。

Result: 在真实世界数据上的实验表明，该方法比现有方法具有更出色的预测性能。

Conclusion: 所提出的结合几何约束和神经CDE的方法能够有效解决旋转物体动态建模中的三个核心挑战，为长期旋转运动预测提供了新方向。

Abstract: Tracking and forecasting the rotation of objects is fundamental in computer
vision and robotics, yet SO(3) extrapolation remains challenging as (1) sensor
observations can be noisy and sparse, (2) motion patterns can be governed by
complex dynamics, and (3) application settings can demand long-term
forecasting. This work proposes modeling continuous-time rotational object
dynamics on $SO(3)$ using Neural Controlled Differential Equations guided by
Savitzky-Golay paths. Unlike existing methods that rely on simplified motion
assumptions, our method learns a general latent dynamical system of the
underlying object trajectory while respecting the geometric structure of
rotations. Experimental results on real-world data demonstrate compelling
forecasting capabilities compared to existing approaches.

</details>


### [482] [Training-Free Identity Preservation in Stylized Image Generation Using Diffusion Models](https://arxiv.org/abs/2506.06802)
*Mohammad Ali Rezaei,Helia Hajikazem,Saeed Khanehgir,Mahdi Javanmardi*

Main category: cs.CV

TL;DR: 提出了一种无需训练的扩散模型框架，用于身份保持的风格化图像合成。通过使用"马赛克恢复内容图像"技术和内容一致性损失，在保持高风格保真度的同时增强身份保留，尤其在面部区域小或相机距离远的情况下表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有风格迁移技术在保持身份特征方面存在不足，尤其是在面部区域较小或相机距离较远的图像中。扩散模型具有强大的生成能力，但需要在身份保持方面进行改进。

Method: 提出了两种核心技术：(1) "马赛克恢复内容图像"技术，增强了复杂场景中的身份保留；(2) 无需训练的内容一致性损失，通过引导模型更多关注原始图像细节来保持细粒度内容。整个框架无需微调或重新训练模型。

Result: 该方法显著超越基线模型，在保持高风格保真度的同时实现了更强的身份完整性，尤其在小面部区域或大相机距离场景下表现突出。

Conclusion: 该框架为扩散模型的真实身份保持风格化提供了一种高效的无训练解决方案，有效解决了现有方法难以同时兼顾风格质量和身份保留的难题，在复杂场景中表现出优越性能。

Abstract: While diffusion models have demonstrated remarkable generative capabilities,
existing style transfer techniques often struggle to maintain identity while
achieving high-quality stylization. This limitation is particularly acute for
images where faces are small or exhibit significant camera-to-face distances,
frequently leading to inadequate identity preservation. To address this, we
introduce a novel, training-free framework for identity-preserved stylized
image synthesis using diffusion models. Key contributions include: (1) the
"Mosaic Restored Content Image" technique, significantly enhancing identity
retention, especially in complex scenes; and (2) a training-free content
consistency loss that enhances the preservation of fine-grained content details
by directing more attention to the original image during stylization. Our
experiments reveal that the proposed approach substantially surpasses the
baseline model in concurrently maintaining high stylistic fidelity and robust
identity integrity, particularly under conditions of small facial regions or
significant camera-to-face distances, all without necessitating model
retraining or fine-tuning.

</details>


### [483] [Stepwise Decomposition and Dual-stream Focus: A Novel Approach for Training-free Camouflaged Object Segmentation](https://arxiv.org/abs/2506.06818)
*Chao Yin,Hao Li,Kequan Yang,Jide Li,Pinpin Zhu,Xiaoqiang Li*

Main category: cs.CV

TL;DR: 本文提出了RDVP-MSD框架，解决在伪装物体分割（COS）中语义歧义和空间分离的问题。该框架使用训练免费的自适应方法，在多基准测试中达到了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 现有可提示分割方法（如SAM）需要手动为每个对象提供视觉提示，而任务通用提示分割方法在应用于伪装物体分割时仍面临两个问题：1）语义歧义——整体标注无法提供足够区分的线索，导致前景-背景混淆；2）语义差异与空间分离——背景采样远离对象边界，导致SAM分割不相关区域。

Method: 提出训练免费的测试时自适应框架RDVP-MSD，结合区域约束双流视觉提示（RDVP）和多模态逐步分解思维链（MSD-CoT）。MSD-CoT逐步解开图像标注以消除语义歧义；RDVP为前景和背景点分别采样视觉提示，注入空间约束并缓解语义差异和空间分离。

Result: 无需训练或监督，在多个COS基准测试中达到了最先进的分割结果，推理速度更快，精度和效率显著提升。

Conclusion: RDVP-MSD有效解决了语义歧义和空间分离问题，在伪装物体分割任务上实现了高性能和高效率，且无需额外训练。

Abstract: While promptable segmentation (\textit{e.g.}, SAM) has shown promise for
various segmentation tasks, it still requires manual visual prompts for each
object to be segmented. In contrast, task-generic promptable segmentation aims
to reduce the need for such detailed prompts by employing only a task-generic
prompt to guide segmentation across all test samples. However, when applied to
Camouflaged Object Segmentation (COS), current methods still face two critical
issues: 1) \textit{\textbf{semantic ambiguity in getting instance-specific text
prompts}}, which arises from insufficient discriminative cues in holistic
captions, leading to foreground-background confusion; 2)
\textit{\textbf{semantic discrepancy combined with spatial separation in
getting instance-specific visual prompts}}, which results from global
background sampling far from object boundaries with low feature correlation,
causing SAM to segment irrelevant regions. To address the issues above, we
propose \textbf{RDVP-MSD}, a novel training-free test-time adaptation framework
that synergizes \textbf{R}egion-constrained \textbf{D}ual-stream
\textbf{V}isual \textbf{P}rompting (RDVP) via \textbf{M}ultimodal
\textbf{S}tepwise \textbf{D}ecomposition Chain of Thought (MSD-CoT). MSD-CoT
progressively disentangles image captions to eliminate semantic ambiguity,
while RDVP injects spatial constraints into visual prompting and independently
samples visual prompts for foreground and background points, effectively
mitigating semantic discrepancy and spatial separation. Without requiring any
training or supervision, RDVP-MSD achieves a state-of-the-art segmentation
result on multiple COS benchmarks and delivers a faster inference speed than
previous methods, demonstrating significantly improved accuracy and efficiency.
The codes will be available at
\href{https://github.com/ycyinchao/RDVP-MSD}{https://github.com/ycyinchao/RDVP-MSD}

</details>


### [484] [Hi-LSplat: Hierarchical 3D Language Gaussian Splatting](https://arxiv.org/abs/2506.06822)
*Chenlu Zhan,Yufei Zhang,Gaoang Wang,Hongwei Wang*

Main category: cs.CV

TL;DR: Hi-LSplat is proposed to solve view inconsistency and hierarchical semantic challenges in 3D language fields using Gaussian Splatting.


<details>
  <summary>Details</summary>
Motivation: Recent 3DGS-based models suffer from view inconsistencies due to reliance on 2D foundation models and open-vocabulary issues hindering hierarchical semantic understanding.

Method: Lifts 2D features to 3D via hierarchical semantic tree with layered clustering; introduces instance-wise/part-wise contrastive losses; uses specialized datasets.

Result: Demonstrates superiority in 3D open-vocabulary segmentation/localization and strong hierarchical semantic capture.

Conclusion: Hi-LSplat effectively addresses view consistency and hierarchical semantics, enhancing 3D scene understanding.

Abstract: Modeling 3D language fields with Gaussian Splatting for open-ended language
queries has recently garnered increasing attention. However, recent 3DGS-based
models leverage view-dependent 2D foundation models to refine 3D semantics but
lack a unified 3D representation, leading to view inconsistencies.
Additionally, inherent open-vocabulary challenges cause inconsistencies in
object and relational descriptions, impeding hierarchical semantic
understanding. In this paper, we propose Hi-LSplat, a view-consistent
Hierarchical Language Gaussian Splatting work for 3D open-vocabulary querying.
To achieve view-consistent 3D hierarchical semantics, we first lift 2D features
to 3D features by constructing a 3D hierarchical semantic tree with layered
instance clustering, which addresses the view inconsistency issue caused by 2D
semantic features. Besides, we introduce instance-wise and part-wise
contrastive losses to capture all-sided hierarchical semantic representations.
Notably, we construct two hierarchical semantic datasets to better assess the
model's ability to distinguish different semantic levels. Extensive experiments
highlight our method's superiority in 3D open-vocabulary segmentation and
localization. Its strong performance on hierarchical semantic datasets
underscores its ability to capture complex hierarchical semantics within 3D
scenes.

</details>


### [485] [Exploring Visual Prompting: Robustness Inheritance and Beyond](https://arxiv.org/abs/2506.06823)
*Qi Li,Liangzhi Li,Zhouqiang Jiang,Bowen Wang,Keke Tang*

Main category: cs.CV

TL;DR: 论文探讨了在源模型具有鲁棒性的情况下，视觉提示（VP）能否继承鲁棒性及是否存在鲁棒性与泛化能力的权衡问题，并提出了一种减轻这种权衡的策略Prompt Boundary Loosening (PBL)。


<details>
  <summary>Details</summary>
Motivation: 现有的视觉提示研究集中于标准源模型，尚未探究其在鲁棒源模型下的表现：是否继承鲁棒性，是否存在鲁棒性与泛化能力的权衡，以及能否针对VP设计缓解策略。

Method: 提出Prompt Boundary Loosening (PBL)，一种轻量级即插即用策略，兼容VP，确保继承源模型鲁棒性的同时增强下游任务泛化能力。

Result: 跨数据集实验证明VP在鲁棒源模型下存在权衡，且PBL策略能有效减轻该限制。

Conclusion: 首次系统解答了关于VP继承模型鲁棒性的三个核心问题，并通过PBL策略在保持鲁棒性的同时显著提升泛化能力。

Abstract: Visual Prompting (VP), an efficient method for transfer learning, has shown
its potential in vision tasks. However, previous works focus exclusively on VP
from standard source models, it is still unknown how it performs under the
scenario of a robust source model: Can the robustness of the source model be
successfully inherited? Does VP also encounter the same trade-off between
robustness and generalization ability as the source model during this process?
If such a trade-off exists, is there a strategy specifically tailored to VP to
mitigate this limitation? In this paper, we thoroughly explore these three
questions for the first time and provide affirmative answers to them. To
mitigate the trade-off faced by VP, we propose a strategy called Prompt
Boundary Loosening (PBL). As a lightweight, plug-and-play strategy naturally
compatible with VP, PBL effectively ensures the successful inheritance of
robustness when the source model is a robust model, while significantly
enhancing VP's generalization ability across various downstream datasets.
Extensive experiments across various datasets show that our findings are
universal and demonstrate the significant benefits of the proposed strategy.

</details>


### [486] [Controllable Coupled Image Generation via Diffusion Models](https://arxiv.org/abs/2506.06826)
*Chenfei Yuan,Nanshan Jia,Hangqi Li,Peter W. Glynn,Zeyu Zheng*

Main category: cs.CV

TL;DR: 提出了一种注意力级别控制方法，用于耦合图像生成任务。该方法在模型的交叉注意力模块中解耦背景和实体组件，并通过时间相关的权重控制参数优化背景耦合、图像对齐和视觉质量。


<details>
  <summary>Details</summary>
Motivation: 解决在同时生成多个图像时保持背景高度一致，同时允许前景物体根据不同文本提示灵活变化的需求。

Method: 在交叉注意力模块中解耦背景和实体组件，通过优化时间步相关的权重控制参数序列来实现背景耦合、文本对齐和视觉质量的平衡。优化目标包括背景耦合度、文本-图像对齐和视觉质量评估。

Result: 经验结果表明，该方法在背景一致性、文本对齐和视觉质量方面优于现有方法。

Conclusion: 所提出的注意力控制方法能有效实现背景高度一致的耦合图像生成，同时保持前景物体的多样性和整体图像质量。

Abstract: We provide an attention-level control method for the task of coupled image
generation, where "coupled" means that multiple simultaneously generated images
are expected to have the same or very similar backgrounds. While backgrounds
coupled, the centered objects in the generated images are still expected to
enjoy the flexibility raised from different text prompts. The proposed method
disentangles the background and entity components in the model's
cross-attention modules, attached with a sequence of time-varying weight
control parameters depending on the time step of sampling. We optimize this
sequence of weight control parameters with a combined objective that assesses
how coupled the backgrounds are as well as text-to-image alignment and overall
visual quality. Empirical results demonstrate that our method outperforms
existing approaches across these criteria.

</details>


### [487] [EndoARSS: Adapting Spatially-Aware Foundation Model for Efficient Activity Recognition and Semantic Segmentation in Endoscopic Surgery](https://arxiv.org/abs/2506.06830)
*Guankun Wang,Rui Tang,Mengya Xu,Long Bai,Huxin Gao,Hongliang Ren*

Main category: cs.CV

TL;DR: 提出了EndoARSS框架，一个基于DINOv2的多任务学习模型，用于内窥镜手术活动识别和语义分割。通过LoRA高效微调、任务共享适配器减少梯度冲突、空间感知多尺度注意力机制增强特征辨别力。在三个新数据集上验证，性能显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 内窥镜手术场景复杂多变，传统深度学习模型在跨任务场景下易受干扰导致性能下降。多任务学习能够利用任务间关联特征提升整体效果。

Method: 1. 基于DINOv2基础模型集成低秩自适应(LoRA)高效微调
2. 任务高效共享低秩适配器减少梯度冲突
3. 空间感知多尺度注意力机制进行全局信息跨空间学习

Result: 在三个新数据集(MTLESD, MTLEndovis, MTLEndovis-Gen)上取得最先进性能，准确性和鲁棒性显著提升

Conclusion: EndoARSS框架通过多任务学习显著提升内窥镜手术理解能力，为AI驱动手术系统发展提供新方向，有望提高手术安全性和效率

Abstract: Endoscopic surgery is the gold standard for robotic-assisted minimally
invasive surgery, offering significant advantages in early disease detection
and precise interventions. However, the complexity of surgical scenes,
characterized by high variability in different surgical activity scenarios and
confused image features between targets and the background, presents challenges
for surgical environment understanding. Traditional deep learning models often
struggle with cross-activity interference, leading to suboptimal performance in
each downstream task. To address this limitation, we explore multi-task
learning, which utilizes the interrelated features between tasks to enhance
overall task performance. In this paper, we propose EndoARSS, a novel
multi-task learning framework specifically designed for endoscopy surgery
activity recognition and semantic segmentation. Built upon the DINOv2
foundation model, our approach integrates Low-Rank Adaptation to facilitate
efficient fine-tuning while incorporating Task Efficient Shared Low-Rank
Adapters to mitigate gradient conflicts across diverse tasks. Additionally, we
introduce the Spatially-Aware Multi-Scale Attention that enhances feature
representation discrimination by enabling cross-spatial learning of global
information. In order to evaluate the effectiveness of our framework, we
present three novel datasets, MTLESD, MTLEndovis and MTLEndovis-Gen, tailored
for endoscopic surgery scenarios with detailed annotations for both activity
recognition and semantic segmentation tasks. Extensive experiments demonstrate
that EndoARSS achieves remarkable performance across multiple benchmarks,
significantly improving both accuracy and robustness in comparison to existing
models. These results underscore the potential of EndoARSS to advance AI-driven
endoscopic surgical systems, offering valuable insights for enhancing surgical
safety and efficiency.

</details>


### [488] [Harnessing Vision-Language Models for Time Series Anomaly Detection](https://arxiv.org/abs/2506.06836)
*Zelin He,Sarah Alnegheimish,Matthew Reimherr*

Main category: cs.CV

TL;DR: 提出ViT4TS和VLM4TS两阶段框架，利用视觉语言模型进行时间序列异常检测，在精度和效率上超越现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有时间序列异常检测方法缺乏视觉-时间推理能力，无法像人类专家那样识别上下文异常，需要结合视觉语言模型来填补这一空白。

Method: (1) ViT4TS：基于轻量级视觉编码器，利用二维时间序列表示定位候选异常；(2) VLM4TS：整合全局时间上下文和VLM推理能力，精炼异常检测结果。

Result: VLM4TS无需时间序列训练即可在多数情况下超越基线方法（F1-max提升24.6%），比基于语言模型的方法效率高36倍。

Conclusion: 视觉语言模型能有效提升时间序列异常检测，两阶段框架在精度和效率上具有显著优势。

Abstract: Time-series anomaly detection (TSAD) has played a vital role in a variety of
fields, including healthcare, finance, and industrial monitoring. Prior
methods, which mainly focus on training domain-specific models on numerical
data, lack the visual-temporal reasoning capacity that human experts have to
identify contextual anomalies. To fill this gap, we explore a solution based on
vision language models (VLMs). Recent studies have shown the ability of VLMs
for visual reasoning tasks, yet their direct application to time series has
fallen short on both accuracy and efficiency. To harness the power of VLMs for
TSAD, we propose a two-stage solution, with (1) ViT4TS, a vision-screening
stage built on a relatively lightweight pretrained vision encoder, which
leverages 2-D time-series representations to accurately localize candidate
anomalies; (2) VLM4TS, a VLM-based stage that integrates global temporal
context and VLM reasoning capacity to refine the detection upon the candidates
provided by ViT4TS. We show that without any time-series training, VLM4TS
outperforms time-series pretrained and from-scratch baselines in most cases,
yielding a 24.6 percent improvement in F1-max score over the best baseline.
Moreover, VLM4TS also consistently outperforms existing language-model-based
TSAD methods and is on average 36 times more efficient in token usage.

</details>


### [489] [Multi-StyleGS: Stylizing Gaussian Splatting with Multiple Styles](https://arxiv.org/abs/2506.06846)
*Yangkai Lin,Jiabao Lei,Kui jia*

Main category: cs.CV

TL;DR: Multi-StyleGS 通过二分匹配和语义风格损失实现3D高斯泼溅场景的多风格局部风格迁移，提升内存效率和多视图一致性。


<details>
  <summary>Details</summary>
Motivation: 解决现有3D高斯泼溅(GS)在多风格适配时的局限：需手动指定区域、内存效率低、局部风格迁移自动化不足的问题。

Method: 1) 二分匹配机制关联风格图与局部渲染区域；2) 引入含分割网络的语义风格损失函数；3) 局部-全局特征匹配增强多视角一致性；4) 高斯粒子语义标签正则化技术。

Result: 实验验证：在视觉效果、内存效率、色彩匹配和编辑灵活性上超越现有方法，可保留更多纹理细节。

Conclusion: Multi-StyleGS为3D GS场景提供自动化多风格局部迁移解决方案，平衡了训练效率与视觉质量。

Abstract: In recent years, there has been a growing demand to stylize a given 3D scene
to align with the artistic style of reference images for creative purposes.
While 3D Gaussian Splatting(GS) has emerged as a promising and efficient method
for realistic 3D scene modeling, there remains a challenge in adapting it to
stylize 3D GS to match with multiple styles through automatic local style
transfer or manual designation, while maintaining memory efficiency for
stylization training. In this paper, we introduce a novel 3D GS stylization
solution termed Multi-StyleGS to tackle these challenges. In particular, we
employ a bipartite matching mechanism to au tomatically identify
correspondences between the style images and the local regions of the rendered
images. To facilitate local style transfer, we introduce a novel semantic style
loss function that employs a segmentation network to apply distinct styles to
various objects of the scene and propose a local-global feature matching to
enhance the multi-view consistency. Furthermore, this technique can achieve
memory efficient training, more texture details and better color match. To
better assign a robust semantic label to each Gaussian, we propose several
techniques to regularize the segmentation network. As demonstrated by our
comprehensive experiments, our approach outperforms existing ones in producing
plausible stylization results and offering flexible editing.

</details>


### [490] [Deep Inertial Pose: A deep learning approach for human pose estimation](https://arxiv.org/abs/2506.06850)
*Sara M. Cerqueira,Manuel Palermo,Cristina P. Santos*

Main category: cs.CV

TL;DR: 本文探讨利用神经网络替代传统生物力学模型进行姿态估计，比较多种网络架构与方法在低成本和高成本传感器上的表现，发现Hybrid LSTM-Madgwick detached方法效果最优。


<details>
  <summary>Details</summary>
Motivation: 传统惯性动作捕捉系统依赖复杂的生物力学模型和专家知识，导致成本高昂（如MVN Awinda）。本研究旨在通过神经网络简化这一流程。

Method: 比较多种神经网络架构与方法，分析数据增强/输出表示/窗口大小/损失函数/磁力计数据等变量对姿态估计误差的影响。

Result: 最佳模型Hybrid LSTM-Madgwick detached使用Mtw Awinda传感器时，四元数角度距离误差仅为7.96

Conclusion: 神经网络姿态估计精度可比肩先进融合滤波器，为低成本动作捕捉提供新方案

Abstract: Inertial-based Motion capture system has been attracting growing attention
due to its wearability and unsconstrained use. However, accurate human joint
estimation demands several complex and expertise demanding steps, which leads
to expensive software such as the state-of-the-art MVN Awinda from Xsens
Technologies. This work aims to study the use of Neural Networks to abstract
the complex biomechanical models and analytical mathematics required for pose
estimation. Thus, it presents a comparison of different Neural Network
architectures and methodologies to understand how accurately these methods can
estimate human pose, using both low cost(MPU9250) and high end (Mtw Awinda)
Magnetic, Angular Rate, and Gravity (MARG) sensors. The most efficient method
was the Hybrid LSTM-Madgwick detached, which achieved an Quaternion Angle
distance error of 7.96, using Mtw Awinda data. Also, an ablation study was
conducted to study the impact of data augmentation, output representation,
window size, loss function and magnetometer data on the pose estimation error.
This work indicates that Neural Networks can be trained to estimate human pose,
with results comparable to the state-of-the-art fusion filters.

</details>


### [491] [Position Prediction Self-Supervised Learning for Multimodal Satellite Imagery Semantic Segmentation](https://arxiv.org/abs/2506.06852)
*John Waithaka,Moise Busogi*

Main category: cs.CV

TL;DR: 该论文提出了一种位置感知的自监督学习方法LOCA，用于卫星图像语义分割，通过相对位置预测任务增强空间定位能力，改进了现有基于重建的方法，并在洪水数据集上取得了更好的效果。


<details>
  <summary>Details</summary>
Motivation: 卫星图像语义分割受限于标注数据，现有自监督方法如MAE专注于图像重建，忽略了分割任务核心的定位能力。需要一种能够增强空间定位的预训练方法适应卫星数据的多模态特性。

Method: 将LOCA位置预测方法适配到多模态卫星图像：1）改进SatMAE通道分组策略支持多模态数据 2）引入同组注意力遮蔽促进跨模态交互 3）以相对块位置预测作为预训练任务。

Result: 在Sen1Floods11洪水数据集上，该方法显著优于基于重建的自监督方法，证明位置预测任务能习得更适合卫星图像分割的表示。

Conclusion: 经适当适配的位置预测自监督学习比重建方法更适合卫星图像语义分割，关键在于增强空间定位能力和多模态处理。

Abstract: Semantic segmentation of satellite imagery is crucial for Earth observation
applications, but remains constrained by limited labelled training data. While
self-supervised pretraining methods like Masked Autoencoders (MAE) have shown
promise, they focus on reconstruction rather than localisation-a fundamental
aspect of segmentation tasks. We propose adapting LOCA (Location-aware), a
position prediction self-supervised learning method, for multimodal satellite
imagery semantic segmentation. Our approach addresses the unique challenges of
satellite data by extending SatMAE's channel grouping from multispectral to
multimodal data, enabling effective handling of multiple modalities, and
introducing same-group attention masking to encourage cross-modal interaction
during pretraining. The method uses relative patch position prediction,
encouraging spatial reasoning for localisation rather than reconstruction. We
evaluate our approach on the Sen1Floods11 flood mapping dataset, where it
significantly outperforms existing reconstruction-based self-supervised
learning methods for satellite imagery. Our results demonstrate that position
prediction tasks, when properly adapted for multimodal satellite imagery, learn
representations more effective for satellite image semantic segmentation than
reconstruction-based approaches.

</details>


### [492] [DONUT: A Decoder-Only Model for Trajectory Prediction](https://arxiv.org/abs/2506.06854)
*Markus Knoche,Daan de Geus,Bastian Leibe*

Main category: cs.CV

TL;DR: 提出了名为 DONUT 的 Transformer 模型改进方法，使用纯解码器架构进行轨迹预测


<details>
  <summary>Details</summary>
Motivation: 现有编码器-解码器模型在轨迹预测中存在信息延迟问题，无法保证预测一致性

Method: 1. 采用纯解码器架构统一编码与预测任务 2. 引入‘过度预测’策略进行未来多步预测

Result: 在 Argoverse 2 单智能体轨迹预测基准上取得 SOTA 结果

Conclusion: 解耦器架构在轨迹预测中优于传统编码器-解码器结构

Abstract: Predicting the motion of other agents in a scene is highly relevant for
autonomous driving, as it allows a self-driving car to anticipate. Inspired by
the success of decoder-only models for language modeling, we propose DONUT, a
Decoder-Only Network for Unrolling Trajectories. Different from existing
encoder-decoder forecasting models, we encode historical trajectories and
predict future trajectories with a single autoregressive model. This allows the
model to make iterative predictions in a consistent manner, and ensures that
the model is always provided with up-to-date information, enhancing the
performance. Furthermore, inspired by multi-token prediction for language
modeling, we introduce an 'overprediction' strategy that gives the network the
auxiliary task of predicting trajectories at longer temporal horizons. This
allows the model to better anticipate the future, and further improves the
performance. With experiments, we demonstrate that our decoder-only approach
outperforms the encoder-decoder baseline, and achieves new state-of-the-art
results on the Argoverse 2 single-agent motion forecasting benchmark.

</details>


### [493] [Vision-EKIPL: External Knowledge-Infused Policy Learning for Visual Reasoning](https://arxiv.org/abs/2506.06856)
*Chaoyang Wang,Zeyu Zhang,Haiyun Jiang*

Main category: cs.CV

TL;DR: Vision-EKIPL是一种新的强化学习框架，通过引入外部模型生成的高质量动作指导策略模型优化，解决了现有RL方法在MLLMs视觉推理中探索空间有限和训练低效的问题，在Reason-RFT-CoT基准上实现了5%的性能提升。


<details>
  <summary>Details</summary>
Motivation: 现有MLLMs的RL微调方法（如GRPO）仅从策略模型本身采样动作组，限制了模型的推理能力上限并导致训练低效。

Method: 提出Vision-EKIPL框架，在RL训练过程中引入外部辅助模型生成的高质量动作指导策略优化，扩展探索空间并加速收敛。

Result: 在Reason-RFT-CoT基准上相比SOTA提升最高达5%，显著提升视觉推理性能和训练效率。

Conclusion: Vision-EKIPL突破传统RL方法的局限，为MLLMs视觉推理研究提供了新的有效范式。

Abstract: Visual reasoning is crucial for understanding complex multimodal data and
advancing Artificial General Intelligence. Existing methods enhance the
reasoning capability of Multimodal Large Language Models (MLLMs) through
Reinforcement Learning (RL) fine-tuning (e.g., GRPO). However, current RL
approaches sample action groups solely from the policy model itself, which
limits the upper boundary of the model's reasoning capability and leads to
inefficient training. To address these limitations, this paper proposes a novel
RL framework called \textbf{Vision-EKIPL}. The core of this framework lies in
introducing high-quality actions generated by external auxiliary models during
the RL training process to guide the optimization of the policy model. The
policy learning with knowledge infusion from external models significantly
expands the model's exploration space, effectively improves the reasoning
boundary, and substantially accelerates training convergence speed and
efficiency. Experimental results demonstrate that our proposed Vision-EKIPL
achieved up to a 5\% performance improvement on the Reason-RFT-CoT Benchmark
compared to the state-of-the-art (SOTA). It reveals that Vision-EKIPL can
overcome the limitations of traditional RL methods, significantly enhance the
visual reasoning performance of MLLMs, and provide a new effective paradigm for
research in this field.

</details>


### [494] [Face recognition on point cloud with cgan-top for denoising](https://arxiv.org/abs/2506.06864)
*Junyu Liu,Jianfeng Ren,Sunhong Liang,Xudong Jiang*

Main category: cs.CV

TL;DR: 提出了一种端到端的3D人脸识别方法，结合去噪和识别模块，使用cGAN-TOP去噪和LDGCNN识别，在Bosphorus数据集上显著提升带噪点云的识别准确率，最高增益14.81%。


<details>
  <summary>Details</summary>
Motivation: 原始点云常因传感器不完美而包含大量噪声，影响3D人脸识别精度。

Method: 1. 设计基于三正交平面的条件生成对抗网络(cGAN-TOP)去除点云噪声；2. 采用链接动态图卷积神经网络(LDGCNN)分层融合局部点特征和多尺度邻域特征进行识别。

Result: 在Bosphorus数据集上，所有噪声设置下识别准确率显著提升，最大增益达14.81%。

Conclusion: 该方法通过协同整合去噪与识别模块，有效提升了带噪点云的人脸识别性能。

Abstract: Face recognition using 3D point clouds is gaining growing interest, while raw
point clouds often contain a significant amount of noise due to imperfect
sensors. In this paper, an end-to-end 3D face recognition on a noisy point
cloud is proposed, which synergistically integrates the denoising and
recognition modules. Specifically, a Conditional Generative Adversarial Network
on Three Orthogonal Planes (cGAN-TOP) is designed to effectively remove the
noise in the point cloud, and recover the underlying features for subsequent
recognition. A Linked Dynamic Graph Convolutional Neural Network (LDGCNN) is
then adapted to recognize faces from the processed point cloud, which
hierarchically links both the local point features and neighboring features of
multiple scales. The proposed method is validated on the Bosphorus dataset. It
significantly improves the recognition accuracy under all noise settings, with
a maximum gain of 14.81%.

</details>


### [495] [Hybrid Vision Transformer-Mamba Framework for Autism Diagnosis via Eye-Tracking Analysis](https://arxiv.org/abs/2506.06886)
*Wafaa Kasri,Yassine Himeur,Abigail Copiaco,Wathiq Mansoor,Ammar Albanna,Valsamma Eapen*

Main category: cs.CV

TL;DR: 提出了一种结合Vision Transformers和Vision Mamba的混合深度学习框架，利用眼动追踪数据检测自闭症谱系障碍（ASD），通过注意力机制融合视觉、语音和面部线索。在Saliency4ASD数据集上测试，性能优于现有方法（准确度0.96），有望用于资源受限的临床环境。


<details>
  <summary>Details</summary>
Motivation: 提高ASD诊断准确率对早期干预至关重要，尤其在缺乏专家诊断资源的场景中。传统手工特征方法效果有限，因此需要更精确、可解释的深度学习模型。

Method: 结合Vision Transformers和Vision Mamba构建混合模型，利用视觉、语音、面部多模态输入；引入注意力融合机制捕捉时空特征；采用可解释性AI技术增加透明度。

Result: 在Saliency4ASD数据集上达到0.96准确率，0.95 F1分数，0.97灵敏度和0.94特异性，性能超越现有方法。

Conclusion: ViT-Mamba框架为ASD筛查提供了高精度、可解释的解决方案，尤其适用于资源有限的远程医疗场景，具备临床推广潜力。

Abstract: Accurate Autism Spectrum Disorder (ASD) diagnosis is vital for early
intervention. This study presents a hybrid deep learning framework combining
Vision Transformers (ViT) and Vision Mamba to detect ASD using eye-tracking
data. The model uses attention-based fusion to integrate visual, speech, and
facial cues, capturing both spatial and temporal dynamics. Unlike traditional
handcrafted methods, it applies state-of-the-art deep learning and explainable
AI techniques to enhance diagnostic accuracy and transparency. Tested on the
Saliency4ASD dataset, the proposed ViT-Mamba model outperformed existing
methods, achieving 0.96 accuracy, 0.95 F1-score, 0.97 sensitivity, and 0.94
specificity. These findings show the model's promise for scalable,
interpretable ASD screening, especially in resource-constrained or remote
clinical settings where access to expert diagnosis is limited.

</details>


### [496] [NSD-Imagery: A benchmark dataset for extending fMRI vision decoding methods to mental imagery](https://arxiv.org/abs/2506.06898)
*Reese Kneeland,Paul S. Scotti,Ghislain St-Yves,Jesse Breedlove,Kendrick Kay,Thomas Naselaris*

Main category: cs.CV

TL;DR: 基于已有的自然场景数据集(NSD)，研究人员发布了NSD-Imagery基准数据集，该数据集将人类fMRI活动与心理图像配对。该工作的动机是评估现有模型在心理图像重建上的表现，因为心理图像在脑活动中的信号更弱、分辨率更低，但对医疗和脑机接口应用至关重要。方法上，研究人员利用该数据集评估了一系列公开的视觉解码模型（如MindEye1、MindEye2等）在心理图像重建上的表现。结果显示，模型在心理图像上的解码性能与其在视觉重建上的表现相关性较低；并且简单线性架构和多模态特征解码模型在心理图像重建上泛化更好，而复杂架构容易对视觉数据过拟合。结论指出，心理图像数据集对发展实用应用至关重要，NSD-Imagery将助力视觉解码方法实现更好的跨任务泛化能力。


<details>
  <summary>Details</summary>
Motivation: 目前基于NSD数据集的视觉解码模型仅在重建'所见图像'上评估过，而真实医疗和脑机接口应用需要重建'心理图像'。心理图像在脑活动中的信号特征（低信噪比、低空间分辨率）与所见图像不同，因此需要专门的数据集验证模型的跨任务泛化能力。

Method: 1) 构建NSD-Imagery数据集——将fMRI脑活动记录与受试者的心理图像配对；2) 评估五类公开NSD训练模型（MindEye1/2, Brain Diffuser等）在新数据上的表现；3) 分析模型架构（线性 vs 复杂）对跨任务泛化的影响。

Result: 1) 模型在心理图像的重建性能与其在视觉重建性能相关性低（存在解耦现象）；2) 采用线性解码和多模态特征的模型泛化效果更好；3) 复杂架构模型在心理图像重建中因过拟合视觉训练数据而表现较差。

Conclusion: 心理图像数据集是发展实用脑机接口的关键基础设施；NSD-Imagery填补了评估模型对心理图像重建能力的空白；模型架构设计应优先考虑跨任务泛化能力而非仅优化视觉重建指标。

Abstract: We release NSD-Imagery, a benchmark dataset of human fMRI activity paired
with mental images, to complement the existing Natural Scenes Dataset (NSD), a
large-scale dataset of fMRI activity paired with seen images that enabled
unprecedented improvements in fMRI-to-image reconstruction efforts. Recent
models trained on NSD have been evaluated only on seen image reconstruction.
Using NSD-Imagery, it is possible to assess how well these models perform on
mental image reconstruction. This is a challenging generalization requirement
because mental images are encoded in human brain activity with relatively lower
signal-to-noise and spatial resolution; however, generalization from seen to
mental imagery is critical for real-world applications in medical domains and
brain-computer interfaces, where the desired information is always internally
generated. We provide benchmarks for a suite of recent NSD-trained open-source
visual decoding models (MindEye1, MindEye2, Brain Diffuser, iCNN, Takagi et
al.) on NSD-Imagery, and show that the performance of decoding methods on
mental images is largely decoupled from performance on vision reconstruction.
We further demonstrate that architectural choices significantly impact
cross-decoding performance: models employing simple linear decoding
architectures and multimodal feature decoding generalize better to mental
imagery, while complex architectures tend to overfit visual training data. Our
findings indicate that mental imagery datasets are critical for the development
of practical applications, and establish NSD-Imagery as a useful resource for
better aligning visual decoding methods with this goal.

</details>


### [497] [KNN-Defense: Defense against 3D Adversarial Point Clouds using Nearest-Neighbor Search](https://arxiv.org/abs/2506.06906)
*Nima Jamali,Matina Mahdizadeh Sani,Hanieh Naderi,Shohreh Kasaei*

Main category: cs.CV

TL;DR: KNN-Defense: 一种基于特征空间最近邻检索的轻量级防御策略，可有效应对3D点云对抗攻击，在保持语义完整性的同时显著提升模型鲁棒性，支持实时应用。


<details>
  <summary>Details</summary>
Motivation: 现有3D点云分类模型易受对抗攻击（点丢弃/移动/增加），导致语义失真且现有防御效率低下。需要开发兼顾高效性和泛化能力的防御机制。

Method: 利用训练集样本特征空间的K最近邻搜索，根据流形假设重建被扰动点云的语义结构（非几何重建）。轻量设计实现快速推理。

Result: ModelNet40测试显示全类型攻击下鲁棒性提升：点丢弃攻击中准确率分别提升PointNet(20.1%)/PointNet++(3.6%)/DGCNN(3.44%)/PCT(7.74%)。

Conclusion: KNN-Defense为3D点云分类器提供可扩展的实时防御方案，通过语义相似性重建有效抵御攻击。开源实现促进应用部署。

Abstract: Deep neural networks (DNNs) have demonstrated remarkable performance in
analyzing 3D point cloud data. However, their vulnerability to adversarial
attacks-such as point dropping, shifting, and adding-poses a critical challenge
to the reliability of 3D vision systems. These attacks can compromise the
semantic and structural integrity of point clouds, rendering many existing
defense mechanisms ineffective. To address this issue, a defense strategy named
KNN-Defense is proposed, grounded in the manifold assumption and
nearest-neighbor search in feature space. Instead of reconstructing surface
geometry or enforcing uniform point distributions, the method restores
perturbed inputs by leveraging the semantic similarity of neighboring samples
from the training set. KNN-Defense is lightweight and computationally
efficient, enabling fast inference and making it suitable for real-time and
practical applications. Empirical results on the ModelNet40 dataset
demonstrated that KNN-Defense significantly improves robustness across various
attack types. In particular, under point-dropping attacks-where many existing
methods underperform due to the targeted removal of critical points-the
proposed method achieves accuracy gains of 20.1%, 3.6%, 3.44%, and 7.74% on
PointNet, PointNet++, DGCNN, and PCT, respectively. These findings suggest that
KNN-Defense offers a scalable and effective solution for enhancing the
adversarial resilience of 3D point cloud classifiers. (An open-source
implementation of the method, including code and data, is available at
https://github.com/nimajam41/3d-knn-defense).

</details>


### [498] [Gaussian Mapping for Evolving Scenes](https://arxiv.org/abs/2506.06909)
*Vladimir Yugay,Thies Kersten,Luca Carlone,Theo Gevers,Martin R. Oswald,Lukas Schmid*

Main category: cs.CV

TL;DR: Too Long; Didn't Read 该论文针对动态场景提出了GaME，一种新型的3D高斯溅射地图系统。它通过动态适应机制和关键帧管理来处理长期场景变化，性能优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 当前的3D高斯溅射方法主要处理静态场景，而短期动态研究较多，长期动态（摄像头视野外的场景演化）研究较少。需要解决因陈旧观测导致的重建几何和语义一致性问题。

Method: 提出动态场景适应机制持续更新3D表示，并设计关键帧管理机制丢弃过时观测但保留有效信息。该系统名为GaME（Gaussian Mapping for Evolving Scenes）。

Result: 在合成和真实数据集上测试表明，GaME的精度优于当前最先进方法。

Conclusion: GaME通过动态适应和关键帧管理成功解决了长期动态场景的建模问题，为AR、机器人和自动驾驶等应用提供了更好的动态场景建模方案。

Abstract: Mapping systems with novel view synthesis (NVS) capabilities are widely used
in computer vision, with augmented reality, robotics, and autonomous driving
applications. Most notably, 3D Gaussian Splatting-based systems show high NVS
performance; however, many current approaches are limited to static scenes.
While recent works have started addressing short-term dynamics (motion within
the view of the camera), long-term dynamics (the scene evolving through changes
out of view) remain less explored. To overcome this limitation, we introduce a
dynamic scene adaptation mechanism that continuously updates the 3D
representation to reflect the latest changes. In addition, since maintaining
geometric and semantic consistency remains challenging due to stale
observations disrupting the reconstruction process, we propose a novel keyframe
management mechanism that discards outdated observations while preserving as
much information as possible. We evaluate Gaussian Mapping for Evolving Scenes
(GaME) on both synthetic and real-world datasets and find it to be more
accurate than the state of the art.

</details>


### [499] [Sleep Stage Classification using Multimodal Embedding Fusion from EOG and PSM](https://arxiv.org/abs/2506.06912)
*Olivier Papillon,Rafik Goubran,James Green,Julien Larivière-Chartier,Caitlin Higginson,Frank Knoefel,Rébecca Robillard*

Main category: cs.CV

TL;DR: 研究提出了一种使用ImageBind多模态模型融合眼电信号(EOG)和压力敏感垫(PSM)数据的新方法,用于五阶段睡眠分期,相比单模态和其他多模态方法效果更好,且无需微调就能表现良好。


<details>
  <summary>Details</summary>
Motivation: 传统基于脑电(EEG)的多导睡眠监测不适合家庭场景,需要开发更便捷的睡眠监测方案。

Method: 使用ImageBind模型融合双通道EOG和PSM数据,在85晚临床数据上评估,并与DeepSleepNet、ViViT、MBT等基准方法对比。

Result: 微调后效果显著优于单模态(EOG或PSM)和其他多模态方法;即使不微调也表现良好,特别适合标签数据有限的医疗场景。

Conclusion: 预训练多模态模型即使非医疗领域训练,也能有效适配睡眠分期任务,性能接近需要复杂EEG的系统,为家庭睡眠监测提供可行方案。

Abstract: Accurate sleep stage classification is essential for diagnosing sleep
disorders, particularly in aging populations. While traditional polysomnography
(PSG) relies on electroencephalography (EEG) as the gold standard, its
complexity and need for specialized equipment make home-based sleep monitoring
challenging. To address this limitation, we investigate the use of
electrooculography (EOG) and pressure-sensitive mats (PSM) as less obtrusive
alternatives for five-stage sleep-wake classification. This study introduces a
novel approach that leverages ImageBind, a multimodal embedding deep learning
model, to integrate PSM data with dual-channel EOG signals for sleep stage
classification. Our method is the first reported approach that fuses PSM and
EOG data for sleep stage classification with ImageBind. Our results demonstrate
that fine-tuning ImageBind significantly improves classification accuracy,
outperforming existing models based on single-channel EOG (DeepSleepNet),
exclusively PSM data (ViViT), and other multimodal deep learning approaches
(MBT). Notably, the model also achieved strong performance without fine-tuning,
highlighting its adaptability to specific tasks with limited labeled data,
making it particularly advantageous for medical applications. We evaluated our
method using 85 nights of patient recordings from a sleep clinic. Our findings
suggest that pre-trained multimodal embedding models, even those originally
developed for non-medical domains, can be effectively adapted for sleep
staging, with accuracies approaching systems that require complex EEG data.

</details>


### [500] [Reading in the Dark with Foveated Event Vision](https://arxiv.org/abs/2506.06918)
*Carl Brander,Giovanni Cioffi,Nico Messikommer,Davide Scaramuzza*

Main category: cs.CV

TL;DR: 提出了一种基于事件的智能眼镜光学字符识别方法，通过结合用户眼动注视点来实现高动态和高速场景下的文本阅读，同时显著降低带宽需求。


<details>
  <summary>Details</summary>
Motivation: 当前智能眼镜的RGB相机在低光和高运动下存在运动模糊和动态范围限制问题，传统方案在密集图像捕获时高功耗和大带宽会导致电池快速耗尽。

Method: 利用用户眼动注视实现事件流聚焦（降98%带宽），提出基于合成数据训练的深度二值重建模型，结合多模态LLM的OCR方案。

Result: 可在RGB相机失效的低光环境下阅读文本，比可穿戴RGB相机节省2400倍带宽。

Conclusion: 事件相机结合注意力机制与LLM是智能眼镜文本识别的可行方案，解决了关键挑战。

Abstract: Current smart glasses equipped with RGB cameras struggle to perceive the
environment in low-light and high-speed motion scenarios due to motion blur and
the limited dynamic range of frame cameras. Additionally, capturing dense
images with a frame camera requires large bandwidth and power consumption,
consequently draining the battery faster. These challenges are especially
relevant for developing algorithms that can read text from images. In this
work, we propose a novel event-based Optical Character Recognition (OCR)
approach for smart glasses. By using the eye gaze of the user, we foveate the
event stream to significantly reduce bandwidth by around 98% while exploiting
the benefits of event cameras in high-dynamic and fast scenes. Our proposed
method performs deep binary reconstruction trained on synthetic data and
leverages multimodal LLMs for OCR, outperforming traditional OCR solutions. Our
results demonstrate the ability to read text in low light environments where
RGB cameras struggle while using up to 2400 times less bandwidth than a
wearable RGB camera.

</details>


### [501] [How Important are Videos for Training Video LLMs?](https://arxiv.org/abs/2506.06928)
*George Lydakis,Alexander Hermans,Ali Athar,Daan de Geus,Bastian Leibe*

Main category: cs.CV

TL;DR: tldr：该论文挑战了视频大型语言模型（Video LLMs）依赖于视频数据进行时间推理的传统观念。研究表明，仅使用图像训练的模型在时间推理基准测试（TVBench）上的表现显著优于随机水平；而一种简单的基于图像序列的微调方案在时间推理任务上，表现接近甚至超过视频训练的模型。这表明当前视频模型未能充分利用视频中的时间特征，值得探索图像训练模型的时间推理机制及当前视频训练方案的低效瓶颈。


<details>
  <summary>Details</summary>
Motivation: 研究动机是揭示一个反直觉现象：仅通过图像训练的视频LLM具有意外良好的时间推理能力，而视频训练带来的提升微乎其微。这促使研究者质疑当前视频训练方法的有效性，并呼吁深入探查图像训练模型的时间推理机制。

Method: 研究方法包括两步：1) 在TVBench时间推理基准测试上评估仅图像训练的LLM（采用LongVU算法）的性能；2) 提出一种简单微调方案：使用带标注的图像序列和针对时间能力的问题进行训练，并与视频训练LLMs对比效果。

Result: 关键结果：1) 仅图像训练的LongVU模型在TVBench表现显著高于随机水平；2) 简单图像序列微调方案在时间推理任务上达到接近甚至超越视频训练模型的性能。

Conclusion: 结论指出：1) 当前视频训练对时间推理的优化效率低下；2) 图像训练模型已具备潜在时间推理能力；3) 未来需探索图像训练模型的时间推理机制，并解决视频特征利用不足的瓶颈问题。

Abstract: Research into Video Large Language Models (LLMs) has progressed rapidly, with
numerous models and benchmarks emerging in just a few years. Typically, these
models are initialized with a pretrained text-only LLM and finetuned on both
image- and video-caption datasets. In this paper, we present findings
indicating that Video LLMs are more capable of temporal reasoning after
image-only training than one would assume, and that improvements from
video-specific training are surprisingly small. Specifically, we show that
image-trained versions of two LLMs trained with the recent LongVU algorithm
perform significantly above chance level on TVBench, a temporal reasoning
benchmark. Additionally, we introduce a simple finetuning scheme involving
sequences of annotated images and questions targeting temporal capabilities.
This baseline results in temporal reasoning performance close to, and
occasionally higher than, what is achieved by video-trained LLMs. This suggests
suboptimal utilization of rich temporal features found in real video by current
models. Our analysis motivates further research into the mechanisms that allow
image-trained LLMs to perform temporal reasoning, as well as into the
bottlenecks that render current video training schemes inefficient.

</details>


### [502] [Polar Hierarchical Mamba: Towards Streaming LiDAR Object Detection with Point Clouds as Egocentric Sequences](https://arxiv.org/abs/2506.06944)
*Mellon M. Zhang,Glen Chou,Saibal Mukhopadhyay*

Main category: cs.CV

TL;DR: 提出了一种用于极坐标流式LiDAR感知的结构State-of-the-art（SOTA）方法PHiM，在Waymo Open Dataset上性能超越先前最佳方法10%，同时匹配完整扫描基线的两倍吞吐量。


<details>
  <summary>Details</summary>
Motivation: 现有流式方法在极坐标系中使用平移不变卷积导致性能下降，而基于Mamba的全扫描方法存在内存密集和难以适应流式处理的问题，需要开发更高效、高精度的极坐标流式检测器。

Method: 设计PHiM架构：局部双向Mamba块处理扇区内空间特征，全局前向Mamba块建模扇区间时序关系；采用维度解耦操作替代卷积和位置编码，实现几何感知建模。

Result: 在Waymo Open Dataset上达到流式检测器新SOTA，较先前最佳方法提升10%性能，并以两倍吞吐量匹配完整扫描基线精度。

Conclusion: PHiM通过创新性Mamba架构实现极坐标流式LiDAR的高效精确检测，为自动驾驶实时感知提供新范式。

Abstract: Accurate and efficient object detection is essential for autonomous vehicles,
where real-time perception requires low latency and high throughput. LiDAR
sensors provide robust depth information, but conventional methods process full
360{\deg} scans in a single pass, introducing significant delay. Streaming
approaches address this by sequentially processing partial scans in the native
polar coordinate system, yet they rely on translation-invariant convolutions
that are misaligned with polar geometry -- resulting in degraded performance or
requiring complex distortion mitigation. Recent Mamba-based state space models
(SSMs) have shown promise for LiDAR perception, but only in the full-scan
setting, relying on geometric serialization and positional embeddings that are
memory-intensive and ill-suited to streaming. We propose Polar Hierarchical
Mamba (PHiM), a novel SSM architecture designed for polar-coordinate streaming
LiDAR. PHiM uses local bidirectional Mamba blocks for intra-sector spatial
encoding and a global forward Mamba for inter-sector temporal modeling,
replacing convolutions and positional encodings with distortion-aware,
dimensionally-decomposed operations. PHiM sets a new state-of-the-art among
streaming detectors on the Waymo Open Dataset, outperforming the previous best
by 10\% and matching full-scan baselines at twice the throughput. Code will be
available at https://github.com/meilongzhang/Polar-Hierarchical-Mamba .

</details>


### [503] [LaTtE-Flow: Layerwise Timestep-Expert Flow-based Transformer](https://arxiv.org/abs/2506.06952)
*Ying Shen,Zhiyang Xu,Jiuhai Chen,Shizhe Diao,Jiaxin Zhang,Yuguang Yao,Joy Rimchala,Ismini Lourentzou,Lifu Huang*

Main category: cs.CV

TL;DR: 提出了LaTtE-Flow，这是一种高效的多模态模型架构，统一了图像理解和生成，通过分层时间步专家流机制提升推理速度


<details>
  <summary>Details</summary>
Motivation: 现有统一模型需要大量预训练且性能不及专用模型，图像生成速度慢限制实际部署

Method: 基于预训练视觉语言模型扩展分层时间步专家流架构，通过Timestep-Conditioned Residual Attention机制增强信息复用

Result: 在理解任务上表现强劲，图像生成质量具竞争力且推理速度比现有统一模型快约6倍

Conclusion: LaTtE-Flow高效统一图像理解与生成，显著提升推理速度

Abstract: Recent advances in multimodal foundation models unifying image understanding
and generation have opened exciting avenues for tackling a wide range of
vision-language tasks within a single framework. Despite progress, existing
unified models typically require extensive pretraining and struggle to achieve
the same level of performance compared to models dedicated to each task.
Additionally, many of these models suffer from slow image generation speeds,
limiting their practical deployment in real-time or resource-constrained
settings. In this work, we propose Layerwise Timestep-Expert Flow-based
Transformer (LaTtE-Flow), a novel and efficient architecture that unifies image
understanding and generation within a single multimodal model. LaTtE-Flow
builds upon powerful pretrained Vision-Language Models (VLMs) to inherit strong
multimodal understanding capabilities, and extends them with a novel Layerwise
Timestep Experts flow-based architecture for efficient image generation.
LaTtE-Flow distributes the flow-matching process across specialized groups of
Transformer layers, each responsible for a distinct subset of timesteps. This
design significantly improves sampling efficiency by activating only a small
subset of layers at each sampling timestep. To further enhance performance, we
propose a Timestep-Conditioned Residual Attention mechanism for efficient
information reuse across layers. Experiments demonstrate that LaTtE-Flow
achieves strong performance on multimodal understanding tasks, while achieving
competitive image generation quality with around 6x faster inference speed
compared to recent unified multimodal models.

</details>


### [504] [Task-driven real-world super-resolution of document scans](https://arxiv.org/abs/2506.06953)
*Maciej Zyrek,Tomasz Tarasiewicz,Jakub Sadel,Aleksandra Krzywon,Michal Kawulok*

Main category: cs.CV

TL;DR: 提出了一种任务驱动的多任务学习框架，用于训练专为OCR任务优化的超分辨率网络。通过引入文本检测、文本识别、关键点定位和色调一致性等高层视觉任务的辅助损失，并结合动态权重平均机制平衡目标，在SRResNet架构上进行验证。实验证明该方法在模拟和真实扫描文档数据集上提升了文本检测精度（IoU指标）并保持整体图像保真度。


<details>
  <summary>Details</summary>
Motivation: 现有基于深度学习的单图像超分辨率方法在模拟数据集上表现良好，但在真实场景（如受复杂退化和语义变化影响的文档扫描）中泛化能力不足。研究旨在缩小模拟训练环境与真实应用之间的差距，特别是针对OCR任务的优化。

Method: 1. 构建多任务学习框架，集成四个辅助损失函数：CTPN文本检测、CRNN文本识别、Key.Net关键点定位和色调一致性损失。2. 采用动态权重平均机制自适应调整损失权重。3. 基于SRResNet架构实现。

Result: 在模拟和真实扫描文档数据集上的实验表明：1. 文本检测IoU指标显著提升；2. 整体图像保真度得以保持；3. 验证了多目标优化对缩小模拟训练与真实场景差距的有效性。

Conclusion: 通过任务驱动的多任务学习框架，结合高层视觉任务损失和动态权重调整机制，有效提升了超分辨率模型在真实文档OCR任务中的性能。该方法强调了多目标优化在连接模拟训练环境与实际应用场景中的重要价值。

Abstract: Single-image super-resolution refers to the reconstruction of a
high-resolution image from a single low-resolution observation. Although recent
deep learning-based methods have demonstrated notable success on simulated
datasets -- with low-resolution images obtained by degrading and downsampling
high-resolution ones -- they frequently fail to generalize to real-world
settings, such as document scans, which are affected by complex degradations
and semantic variability. In this study, we introduce a task-driven, multi-task
learning framework for training a super-resolution network specifically
optimized for optical character recognition tasks. We propose to incorporate
auxiliary loss functions derived from high-level vision tasks, including text
detection using the connectionist text proposal network, text recognition via a
convolutional recurrent neural network, keypoints localization using Key.Net,
and hue consistency. To balance these diverse objectives, we employ dynamic
weight averaging mechanism, which adaptively adjusts the relative importance of
each loss term based on its convergence behavior. We validate our approach upon
the SRResNet architecture, which is a well-established technique for
single-image super-resolution. Experimental evaluations on both simulated and
real-world scanned document datasets demonstrate that the proposed approach
improves text detection, measured with intersection over union, while
preserving overall image fidelity. These findings underscore the value of
multi-objective optimization in super-resolution models for bridging the gap
between simulated training regimes and practical deployment in real-world
scenarios.

</details>


### [505] [AR-RAG: Autoregressive Retrieval Augmentation for Image Generation](https://arxiv.org/abs/2506.06962)
*Jingyuan Qi,Zhiyang Xu,Qifan Wang,Lifu Huang*

Main category: cs.CV

TL;DR: AR-RAG是一种新颖的自回归检索增强范式，通过逐块动态检索增强图像生成，解决了现有方法单次静态检索导致的过复制和风格偏差问题。提出DAiD（解码时分布增强）和FAiD（解码时特征增强）两种实现框架，在多个基准测试上显著超越现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有图像生成方法仅执行单次静态检索后照搬参考图像，导致过复制、风格偏差等问题。需要动态检索机制适应生成过程的演化需求。

Method: AR-RAG在生成过程中以已生成块为查询，自回归执行K近邻检索：1）DAiD直接合并预测块与检索块的分布；2）FAiD通过多尺度卷积平滑检索块特征后增强生成。

Result: 在Midjourney-30K、GenEval和DPG-Bench等基准测试中，AR-RAG显著超越SOTA图像生成模型。

Conclusion: 自回归动态检索范式能有效解决静态检索的固有问题，DAiD/FAiD框架分别提供免训练和微调两种高效实现路径。

Abstract: We introduce Autoregressive Retrieval Augmentation (AR-RAG), a novel paradigm
that enhances image generation by autoregressively incorporating knearest
neighbor retrievals at the patch level. Unlike prior methods that perform a
single, static retrieval before generation and condition the entire generation
on fixed reference images, AR-RAG performs context-aware retrievals at each
generation step, using prior-generated patches as queries to retrieve and
incorporate the most relevant patch-level visual references, enabling the model
to respond to evolving generation needs while avoiding limitations (e.g.,
over-copying, stylistic bias, etc.) prevalent in existing methods. To realize
AR-RAG, we propose two parallel frameworks: (1) Distribution-Augmentation in
Decoding (DAiD), a training-free plug-and-use decoding strategy that directly
merges the distribution of model-predicted patches with the distribution of
retrieved patches, and (2) Feature-Augmentation in Decoding (FAiD), a
parameter-efficient fine-tuning method that progressively smooths the features
of retrieved patches via multi-scale convolution operations and leverages them
to augment the image generation process. We validate the effectiveness of
AR-RAG on widely adopted benchmarks, including Midjourney-30K, GenEval and
DPG-Bench, demonstrating significant performance gains over state-of-the-art
image generation models.

</details>


### [506] [Dual-view Spatio-Temporal Feature Fusion with CNN-Transformer Hybrid Network for Chinese Isolated Sign Language Recognition](https://arxiv.org/abs/2506.06966)
*Siyuan Jing,Guangxue Wang,Haoyang Zhai,Qin Tao,Jun Yang,Bing Wang,Peng Jin*

Main category: cs.CV

TL;DR: 本文介绍了 NationalCSL-DP 数据集，用于解决孤立手语识别（ISLR）中的词汇覆盖不足和单视角遮挡问题。该数据集包含 134140 个双视角（正面与左侧）视频，覆盖了完整的中国国家手语词汇表。同时提出了 CNN-Transformer 基线模型和一种简单有效的融合策略。


<details>
  <summary>Details</summary>
Motivation: 现有 ISLR 数据集存在词汇覆盖不全和单视角遮挡问题，难以应用于现实场景。

Method: 1) 构建双视角（正面/左侧）手语数据集 NationalCSL-DP；2) 提出 CNN-Transformer 基线模型；3) 设计简单融合策略提升性能。

Result: 融合策略显著提升 ISLR 性能，但序列模型难以从双视角视频中学习互补特征（无论早期或晚期融合）。

Conclusion: 双视角数据集可缓解手部遮挡问题，超简单融合策略有效；但多视角特征自动融合仍需探索。

Abstract: Due to the emergence of many sign language datasets, isolated sign language
recognition (ISLR) has made significant progress in recent years. In addition,
the development of various advanced deep neural networks is another reason for
this breakthrough. However, challenges remain in applying the technique in the
real world. First, existing sign language datasets do not cover the whole sign
vocabulary. Second, most of the sign language datasets provide only single view
RGB videos, which makes it difficult to handle hand occlusions when performing
ISLR. To fill this gap, this paper presents a dual-view sign language dataset
for ISLR named NationalCSL-DP, which fully covers the Chinese national sign
language vocabulary. The dataset consists of 134140 sign videos recorded by ten
signers with respect to two vertical views, namely, the front side and the left
side. Furthermore, a CNN transformer network is also proposed as a strong
baseline and an extremely simple but effective fusion strategy for prediction.
Extensive experiments were conducted to prove the effectiveness of the datasets
as well as the baseline. The results show that the proposed fusion strategy can
significantly increase the performance of the ISLR, but it is not easy for the
sequence-to-sequence model, regardless of whether the early-fusion or
late-fusion strategy is applied, to learn the complementary features from the
sign videos of two vertical views.

</details>


### [507] [Guiding Cross-Modal Representations with MLLM Priors via Preference Alignment](https://arxiv.org/abs/2506.06970)
*Pengfei Zhao,Rongbo Luan,Wei Zhang,Peng Wu,Sifeng He*

Main category: cs.CV

TL;DR: MAPLE提出了一种新的跨模态表示学习框架，利用多模态大语言模型的细粒度对齐先验来解决模态鸿沟问题。它通过强化学习，自动构建偏好数据并使用新的相对偏好对齐损失函数，显著提升了细粒度跨模态检索的效果。


<details>
  <summary>Details</summary>
Motivation: 对比语言图像预训练模型存在特征空间模态鸿沟问题。现有基于多模态大语言模型的检索方法仅实现粗粒度对齐，潜力受限。因此需要一种能利用多模态大语言模型细粒度对齐先验的新方法。

Method: 提出了MAPLE框架，包含两个核心组件：(1)使用现成多模态大语言模型自动构建偏好数据；(2)设计新的相对偏好对齐损失函数，将直接偏好优化技术适配到嵌入学习场景。整个学习过程被建模为强化学习问题。

Result: 实验结果显示，偏好引导对齐方法在细粒度跨模态检索任务中取得显著性能提升，证明其处理细微语义区分的能力。

Conclusion: MAPLE通过利用多模态大语言模型的细粒度对齐特性，有效缩小了模态鸿沟。所提出的相对偏好对齐损失和自动数据构建方法为跨模态学习提供了新思路。

Abstract: Despite Contrastive Language-Image Pretraining (CLIP)'s remarkable capability
to retrieve content across modalities, a substantial modality gap persists in
its feature space. Intriguingly, we discover that off-the-shelf MLLMs
(Multimodal Large Language Models) demonstrate powerful inherent modality
alignment properties. While recent MLLM-based retrievers with unified
architectures partially mitigate this gap, their reliance on coarse modality
alignment mechanisms fundamentally limits their potential. In this work, We
introduce MAPLE (Modality-Aligned Preference Learning for Embeddings), a novel
framework that leverages the fine grained alignment priors inherent in MLLM to
guide cross modal representation learning. MAPLE formulates the learning
process as reinforcement learning with two key components: (1) Automatic
preference data construction using off-the-shelf MLLM, and (2) a new Relative
Preference Alignment (RPA) loss, which adapts Direct Preference Optimization
(DPO) to the embedding learning setting. Experimental results show that our
preference-guided alignment achieves substantial gains in fine-grained
cross-modal retrieval, underscoring its effectiveness in handling nuanced
semantic distinctions.

</details>


### [508] [Hybrid Mesh-Gaussian Representation for Efficient Indoor Scene Reconstruction](https://arxiv.org/abs/2506.06988)
*Binxiao Huang,Zhihao Li,Shiyong Liu,Xiao Tang,Jiajun Tang,Jiaqi Lin,Yuxin Cheng,Zhenyu Chen,Xiaofei Wu,Ngai Wong*

Main category: cs.CV

TL;DR: 该论文提出了一种混合表示方法，结合3D高斯溅射和纹理网格以提高室内场景渲染效率，通过网格处理纹理丰富平面区域并保留高斯用于复杂几何，从而减少高斯图元数量并提升FPS。


<details>
  <summary>Details</summary>
Motivation: 现有3D高斯溅射在复杂纹理区域需要大量高斯图元导致渲染效率低下，尤其室内场景中纹理丰富的平面区域（如墙壁、地板）存在冗余。

Method: 1. 用纹理网格建模纹理丰富平面区域；2. 保留高斯建模复杂几何；3. 包括网格修剪优化、联合优化（含预热策略和透射率感知监督）。

Result: 在保持渲染质量的同时减少高斯图元数量，实现更高FPS（具体数字未提及）。

Conclusion: 混合表示有效平衡渲染质量与效率，为室内场景提供更优解决方案。

Abstract: 3D Gaussian splatting (3DGS) has demonstrated exceptional performance in
image-based 3D reconstruction and real-time rendering. However, regions with
complex textures require numerous Gaussians to capture significant color
variations accurately, leading to inefficiencies in rendering speed. To address
this challenge, we introduce a hybrid representation for indoor scenes that
combines 3DGS with textured meshes. Our approach uses textured meshes to handle
texture-rich flat areas, while retaining Gaussians to model intricate
geometries. The proposed method begins by pruning and refining the extracted
mesh to eliminate geometrically complex regions. We then employ a joint
optimization for 3DGS and mesh, incorporating a warm-up strategy and
transmittance-aware supervision to balance their contributions
seamlessly.Extensive experiments demonstrate that the hybrid representation
maintains comparable rendering quality and achieves superior frames per second
FPS with fewer Gaussian primitives.

</details>


### [509] [Boosting Adversarial Transferability via Commonality-Oriented Gradient Optimization](https://arxiv.org/abs/2506.06992)
*Yanting Gao,Yepeng Liu,Junming Liu,Qi Zhang,Hongyun Zhang,Duoqian Miao,Cairong Zhao*

Main category: cs.CV

TL;DR: 本文提出了一种共性导向梯度优化策略（COGO），通过增强共享特征扰动和抑制个体特征扰动来提升对抗样本在Vision Transformers（ViTs）之间的迁移攻击效果。


<details>
  <summary>Details</summary>
Motivation: 现有方法未充分利用同任务替代模型的共享特征，导致对抗样本迁移性不足。增强共享共性特征扰动同时抑制个体特征扰动可有效提升迁移性。

Method: 1. 共性增强（CE）：扰动中低频区域（ViTs分类主要依赖中低频信息）
2. 个体抑制（IS）：通过自适应阈值评估梯度与模型个体相关性，加权调整梯度

Result: 实验表明COGO显著提升对抗攻击迁移成功率，超越当前SOTA方法。

Conclusion: 通过双重优化策略平衡共性特征扰动与个体特征抑制，可有效提升对抗样本在ViTs间的迁移性。

Abstract: Exploring effective and transferable adversarial examples is vital for
understanding the characteristics and mechanisms of Vision Transformers (ViTs).
However, adversarial examples generated from surrogate models often exhibit
weak transferability in black-box settings due to overfitting. Existing methods
improve transferability by diversifying perturbation inputs or applying uniform
gradient regularization within surrogate models, yet they have not fully
leveraged the shared and unique features of surrogate models trained on the
same task, leading to suboptimal transfer performance. Therefore, enhancing
perturbations of common information shared by surrogate models and suppressing
those tied to individual characteristics offers an effective way to improve
transferability. Accordingly, we propose a commonality-oriented gradient
optimization strategy (COGO) consisting of two components: Commonality
Enhancement (CE) and Individuality Suppression (IS). CE perturbs the mid-to-low
frequency regions, leveraging the fact that ViTs trained on the same dataset
tend to rely more on mid-to-low frequency information for classification. IS
employs adaptive thresholds to evaluate the correlation between backpropagated
gradients and model individuality, assigning weights to gradients accordingly.
Extensive experiments demonstrate that COGO significantly improves the transfer
success rates of adversarial attacks, outperforming current state-of-the-art
methods.

</details>


### [510] [DM$^3$Net: Dual-Camera Super-Resolution via Domain Modulation and Multi-scale Matching](https://arxiv.org/abs/2506.06993)
*Cong Guan,Jiacheng Ying,Yuya Ieiri,Osamu Yoshie*

Main category: cs.CV

TL;DR: 提出DM$^3$Net网络，利用远摄图像提升广角图像分辨率，通过域调制缩小域差距，多尺度匹配增强结构细节迁移，引入密钥剪枝减少内存占用。在三个数据集上超越现有方法。


<details>
  <summary>Details</summary>
Motivation: 智能手机双摄系统存在域差距问题：广角镜头分辨率不足（待超分域），远摄镜头提供参考但存在分辨率差异（高分辨率域）。需解决跨域高频信息对齐难题。

Method: 1.域调制：提取双域的压缩全局特征缩小域差
2.多尺度匹配：在多个感受野进行特征块级匹配检索
3.密钥剪枝：优化内存及时耗

Result: 在三个真实数据集上评估均超越SOTA方法，例如在Cityscape-X2任务上PSNR值提升0.8dB

Conclusion: DM$^3$Net是首个结合域调制+多尺度匹配的双摄超分方案，通过结构化特征对齐显著提升超分精度，密钥剪枝保证实用性。

Abstract: Dual-camera super-resolution is highly practical for smartphone photography
that primarily super-resolve the wide-angle images using the telephoto image as
a reference. In this paper, we propose DM$^3$Net, a novel dual-camera
super-resolution network based on Domain Modulation and Multi-scale Matching.
To bridge the domain gap between the high-resolution domain and the degraded
domain, we learn two compressed global representations from image pairs
corresponding to the two domains. To enable reliable transfer of high-frequency
structural details from the reference image, we design a multi-scale matching
module that conducts patch-level feature matching and retrieval across multiple
receptive fields to improve matching accuracy and robustness. Moreover, we also
introduce Key Pruning to achieve a significant reduction in memory usage and
inference time with little model performance sacrificed. Experimental results
on three real-world datasets demonstrate that our DM$^3$Net outperforms the
state-of-the-art approaches.

</details>


### [511] [Technical Report for ICRA 2025 GOOSE 3D Semantic Segmentation Challenge: Adaptive Point Cloud Understanding for Heterogeneous Robotic Systems](https://arxiv.org/abs/2506.06995)
*Xiaoya Zhang*

Main category: cs.CV

TL;DR: 本文提出了一种基于点提示调优（PPT）和Point Transformer v3（PTv3）的方法，解决了多个机器人平台的非结构化室外环境点云语义分割问题，无需额外数据即可提升性能。


<details>
  <summary>Details</summary>
Motivation: 挑战来自不同机器人平台的异构LiDAR数据导致的点云语义分割困难，需要同时处理平台差异和跨数据集类别对齐问题。

Method: 将点提示调优（PPT）与Point Transformer v3（PTv3）主干网络集成，通过平台特定条件化和跨数据集类别对齐策略实现自适应处理。

Result: 在挑战性平台上比基线PTv3模型大幅提升性能（mIoU最高提升22.59%），且未使用外部额外数据。

Conclusion: 该方法证明了自适应点云理解在野外机器人应用中的有效性，为处理异构传感器数据提供了实用解决方案。

Abstract: This technical report presents the implementation details of the winning
solution for the ICRA 2025 GOOSE 3D Semantic Segmentation Challenge. This
challenge focuses on semantic segmentation of 3D point clouds from diverse
unstructured outdoor environments collected from multiple robotic platforms.
This problem was addressed by implementing Point Prompt Tuning (PPT) integrated
with Point Transformer v3 (PTv3) backbone, enabling adaptive processing of
heterogeneous LiDAR data through platform-specific conditioning and
cross-dataset class alignment strategies. The model is trained without
requiring additional external data. As a result, this approach achieved
substantial performance improvements with mIoU increases of up to 22.59% on
challenging platforms compared to the baseline PTv3 model, demonstrating the
effectiveness of adaptive point cloud understanding for field robotics
applications.

</details>


### [512] [BePo: Leveraging Birds Eye View and Sparse Points for Efficient and Accurate 3D Occupancy Prediction](https://arxiv.org/abs/2506.07002)
*Yunxiao Shi,Hong Cai,Jisoo Jeong,Yinhao Zhu,Shizhong Han,Amin Ansari,Fatih Porikli*

Main category: cs.CV

TL;DR: 提出了BePo方法，结合BEV和稀疏点分支，解决3D占据预测中BEV在小型物体上信息丢失和稀疏点在大表面效率低的问题，并通过交叉注意力共享信息，在Occ3D基准上实现优越性能和创新速度。


<details>
  <summary>Details</summary>
Motivation: 为解决3D占据预测中BEV方法在小型物体上的信息损失和稀疏点方法在平坦表面或大型物体上的低效问题。

Method: 设计了双分支架构：基于查询的稀疏点分支和BEV分支，通过交叉注意力共享稀疏点的3D信息以增强BEV分支，最终融合分支输出生成3D占据预测。

Result: 在Occ3D-nuScenes和Occ3D-Waymo基准测试中表现出优越性，推理速度与最新高效方法相比具有竞争力。

Conclusion: BePo融合BEV和稀疏点的优势，有效提升3D几何与语义场景理解并兼顾效率，为自动驾驶3D表征提供新方案。

Abstract: 3D occupancy provides fine-grained 3D geometry and semantics for scene
understanding which is critical for autonomous driving. Most existing methods,
however, carry high compute costs, requiring dense 3D feature volume and
cross-attention to effectively aggregate information. More recent works have
adopted Bird's Eye View (BEV) or sparse points as scene representation with
much reduced cost, but still suffer from their respective shortcomings. More
concretely, BEV struggles with small objects that often experience significant
information loss after being projected to the ground plane. On the other hand,
points can flexibly model little objects in 3D, but is inefficient at capturing
flat surfaces or large objects. To address these challenges, in this paper, we
present a novel 3D occupancy prediction approach, BePo, which combines BEV and
sparse points based representations. We propose a dual-branch design: a
query-based sparse points branch and a BEV branch. The 3D information learned
in the sparse points branch is shared with the BEV stream via cross-attention,
which enriches the weakened signals of difficult objects on the BEV plane. The
outputs of both branches are finally fused to generate predicted 3D occupancy.
We conduct extensive experiments on the Occ3D-nuScenes and Occ3D-Waymo
benchmarks that demonstrate the superiority of our proposed BePo. Moreover,
BePo also delivers competitive inference speed when compared to the latest
efficient approaches.

</details>


### [513] [UNO: Unified Self-Supervised Monocular Odometry for Platform-Agnostic Deployment](https://arxiv.org/abs/2506.07013)
*Wentao Zhao,Yihe Niu,Yanbo Wang,Tianchen Deng,Shenghai Yuan,Zhenli Wang,Rui Guo,Jingchuan Wang*

Main category: cs.CV

TL;DR: 提出UNO框架，通过混合专家策略和可微Gumbel-Softmax模块，实现跨平台、多场景的鲁棒单目视觉里程计


<details>
  <summary>Details</summary>
Motivation: 克服传统方法需要针对部署场景调参或依赖预设运动先验的问题，适应多种平台（自动驾驶汽车/无人机/移动机器人/手持设备）的运动模式

Method: 1. 混合专家策略：多个专用解码器处理不同运动模式 2. Gumbel-Softmax模块构建关联图/选择最优专家/剔除错误估计 3. 后端结合预训练尺度不变深度先验与轻量捆集调整

Result: 在KITTI（室外驾驶）、EuRoC-MAV（室内无人机）、TUM-RGBD（室内手持）三大基准测试达到SOTA性能

Conclusion: UNO首次实现统一框架下对多样化运动模式/平台/场景的泛化，且效果优于现有方法

Abstract: This work presents UNO, a unified monocular visual odometry framework that
enables robust and adaptable pose estimation across diverse environments,
platforms, and motion patterns. Unlike traditional methods that rely on
deployment-specific tuning or predefined motion priors, our approach
generalizes effectively across a wide range of real-world scenarios, including
autonomous vehicles, aerial drones, mobile robots, and handheld devices. To
this end, we introduce a Mixture-of-Experts strategy for local state
estimation, with several specialized decoders that each handle a distinct class
of ego-motion patterns. Moreover, we introduce a fully differentiable
Gumbel-Softmax module that constructs a robust inter-frame correlation graph,
selects the optimal expert decoder, and prunes erroneous estimates. These cues
are then fed into a unified back-end that combines pre-trained,
scale-independent depth priors with a lightweight bundling adjustment to
enforce geometric consistency. We extensively evaluate our method on three
major benchmark datasets: KITTI (outdoor/autonomous driving), EuRoC-MAV
(indoor/aerial drones), and TUM-RGBD (indoor/handheld), demonstrating
state-of-the-art performance.

</details>


### [514] [TABLET: Table Structure Recognition using Encoder-only Transformers](https://arxiv.org/abs/2506.07015)
*Qiyu Hou,Jun Wang*

Main category: cs.CV

TL;DR: 提出了一种用于大规模密集表格结构识别的Split-Merge上下结构模型，通过序列标注和网格分类消除边界框预测，在精度和速度上取得突破


<details>
  <summary>Details</summary>
Motivation: 解决大而密集的表格结构识别中边界框预测不稳定、分辨率损失和计算复杂度高的问题

Method: 采用双Transformer编码器进行行列拆分的序列标注，使用额外Transformer编码器进行网格单元分类的合并处理

Result: 在FinTabNet和PubTabNet数据集上超越现有方法，实现高精度快速处理

Conclusion: 为大规模表格识别提供了鲁棒、可扩展且高效的解决方案，适用于工业部署

Abstract: To address the challenges of table structure recognition, we propose a novel
Split-Merge-based top-down model optimized for large, densely populated tables.
Our approach formulates row and column splitting as sequence labeling tasks,
utilizing dual Transformer encoders to capture feature interactions. The
merging process is framed as a grid cell classification task, leveraging an
additional Transformer encoder to ensure accurate and coherent merging. By
eliminating unstable bounding box predictions, our method reduces resolution
loss and computational complexity, achieving high accuracy while maintaining
fast processing speed. Extensive experiments on FinTabNet and PubTabNet
demonstrate the superiority of our model over existing approaches, particularly
in real-world applications. Our method offers a robust, scalable, and efficient
solution for large-scale table recognition, making it well-suited for
industrial deployment.

</details>


### [515] [MAGNET: A Multi-agent Framework for Finding Audio-Visual Needles by Reasoning over Multi-Video Haystacks](https://arxiv.org/abs/2506.07016)
*Sanjoy Chowdhury,Mohamed Elmoghany,Yohan Abeysinghe,Junjie Fei,Sayan Nag,Salman Khan,Mohamed Elhoseiny,Dinesh Manocha*

Main category: cs.CV

TL;DR: 论文提出了AV-HaystacksQA任务和AVHaystacks基准，用于评估大型多模态模型在跨视频检索和时序定位的能力。同时提出了MAGNET框架和两个新评测指标STEM与MTGS，相比基线模型取得显著提升。


<details>
  <summary>Details</summary>
Motivation: 现有视频问答基准通常仅使用单段视频片段，无法评估模型在大规模音视频检索与复杂推理场景下的性能，因此需要创建更符合实际应用挑战的新基准。

Method: 提出多智能体框架MAGNET，该框架通过协作代理机制实现跨视频的时序定位和推理。创建包含3100个问答对的AVHaystacks基准，并设计STEM（时序对齐误差）和MTGS（分段定位评分）两个新型评测指标。

Result: MAGNET在BLEU@4和GPT评测分数上分别取得89%和65%的相对提升。新指标STEM和MTGS能有效评估多视频检索与定位性能。

Conclusion: AVHaystacksQA任务和基准填补了大规模音视频推理评估的空白，MAGNET框架显示出跨视频推理的优越性，新指标为未来研究提供更精细的评估工具。

Abstract: Large multimodal models (LMMs) have shown remarkable progress in audio-visual
understanding, yet they struggle with real-world scenarios that require complex
reasoning across extensive video collections. Existing benchmarks for video
question answering remain limited in scope, typically involving one clip per
query, which falls short of representing the challenges of large-scale,
audio-visual retrieval and reasoning encountered in practical applications. To
bridge this gap, we introduce a novel task named AV-HaystacksQA, where the goal
is to identify salient segments across different videos in response to a query
and link them together to generate the most informative answer. To this end, we
present AVHaystacks, an audio-visual benchmark comprising 3100 annotated QA
pairs designed to assess the capabilities of LMMs in multi-video retrieval and
temporal grounding task. Additionally, we propose a model-agnostic, multi-agent
framework MAGNET to address this challenge, achieving up to 89% and 65%
relative improvements over baseline methods on BLEU@4 and GPT evaluation scores
in QA task on our proposed AVHaystacks. To enable robust evaluation of
multi-video retrieval and temporal grounding for optimal response generation,
we introduce two new metrics, STEM, which captures alignment errors between a
ground truth and a predicted step sequence and MTGS, to facilitate balanced and
interpretable evaluation of segment-level grounding performance. Project:
https://schowdhury671.github.io/magnet_project/

</details>


### [516] [Interpretable and Reliable Detection of AI-Generated Images via Grounded Reasoning in MLLMs](https://arxiv.org/abs/2506.07045)
*Yikun Ji,Hong Yan,Jun Lan,Huijia Zhu,Weiqiang Wang,Qi Fan,Liqing Zhang,Jianfu Zhang*

Main category: cs.CV

TL;DR: 论文提出了一种基于多模态大语言模型（MLLMs）的AI生成图像检测方法，通过构建带有标注框和描述性文字的数据集，并采用多阶段优化策略微调模型，显著提升了检测精度和可解释性。


<details>
  <summary>Details</summary>
Motivation: 现有AI生成图像检测方法虽精度高但缺乏可解释性，且多模态大语言模型在处理该任务时存在幻觉问题及视觉理解偏差。

Method: 1) 构建包含合成伪影标注（边界框和文字描述）的数据集；2) 设计多阶段优化策略平衡检测精度、视觉定位和文本解释能力。

Result: 模型在检测AI生成图像和定位视觉瑕疵方面显著超越基线方法。

Conclusion: 该方法通过视觉-文本联合推理框架解决了MLLMs的幻觉问题，实现了可解释且鲁棒的AI生成图像检测。

Abstract: The rapid advancement of image generation technologies intensifies the demand
for interpretable and robust detection methods. Although existing approaches
often attain high accuracy, they typically operate as black boxes without
providing human-understandable justifications. Multi-modal Large Language
Models (MLLMs), while not originally intended for forgery detection, exhibit
strong analytical and reasoning capabilities. When properly fine-tuned, they
can effectively identify AI-generated images and offer meaningful explanations.
However, existing MLLMs still struggle with hallucination and often fail to
align their visual interpretations with actual image content and human
reasoning. To bridge this gap, we construct a dataset of AI-generated images
annotated with bounding boxes and descriptive captions that highlight synthesis
artifacts, establishing a foundation for human-aligned visual-textual grounded
reasoning. We then finetune MLLMs through a multi-stage optimization strategy
that progressively balances the objectives of accurate detection, visual
localization, and coherent textual explanation. The resulting model achieves
superior performance in both detecting AI-generated images and localizing
visual flaws, significantly outperforming baseline methods.

</details>


### [517] [From Swath to Full-Disc: Advancing Precipitation Retrieval with Multimodal Knowledge Expansion](https://arxiv.org/abs/2506.07050)
*Zheng Wang,Kai Ying,Bin Xu,Chunjiao Wang,Cong Bai*

Main category: cs.CV

TL;DR: 该论文提出了PRE-Net模型，通过两阶段训练实现红外降水估算精度提升。第一阶段在扫描区内使用多模态知识蒸馏技术，第二阶段在全圆盘范围自适应微调，显著优于主流方法并建立新基准。


<details>
  <summary>Details</summary>
Motivation: 现有红外降水算法精度低，微波/雷达算法精度高但覆盖范围有限。研究旨在扩展红外算法的精确估算能力至全球范围。

Method: 提出了两阶段多模态知识拓展框架：1)扫描区内利用带掩模协调与小波增强的知识蒸馏；2)全圆盘范围通过自掩模调整融合多模态与红外知识。

Result: 在PRE基准测试中表现突出，优于PERSIANN-CCS、PDIR和IMERG等主流产品，代码即将开源。

Conclusion: PRE-Net成功突破红外降水估算的覆盖限制，通过知识迁移和自适应微调实现全圆盘高精度降水反演。

Abstract: Accurate near-real-time precipitation retrieval has been enhanced by
satellite-based technologies. However, infrared-based algorithms have low
accuracy due to weak relations with surface precipitation, whereas passive
microwave and radar-based methods are more accurate but limited in range. This
challenge motivates the Precipitation Retrieval Expansion (PRE) task, which
aims to enable accurate, infrared-based full-disc precipitation retrievals
beyond the scanning swath. We introduce Multimodal Knowledge Expansion, a
two-stage pipeline with the proposed PRE-Net model. In the Swath-Distilling
stage, PRE-Net transfers knowledge from a multimodal data integration model to
an infrared-based model within the scanning swath via Coordinated Masking and
Wavelet Enhancement (CoMWE). In the Full-Disc Adaptation stage, Self-MaskTune
refines predictions across the full disc by balancing multimodal and full-disc
infrared knowledge. Experiments on the introduced PRE benchmark demonstrate
that PRE-Net significantly advanced precipitation retrieval performance,
outperforming leading products like PERSIANN-CCS, PDIR, and IMERG. The code
will be available at https://github.com/Zjut-MultimediaPlus/PRE-Net.

</details>


### [518] [A Layered Self-Supervised Knowledge Distillation Framework for Efficient Multimodal Learning on the Edge](https://arxiv.org/abs/2506.07055)
*Tarique Dahri,Zulfiqar Ali Memon,Zhenyu Yu,Mohd. Yamani Idna Idris,Sheheryar Khan,Sadiq Ahmad,Maged Shoman,Saddam Aziz,Rizwan Qureshi*

Main category: cs.CV

TL;DR: LSSKD是一种轻量级自监督知识蒸馏框架，通过中间层辅助分类器生成多样化知识，无需预训练教师网络，在多个数据集上超越现有方法，推理时无额外计算成本。


<details>
  <summary>Details</summary>
Motivation: 传统知识蒸馏依赖大型教师网络，计算开销大且部署困难。LSSKD旨在通过自监督方式提取中间层知识，实现高效模型压缩。

Method: 在主干网络中间层附加辅助分类器，生成自监督知识信号，实现跨网络阶段的逐层知识转移。

Result: CIFAR-100上平均提升4.54%（优于PS-KD）和1.14%（优于SSKD）；ImageNet提升0.32%（优于HASSKD）；Tiny ImageNet小样本学习达SOTA。

Conclusion: LSSKD无需大型教师网络即可提升模型性能，辅助分类器可移除保证零推理开销，适用于低算力设备和弱监督学习场景。

Abstract: We introduce Layered Self-Supervised Knowledge Distillation (LSSKD) framework
for training compact deep learning models. Unlike traditional methods that rely
on pre-trained teacher networks, our approach appends auxiliary classifiers to
intermediate feature maps, generating diverse self-supervised knowledge and
enabling one-to-one transfer across different network stages. Our method
achieves an average improvement of 4.54\% over the state-of-the-art PS-KD
method and a 1.14% gain over SSKD on CIFAR-100, with a 0.32% improvement on
ImageNet compared to HASSKD. Experiments on Tiny ImageNet and CIFAR-100 under
few-shot learning scenarios also achieve state-of-the-art results. These
findings demonstrate the effectiveness of our approach in enhancing model
generalization and performance without the need for large over-parameterized
teacher networks. Importantly, at the inference stage, all auxiliary
classifiers can be removed, yielding no extra computational cost. This makes
our model suitable for deploying small language models on affordable
low-computing devices. Owing to its lightweight design and adaptability, our
framework is particularly suitable for multimodal sensing and cyber-physical
environments that require efficient and responsive inference. LSSKD facilitates
the development of intelligent agents capable of learning from limited sensory
data under weak supervision.

</details>


### [519] [D2R: dual regularization loss with collaborative adversarial generation for model robustness](https://arxiv.org/abs/2506.07056)
*Zhenyu Liu,Huizhi Liang,Rajiv Ranjan,Zhanxing Zhu,Vaclav Snasel,Varun Ojha*

Main category: cs.CV

TL;DR: 该论文提出了一种双正则化损失（D2R Loss）方法和协作对抗生成（CAG）策略，通过两种优化步骤增强模型鲁棒性：对抗分布优化和干净分布优化，以及基于梯度的协作生成对抗样本。在多个基准数据集和模型上的实验证明了方法的有效性。


<details>
  <summary>Details</summary>
Motivation: 现有方法存在两个关键局限：（i）损失函数对目标模型的引导不足，（ii）非协作式的对抗样本生成。因此需要更有效的损失函数和协作策略来提升模型对抗攻击的鲁棒性。

Method: 提出双正则化损失（D2R Loss）分两个优化步骤：对抗分布优化和干净分布优化，利用函数空间探索精确聚焦目标模型分布；提出协作对抗生成（CAG）策略，通过指导模型与目标模型的梯度协作生成对抗样本。

Result: 在CIFAR-10、CIFAR-100、Tiny ImageNet数据集及WideResNet34-10和PreActResNet18模型上的实验表明，所提方法能生成高鲁棒性模型。

Conclusion: D2R Loss结合CAG策略能有效提升深度学习模型对抗攻击的防御能力，解决了现有方法在损失引导和对抗生成方面的不足。

Abstract: The robustness of Deep Neural Network models is crucial for defending models
against adversarial attacks. Recent defense methods have employed collaborative
learning frameworks to enhance model robustness. Two key limitations of
existing methods are (i) insufficient guidance of the target model via loss
functions and (ii) non-collaborative adversarial generation. We, therefore,
propose a dual regularization loss (D2R Loss) method and a collaborative
adversarial generation (CAG) strategy for adversarial training. D2R loss
includes two optimization steps. The adversarial distribution and clean
distribution optimizations enhance the target model's robustness by leveraging
the strengths of different loss functions obtained via a suitable function
space exploration to focus more precisely on the target model's distribution.
CAG generates adversarial samples using a gradient-based collaboration between
guidance and target models. We conducted extensive experiments on three
benchmark databases, including CIFAR-10, CIFAR-100, Tiny ImageNet, and two
popular target models, WideResNet34-10 and PreActResNet18. Our results show
that D2R loss with CAG produces highly robust models.

</details>


### [520] [FLAIR-HUB: Large-scale Multimodal Dataset for Land Cover and Crop Mapping](https://arxiv.org/abs/2506.07080)
*Anatol Garioud,Sébastien Giordano,Nicolas David,Nicolas Gonthier*

Main category: cs.CV

TL;DR: FLAIR-HUB is the largest multi-sensor land cover dataset with high-resolution annotations for France, addressing the challenges of processing and annotating diverse Earth Observation data.


<details>
  <summary>Details</summary>
Motivation: The volume and heterogeneity of Earth Observation data create processing and annotation difficulties, necessitating large annotated datasets for effective land cover and crop monitoring.

Method: Combines six aligned modalities including aerial imagery, Sentinel series, SPOT imagery, topographic data, and historical images. Evaluates multimodal fusion and deep learning models (CNNs, transformers) with extensive benchmarks.

Result: Achieved best land cover performance at 78.2% accuracy and 65.8% mIoU using nearly all modalities, highlighting the complexity of multimodal fusion and fine-grained classification.

Conclusion: FLAIR-HUB dataset enables effective supervised and multimodal pretraining for land cover and crop mapping, with demonstrated practical utility and publicly available data/code.

Abstract: The growing availability of high-quality Earth Observation (EO) data enables
accurate global land cover and crop type monitoring. However, the volume and
heterogeneity of these datasets pose major processing and annotation
challenges. To address this, the French National Institute of Geographical and
Forest Information (IGN) is actively exploring innovative strategies to exploit
diverse EO data, which require large annotated datasets. IGN introduces
FLAIR-HUB, the largest multi-sensor land cover dataset with
very-high-resolution (20 cm) annotations, covering 2528 km2 of France. It
combines six aligned modalities: aerial imagery, Sentinel-1/2 time series, SPOT
imagery, topographic data, and historical aerial images. Extensive benchmarks
evaluate multimodal fusion and deep learning models (CNNs, transformers) for
land cover or crop mapping and also explore multi-task learning. Results
underscore the complexity of multimodal fusion and fine-grained classification,
with best land cover performance (78.2% accuracy, 65.8% mIoU) achieved using
nearly all modalities. FLAIR-HUB supports supervised and multimodal
pretraining, with data and code available at
https://ignf.github.io/FLAIR/flairhub.

</details>


### [521] [UCOD-DPL: Unsupervised Camouflaged Object Detection via Dynamic Pseudo-label Learning](https://arxiv.org/abs/2506.07087)
*Weiqi Yan,Lvhai Chen,Huaijia Kou,Shengchuan Zhang,Yan Zhang,Liujuan Cao*

Main category: cs.CV

TL;DR: 提出了一种名为UCOD-DPL的无监督伪装目标检测方法，通过动态伪标签学习和教师-学生框架解决现有方法中伪标签噪声大、解码器简单导致的性能不足问题。


<details>
  <summary>Details</summary>
Motivation: 现有无监督伪装目标检测方法使用固定策略生成伪标签，并用简单解码器训练，导致性能低于全监督方法。主要问题包括：1) 伪标签噪声大使模型易学习错误知识；2) 简单解码器无法捕捉语义特征，尤其是小目标，且存在前景背景混淆。

Method: 提出UCOD-DPL框架：1) 自适应伪标签模块(APM)动态融合固定策略和教师模型生成的伪标签；2) 双分支对抗(DBA)解码器通过对抗学习解决前景背景混淆；3) Look-Twice机制二次精炼小目标。

Result: 大量实验表明，该方法性能优异，甚至超越部分全监督方法。代码已开源。

Conclusion: UCOD-DPL通过动态伪标签学习和专门设计的解码器，显著提升了无监督伪装目标检测性能，解决了噪声适应和特征学习问题。

Abstract: Unsupervised Camoflaged Object Detection (UCOD) has gained attention since it
doesn't need to rely on extensive pixel-level labels. Existing UCOD methods
typically generate pseudo-labels using fixed strategies and train 1 x1
convolutional layers as a simple decoder, leading to low performance compared
to fully-supervised methods. We emphasize two drawbacks in these approaches:
1). The model is prone to fitting incorrect knowledge due to the pseudo-label
containing substantial noise. 2). The simple decoder fails to capture and learn
the semantic features of camouflaged objects, especially for small-sized
objects, due to the low-resolution pseudo-labels and severe confusion between
foreground and background pixels. To this end, we propose a UCOD method with a
teacher-student framework via Dynamic Pseudo-label Learning called UCOD-DPL,
which contains an Adaptive Pseudo-label Module (APM), a Dual-Branch Adversarial
(DBA) decoder, and a Look-Twice mechanism. The APM module adaptively combines
pseudo-labels generated by fixed strategies and the teacher model to prevent
the model from overfitting incorrect knowledge while preserving the ability for
self-correction; the DBA decoder takes adversarial learning of different
segmentation objectives, guides the model to overcome the foreground-background
confusion of camouflaged objects, and the Look-Twice mechanism mimics the human
tendency to zoom in on camouflaged objects and performs secondary refinement on
small-sized objects. Extensive experiments show that our method demonstrates
outstanding performance, even surpassing some existing fully supervised
methods. The code is available now.

</details>


### [522] [SceneLCM: End-to-End Layout-Guided Interactive Indoor Scene Generation with Latent Consistency Model](https://arxiv.org/abs/2506.07091)
*Yangkai Lin,Jiabao Lei,Kui Jia*

Main category: cs.CV

TL;DR: SceneLCM：结合LLM和LCM的端到端框架，通过四个模块化流程（布局生成、家具生成、环境优化和物理编辑）解决现有室内场景生成方法的编辑限制、物理不连贯、人力消耗大等问题，实现高质量可交互场景的自动化生成。


<details>
  <summary>Details</summary>
Motivation: 现有室内场景生成方法存在编辑限制严格、物理不连贯、人力消耗大、单房间限制和材质质量差等问题，需要一种能够自动化生成符合用户提示的复杂可交互场景的解决方案。

Method: （1）利用LLM进行3D空间推理将文本描述转为参数化布局，通过迭代的编程验证机制优化布局；（2）采用基于LCM的CTS损失实现快速高质量的家具表示；（3）通过多分辨率纹理场和法线感知交叉注意力解码器优化环境；（4）整合物理模拟实现物理编辑功能。

Result: 在广泛实验中证明优于现有技术，展示出在不同应用场景中的广泛潜力。

Conclusion: SceneLCM通过协同集成LLM和LCM，解决了现有方法的局限性，实现了物理连贯的高质量室内场景生成与编辑。

Abstract: Our project page: https://scutyklin.github.io/SceneLCM/. Automated generation
of complex, interactive indoor scenes tailored to user prompt remains a
formidable challenge. While existing methods achieve indoor scene synthesis,
they struggle with rigid editing constraints, physical incoherence, excessive
human effort, single-room limitations, and suboptimal material quality. To
address these limitations, we propose SceneLCM, an end-to-end framework that
synergizes Large Language Model (LLM) for layout design with Latent Consistency
Model(LCM) for scene optimization. Our approach decomposes scene generation
into four modular pipelines: (1) Layout Generation. We employ LLM-guided 3D
spatial reasoning to convert textual descriptions into parametric blueprints(3D
layout). And an iterative programmatic validation mechanism iteratively refines
layout parameters through LLM-mediated dialogue loops; (2) Furniture
Generation. SceneLCM employs Consistency Trajectory Sampling(CTS), a
consistency distillation sampling loss guided by LCM, to form fast,
semantically rich, and high-quality representations. We also offer two
theoretical justification to demonstrate that our CTS loss is equivalent to
consistency loss and its distillation error is bounded by the truncation error
of the Euler solver; (3) Environment Optimization. We use a multiresolution
texture field to encode the appearance of the scene, and optimize via CTS loss.
To maintain cross-geometric texture coherence, we introduce a normal-aware
cross-attention decoder to predict RGB by cross-attending to the anchors
locations in geometrically heterogeneous instance. (4)Physically Editing.
SceneLCM supports physically editing by integrating physical simulation,
achieved persistent physical realism. Extensive experiments validate SceneLCM's
superiority over state-of-the-art techniques, showing its wide-ranging
potential for diverse applications.

</details>


### [523] [EdgeSpotter: Multi-Scale Dense Text Spotting for Industrial Panel Monitoring](https://arxiv.org/abs/2506.07112)
*Changhong Fu,Hua Lin,Haobo Zuo,Liangliang Yao,Liguo Zhang*

Main category: cs.CV

TL;DR: 提出了用于工业面板监控的EdgeSpotter：一种新型多尺度密集文本识别器，采用高效Mixer的Transformer增强多级特征交互，设计基于Catmull-Rom样条的特征采样方法解决漏检问题。建立了IPM数据集，实验验证方法在边缘AI视觉系统的有效性。


<details>
  <summary>Details</summary>
Motivation: 工业面板文本识别存在多尺度定位困难和密集文本边界模糊问题，现有方法缺乏对多尺度文本特征的综合利用，需提升边缘设备上的监测准确性。

Method: 1. 提出带高效Mixer的Transformer学习多级特征依赖，融合空间与语义线索；2. 设计Catmull-Rom样条特征采样，显式编码文本形状/位置/语义信息；3. 构建工业面板监控数据集IPM。

Result: 在IPM数据集上经定量定性评估验证优越性，边缘AI视觉系统实际测试证明实用性，代码即将开源。

Conclusion: EdgeSpotter通过多尺度特征融合与新型采样策略，有效解决工业面板监控中的多尺度文本漏检和识别错误问题，具备实际部署价值。

Abstract: Text spotting for industrial panels is a key task for intelligent monitoring.
However, achieving efficient and accurate text spotting for complex industrial
panels remains challenging due to issues such as cross-scale localization and
ambiguous boundaries in dense text regions. Moreover, most existing methods
primarily focus on representing a single text shape, neglecting a comprehensive
exploration of multi-scale feature information across different texts. To
address these issues, this work proposes a novel multi-scale dense text spotter
for edge AI-based vision system (EdgeSpotter) to achieve accurate and robust
industrial panel monitoring. Specifically, a novel Transformer with efficient
mixer is developed to learn the interdependencies among multi-level features,
integrating multi-layer spatial and semantic cues. In addition, a new feature
sampling with catmull-rom splines is designed, which explicitly encodes the
shape, position, and semantic information of text, thereby alleviating missed
detections and reducing recognition errors caused by multi-scale or dense text
regions. Furthermore, a new benchmark dataset for industrial panel monitoring
(IPM) is constructed. Extensive qualitative and quantitative evaluations on
this challenging benchmark dataset validate the superior performance of the
proposed method in different challenging panel monitoring tasks. Finally,
practical tests based on the self-designed edge AI-based vision system
demonstrate the practicality of the method. The code and demo will be available
at https://github.com/vision4robotics/EdgeSpotter.

</details>


### [524] [Image segmentation and classification of E-waste for waste segregation](https://arxiv.org/abs/2506.07122)
*Prakriti Tripathi,Theertha Biju,Maniram Thota,Rakesh Lingam*

Main category: cs.CV

TL;DR: 文章提出了一种利用YOLOv11和Mask-RCNN模型对电子废物进行分类的方法，通过创建自定义数据集并训练模型，YOLOv11实现了70 mAP的实时性能，将集成到分拣机器人中。


<details>
  <summary>Details</summary>
Motivation: 工业界需要一种通过机器学习分类电子废物的解决方案，以辅助分拣机器人进行废物分离。

Method: 收集常见电子废物（如鼠标和充电器），拆解后拍照构建自定义数据集，随后训练YOLOv11和Mask-RCNN目标检测模型。

Result: YOLOv11模型达到70 mAP的实时检测性能；Mask-RCNN模型达到41 mAP。

Conclusion: YOLOv11模型在电子废物分类中表现更优，未来将集成到分拣机器人系统中实现自动分离。

Abstract: Industry partners provided a problem statement that involves classifying
electronic waste using machine learning models that will be used by
pick-and-place robots for waste segregation. We started by taking common
electronic waste items, such as a mouse and charger, unsoldering them, and
taking pictures to create a custom dataset. Then state-of-the art YOLOv11 model
was trained and run to achieve 70 mAP in real-time. Mask-RCNN model was also
trained and achieved 41 mAP. The model will be further integrated with
pick-and-place robots to perform segregation of e-waste.

</details>


### [525] [Hi-VAE: Efficient Video Autoencoding with Global and Detailed Motion](https://arxiv.org/abs/2506.07136)
*Huaize Liu,Wenzhang Sun,Qiyuan Zhang,Donglin Di,Biao Gong,Hao Li,Chen Wei,Changqing Zou*

Main category: cs.CV

TL;DR: Hi-VAE是一种高效的分层视频自编码框架，通过将视频动态分解为全局运动和细节运动两个潜在空间，显著减少时空冗余，达到1428倍压缩率，比基线方法高约30倍，同时保持高重建质量。


<details>
  <summary>Details</summary>
Motivation: 现有视频自编码器未能高效建模动态中的时空冗余，导致压缩率低且下游任务训练成本过高。

Method: 1. 将视频动态分层编码为全局运动（宏观模式）和细节运动（高频细节）两个潜在空间
2. 使用自监督运动编码器压缩视频潜在表示
3. 基于条件扩散解码器结合分层运动信息重建视频

Result: 压缩率1428倍（Cosmos-VAE基线仅48倍），在极高压缩率下保持高重建质量，下游生成任务表现优异。

Conclusion: Hi-VAE通过分层运动表示实现超高效率压缩，同时具备可解释性和扩展性，为视频潜在表示研究提供新方向。

Abstract: Recent breakthroughs in video autoencoders (Video AEs) have advanced video
generation, but existing methods fail to efficiently model spatio-temporal
redundancies in dynamics, resulting in suboptimal compression factors. This
shortfall leads to excessive training costs for downstream tasks. To address
this, we introduce Hi-VAE, an efficient video autoencoding framework that
hierarchically encode coarse-to-fine motion representations of video dynamics
and formulate the decoding process as a conditional generation task.
Specifically, Hi-VAE decomposes video dynamics into two latent spaces: Global
Motion, capturing overarching motion patterns, and Detailed Motion, encoding
high-frequency spatial details. Using separate self-supervised motion encoders,
we compress video latents into compact motion representations to reduce
redundancy significantly. A conditional diffusion decoder then reconstructs
videos by combining hierarchical global and detailed motions, enabling
high-fidelity video reconstructions. Extensive experiments demonstrate that
Hi-VAE achieves a high compression factor of 1428$\times$, almost 30$\times$
higher than baseline methods (e.g., Cosmos-VAE at 48$\times$), validating the
efficiency of our approach. Meanwhile, Hi-VAE maintains high reconstruction
quality at such high compression rates and performs effectively in downstream
generative tasks. Moreover, Hi-VAE exhibits interpretability and scalability,
providing new perspectives for future exploration in video latent
representation and generation.

</details>


### [526] [Learning Compact Vision Tokens for Efficient Large Multimodal Models](https://arxiv.org/abs/2506.07138)
*Hao Tang,Chengchao Shen*

Main category: cs.CV

TL;DR: 该论文提出了一种通过减少视觉令牌数量来加速大型多模态模型推理的方法，包括空间令牌融合和多重区块令牌融合，能在保持性能的同时减少75%的视觉令牌使用。


<details>
  <summary>Details</summary>
Motivation: 大型多模态模型在处理长视觉令牌序列时存在计算效率低下的问题，主要源于语言模型的高计算成本和视觉令牌二次复杂性问题。现有方法中冻结的视觉编码器难以适应多样化下游任务的需求。

Method: 结合空间令牌融合（STF）压缩相邻视觉令牌序列，通过多重区块令牌融合（MBTF）补充多粒度特征，在减少令牌数量的同时保持信息完整性。

Result: 在LLaVA-1.5模型上，仅使用基线模型25%的视觉令牌，就能在8个主流视觉语言基准测试中获得可比甚至更优的性能。

Conclusion: 该研究实现了推理效率与模型性能的平衡，为多模态模型部署提供高效解决方案，相关代码和权重已开源。

Abstract: Large multimodal models (LMMs) suffer significant computational challenges
due to the high cost of Large Language Models (LLMs) and the quadratic
complexity of processing long vision token sequences. In this paper, we explore
the spatial redundancy among vision tokens and shorten the length of vision
token sequences for inference acceleration. Specifically, we propose a Spatial
Token Fusion (STF) method to learn compact vision tokens for short vision token
sequence, where spatial-adjacent tokens are fused into one. Meanwhile,
weight-frozen vision encoder can not well adapt to the demand of extensive
downstream vision-language tasks. To this end, we further introduce a
Multi-Block Token Fusion (MBTF) module to supplement multi-granularity features
for the reduced token sequence. Overall, we combine STF and MBTF module to
balance token reduction and information preservation, thereby improving
inference efficiency without sacrificing multimodal reasoning capabilities.
Experimental results demonstrate that our method based on LLaVA-1.5 achieves
comparable or even superior performance to the baseline on 8 popular
vision-language benchmarks with only $25\%$ vision tokens of baseline. The
source code and trained weights are available at
https://github.com/visresearch/LLaVA-STF.

</details>


### [527] [GoTrack: Generic 6DoF Object Pose Refinement and Tracking](https://arxiv.org/abs/2506.07155)
*Van Nguyen Nguyen,Christian Forster,Sindi Shkodrani,Vincent Lepetit,Bugra Tekin,Cem Keskin,Tomas Hodan*

Main category: cs.CV

TL;DR: GoTrack是一种高效、准确的6自由度物体姿态细化和跟踪方法，无需物体特定训练。它融合了模型到帧和帧到帧的配准，使用光流估计实现，在标准基准测试中达到SOTA结果。


<details>
  <summary>Details</summary>
Motivation: 现有跟踪方法仅依赖分析-合成（model-to-frame）进行配准，计算开销大且稳定性不足。GoTrack通过集成帧间配准（frame-to-frame）减少计算并提升稳定性。

Method: 1.模型到帧配准：基于DINOv2使用Transformer估计光流，简化流程并生成可靠姿态置信度；2.帧间配准：采用轻量级现成光流模型处理连续帧。可与粗姿态估计方法无缝结合。

Result: 在6自由度物体姿态估计与跟踪标准基准测试中实现最先进（SOTA）的仅RGB结果。

Conclusion: GoTrack通过双配准策略平衡精度与效率，为通用物体姿态跟踪提供鲁棒解决方案，代码已开源。

Abstract: We introduce GoTrack, an efficient and accurate CAD-based method for 6DoF
object pose refinement and tracking, which can handle diverse objects without
any object-specific training. Unlike existing tracking methods that rely solely
on an analysis-by-synthesis approach for model-to-frame registration, GoTrack
additionally integrates frame-to-frame registration, which saves compute and
stabilizes tracking. Both types of registration are realized by optical flow
estimation. The model-to-frame registration is noticeably simpler than in
existing methods, relying only on standard neural network blocks (a transformer
is trained on top of DINOv2) and producing reliable pose confidence scores
without a scoring network. For the frame-to-frame registration, which is an
easier problem as consecutive video frames are typically nearly identical, we
employ a light off-the-shelf optical flow model. We demonstrate that GoTrack
can be seamlessly combined with existing coarse pose estimation methods to
create a minimal pipeline that reaches state-of-the-art RGB-only results on
standard benchmarks for 6DoF object pose estimation and tracking. Our source
code and trained models are publicly available at
https://github.com/facebookresearch/gotrack

</details>


### [528] [Faster than Fast: Accelerating Oriented FAST Feature Detection on Low-end Embedded GPUs](https://arxiv.org/abs/2506.07164)
*Qiong Chang,Xinyuan Chen,Xiang Li,Weimin Wang,Jun Miyazaki*

Main category: cs.CV

TL;DR: 本文提出了两种在低端嵌入式GPU上加速Oriented FAST特征检测的方法，通过二进制编码策略和可分离Harris检测策略实现，在Jetson TX2上比OpenCV GPU加速了7.3倍。


<details>
  <summary>Details</summary>
Motivation: 现有基于ORB的SLAM系统在移动平台上难以满足实时性需求，主要因为Oriented FAST计算消耗了约50%的处理时间，需要针对嵌入式环境优化。

Method: 1. 使用二进制级编码策略快速确定候选点 2. 采用可分离Harris检测策略配合底层GPU硬件指令。优化FAST特征点检测和Harris角点检测两个最耗时的步骤。

Result: 在Jetson TX2嵌入式GPU上的实验显示，相比支持GPU的OpenCV实现，平均加速比达到7.3倍以上。

Conclusion: 该方法显著提升了Oriented FAST在嵌入式设备上的计算效率，证明了其在移动和资源受限环境中实时应用的潜力。

Abstract: The visual-based SLAM (Simultaneous Localization and Mapping) is a technology
widely used in applications such as robotic navigation and virtual reality,
which primarily focuses on detecting feature points from visual images to
construct an unknown environmental map and simultaneously determines its own
location. It usually imposes stringent requirements on hardware power
consumption, processing speed and accuracy. Currently, the ORB (Oriented FAST
and Rotated BRIEF)-based SLAM systems have exhibited superior performance in
terms of processing speed and robustness. However, they still fall short of
meeting the demands for real-time processing on mobile platforms. This
limitation is primarily due to the time-consuming Oriented FAST calculations
accounting for approximately half of the entire SLAM system. This paper
presents two methods to accelerate the Oriented FAST feature detection on
low-end embedded GPUs. These methods optimize the most time-consuming steps in
Oriented FAST feature detection: FAST feature point detection and Harris corner
detection, which is achieved by implementing a binary-level encoding strategy
to determine candidate points quickly and a separable Harris detection strategy
with efficient low-level GPU hardware-specific instructions. Extensive
experiments on a Jetson TX2 embedded GPU demonstrate an average speedup of over
7.3 times compared to widely used OpenCV with GPU support. This significant
improvement highlights its effectiveness and potential for real-time
applications in mobile and resource-constrained environments.

</details>


### [529] [Frame Guidance: Training-Free Guidance for Frame-Level Control in Video Diffusion Models](https://arxiv.org/abs/2506.07177)
*Sangwon Jang,Taekyung Ki,Jaehyeong Jo,Jaehong Yoon,Soo Ye Kim,Zhe Lin,Sung Ju Hwang*

Main category: cs.CV

TL;DR: 提出了Frame Guidance，一种无需训练的引导方法，用于视频生成中的帧级控制，如关键帧、风格参考等。该方法通过潜在空间处理和优化，减少内存消耗，提升全局连贯性。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖针对特定任务微调大型视频模型，但随着模型规模增大，这变得不切实际。因此，需要无需训练且兼容任何视频模型的通用控制方法。

Method: Frame Guidance: 基于帧级信号（关键帧/风格图/草图/深度图）进行训练的指导。结合潜空间处理降低内存消耗，并使用全局连贯性优化策略。

Result: 实验证明，该方法在关键帧引导、风格迁移、循环视频等任务中均能生成高质量可控视频，适用于多种输入信号和视频模型。

Conclusion: Frame Guidance为视频生成提供了一种高效、通用且无需训练的控制方案，为细粒度视频生成研究指明新方向。

Abstract: Advancements in diffusion models have significantly improved video quality,
directing attention to fine-grained controllability. However, many existing
methods depend on fine-tuning large-scale video models for specific tasks,
which becomes increasingly impractical as model sizes continue to grow. In this
work, we present Frame Guidance, a training-free guidance for controllable
video generation based on frame-level signals, such as keyframes, style
reference images, sketches, or depth maps. For practical training-free
guidance, we propose a simple latent processing method that dramatically
reduces memory usage, and apply a novel latent optimization strategy designed
for globally coherent video generation. Frame Guidance enables effective
control across diverse tasks, including keyframe guidance, stylization, and
looping, without any training, compatible with any video models. Experimental
results show that Frame Guidance can produce high-quality controlled videos for
a wide range of tasks and input signals.

</details>


### [530] [Hierarchical Feature-level Reverse Propagation for Post-Training Neural Networks](https://arxiv.org/abs/2506.07188)
*Ni Ding,Lei He,Shengbo Eben Li,Keqiang Li*

Main category: cs.CV

TL;DR: 提出了一种分层解耦的后训练框架，用于预训练神经网络，通过重构中间特征图引入代理监督信号，避免传统端到端反向传播的复杂性和耦合性。


<details>
  <summary>Details</summary>
Motivation: 端到端自动驾驶系统作为主流范式，因其黑盒模型内在的高耦合性，导致可解释性和安全性保障存在挑战。为解决这一问题，提高模型透明度和训练灵活性。

Method: 利用真实标签重构中间特征图，在过渡层引入代理监督信号，将特征级反向计算形式化为良定优化问题（线性方程组或最小二乘问题），建立特征反向传播新范式。

Result: 在多个标准图像分类基准测试中，该方法比传统训练方法具有更优的泛化性能和计算效率。

Conclusion: 该方法通过分层解耦训练，实现了模型透明度的提升和训练效率的优化，为神经网络内部机制提供可解释性。

Abstract: End-to-end autonomous driving has emerged as a dominant paradigm, yet its
highly entangled black-box models pose significant challenges in terms of
interpretability and safety assurance. To improve model transparency and
training flexibility, this paper proposes a hierarchical and decoupled
post-training framework tailored for pretrained neural networks. By
reconstructing intermediate feature maps from ground-truth labels, surrogate
supervisory signals are introduced at transitional layers to enable independent
training of specific components, thereby avoiding the complexity and coupling
of conventional end-to-end backpropagation and providing interpretable insights
into networks' internal mechanisms. To the best of our knowledge, this is the
first method to formalize feature-level reverse computation as well-posed
optimization problems, which we rigorously reformulate as systems of linear
equations or least squares problems. This establishes a novel and efficient
training paradigm that extends gradient backpropagation to feature
backpropagation. Extensive experiments on multiple standard image
classification benchmarks demonstrate that the proposed method achieves
superior generalization performance and computational efficiency compared to
traditional training approaches, validating its effectiveness and potential.

</details>


### [531] [SAP-Bench: Benchmarking Multimodal Large Language Models in Surgical Action Planning](https://arxiv.org/abs/2506.07196)
*Mengya Xu,Zhongzhen Huang,Dillan Imans,Yiru Ye,Xiaofan Zhang,Qi Dou*

Main category: cs.CV

TL;DR: 提出SAP-Bench数据集和MLLM-SAP框架，用于评估多模态大语言模型在手术动作规划中的表现，发现现有SOTA模型存在不足。


<details>
  <summary>Details</summary>
Motivation: 现有基准无法充分评估手术决策这类需要精确、可验证过程的生命关键任务，手术动作规划需区分原子视觉动作和协调长流程。

Method: 构建含1226个临床验证手术动作片段的数据集，提出MLLM-SAP框架（注入领域知识的MLLM），评估7个SOTA模型的下一个动作预测能力。

Result: 所有测试模型均存在显著性能差距，突显当前MLLMs在手术推理方面的局限性。

Conclusion: SAP-Bench填补了手术动作规划评估空白，揭示了现有MLLMs在生命关键领域应用的缺陷，需进一步研究提升可靠性和可解释性。

Abstract: Effective evaluation is critical for driving advancements in MLLM research.
The surgical action planning (SAP) task, which aims to generate future action
sequences from visual inputs, demands precise and sophisticated analytical
capabilities. Unlike mathematical reasoning, surgical decision-making operates
in life-critical domains and requires meticulous, verifiable processes to
ensure reliability and patient safety. This task demands the ability to
distinguish between atomic visual actions and coordinate complex, long-horizon
procedures, capabilities that are inadequately evaluated by current benchmarks.
To address this gap, we introduce SAP-Bench, a large-scale, high-quality
dataset designed to enable multimodal large language models (MLLMs) to perform
interpretable surgical action planning. Our SAP-Bench benchmark, derived from
the cholecystectomy procedures context with the mean duration of 1137.5s, and
introduces temporally-grounded surgical action annotations, comprising the
1,226 clinically validated action clips (mean duration: 68.7s) capturing five
fundamental surgical actions across 74 procedures. The dataset provides 1,152
strategically sampled current frames, each paired with the corresponding next
action as multimodal analysis anchors. We propose the MLLM-SAP framework that
leverages MLLMs to generate next action recommendations from the current
surgical scene and natural language instructions, enhanced with injected
surgical domain knowledge. To assess our dataset's effectiveness and the
broader capabilities of current models, we evaluate seven state-of-the-art
MLLMs (e.g., OpenAI-o1, GPT-4o, QwenVL2.5-72B, Claude-3.5-Sonnet, GeminiPro2.5,
Step-1o, and GLM-4v) and reveal critical gaps in next action prediction
performance.

</details>


### [532] [TV-LiVE: Training-Free, Text-Guided Video Editing via Layer Informed Vitality Exploitation](https://arxiv.org/abs/2506.07205)
*Min-Jung Kim,Dongjin Kim,Seokju Yun,Jaegul Choo*

Main category: cs.CV

TL;DR: 提出了一个无需训练、文本引导的视频编辑框架 TV-LiVE，该框架通过识别视频生成模型中的关键层实现了复杂编辑任务，包括添加新物体和非刚性变形。


<details>
  <summary>Details</summary>
Motivation: 现有视频编辑方法集中在结构化保持任务（如风格迁移、背景替换），缺乏对复杂任务（如新增物体、非刚性编辑）的探索。需要更灵活的视频编辑工具满足创意需求。

Method: 1. 识别与旋转位置嵌入（RoPE）相关的关键层（vital layers） 2. 选择性注入源模型键值特征 3. 新增物体任务中提取目标提示对应掩码区域

Result: 在物体添加和非刚性编辑任务上超越现有方法，编辑掩码区域精准。

Conclusion: TV-LiVE 无需微调即可实现复杂视频编辑，利用生成模型中的关键层特征实现精准控制，为创意视频编辑提供新途径。

Abstract: Video editing has garnered increasing attention alongside the rapid progress
of diffusion-based video generation models. As part of these advancements,
there is a growing demand for more accessible and controllable forms of video
editing, such as prompt-based editing. Previous studies have primarily focused
on tasks such as style transfer, background replacement, object substitution,
and attribute modification, while maintaining the content structure of the
source video. However, more complex tasks, including the addition of novel
objects and nonrigid transformations, remain relatively unexplored. In this
paper, we present TV-LiVE, a Training-free and text-guided Video editing
framework via Layerinformed Vitality Exploitation. We empirically identify
vital layers within the video generation model that significantly influence the
quality of generated outputs. Notably, these layers are closely associated with
Rotary Position Embeddings (RoPE). Based on this observation, our method
enables both object addition and non-rigid video editing by selectively
injecting key and value features from the source model into the corresponding
layers of the target model guided by the layer vitality. For object addition,
we further identify prominent layers to extract the mask regions corresponding
to the newly added target prompt. We found that the extracted masks from the
prominent layers faithfully indicate the region to be edited. Experimental
results demonstrate that TV-LiVE outperforms existing approaches for both
object addition and non-rigid video editing. Project Page:
https://emjay73.github.io/TV_LiVE/

</details>


### [533] [Backdoor Attack on Vision Language Models with Stealthy Semantic Manipulation](https://arxiv.org/abs/2506.07214)
*Zhiyuan Zhong,Zhen Sun,Yepang Liu,Xinlei He,Guanhong Tao*

Main category: cs.CV

TL;DR: 这篇论文提出了一种名为BadSem的新型后门攻击方法，利用跨模态语义不匹配作为隐式触发器，通过在训练过程中故意对齐图文对注入后门。攻击效果显著（ASR>98%），且现有防御方法无法有效抵御。


<details>
  <summary>Details</summary>
Motivation: 现有视觉语言模型（VLM）后门攻击主要依赖单模态触发器，未充分探索跨模态融合的漏洞。

Method: 1. 提出语义不匹配作为隐式触发器；2. 构建SIMBad数据集（针对颜色/物体属性）；3. 通过故意错位图文对进行数据投毒。

Result: 1. 在4个主流VLM上ASR超98%；2. 具备OOD泛化能力；3. 可跨投毒模态迁移；4. 注意力可视化显示异常聚焦语义敏感区域；5. 现有提示词/SFT防御均失效。

Conclusion: BadSem暴露了VLM的语义层安全漏洞，需开发新防御机制确保模型部署安全。

Abstract: Vision Language Models (VLMs) have shown remarkable performance, but are also
vulnerable to backdoor attacks whereby the adversary can manipulate the model's
outputs through hidden triggers. Prior attacks primarily rely on
single-modality triggers, leaving the crucial cross-modal fusion nature of VLMs
largely unexplored. Unlike prior work, we identify a novel attack surface that
leverages cross-modal semantic mismatches as implicit triggers. Based on this
insight, we propose BadSem (Backdoor Attack with Semantic Manipulation), a data
poisoning attack that injects stealthy backdoors by deliberately misaligning
image-text pairs during training. To perform the attack, we construct SIMBad, a
dataset tailored for semantic manipulation involving color and object
attributes. Extensive experiments across four widely used VLMs show that BadSem
achieves over 98% average ASR, generalizes well to out-of-distribution
datasets, and can transfer across poisoning modalities. Our detailed analysis
using attention visualization shows that backdoored models focus on
semantically sensitive regions under mismatched conditions while maintaining
normal behavior on clean inputs. To mitigate the attack, we try two defense
strategies based on system prompt and supervised fine-tuning but find that both
of them fail to mitigate the semantic backdoor. Our findings highlight the
urgent need to address semantic vulnerabilities in VLMs for their safer
deployment.

</details>


### [534] [AugmentGest: Can Random Data Cropping Augmentation Boost Gesture Recognition Performance?](https://arxiv.org/abs/2506.07216)
*Nada Aboudeshish,Dmitry Ignatov,Radu Timofte*

Main category: cs.CV

TL;DR: 提出了一个全面的数据增强框架，结合几何变换、随机裁剪、旋转、缩放和强度变换等，应用于骨架数据。方法在三个模型（e2eET、FPPR-PCD、DD-Net）和三个数据集（DHG14/28、SHREC'17、JHMDB）上验证，显著提升模型泛化能力并达到SOTA结果。


<details>
  <summary>Details</summary>
Motivation: 解决骨架数据集多样性不足的问题，通过模拟真实世界变化（如视角偏差、遮挡等）来增强数据多样性，从而提升手势识别和动作识别的鲁棒性。

Method: 整合了多种数据增强技术：几何变换、随机裁剪（保持时空完整性）、旋转、缩放、强度变换（亮度和对比度调整）。每个样本生成三个增强版本，使数据集规模翻两番。

Result: 在多个模型和数据集上取得显著提升：e2eET在DHG14/28和SHREC'17达到SOTA；FPPR-PCD在SHREC'17点云识别中表现第二优；DD-Net在SHREC'17和JHMDB上同样提升。证明了框架的普适性和有效性。

Conclusion: 该增强框架不仅显著提升了多种模型的性能并实现SOTA，还为HGR和动作识别提供了可扩展的解决方案，增强了真实场景应用的鲁棒性。代码已开源。

Abstract: Data augmentation is a crucial technique in deep learning, particularly for
tasks with limited dataset diversity, such as skeleton-based datasets. This
paper proposes a comprehensive data augmentation framework that integrates
geometric transformations, random cropping, rotation, zooming and
intensity-based transformations, brightness and contrast adjustments to
simulate real-world variations. Random cropping ensures the preservation of
spatio-temporal integrity while addressing challenges such as viewpoint bias
and occlusions. The augmentation pipeline generates three augmented versions
for each sample in addition to the data set sample, thus quadrupling the data
set size and enriching the diversity of gesture representations. The proposed
augmentation strategy is evaluated on three models: multi-stream e2eET, FPPR
point cloud-based hand gesture recognition (HGR), and DD-Network. Experiments
are conducted on benchmark datasets including DHG14/28, SHREC'17, and JHMDB.
The e2eET model, recognized as the state-of-the-art for hand gesture
recognition on DHG14/28 and SHREC'17. The FPPR-PCD model, the second-best
performing model on SHREC'17, excels in point cloud-based gesture recognition.
DD-Net, a lightweight and efficient architecture for skeleton-based action
recognition, is evaluated on SHREC'17 and the Human Motion Data Base (JHMDB).
The results underline the effectiveness and versatility of the proposed
augmentation strategy, significantly improving model generalization and
robustness across diverse datasets and architectures. This framework not only
establishes state-of-the-art results on all three evaluated models but also
offers a scalable solution to advance HGR and action recognition applications
in real-world scenarios. The framework is available at
https://github.com/NadaAbodeshish/Random-Cropping-augmentation-HGR

</details>


### [535] [Hallucination at a Glance: Controlled Visual Edits and Fine-Grained Multimodal Learning](https://arxiv.org/abs/2506.07227)
*Tianyi Bai,Yuxuan Fan,Jiantao Qiu,Fupeng Sun,Jiayi Song,Junlin Han,Zichen Liu,Conghui He,Wentao Zhang,Binhang Yuan*

Main category: cs.CV

TL;DR: 提出了一种生成细微编辑图像对的数据集(MED)和监督微调框架，以提高多模态大语言模型在细粒度视觉差异上的性能。


<details>
  <summary>Details</summary>
Motivation: 当前MLLMs在处理细粒度视觉差异时存在幻觉或遗漏语义变化的问题。这源于训练数据和学习目标的限制。

Method: 1) 开发受控数据生成流水线创建细微编辑图像对和语义对齐描述；2) 构建Micro Edit Dataset (MED)包含超5万对图像文本；3) 提出带特征级一致性损失的SFT框架提升视觉嵌入稳定性。

Result: 1) 在Micro Edit Detection基准上提升差异检测准确率并减少幻觉；2) 优于GPT-4o等基线；3) 在图像描述和视觉问答等标准任务上取得一致性提升。

Conclusion: 结合针对性数据和一致性目标的微调能有效增强MLLMs的细粒度视觉推理能力。

Abstract: Multimodal large language models (MLLMs) have achieved strong performance on
vision-language tasks but still struggle with fine-grained visual differences,
leading to hallucinations or missed semantic shifts. We attribute this to
limitations in both training data and learning objectives. To address these
issues, we propose a controlled data generation pipeline that produces
minimally edited image pairs with semantically aligned captions. Using this
pipeline, we construct the Micro Edit Dataset (MED), containing over 50K
image-text pairs spanning 11 fine-grained edit categories, including attribute,
count, position, and object presence changes. Building on MED, we introduce a
supervised fine-tuning (SFT) framework with a feature-level consistency loss
that promotes stable visual embeddings under small edits. We evaluate our
approach on the Micro Edit Detection benchmark, which includes carefully
balanced evaluation pairs designed to test sensitivity to subtle visual
variations across the same edit categories. Our method improves difference
detection accuracy and reduces hallucinations compared to strong baselines,
including GPT-4o. Moreover, it yields consistent gains on standard
vision-language tasks such as image captioning and visual question answering.
These results demonstrate the effectiveness of combining targeted data and
alignment objectives for enhancing fine-grained visual reasoning in MLLMs.

</details>


### [536] [Multi-Step Visual Reasoning with Visual Tokens Scaling and Verification](https://arxiv.org/abs/2506.07235)
*Tianyi Bai,Zengjie Hu,Fupeng Sun,Jiantao Qiu,Yizhen Jiang,Guangxin He,Bohan Zeng,Conghui He,Binhang Yuan,Wentao Zhang*

Main category: cs.CV

TL;DR: 介绍了一种动态推理框架VTS（visual token scaling），用于改进多模态大语言模型（MLLM）的视觉推理能力。通过马尔可夫决策过程和基于DPO的验证器实现迭代式视觉token缩放，显著提升了多个视觉推理基准的准确性。


<details>
  <summary>Details</summary>
Motivation: 现有MLLM静态编码整个图像，无法动态适应上下文或迭代优化理解能力，而人类感知具有动态选择性特征。

Method: 构建马尔可夫决策过程框架：1) 提议视觉动作的推理器；2) 基于多步DPO训练的验证器评估动作并决定终止时机。配套创建VTS数据集（含VTS-SFT监督轨迹和VTS-DPO偏好数据）。

Result: 在多个视觉推理基准测试中显著优于现有方法（提升精度），同时增强推理过程的解释性和可追溯性。

Conclusion: 动态推理机制在细粒度、上下文感知的视觉推理任务中具有重要前景，为下一代MLLM奠定基础。

Abstract: Multi-modal large language models (MLLMs) have achieved remarkable
capabilities by integrating visual perception with language understanding,
enabling applications such as image-grounded dialogue, visual question
answering, and scientific analysis. However, most MLLMs adopt a static
inference paradigm, encoding the entire image into fixed visual tokens upfront,
which limits their ability to iteratively refine understanding or adapt to
context during inference. This contrasts sharply with human perception, which
is dynamic, selective, and feedback-driven. In this work, we introduce a novel
framework for inference-time visual token scaling that enables MLLMs to perform
iterative, verifier-guided reasoning over visual content. We formulate the
problem as a Markov Decision Process, involving a reasoner that proposes visual
actions and a verifier, which is trained via multi-step Direct Preference
Optimization (DPO), that evaluates these actions and determines when reasoning
should terminate. To support this, we present a new dataset, VTS, comprising
supervised reasoning trajectories (VTS-SFT) and preference-labeled reasoning
comparisons (VTS-DPO). Our method significantly outperforms existing approaches
across diverse visual reasoning benchmarks, offering not only improved accuracy
but also more interpretable and grounded reasoning processes. These results
demonstrate the promise of dynamic inference mechanisms for enabling
fine-grained, context-aware visual reasoning in next-generation MLLMs.

</details>


### [537] [From Generation to Generalization: Emergent Few-Shot Learning in Video Diffusion Models](https://arxiv.org/abs/2506.07280)
*Pablo Acuaviva,Aram Davtyan,Mariam Hassan,Sebastian Stapf,Ahmad Rahimi,Alexandre Alahi,Paolo Favaro*

Main category: cs.CV

TL;DR: 本研究提出一个针对视频扩散模型（VDMs）的少样本微调框架，证明VDMs通过训练不仅能够生成高质量视频，还内在学习了视觉世界的结构化表示，可以轻松适应多种视觉任务。


<details>
  <summary>Details</summary>
Motivation: 视频扩散模型（VDMs）在训练中为建模连贯视频序列，需要学习视觉世界的结构化表征和隐含理解。本研究旨在探索VDMs内在知识的深度，验证其能否超越视频生成任务，成为基础视觉模型的骨干。

Method: 提出少样本微调框架：1. 将新任务重新定义为视觉转换（如分割任务转换为原图到分割图的转换）2. 仅用少量示例输入-输出序列训练LoRA权重 3. 保持VDM骨干冻结，不更改其生成接口。

Result: 模型在极少量监督下展现出强大泛化能力：1. 涵盖底层视觉（如分割、姿态估计）与高层推理（如ARC-AGI）任务 2. 任务适应过程仅需少数样本 3. 所有任务均可通过同一套冻结VDM实现。

Conclusion: VDMs不仅是生成引擎，更是具有自适应学习能力的视觉骨干模型。其内在结构化和推理能力可为未来视觉基础模型提供核心支持。

Abstract: Video Diffusion Models (VDMs) have emerged as powerful generative tools,
capable of synthesizing high-quality spatiotemporal content. Yet, their
potential goes far beyond mere video generation. We argue that the training
dynamics of VDMs, driven by the need to model coherent sequences, naturally
pushes them to internalize structured representations and an implicit
understanding of the visual world. To probe the extent of this internal
knowledge, we introduce a few-shot fine-tuning framework that repurposes VDMs
for new tasks using only a handful of examples. Our method transforms each task
into a visual transition, enabling the training of LoRA weights on short
input-output sequences without altering the generative interface of a frozen
VDM. Despite minimal supervision, the model exhibits strong generalization
across diverse tasks, from low-level vision (for example, segmentation and pose
estimation) to high-level reasoning (for example, on ARC-AGI). These results
reframe VDMs as more than generative engines. They are adaptable visual
learners with the potential to serve as the backbone for future foundation
models in vision.

</details>


### [538] [Multi-Step Guided Diffusion for Image Restoration on Edge Devices: Toward Lightweight Perception in Embodied AI](https://arxiv.org/abs/2506.07286)
*Aditya Chakravarty*

Main category: cs.CV

TL;DR: 提出了一种在去噪步骤中采用多步优化策略的方法，显著提升了图像质量、感知准确性和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有方法（如MPGD）在每个去噪步骤仅应用一次梯度更新，限制了恢复的保真度和鲁棒性，尤其在嵌入式或分布外场景中。

Method: 在每次去噪时间步内引入多步优化策略，增加梯度更新次数。在超分辨率和去高斯模糊任务上进行了实验验证。

Result: 增加梯度更新次数提高了LPIPS和PSNR指标，延迟开销小。在Jetson Orin Nano上使用退化ImageNet和无人机数据集验证，展示了对自然和航拍场景的泛化能力。

Conclusion: 该方法为轻量级、即插即用的恢复模块在无人机、移动机器人等嵌入式AI领域提供了解决方案，MPGD具有成为实时视觉感知模块的潜力。

Abstract: Diffusion models have shown remarkable flexibility for solving inverse
problems without task-specific retraining. However, existing approaches such as
Manifold Preserving Guided Diffusion (MPGD) apply only a single gradient update
per denoising step, limiting restoration fidelity and robustness, especially in
embedded or out-of-distribution settings. In this work, we introduce a
multistep optimization strategy within each denoising timestep, significantly
enhancing image quality, perceptual accuracy, and generalization. Our
experiments on super-resolution and Gaussian deblurring demonstrate that
increasing the number of gradient updates per step improves LPIPS and PSNR with
minimal latency overhead. Notably, we validate this approach on a Jetson Orin
Nano using degraded ImageNet and a UAV dataset, showing that MPGD, originally
trained on face datasets, generalizes effectively to natural and aerial scenes.
Our findings highlight MPGD's potential as a lightweight, plug-and-play
restoration module for real-time visual perception in embodied AI agents such
as drones and mobile robots.

</details>


### [539] [FANVID: A Benchmark for Face and License Plate Recognition in Low-Resolution Videos](https://arxiv.org/abs/2506.07304)
*Kavitha Viswanathan,Vrinda Goel,Shlesh Gholap,Devayan Ghosh,Madhav Gupta,Dhruvi Ganatra,Sanket Potdar,Amit Sethi*

Main category: cs.CV

TL;DR: 提出了一个名为FANVID的基准数据集，包含1,463个低分辨率监控视频片段，用于推进人脸匹配和车牌识别任务。研究构建了两个任务(人脸匹配和车牌识别)，通过设计评估指标和基线方法(预训练模型组合)证明了任务的可行性(0.58)和挑战性(0.42)。


<details>
  <summary>Details</summary>
Motivation: 为弥补现有研究中对低分辨率视频时序建模的空白，提出一个符合真实监控场景的数据集(单帧难以识别，需时序信息)以推动识别模型发展，适用于安防/司法/自动驾驶领域。

Method: 数据集构建：从高清源生成不可单帧识别的低分辨率视频(180*320)，包含干扰项并手工标注31,096个边界框和标签。设计两个任务和评估指标：人脸匹配(基于身份正确性的mAP)和车牌识别(字符级精度)。基线方法由预训练视频超分+检测+识别模型组成。

Result: 基线方法性能: 人脸匹配0.58 mAP，车牌识别0.42精度。证明任务可行但有明显提升空间。数据集平衡了物体多样性与识别难度。

Conclusion: FANVID填补了视频时序识别基准空缺，通过发布数据集/评估代码/基线模型促进相关研究，可催化交通监控/司法等领域的低分辨率时序模型创新。

Abstract: Real-world surveillance often renders faces and license plates unrecognizable
in individual low-resolution (LR) frames, hindering reliable identification. To
advance temporal recognition models, we present FANVID, a novel video-based
benchmark comprising nearly 1,463 LR clips (180 x 320, 20--60 FPS) featuring 63
identities and 49 license plates from three English-speaking countries. Each
video includes distractor faces and plates, increasing task difficulty and
realism. The dataset contains 31,096 manually verified bounding boxes and
labels.
  FANVID defines two tasks: (1) face matching -- detecting LR faces and
matching them to high-resolution mugshots, and (2) license plate recognition --
extracting text from LR plates without a predefined database. Videos are
downsampled from high-resolution sources to ensure that faces and text are
indecipherable in single frames, requiring models to exploit temporal
information. We introduce evaluation metrics adapted from mean Average
Precision at IoU > 0.5, prioritizing identity correctness for faces and
character-level accuracy for text.
  A baseline method with pre-trained video super-resolution, detection, and
recognition achieved performance scores of 0.58 (face matching) and 0.42 (plate
recognition), highlighting both the feasibility and challenge of the tasks.
FANVID's selection of faces and plates balances diversity with recognition
challenge. We release the software for data access, evaluation, baseline, and
annotation to support reproducibility and extension. FANVID aims to catalyze
innovation in temporal modeling for LR recognition, with applications in
surveillance, forensics, and autonomous vehicles.

</details>


### [540] [AllTracker: Efficient Dense Point Tracking at High Resolution](https://arxiv.org/abs/2506.07310)
*Adam W. Harley,Yang You,Xinglong Sun,Yang Zheng,Nikhil Raghuraman,Yunqi Gu,Sheldon Liang,Wen-Hsuan Chu,Achal Dave,Pavel Tokmakov,Suya You,Rares Ambrus,Katerina Fragkiadaki,Leonidas J. Guibas*

Main category: cs.CV

TL;DR: AllTracker模型实现了视频全像素点跨帧追踪的方法，解决了现有光流不能长距离跟踪的问题。


<details>
  <summary>Details</summary>
Motivation: 现有的点追踪模型不能提供所有像素的高分辨率轨迹，现有光流方法只能做相邻两帧之间的追踪。

Method: 构建了融合光流追踪与点追踪技术的模型架构，在空间上用卷积层传播信息，在时间上使用注意力层。

Result: 模型较小且有高效率，实现768×1024像素的高分辨率跟踪，在点追踪任务中达到最优结果。

Conclusion: 结合多种数据集训练至关重要，模型成功实现了跨越数百帧的点定位。

Abstract: We introduce AllTracker: a model that estimates long-range point tracks by
way of estimating the flow field between a query frame and every other frame of
a video. Unlike existing point tracking methods, our approach delivers
high-resolution and dense (all-pixel) correspondence fields, which can be
visualized as flow maps. Unlike existing optical flow methods, our approach
corresponds one frame to hundreds of subsequent frames, rather than just the
next frame. We develop a new architecture for this task, blending techniques
from existing work in optical flow and point tracking: the model performs
iterative inference on low-resolution grids of correspondence estimates,
propagating information spatially via 2D convolution layers, and propagating
information temporally via pixel-aligned attention layers. The model is fast
and parameter-efficient (16 million parameters), and delivers state-of-the-art
point tracking accuracy at high resolution (i.e., tracking 768x1024 pixels, on
a 40G GPU). A benefit of our design is that we can train on a wider set of
datasets, and we find that doing so is crucial for top performance. We provide
an extensive ablation study on our architecture details and training recipe,
making it clear which details matter most. Our code and model weights are
available at https://alltracker.github.io .

</details>


### [541] ["CASE: Contrastive Activation for Saliency Estimation](https://arxiv.org/abs/2506.07327)
*Dane Williamson,Yangfeng Ji,Matthew Dwyer*

Main category: cs.CV

TL;DR: 本文指出了现有显著性方法存在类别不敏感问题，即不同类别标签下的解释相似。为此，作者提出了一种新的对比解释方法CASE，能够生成区分不同类别的解释。


<details>
  <summary>Details</summary>
Motivation: 当前显著性方法在可视化模型预测依据时，其直观性掩盖了关键缺陷：无法区分不同类别的输入特征。

Method: 通过诊断测试揭示多种主流方法存在‘类别不敏感’问题；为解决该问题，设计对比解释方法CASE——通过隔离区分预测类的特征生成解释。

Result: 实验表明：1) 常见显著性方法对竞争性类标签输出相似解释 2) CASE通过诊断测试和保真度测试，证明其具有更高类别特异性和忠实性

Conclusion: 显著方法的类别敏感性是核心评价指标；CASE能有效解决现有方法的局限性

Abstract: Saliency methods are widely used to visualize which input features are deemed
relevant to a model's prediction. However, their visual plausibility can
obscure critical limitations. In this work, we propose a diagnostic test for
class sensitivity: a method's ability to distinguish between competing class
labels on the same input. Through extensive experiments, we show that many
widely used saliency methods produce nearly identical explanations regardless
of the class label, calling into question their reliability. We find that
class-insensitive behavior persists across architectures and datasets,
suggesting the failure mode is structural rather than model-specific. Motivated
by these findings, we introduce CASE, a contrastive explanation method that
isolates features uniquely discriminative for the predicted class. We evaluate
CASE using the proposed diagnostic and a perturbation-based fidelity test, and
show that it produces faithful and more class-specific explanations than
existing methods.

</details>


### [542] [Hierarchical Scoring with 3D Gaussian Splatting for Instance Image-Goal Navigation](https://arxiv.org/abs/2506.07338)
*Yijie Deng,Shuaihang Yuan,Geeta Chandra Raju Bethala,Anthony Tzes,Yu-Shen Liu,Yi Fang*

Main category: cs.CV

TL;DR: 本文提出了一个层级评分框架用于实例图像目标导航，通过结合语义和几何评分来选择最优视角，减少冗余并提升效率。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖随机采样多个视角，导致渲染和比较开销大，缺乏有原则的视角选择机制

Method: 1. 跨层级语义评分：利用CLIP衍生的相关场识别与目标物体类别语义相似度高的区域 
2. 局部几何评分：在候选区域内进行精确位姿估计 
3. 层级评分范式整合两者

Result: 在模拟IIN基准测试中达到SOTA性能，并验证了真实世界适用性

Conclusion: 所提出的层级评分框架通过优化视角选择，显著提高了实例图像目标导航的效率和准确性

Abstract: Instance Image-Goal Navigation (IIN) requires autonomous agents to identify
and navigate to a target object or location depicted in a reference image
captured from any viewpoint. While recent methods leverage powerful novel view
synthesis (NVS) techniques, such as three-dimensional Gaussian splatting
(3DGS), they typically rely on randomly sampling multiple viewpoints or
trajectories to ensure comprehensive coverage of discriminative visual cues.
This approach, however, creates significant redundancy through overlapping
image samples and lacks principled view selection, substantially increasing
both rendering and comparison overhead. In this paper, we introduce a novel IIN
framework with a hierarchical scoring paradigm that estimates optimal
viewpoints for target matching. Our approach integrates cross-level semantic
scoring, utilizing CLIP-derived relevancy fields to identify regions with high
semantic similarity to the target object class, with fine-grained local
geometric scoring that performs precise pose estimation within promising
regions. Extensive evaluations demonstrate that our method achieves
state-of-the-art performance on simulated IIN benchmarks and real-world
applicability.

</details>


### [543] [CBAM-STN-TPS-YOLO: Enhancing Agricultural Object Detection through Spatially Adaptive Attention Mechanisms](https://arxiv.org/abs/2506.07357)
*Satvik Praveen,Yoonsung Jung*

Main category: cs.CV

TL;DR: 提出CBAM-STN-TPS-YOLO模型，結合Thin-Plate Splines的空間變換和CBAM注意力機制，提升農業場景中遮擋和變形物體的檢測精度。


<details>
  <summary>Details</summary>
Motivation: 現有YOLO模型在植物監測場景中因遮擋、非剛體變形和背景噪聲導致檢測精度下降，傳統STN的仿射變換無法處理彎曲葉片等非剛體變形。

Method: 1. 將Thin-Plate Splines (TPS) 集成到STN中以實現非剛性空間變換
2. 加入CBAM模塊進行通道和空間注意力權重分配
3. 研究TPS正則化參數對變換平滑性和檢測性能的影響

Result: 1. 在PGP數據集上精確率、召回率和mAP均超越STN-YOLO
2. 誤檢率降低12%
3. 實現輕量級模型並支持實時邊緣部署

Conclusion: 模型通過TPS增強空間靈活性和CBAM抑制噪聲，顯著提升複雜農業場景中的檢測性能，且適合智能農業的實時應用需求。

Abstract: Object detection is vital in precision agriculture for plant monitoring,
disease detection, and yield estimation. However, models like YOLO struggle
with occlusions, irregular structures, and background noise, reducing detection
accuracy. While Spatial Transformer Networks (STNs) improve spatial invariance
through learned transformations, affine mappings are insufficient for non-rigid
deformations such as bent leaves and overlaps.
  We propose CBAM-STN-TPS-YOLO, a model integrating Thin-Plate Splines (TPS)
into STNs for flexible, non-rigid spatial transformations that better align
features. Performance is further enhanced by the Convolutional Block Attention
Module (CBAM), which suppresses background noise and emphasizes relevant
spatial and channel-wise features.
  On the occlusion-heavy Plant Growth and Phenotyping (PGP) dataset, our model
outperforms STN-YOLO in precision, recall, and mAP. It achieves a 12% reduction
in false positives, highlighting the benefits of improved spatial flexibility
and attention-guided refinement. We also examine the impact of the TPS
regularization parameter in balancing transformation smoothness and detection
performance.
  This lightweight model improves spatial awareness and supports real-time edge
deployment, making it ideal for smart farming applications requiring accurate
and efficient monitoring.

</details>


### [544] [Multiple Object Stitching for Unsupervised Representation Learning](https://arxiv.org/abs/2506.07364)
*Chengchao Shen,Dawei Liu,Jianxin Wang*

Main category: cs.CV

TL;DR: MOS方法通过拼接单目标图像生成多目标图像，利用预设对象对应关系提升对比学习中多目标图像的表征性能，在下游任务中表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有的对比学习方法在多目标图像上的无监督表征性能较差。为了在没有人工标注的情况下，增强对比学习对多目标图像的表征能力...

Method: 提出Multiple Object Stitching（MOS）方法：将单目标中心图像拼接合成为多目标图像，其中物体位置已知。利用这种预设的对象对应关系作为附加监督信号...

Result: 在ImageNet、CIFAR和COCO数据集上验证，MOS在单目标和多目标图像上都取得了领先的无监督表征性能...

Conclusion: MOS通过简单有效的合成多目标图像机制，利用对象位置先验提升表征学习，尤其改善了下游密集预测任务的效果。

Abstract: Contrastive learning for single object centric images has achieved remarkable
progress on unsupervised representation, but suffering inferior performance on
the widespread images with multiple objects. In this paper, we propose a simple
but effective method, Multiple Object Stitching (MOS), to refine the
unsupervised representation for multi-object images. Specifically, we construct
the multi-object images by stitching the single object centric ones, where the
objects in the synthesized multi-object images are predetermined. Hence,
compared to the existing contrastive methods, our method provides additional
object correspondences between multi-object images without human annotations.
In this manner, our method pays more attention to the representations of each
object in multi-object image, thus providing more detailed representations for
complicated downstream tasks, such as object detection and semantic
segmentation. Experimental results on ImageNet, CIFAR and COCO datasets
demonstrate that our proposed method achieves the leading unsupervised
representation performance on both single object centric images and
multi-object ones. The source code is available at
https://github.com/visresearch/MultipleObjectStitching.

</details>


### [545] [C3S3: Complementary Competition and Contrastive Selection for Semi-Supervised Medical Image Segmentation](https://arxiv.org/abs/2506.07368)
*Jiaying He,Yitong Lin,Jiahe Chen,Honghui Xu,Jianwei Zheng*

Main category: cs.CV

TL;DR: 提出C3S3模型解决医学图像分割边界模糊问题：通过竞争对比机制提升半监督学习的边界识别精度，在MRI/CT数据集上实现95HD/ASD指标6%+提升


<details>
  <summary>Details</summary>
Motivation: 现有半监督医学分割方法对目标主体效果良好但边界识别不足，易导致诊断误差；需提升边界敏感度

Method: 1) 创新性融合互补竞争-对比选择双模块；2) 结果驱动对比学习优化边界定位；3) 动态互补双子网生成伪标签

Result: 在两个公共数据集上超越SOTA方法：95HD和ASD指标显著提升至少6%，模型泛化性强(MRI/CT双模态验证)

Conclusion: C3S3有效解决边界模糊痛点，为小样本医学分割提供新思路；代码已开源

Abstract: For the immanent challenge of insufficiently annotated samples in the medical
field, semi-supervised medical image segmentation (SSMIS) offers a promising
solution. Despite achieving impressive results in delineating primary target
areas, most current methodologies struggle to precisely capture the subtle
details of boundaries. This deficiency often leads to significant diagnostic
inaccuracies. To tackle this issue, we introduce C3S3, a novel semi-supervised
segmentation model that synergistically integrates complementary competition
and contrastive selection. This design significantly sharpens boundary
delineation and enhances overall precision. Specifically, we develop an
$\textit{Outcome-Driven Contrastive Learning}$ module dedicated to refining
boundary localization. Additionally, we incorporate a $\textit{Dynamic
Complementary Competition}$ module that leverages two high-performing
sub-networks to generate pseudo-labels, thereby further improving segmentation
quality. The proposed C3S3 undergoes rigorous validation on two publicly
accessible datasets, encompassing the practices of both MRI and CT scans. The
results demonstrate that our method achieves superior performance compared to
previous cutting-edge competitors. Especially, on the 95HD and ASD metrics, our
approach achieves a notable improvement of at least $6\%$, highlighting the
significant advancements. The code is available at
https://github.com/Y-TARL/C3S3.

</details>


### [546] [Generative Models at the Frontier of Compression: A Survey on Generative Face Video Coding](https://arxiv.org/abs/2506.07369)
*Bolin Chen,Shanzhi Yin,Goluck Konuko,Giuseppe Valenzise,Zihan Zhang,Shiqi Wang,Yan Ye*

Main category: cs.CV

TL;DR: 该论文对生成式人脸视频编码（GFVC）的首次全面调研进行了综述。GFVC利用深度生成模型在人脸视频压缩中实现超低码率下的高保真通信，超越了传统编解码器。文章通过回顾现有研究方法、构建主观质量评价数据库、探讨标准化潜力和开发低复杂度系统，旨在推动GFVC的技术发展和工业应用。


<details>
  <summary>Details</summary>
Motivation: 为解决传统视频编码在超低码率下人脸视频质量急剧下降的问题，利用深度生成模型的语义表示和人脸合成能力，构建高效压缩的GFVC解决方案。通过系统整合理论创新与工业标准化需求，加速产业部署。

Method: 1）系统回顾GFVC不同特征表示和优化策略；2）构建大规模主观质量数据库并测试感知指标；3）设计统一高层语法标准化框架，开发低复杂度GFVC系统原型。

Result: 1）揭示生成式方法的性能优势（超低码率下超越VVC）；2）确立适用于GFVC的质量评估指标；3）证明标准化潜力并提出可行部署方案。

Conclusion: GFVC开创性地解决了人脸视频压缩在效率与质量上的平衡问题，标准化工作与技术优化将拓展工业应用前景。未来需提升系统鲁棒性、实时性及跨场景泛化能力。

Abstract: The rise of deep generative models has greatly advanced video compression,
reshaping the paradigm of face video coding through their powerful capability
for semantic-aware representation and lifelike synthesis. Generative Face Video
Coding (GFVC) stands at the forefront of this revolution, which could
characterize complex facial dynamics into compact latent codes for bitstream
compactness at the encoder side and leverages powerful deep generative models
to reconstruct high-fidelity face signal from the compressed latent codes at
the decoder side. As such, this well-designed GFVC paradigm could enable
high-fidelity face video communication at ultra-low bitrate ranges, far
surpassing the capabilities of the latest Versatile Video Coding (VVC)
standard. To pioneer foundational research and accelerate the evolution of
GFVC, this paper presents the first comprehensive survey of GFVC technologies,
systematically bridging critical gaps between theoretical innovation and
industrial standardization. In particular, we first review a broad range of
existing GFVC methods with different feature representations and optimization
strategies, and conduct a thorough benchmarking analysis. In addition, we
construct a large-scale GFVC-compressed face video database with subjective
Mean Opinion Scores (MOSs) based on human perception, aiming to identify the
most appropriate quality metrics tailored to GFVC. Moreover, we summarize the
GFVC standardization potentials with a unified high-level syntax and develop a
low-complexity GFVC system which are both expected to push forward future
practical deployments and applications. Finally, we envision the potential of
GFVC in industrial applications and deliberate on the current challenges and
future opportunities.

</details>


### [547] [ARGUS: Hallucination and Omission Evaluation in Video-LLMs](https://arxiv.org/abs/2506.07371)
*Ruchit Rawal,Reza Shirkavand,Heng Huang,Gowthami Somepalli,Tom Goldstein*

Main category: cs.CV

TL;DR: ARGUS作为VideoLLM的基准测试,通过自由文本生成任务(视频描述)评估幻觉率(错误内容/时序关系)和遗漏率(重要细节缺失),弥补传统多选题验证的不足。


<details>
  <summary>Details</summary>
Motivation: 现有Video-LLM基准多依赖选择题,难以检测文本生成任务中的严重幻觉现象,需构建能量化自由文本生成质量的评估体系。

Method: 提出ARGUS基准:将模型生成的视频描述与人工标注对比,测量两项指标——描述性细节的遗漏率、包含错误视频内容/时间关系的幻觉率。

Result: 该指标同时捕捉生成的准确性和完整性,为视频字幕任务提供双维度量化评估。结果显示Video-LLM在自由文本生成中的幻觉问题远超多选题场景。

Conclusion: ARGUS首次系统评估Video-LLM自由生成能力,揭示文本生成任务中更严重的幻觉缺陷,推动模型改进方向。

Abstract: Video large language models have not yet been widely deployed, largely due to
their tendency to hallucinate. Typical benchmarks for Video-LLMs rely simply on
multiple-choice questions. Unfortunately, VideoLLMs hallucinate far more
aggressively on freeform text generation tasks like video captioning than they
do on multiple choice verification tasks. To address this weakness, we propose
ARGUS, a VideoLLM benchmark that measures freeform video captioning
performance. By comparing VideoLLM outputs to human ground truth captions,
ARGUS quantifies dual metrics. First, we measure the rate of hallucinations in
the form of incorrect statements about video content or temporal relationships.
Second, we measure the rate at which the model omits important descriptive
details. Together, these dual metrics form a comprehensive view of video
captioning performance.

</details>


### [548] [DINO-CoDT: Multi-class Collaborative Detection and Tracking with Vision Foundation Models](https://arxiv.org/abs/2506.07375)
*Xunjie He,Christina Dao Wen Lee,Meiling Wang,Chengran Yuan,Zefan Huang,Yufeng Yue,Marcelo H. Ang Jr*

Main category: cs.CV

TL;DR: 作者提出了一种多类协同检测和跟踪框架，针对多样化道路用户。该框架包含全局空间注意力融合（GSAF）模块提升多尺度特征学习，轨迹重识别（REID）模块利用视觉基础模型减少ID切换错误，以及基于速度的自适应轨迹管理（VATM）模块动态调整跟踪间隔。在V2X-Real和OPV2V数据集上的实验表明，该框架在检测和跟踪精度上显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有协同感知研究主要集中在车辆超类，缺乏针对多类物体（如行人和车辆）的有效解决方案。现实场景涉及具有不同外观和运动模式的多样化物体类别，现有方法的适用性受限。

Method: 1. 全局空间注意力融合（GSAF）模块：增强多尺度特征学习；2. 轨迹重识别（REID）模块：利用视觉基础模型减少ID切换错误；3. 基于速度的自适应轨迹管理（VATM）模块：根据物体运动动态调整跟踪间隔。

Result: 在V2X-Real和OPV2V数据集上的实验表明，该方法在检测和跟踪精度上显著超越现有最先进方法。

Conclusion: 该框架通过有效处理多类物体检测与跟踪，提升了协同感知在现实场景中的适用性，解决了现有方法局限于车辆超类的问题。

Abstract: Collaborative perception plays a crucial role in enhancing environmental
understanding by expanding the perceptual range and improving robustness
against sensor failures, which primarily involves collaborative 3D detection
and tracking tasks. The former focuses on object recognition in individual
frames, while the latter captures continuous instance tracklets over time.
However, existing works in both areas predominantly focus on the vehicle
superclass, lacking effective solutions for both multi-class collaborative
detection and tracking. This limitation hinders their applicability in
real-world scenarios, which involve diverse object classes with varying
appearances and motion patterns. To overcome these limitations, we propose a
multi-class collaborative detection and tracking framework tailored for diverse
road users. We first present a detector with a global spatial attention fusion
(GSAF) module, enhancing multi-scale feature learning for objects of varying
sizes. Next, we introduce a tracklet RE-IDentification (REID) module that
leverages visual semantics with a vision foundation model to effectively reduce
ID SWitch (IDSW) errors, in cases of erroneous mismatches involving small
objects like pedestrians. We further design a velocity-based adaptive tracklet
management (VATM) module that adjusts the tracking interval dynamically based
on object motion. Extensive experiments on the V2X-Real and OPV2V datasets show
that our approach significantly outperforms existing state-of-the-art methods
in both detection and tracking accuracy.

</details>


### [549] [Adapter Naturally Serves as Decoupler for Cross-Domain Few-Shot Semantic Segmentation](https://arxiv.org/abs/2506.07376)
*Jintao Tong,Ran Ma,Yixiong Zou,Guangyao Chen,Yuhua Li,Ruixuan Li*

Main category: cs.CV

TL;DR: 本文提出了一种名为Domain Feature Navigator（DFN）的结构化域信息解耦器，用于解决跨域少样本分割（CD-FSS）中的域差异和数据稀缺问题。DFN通过捕获域特定信息引导模型关注域无关知识，并结合SAM-SVN方法防止过拟合，在1-shot和5-shot场景下分别超越当前SOTA方法2.69%和4.68% MIoU。


<details>
  <summary>Details</summary>
Motivation: 解决CD-FSS任务中存在的两大挑战：（1）源域和目标域之间的域差异问题（2）目标域数据稀缺导致微调困难。通过发现模型固有结构可自然解耦域信息的现象，设计无需依赖损失函数的解耦方案。

Method: 1. 提出基于结构的域特征导航器（DFN）：替代传统基于损失函数的域解耦方法，主动捕获域特定信息；2. 设计SAM-SVN正则化方法：约束模型在源域训练时避免学习样本特异性知识；3. 目标域微调策略：冻结主干网络，仅微调DFN模块获取目标域知识。

Result: 在跨域少样本分割任务中取得SOTA：1-shot场景下MIoU提升2.69%，5-shot场景下提升4.68%。实验证明DFN能有效解耦域特征，SAM-SVN成功抑制了过拟合。

Conclusion: 1. 首次揭示adapter模块具有天然域解耦特性；2. DFN作为结构化解耦器比损失函数方案更有效；3. 冻结主干+微调DFN的方案平衡了域适应与过拟合风险。该框架为领域自适应问题提供了新视角。

Abstract: Cross-domain few-shot segmentation (CD-FSS) is proposed to pre-train the
model on a source-domain dataset with sufficient samples, and then transfer the
model to target-domain datasets where only a few samples are available for
efficient fine-tuning. There are majorly two challenges in this task: (1) the
domain gap and (2) fine-tuning with scarce data. To solve these challenges, we
revisit the adapter-based methods, and discover an intriguing insight not
explored in previous works: the adapter not only helps the fine-tuning of
downstream tasks but also naturally serves as a domain information decoupler.
Then, we delve into this finding for an interpretation, and find the model's
inherent structure could lead to a natural decoupling of domain information.
Building upon this insight, we propose the Domain Feature Navigator (DFN),
which is a structure-based decoupler instead of loss-based ones like current
works, to capture domain-specific information, thereby directing the model's
attention towards domain-agnostic knowledge. Moreover, to prevent the potential
excessive overfitting of DFN during the source-domain training, we further
design the SAM-SVN method to constrain DFN from learning sample-specific
knowledge. On target domains, we freeze the model and fine-tune the DFN to
learn target-specific knowledge specific. Extensive experiments demonstrate
that our method surpasses the state-of-the-art method in CD-FSS significantly
by 2.69% and 4.68% MIoU in 1-shot and 5-shot scenarios, respectively.

</details>


### [550] [MrM: Black-Box Membership Inference Attacks against Multimodal RAG Systems](https://arxiv.org/abs/2506.07399)
*Peiru Yang,Jinhua Yin,Haoran Zheng,Xueying Bai,Huili Wang,Yufei Sun,Xintian Li,Shangguang Wang,Yongfeng Huang,Tao Qi*

Main category: cs.CV

TL;DR: 提出了名为MrM的黑盒成员推理攻击(MIA)框架，针对多模态RAG系统的隐私漏洞进行视觉模态攻击


<details>
  <summary>Details</summary>
Motivation: 当前针对RAG系统的MIA方法主要关注文本模态，视觉模态的隐私风险研究不足。多模态RAG系统中的敏感视觉信息可能面临成员推理攻击威胁。

Method: 1) 对象感知数据扰动保留关键语义确保成功检索；2) 基于反事实的掩模选择策略放大攻击效果；3) 通过响应模式建模统计推理成员信息

Result: 在两个视觉数据集和8个主流视觉语言模型(如GPT-4o、Gemini-2)上验证，MrM在样本级和集合级评估中均表现强劲，并能抵御自适应防御

Conclusion: 该研究揭示了多模态RAG系统在视觉模态上的隐私风险，提出的MrM攻击框架能有效推断数据成员关系，推动开发更强隐私保护机制的需求

Abstract: Multimodal retrieval-augmented generation (RAG) systems enhance large
vision-language models by integrating cross-modal knowledge, enabling their
increasing adoption across real-world multimodal tasks. These knowledge
databases may contain sensitive information that requires privacy protection.
However, multimodal RAG systems inherently grant external users indirect access
to such data, making them potentially vulnerable to privacy attacks,
particularly membership inference attacks (MIAs). % Existing MIA methods
targeting RAG systems predominantly focus on the textual modality, while the
visual modality remains relatively underexplored. To bridge this gap, we
propose MrM, the first black-box MIA framework targeted at multimodal RAG
systems. It utilizes a multi-object data perturbation framework constrained by
counterfactual attacks, which can concurrently induce the RAG systems to
retrieve the target data and generate information that leaks the membership
information. Our method first employs an object-aware data perturbation method
to constrain the perturbation to key semantics and ensure successful retrieval.
Building on this, we design a counterfact-informed mask selection strategy to
prioritize the most informative masked regions, aiming to eliminate the
interference of model self-knowledge and amplify attack efficacy. Finally, we
perform statistical membership inference by modeling query trials to extract
features that reflect the reconstruction of masked semantics from response
patterns. Experiments on two visual datasets and eight mainstream commercial
visual-language models (e.g., GPT-4o, Gemini-2) demonstrate that MrM achieves
consistently strong performance across both sample-level and set-level
evaluations, and remains robust under adaptive defenses.

</details>


### [551] [Compressed Feature Quality Assessment: Dataset and Baselines](https://arxiv.org/abs/2506.07412)
*Changsheng Gao,Wei Zhou,Guosheng Lin,Weisi Lin*

Main category: cs.CV

TL;DR: 该论文提出压缩特征质量评估(CFQA)问题,发布了首个包含300个原始特征和12000个压缩特征的基准数据集,评估了三种传统指标的有效性,指出需要更精细的语义退化评估指标。


<details>
  <summary>Details</summary>
Motivation: 在资源受限环境中部署大型模型需要高效传输特征,但特征压缩会引起难以量化的语义退化,因此需要评估压缩特征的语义保真度。

Method: 构建首个CFQA数据集(含300原始特征和12000压缩特征,来自3个视觉任务和4种特征编码器);用任务性能下降作为真实语义失真;评估MSE、余弦相似度和中心核对齐三种指标的语义退化捕捉能力。

Result: 验证了数据集的代表性,发现现有指标难以准确捕捉压缩特征的语义退化,表明需要开发更精细的评估指标。

Conclusion: CFQA是一个重要研究问题,提出的数据集和代码将促进该领域发展,未来需要开发更有效的语义失真评估指标。

Abstract: The widespread deployment of large models in resource-constrained
environments has underscored the need for efficient transmission of
intermediate feature representations. In this context, feature coding, which
compresses features into compact bitstreams, becomes a critical component for
scenarios involving feature transmission, storage, and reuse. However, this
compression process introduces inherent semantic degradation that is
notoriously difficult to quantify with traditional metrics. To address this,
this paper introduces the research problem of Compressed Feature Quality
Assessment (CFQA), which seeks to evaluate the semantic fidelity of compressed
features. To advance CFQA research, we propose the first benchmark dataset,
comprising 300 original features and 12000 compressed features derived from
three vision tasks and four feature codecs. Task-specific performance drops are
provided as true semantic distortion for the evaluation of CFQA metrics. We
assess the performance of three widely used metrics (MSE, cosine similarity,
and Centered Kernel Alignment) in capturing semantic degradation. The results
underscore the representativeness of the dataset and highlight the need for
more refined metrics capable of addressing the nuances of semantic distortion
in compressed features. To facilitate the ongoing development of CFQA research,
we release the dataset and all accompanying source code at
\href{https://github.com/chansongoal/Compressed-Feature-Quality-Assessment}{https://github.com/chansongoal/Compressed-Feature-Quality-Assessment}.
This contribution aims to advance the field and provide a foundational resource
for the community to explore CFQA.

</details>


### [552] [DPFormer: Dynamic Prompt Transformer for Continual Learning](https://arxiv.org/abs/2506.07414)
*Sheng-Kai Huang,Jiun-Feng Chang,Chun-Rong Huang*

Main category: cs.CV

TL;DR: 提出了一个名为DPFormer的动态提示转换器，以解决持续学习中的灾难性遗忘和任务间混淆问题。通过提示方案，模型在固定参数量的情况下记忆旧知识并学习新知识。方法结合了多种损失函数进行端到端训练，在多个数据集上达到最优性能。


<details>
  <summary>Details</summary>
Motivation: 持续学习中的灾难性遗忘（旧知识丢失）和任务间混淆问题（因缺乏任务间知识交流导致）。

Method: 动态提示转换器（DPFormer）及提示方案：用提示向量记忆旧知识/学习新知识，解决任务表征差异。统一分类模块结合二元交叉熵、知识蒸馏和辅助损失进行端到端训练。

Result: 在CIFAR-100、ImageNet100和ImageNet1K数据集的持续学习场景下，不同类增量设置中均优于现有方法。

Conclusion: DPFormer通过动态提示方案有效平衡稳定性和可塑性，解决任务间混淆，且模型参数几乎固定。

Abstract: In continual learning, solving the catastrophic forgetting problem may make
the models fall into the stability-plasticity dilemma. Moreover, inter-task
confusion will also occur due to the lack of knowledge exchanges between
different tasks. In order to solve the aforementioned problems, we propose a
novel dynamic prompt transformer (DPFormer) with prompt schemes. The prompt
schemes help the DPFormer memorize learned knowledge of previous classes and
tasks, and keep on learning new knowledge from new classes and tasks under a
single network structure with a nearly fixed number of model parameters.
Moreover, they also provide discrepant information to represent different tasks
to solve the inter-task confusion problem. Based on prompt schemes, a unified
classification module with the binary cross entropy loss, the knowledge
distillation loss and the auxiliary loss is proposed to train the whole model
in an end-to-end trainable manner. Compared with state-of-the-art methods, our
method achieves the best performance in the CIFAR-100, ImageNet100 and
ImageNet1K datasets under different class-incremental settings in continual
learning. The source code will be available at our GitHub after acceptance.

</details>


### [553] [FAMSeg: Fetal Femur and Cranial Ultrasound Segmentation Using Feature-Aware Attention and Mamba Enhancement](https://arxiv.org/abs/2506.07431)
*Jie He,Minglang Chen,Minying Lu,Bocheng Liang,Junming Wei,Guiyan Peng,Jiaxi Chen,Ying Tan*

Main category: cs.CV

TL;DR: 提出了一个基于特征感知和Mamba增强的胎儿股骨和头部超声图像分割模型FAMSeg，以解决现有模型在噪声高、相似性高的超声图像上难以适应的问题，特别是在小目标分割中的锯齿效应。


<details>
  <summary>Details</summary>
Motivation: 超声图像的精确分割对于精准生物测量和评估关键，但现有模型针对自然场景对象而设计，难以适应高噪声和高相似性的超声图像，尤其是在小目标分割时出现明显锯齿效应。

Method: 设计了纵向和横向独立视角扫描卷积模块与特征感知模块以增强细节捕捉上下信息融合能力，结合Mamba优化的残差结构抑制原始噪声；通过建立全局信息和局部特征依赖关系，并使用多种优化器组合训练。

Result: 经过大量实验，FAMSeg网络在不同尺寸和方向的图像上实现了最快的损失下降和最佳分割性能。

Conclusion: 所提出的模型显著提升了超声图像分割的准确性和鲁棒性，特别是在小目标结构上，为解决高噪声医学图像分割问题提供了有效方案。

Abstract: Accurate ultrasound image segmentation is a prerequisite for precise
biometrics and accurate assessment. Relying on manual delineation introduces
significant errors and is time-consuming. However, existing segmentation models
are designed based on objects in natural scenes, making them difficult to adapt
to ultrasound objects with high noise and high similarity. This is particularly
evident in small object segmentation, where a pronounced jagged effect occurs.
Therefore, this paper proposes a fetal femur and cranial ultrasound image
segmentation model based on feature perception and Mamba enhancement to address
these challenges. Specifically, a longitudinal and transverse independent
viewpoint scanning convolution block and a feature perception module were
designed to enhance the ability to capture local detail information and improve
the fusion of contextual information. Combined with the Mamba-optimized
residual structure, this design suppresses the interference of raw noise and
enhances local multi-dimensional scanning. The system builds global information
and local feature dependencies, and is trained with a combination of different
optimizers to achieve the optimal solution. After extensive experimental
validation, the FAMSeg network achieved the fastest loss reduction and the best
segmentation performance across images of varying sizes and orientations.

</details>


### [554] [Prompt to Protection: A Comparative Study of Multimodal LLMs in Construction Hazard Recognition](https://arxiv.org/abs/2506.07436)
*Nishi Chaudhary,S M Jamil Uddin,Sathvik Sharath Chandra,Anto Ovid,Alex Albert*

Main category: cs.CV

TL;DR: 这篇论文评估了五种多模态大语言模型（Claude-3 Opus、GPT-4.5、GPT-4o、GPT-03、Gemini 2.0 Pro）在建筑工地视觉危险识别中的表现，比较了零样本、少样本和思维链（CoT）三种提示策略的效果。


<details>
  <summary>Details</summary>
Motivation: 多模态LLMs为改进建筑工地视觉危险识别提供了新机会，但目前缺乏对不同模型在建筑安全关键任务中的性能比较研究。

Method: 使用真实建筑图像测试五种模型，采用三类提示策略：零样本（无指令）、少样本（基本安全背景+助记符）和思维链（分步推理示例）。定量分析采用精确率、召回率和F1值。

Result: CoT提示策略在所有模型中持续产生更高准确率；GPT-4.5和GPT-03在多数情况下优于其他模型；提示设计对提高多模态LLMs的准确性和一致性具有关键作用。

Conclusion: 研究为整合提示工程与LLMs应用于实际危险识别提供了可行见解，有助于开发更可靠的AI辅助安全系统。

Abstract: The recent emergence of multimodal large language models (LLMs) has
introduced new opportunities for improving visual hazard recognition on
construction sites. Unlike traditional computer vision models that rely on
domain-specific training and extensive datasets, modern LLMs can interpret and
describe complex visual scenes using simple natural language prompts. However,
despite growing interest in their applications, there has been limited
investigation into how different LLMs perform in safety-critical visual tasks
within the construction domain. To address this gap, this study conducts a
comparative evaluation of five state-of-the-art LLMs: Claude-3 Opus, GPT-4.5,
GPT-4o, GPT-o3, and Gemini 2.0 Pro, to assess their ability to identify
potential hazards from real-world construction images. Each model was tested
under three prompting strategies: zero-shot, few-shot, and chain-of-thought
(CoT). Zero-shot prompting involved minimal instruction, few-shot incorporated
basic safety context and a hazard source mnemonic, and CoT provided
step-by-step reasoning examples to scaffold model thinking. Quantitative
analysis was performed using precision, recall, and F1-score metrics across all
conditions. Results reveal that prompting strategy significantly influenced
performance, with CoT prompting consistently producing higher accuracy across
models. Additionally, LLM performance varied under different conditions, with
GPT-4.5 and GPT-o3 outperforming others in most settings. The findings also
demonstrate the critical role of prompt design in enhancing the accuracy and
consistency of multimodal LLMs for construction safety applications. This study
offers actionable insights into the integration of prompt engineering and LLMs
for practical hazard recognition, contributing to the development of more
reliable AI-assisted safety systems.

</details>


### [555] [PhysiInter: Integrating Physical Mapping for High-Fidelity Human Interaction Generation](https://arxiv.org/abs/2506.07456)
*Wei Yao,Yunlian Sun,Chang Liu,Hongwen Zhang,Jinhui Tang*

Main category: cs.CV

TL;DR: 该论文提出一种物理映射方法，集成于多人交互动作生成流程，通过物理模拟修正动作数据，并结合新的动作表示框架与损失函数，显著提升生成动作的物理真实性与质量。


<details>
  <summary>Details</summary>
Motivation: 现有动作捕捉与生成模型常忽视物理约束，导致穿透、滑动等失真问题；尤其在多人交互场景中该问题更为突出，亟需物理校正方法。

Method: 1. 使用基于物理的仿真环境通过运动模仿投射目标动作到物理有效空间
2. 构建针对性动作表示框架
3. 设计运动一致性（MC）和基于标记的交互（MI）损失函数

Result: 物理保真度提升3%-89%，显著改善生成动作的物理合理性与交互真实性。

Conclusion: 物理映射与定制化表示框架能有效解决多人生成动作的物理失真问题，为复杂交互场景提供高质量动作合成方案。

Abstract: Driven by advancements in motion capture and generative artificial
intelligence, leveraging large-scale MoCap datasets to train generative models
for synthesizing diverse, realistic human motions has become a promising
research direction. However, existing motion-capture techniques and generative
models often neglect physical constraints, leading to artifacts such as
interpenetration, sliding, and floating. These issues are exacerbated in
multi-person motion generation, where complex interactions are involved. To
address these limitations, we introduce physical mapping, integrated throughout
the human interaction generation pipeline. Specifically, motion imitation
within a physics-based simulation environment is used to project target motions
into a physically valid space. The resulting motions are adjusted to adhere to
real-world physics constraints while retaining their original semantic meaning.
This mapping not only improves MoCap data quality but also directly informs
post-processing of generated motions. Given the unique interactivity of
multi-person scenarios, we propose a tailored motion representation framework.
Motion Consistency (MC) and Marker-based Interaction (MI) loss functions are
introduced to improve model performance. Experiments show our method achieves
impressive results in generated human motion quality, with a 3%-89% improvement
in physical fidelity. Project page http://yw0208.github.io/physiinter

</details>


### [556] [GLOS: Sign Language Generation with Temporally Aligned Gloss-Level Conditioning](https://arxiv.org/abs/2506.07460)
*Taeryung Lee,Hyeongjin Nam,Gyeongsik Moon,Kyoung Mu Lee*

Main category: cs.CV

TL;DR: 提出GLOS框架，通过时间对齐的手语词级条件，解决手语生成中的词汇顺序错误和语义不准确问题。框架包含手语词级条件和TAC模块，在两个数据集上优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有手语生成方法因依赖整个句子的单一特征向量导致时间结构缺失和词汇顺序错误，需细粒度控制。

Method: 1. 使用与动作序列时间对齐的手语词级条件；2. 提出时间对齐条件（TAC）模块传递细粒度语义与时间结构信息。

Result: 在CSL-Daily和Phoenix-2014T数据集上生成的手语词汇顺序正确、语义准确度更高，性能优于现有方法。

Conclusion: 利用时间对齐的手语词级条件可提升手语生成性能，证明细粒度条件控制的必要性。

Abstract: Sign language generation (SLG), or text-to-sign generation, bridges the gap
between signers and non-signers. Despite recent progress in SLG, existing
methods still often suffer from incorrect lexical ordering and low semantic
accuracy. This is primarily due to sentence-level condition, which encodes the
entire sentence of the input text into a single feature vector as a condition
for SLG. This approach fails to capture the temporal structure of sign language
and lacks the granularity of word-level semantics, often leading to disordered
sign sequences and ambiguous motions. To overcome these limitations, we propose
GLOS, a sign language generation framework with temporally aligned gloss-level
conditioning. First, we employ gloss-level conditions, which we define as
sequences of gloss embeddings temporally aligned with the motion sequence. This
enables the model to access both the temporal structure of sign language and
word-level semantics at each timestep. As a result, this allows for
fine-grained control of signs and better preservation of lexical order. Second,
we introduce a condition fusion module, temporal alignment conditioning (TAC),
to efficiently deliver the word-level semantic and temporal structure provided
by the gloss-level condition to the corresponding motion timesteps. Our method,
which is composed of gloss-level conditions and TAC, generates signs with
correct lexical order and high semantic accuracy, outperforming prior methods
on CSL-Daily and Phoenix-2014T.

</details>


### [557] [DeepVideo-R1: Video Reinforcement Fine-Tuning via Difficulty-aware Regressive GRPO](https://arxiv.org/abs/2506.07464)
*Jinyoung Park,Jeehye Na,Jinyoung Kim,Hyunwoo J. Kim*

Main category: cs.CV

TL;DR: 该论文针对GRPO在视频大语言模型（Video LLMs）中应用存在的两大问题（依赖保障措施和优势消失问题），提出了DeepVideo-R1模型。它结合了改进的Reg-GRPO算法（将GRPO目标重构为回归任务直接预测优势值）和难度感知数据增强策略，在多个视频推理基准测试中显著提升了性能。


<details>
  <summary>Details</summary>
Motivation: 虽然强化学习后训练（如GRPO）能提升语言模型的推理能力，但该方法在视频大语言模型中的研究不足且存在学习效率问题，主要是：（1）对保障措施的依赖限制了策略引导效率；（2）优势消失问题阻碍有效学习。

Method: 提出Reg-GRPO方法——将GRPO目标重构为回归任务直接预测优势值，消除对clip/min等保障措施的依赖；同时设计难度感知数据增强策略，动态生成难度适配的训练样本以获取多样化奖励信号。

Result: DeepVideo-R1模型在多个视频推理基准测试中表现出显著性能提升，证明所提方法有效克服了原有GRPO在视频LLMs中的学习障碍。

Conclusion: 通过将GRPO目标重构为回归任务并配合动态数据增强，解决了视频大语言模型强化学习训练中的两大关键问题，为视频推理任务提供了更高效的优化框架。

Abstract: Recent works have demonstrated the effectiveness of reinforcement learning
(RL)-based post-training in enhancing the reasoning capabilities of large
language models (LLMs). In particular, Group Relative Policy Optimization
(GRPO) has shown impressive success by employing a PPO-style reinforcement
algorithm with group-based normalized rewards. However, the application of GRPO
to Video Large Language Models (Video LLMs) has been less studied. In this
paper, we explore GRPO for video LLMs and identify two primary issues that
impede its effective learning: (1) reliance on safeguards, and (2) the
vanishing advantage problem. To mitigate these challenges, we propose
DeepVideo-R1, a video large language model trained with our proposed Reg-GRPO
(Regressive GRPO) and difficulty-aware data augmentation strategy. Reg-GRPO
reformulates the GRPO objective as a regression task, directly predicting the
advantage in GRPO. This design eliminates the need for safeguards like clipping
and min functions, thereby facilitating more direct policy guidance by aligning
the model with the advantage values. We also design the difficulty-aware data
augmentation strategy that dynamically augments training samples at solvable
difficulty levels, fostering diverse and informative reward signals. Our
comprehensive experiments show that DeepVideo-R1 significantly improves video
reasoning performance across multiple video reasoning benchmarks.

</details>


### [558] [Ambiguity-Restrained Text-Video Representation Learning for Partially Relevant Video Retrieval](https://arxiv.org/abs/2506.07471)
*CH Cho,WJ Moon,W Jun,MS Jung,JP Heo*

Main category: cs.CV

TL;DR: 提出了一个名为ARL（Ambiguity-Restrained representation Learning）的框架来解决PRVR任务中文本与视频内容的固有歧义问题，通过多正例对比学习和双三元组边界损失进行训练，结合跨模型歧义检测以减轻错误传播，提升部分相关视频检索性能。


<details>
  <summary>Details</summary>
Motivation: 传统PRVR训练假设文本查询与视频存在一对一关系，但本文指出文本与视频内容在概念范围上存在固有歧义，需要将这种歧义纳入模型学习过程。

Method: 1) 基于不确定性和相似性标准检测歧义文本-视频对；2) 通过多正例对比学习和双三元组边界损失分层学习语义关系；3) 在文本-帧级别利用未修剪视频中的多上下文增强学习；4) 引入跨模型歧义检测以缓解单模型检测歧义对导致的错误传播。

Result: 提出的方法在PRVR任务中展示了有效性（从摘要结尾的表述推断，但具体指标需看正文）

Conclusion: 解决文本-视频歧义问题能提升PRVR性能，提出的ARL框架通过系统化检测和处理歧义对实现了这一目标。

Abstract: Partially Relevant Video Retrieval~(PRVR) aims to retrieve a video where a
specific segment is relevant to a given text query. Typical training processes
of PRVR assume a one-to-one relationship where each text query is relevant to
only one video. However, we point out the inherent ambiguity between text and
video content based on their conceptual scope and propose a framework that
incorporates this ambiguity into the model learning process. Specifically, we
propose Ambiguity-Restrained representation Learning~(ARL) to address ambiguous
text-video pairs. Initially, ARL detects ambiguous pairs based on two criteria:
uncertainty and similarity. Uncertainty represents whether instances include
commonly shared context across the dataset, while similarity indicates
pair-wise semantic overlap. Then, with the detected ambiguous pairs, our ARL
hierarchically learns the semantic relationship via multi-positive contrastive
learning and dual triplet margin loss. Additionally, we delve into fine-grained
relationships within the video instances. Unlike typical training at the
text-video level, where pairwise information is provided, we address the
inherent ambiguity within frames of the same untrimmed video, which often
contains multiple contexts. This allows us to further enhance learning at the
text-frame level. Lastly, we propose cross-model ambiguity detection to
mitigate the error propagation that occurs when a single model is employed to
detect ambiguous pairs for its training. With all components combined, our
proposed method demonstrates its effectiveness in PRVR.

</details>


### [559] [CoCoA-Mix: Confusion-and-Confidence-Aware Mixture Model for Context Optimization](https://arxiv.org/abs/2506.07484)
*Dasol Hong,Wooju Lee,Hyun Myung*

Main category: cs.CV

TL;DR: 该论文提出了一个名为CoCoA-Mix的方法，通过混淆感知损失（CoA-loss）和置信感知权重（CoA-weights）来改进提示调优，提升特定任务的专业化和对未见域的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 冻结编码器在提示调优过程中会导致特征错位，从而引起类别混淆并限制专业化。为解决这个问题，需要同时增强专业化和泛化能力

Method: 1. 引入混淆感知损失（CoA-loss）以细化混淆类别间决策边界；2. 采用基于置信感知权重（CoA-weights）的混合模型来平衡专业化和泛化

Result: 实验显示CoCoA-Mix在多项任务中超越最先进方法，证明了在专业化和泛化方面的改进

Conclusion: 所提出的CoA-loss能有效解决特征错位问题，而结合CoA-weights的混合模型提升了模型性能，同时不牺牲专业化能力

Abstract: Prompt tuning, which adapts vision-language models by freezing model
parameters and optimizing only the prompt, has proven effective for
task-specific adaptations. The core challenge in prompt tuning is improving
specialization for a specific task and generalization for unseen domains.
However, frozen encoders often produce misaligned features, leading to
confusion between classes and limiting specialization. To overcome this issue,
we propose a confusion-aware loss (CoA-loss) that improves specialization by
refining the decision boundaries between confusing classes. Additionally, we
mathematically demonstrate that a mixture model can enhance generalization
without compromising specialization. This is achieved using confidence-aware
weights (CoA-weights), which adjust the weights of each prediction in the
mixture model based on its confidence within the class domains. Extensive
experiments show that CoCoA-Mix, a mixture model with CoA-loss and CoA-weights,
outperforms state-of-the-art methods by enhancing specialization and
generalization. Our code is publicly available at
https://github.com/url-kaist/CoCoA-Mix.

</details>


### [560] [Drive Any Mesh: 4D Latent Diffusion for Mesh Deformation from Video](https://arxiv.org/abs/2506.07489)
*Yahao Shi,Yang Liu,Yanmin Wu,Xing Liu,Chen Zhao,Jie Luo,Bin Zhou*

Main category: cs.CV

TL;DR: DriveAnyMesh是一种通过单目视频驱动网格的方法，解决了现有4D生成技术在渲染引擎兼容性、效率和泛化性方面的不足。利用4D扩散模型处理点云轨迹序列，生成高质量网格动画，适用于游戏和影视行业。


<details>
  <summary>Details</summary>
Motivation: 当前4D生成技术存在渲染效率低、引擎兼容性差（隐式方法）及人工成本高、跨类别泛化能力弱（骨骼方法）的问题。动画化现有3D资产需要深入理解3D结构。为应对这些挑战，提出DriveAnyMesh方法。

Method: 1. 使用基于Transformer的变分自编码器（VAE）捕获点云轨迹序列的3D形状和运动信息，生成潜在集。
2. 采用时空Transformer扩散模型对潜在集序列去噪。
3. 将去噪后的潜在集解码为网格动画序列。

Result: 实验证明：
1. 能在现代渲染引擎中高效生成高质量复杂运动动画。
2. 比现有方法更具泛化性(跨类别)和兼容性(支持光栅化引擎)。
3. 显著减少人工干预需求。

Conclusion: DriveAnyMesh实现了：
1. 单目视频驱动的网格动画生成
2. 与主流渲染引擎兼容
3. 高效率与强泛化能力
为游戏/影视行业提供了新的4D内容生产解决方案。

Abstract: We propose DriveAnyMesh, a method for driving mesh guided by monocular video.
Current 4D generation techniques encounter challenges with modern rendering
engines. Implicit methods have low rendering efficiency and are unfriendly to
rasterization-based engines, while skeletal methods demand significant manual
effort and lack cross-category generalization. Animating existing 3D assets,
instead of creating 4D assets from scratch, demands a deep understanding of the
input's 3D structure. To tackle these challenges, we present a 4D diffusion
model that denoises sequences of latent sets, which are then decoded to produce
mesh animations from point cloud trajectory sequences. These latent sets
leverage a transformer-based variational autoencoder, simultaneously capturing
3D shape and motion information. By employing a spatiotemporal,
transformer-based diffusion model, information is exchanged across multiple
latent frames, enhancing the efficiency and generalization of the generated
results. Our experimental results demonstrate that DriveAnyMesh can rapidly
produce high-quality animations for complex motions and is compatible with
modern rendering engines. This method holds potential for applications in both
the gaming and filming industries.

</details>


### [561] [SpatialLM: Training Large Language Models for Structured Indoor Modeling](https://arxiv.org/abs/2506.07491)
*Yongsen Mao,Junhao Zhong,Chuan Fang,Jia Zheng,Rui Tang,Hao Zhu,Ping Tan,Zihan Zhou*

Main category: cs.CV

TL;DR: SpatialLM是一个处理3D点云数据的大语言模型，用于生成结构化3D场景理解输出（如墙壁、门窗等）。它采用标准多模态LLM架构，并基于开源LLM微调。使用大规模合成数据集训练，在布局估计任务上达到SOTA，在物体检测上表现优异，增强LLM空间理解能力。


<details>
  <summary>Details</summary>
Motivation: 现有方法多采用任务专用网络设计，本工作旨在探索标准多模态LLM架构是否能在3D场景理解任务（如布局估计、物体检测）上取得竞争力，并增强LLM的空间理解能力以适应AR/机器人等应用。

Method: 1. 构建包含12,328室内场景（54,778房间）的大规模合成点云数据集，含精确3D标注。2. 基于开源LLM采用标准多模态架构，直接微调处理点云数据。3. 详细研究建模与训练决策。

Result: 1. 公开基准测试中：布局估计任务达到SOTA，3D物体检测任务获得有竞争力结果。2. 证明基于标准架构微调开源LLM的可行性。

Conclusion: 通过SpatialLM验证了标准多模态LLM架构处理3D点云数据的有效性，为增强LLM空间理解能力提供了可行路径，适用于AR/机器人等领域。合成数据规模化训练是关键成功因素。

Abstract: SpatialLM is a large language model designed to process 3D point cloud data
and generate structured 3D scene understanding outputs. These outputs include
architectural elements like walls, doors, windows, and oriented object boxes
with their semantic categories. Unlike previous methods which exploit
task-specific network designs, our model adheres to the standard multimodal LLM
architecture and is fine-tuned directly from open-source LLMs.
  To train SpatialLM, we collect a large-scale, high-quality synthetic dataset
consisting of the point clouds of 12,328 indoor scenes (54,778 rooms) with
ground-truth 3D annotations, and conduct a careful study on various modeling
and training decisions. On public benchmarks, our model gives state-of-the-art
performance in layout estimation and competitive results in 3D object
detection. With that, we show a feasible path for enhancing the spatial
understanding capabilities of modern LLMs for applications in augmented
reality, embodied robotics, and more.

</details>


### [562] [Genesis: Multimodal Driving Scene Generation with Spatio-Temporal and Cross-Modal Consistency](https://arxiv.org/abs/2506.07497)
*Xiangyu Guo,Zhanqian Wu,Kaixin Xiong,Ziyang Xu,Lijun Zhou,Gangwei Xu,Shaoqing Xu,Haiyang Sun,Bing Wang,Guang Chen,Hangjun Ye,Wenyu Liu,Xinggang Wang*

Main category: cs.CV

TL;DR: Genesis是一个统一框架，用于联合生成多视角驾驶视频和LiDAR序列，通过共享潜空间保证时空与跨模态一致性。采用两阶段架构：整合DiT视频扩散模型与3D-VAE，以及结合NeRF渲染的BEV LiDAR生成器。引入DataCrafter模块提供结构化语义监督。在nuScenes上实现SOTA指标（FVD 16.95/FID 4.24/Chamfer 0.611），增强了下游任务性能。


<details>
  <summary>Details</summary>
Motivation: 解决当前多模态自动驾驶数据生成中时空不连贯和模态割裂问题，通过联合生成视频与LiDAR数据提升合成数据的真实性与下游任务实用性。

Method: 两阶段架构：1) DiT视频扩散模型+3D-VAE编码视频 2) BEV LiDAR生成器（NeRF渲染+自适应采样）。跨模态共享潜空间。DataCrafter模块基于VLM提供场景级/实例级语义监督。

Result: nuScenes基准测试SOTA：视频指标FVD=16.95/FID=4.24，LiDAR指标Chamfer=0.611。提升下游任务（语义分割/3D检测）性能，证明生成数据语义保真度高。

Conclusion: Genesis首次实现视频与LiDAR的端到端联合生成，共享潜空间设计有效保障跨模态一致性。结构化语义监督提升生成质量，合成数据可增强下游任务训练。

Abstract: We present Genesis, a unified framework for joint generation of multi-view
driving videos and LiDAR sequences with spatio-temporal and cross-modal
consistency. Genesis employs a two-stage architecture that integrates a
DiT-based video diffusion model with 3D-VAE encoding, and a BEV-aware LiDAR
generator with NeRF-based rendering and adaptive sampling. Both modalities are
directly coupled through a shared latent space, enabling coherent evolution
across visual and geometric domains. To guide the generation with structured
semantics, we introduce DataCrafter, a captioning module built on
vision-language models that provides scene-level and instance-level
supervision. Extensive experiments on the nuScenes benchmark demonstrate that
Genesis achieves state-of-the-art performance across video and LiDAR metrics
(FVD 16.95, FID 4.24, Chamfer 0.611), and benefits downstream tasks including
segmentation and 3D detection, validating the semantic fidelity and practical
utility of the generated data.

</details>


### [563] [MoQAE: Mixed-Precision Quantization for Long-Context LLM Inference via Mixture of Quantization-Aware Experts](https://arxiv.org/abs/2506.07533)
*Wei Tao,Haocheng Lu,Xiaoyang Qu,Bin Zhang,Kai Lu,Jiguang Wan,Jianzong Wang*

Main category: cs.CV

TL;DR: 提出MoQAE方法，一种混合精度的量化方法，用于优化大型语言模型的长上下文推理中的KV缓存内存占用，通过专家混合和路由器优化平衡效率和准确性。


<details>
  <summary>Details</summary>
Motivation: 优化大型语言模型长上下文推理时KV缓存的高内存消耗。现有量化方法无法同时兼顾效率和效果。

Method: 1. 将不同量化位宽视为专家，使用基于块的MoE路由选择最优配置；2. 设计轻量级路由器微调，平衡精度和内存；3. 引入路由冻结和共享机制减少推理开销。

Result: 在多个基准数据集上超越当前最优的KV缓存量化方法，同时提高效率和效果。

Conclusion: MoQAE通过混合精度量化和路由优化，解决了KV缓存的高内存问题，实现效率和准确性的平衡。

Abstract: One of the primary challenges in optimizing large language models (LLMs) for
long-context inference lies in the high memory consumption of the Key-Value
(KV) cache. Existing approaches, such as quantization, have demonstrated
promising results in reducing memory usage. However, current quantization
methods cannot take both effectiveness and efficiency into account. In this
paper, we propose MoQAE, a novel mixed-precision quantization method via
mixture of quantization-aware experts. First, we view different quantization
bit-width configurations as experts and use the traditional mixture of experts
(MoE) method to select the optimal configuration. To avoid the inefficiency
caused by inputting tokens one by one into the router in the traditional MoE
method, we input the tokens into the router chunk by chunk. Second, we design a
lightweight router-only fine-tuning process to train MoQAE with a comprehensive
loss to learn the trade-off between model accuracy and memory usage. Finally,
we introduce a routing freezing (RF) and a routing sharing (RS) mechanism to
further reduce the inference overhead. Extensive experiments on multiple
benchmark datasets demonstrate that our method outperforms state-of-the-art KV
cache quantization approaches in both efficiency and effectiveness.

</details>


### [564] [Domain Randomization for Object Detection in Manufacturing Applications using Synthetic Data: A Comprehensive Study](https://arxiv.org/abs/2506.07539)
*Xiaomeng Zhu,Jacob Henningsson,Duruo Li,Pär Mårtensson,Lars Hanson,Mårten Björkman,Atsuto Maki*

Main category: cs.CV

TL;DR: 提出了一个全面的合成数据生成流程和SIP15-OD数据集，用于研究制造业物体检测中的领域随机化。通过优化材质、渲染等关键因素，使用纯合成数据训练的Yolov8在机器人数据集上达到96.4% mAP@50，在三个工业用例中分别达到94.1%、99.5%和95.3%。


<details>
  <summary>Details</summary>
Motivation: 解决制造领域物体检测应用中合成数据生成的关键问题，探索从模拟到真实场景的可行性和挑战。

Method: 设计综合数据生成流程（包含物体特征、背景、光照等元素），创建含15个工业对象的SIP15-OD数据集，利用公开的工业数据集进行对比实验，采用Yolov8模型进行性能测试。

Result: 在公开机器人数据集上mAP@50达96.4%；在SIP15-OD三个工业用例中分别达到94.1%/99.5%/95.3%，证明领域随机化能有效覆盖真实数据分布。

Conclusion: 材质属性、渲染方法等关键因素显著影响性能，所提方法验证了纯合成数据训练在工业物体检测中的有效性，为sim-to-real提供新见解。

Abstract: This paper addresses key aspects of domain randomization in generating
synthetic data for manufacturing object detection applications. To this end, we
present a comprehensive data generation pipeline that reflects different
factors: object characteristics, background, illumination, camera settings, and
post-processing. We also introduce the Synthetic Industrial Parts Object
Detection dataset (SIP15-OD) consisting of 15 objects from three industrial use
cases under varying environments as a test bed for the study, while also
employing an industrial dataset publicly available for robotic applications. In
our experiments, we present more abundant results and insights into the
feasibility as well as challenges of sim-to-real object detection. In
particular, we identified material properties, rendering methods,
post-processing, and distractors as important factors. Our method, leveraging
these, achieves top performance on the public dataset with Yolov8 models
trained exclusively on synthetic data; mAP@50 scores of 96.4% for the robotics
dataset, and 94.1%, 99.5%, and 95.3% across three of the SIP15-OD use cases,
respectively. The results showcase the effectiveness of the proposed domain
randomization, potentially covering the distribution close to real data for the
applications.

</details>


### [565] [APTOS-2024 challenge report: Generation of synthetic 3D OCT images from fundus photographs](https://arxiv.org/abs/2506.07542)
*Bowen Liu,Weiyi Zhang,Peranut Chotcomwongse,Xiaolan Chen,Ruoyu Chen,Pawin Pakaymaskul,Niracha Arjkongharn,Nattaporn Vongsa,Xuelian Cheng,Zongyuan Ge,Kun Huang,Xiaohui Li,Yiru Duan,Zhenbang Wang,BaoYe Xie,Qiang Chen,Huazhu Fu,Michael A. Mahr,Jiaqi Qu,Wangyiyang Chen,Shiye Wang,Yubo Tan,Yongjie Li,Mingguang He,Danli Shi,Paisan Ruamviboonsuk*

Main category: cs.CV

TL;DR: APTOS-2024挑战赛建立首个3D OCT合成基准，通过混合数据预处理、跨模态协作等创新方法实现眼底图到3D OCT的转换。大赛342支队验证可行性，改善欠发达地区眼科诊疗可达性。


<details>
  <summary>Details</summary>
Motivation: 解决OCT设备成本高、操作专业性强导致普及受限问题；利用易获取的二维眼底图生成三维OCT影像，推动资源匮乏地区的眼科诊疗发展。

Method: 设计眼底图到3D OCT合成挑战赛框架：包含基准数据集、双重评估指标（图像相似度和视频语义一致性）、分析顶级团队解决方案（混合数据增强、外部数据集预训练、视觉基础模型集成）。

Result: 342支团队参赛，9支决赛团队表现优异；创新方法验证从二维眼底图生成三维OCT的可行性。

Conclusion: 该挑战赛证明眼底图转OCT技术能提升资源匮乏地区眼科医疗可及性；跨模态生成模型为医疗研究临床应用提供新路径。

Abstract: Optical Coherence Tomography (OCT) provides high-resolution, 3D, and
non-invasive visualization of retinal layers in vivo, serving as a critical
tool for lesion localization and disease diagnosis. However, its widespread
adoption is limited by equipment costs and the need for specialized operators.
In comparison, 2D color fundus photography offers faster acquisition and
greater accessibility with less dependence on expensive devices. Although
generative artificial intelligence has demonstrated promising results in
medical image synthesis, translating 2D fundus images into 3D OCT images
presents unique challenges due to inherent differences in data dimensionality
and biological information between modalities. To advance generative models in
the fundus-to-3D-OCT setting, the Asia Pacific Tele-Ophthalmology Society
(APTOS-2024) organized a challenge titled Artificial Intelligence-based OCT
Generation from Fundus Images. This paper details the challenge framework
(referred to as APTOS-2024 Challenge), including: the benchmark dataset,
evaluation methodology featuring two fidelity metrics-image-based distance
(pixel-level OCT B-scan similarity) and video-based distance (semantic-level
volumetric consistency), and analysis of top-performing solutions. The
challenge attracted 342 participating teams, with 42 preliminary submissions
and 9 finalists. Leading methodologies incorporated innovations in hybrid data
preprocessing or augmentation (cross-modality collaborative paradigms),
pre-training on external ophthalmic imaging datasets, integration of vision
foundation models, and model architecture improvement. The APTOS-2024 Challenge
is the first benchmark demonstrating the feasibility of fundus-to-3D-OCT
synthesis as a potential solution for improving ophthalmic care accessibility
in under-resourced healthcare settings, while helping to expedite medical
research and clinical applications.

</details>


### [566] [Synthesize Privacy-Preserving High-Resolution Images via Private Textual Intermediaries](https://arxiv.org/abs/2506.07555)
*Haoxiang Wang,Zinan Lin,Da Yu,Huishuai Zhang*

Main category: cs.CV

TL;DR: SPTI提出了一种通过文本中介生成高保真差分隐私合成图像的新方法，无需训练现成模型即可实现高分辨率输出，FID指标显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有差分隐私图像合成方法难以生成高分辨率且忠实于原始数据结构的图像，需开发更高效的方法实现隐私保护的视觉数据共享。

Method: 1. 使用图文模型将私有图像转为文本描述
2. 应用改进的Private Evolution算法生成差分隐私文本
3. 通过文生图模型重建合成图像

Result: 1. LSUN卧室数据集：ε=1时FID≤26.71（基线为40.36）
2. MM CelebA HQ数据集：ε=1时FID≤33.27（基线为57.01）

Conclusion: SPTI提供资源高效的兼容框架，显著提升差分隐私合成图像质量，拓宽私有视觉数据访问渠道。

Abstract: Generating high fidelity, differentially private (DP) synthetic images offers
a promising route to share and analyze sensitive visual data without
compromising individual privacy. However, existing DP image synthesis methods
struggle to produce high resolution outputs that faithfully capture the
structure of the original data. In this paper, we introduce a novel method,
referred to as Synthesis via Private Textual Intermediaries (SPTI), that can
generate high resolution DP images with easy adoption. The key idea is to shift
the challenge of DP image synthesis from the image domain to the text domain by
leveraging state of the art DP text generation methods. SPTI first summarizes
each private image into a concise textual description using image to text
models, then applies a modified Private Evolution algorithm to generate DP
text, and finally reconstructs images using text to image models. Notably, SPTI
requires no model training, only inference with off the shelf models. Given a
private dataset, SPTI produces synthetic images of substantially higher quality
than prior DP approaches. On the LSUN Bedroom dataset, SPTI attains an FID less
than or equal to 26.71 under epsilon equal to 1.0, improving over Private
Evolution FID of 40.36. Similarly, on MM CelebA HQ, SPTI achieves an FID less
than or equal to 33.27 at epsilon equal to 1.0, compared to 57.01 from DP fine
tuning baselines. Overall, our results demonstrate that Synthesis via Private
Textual Intermediaries provides a resource efficient and proprietary model
compatible framework for generating high resolution DP synthetic images,
greatly expanding access to private visual datasets.

</details>


### [567] [Cross-channel Perception Learning for H&E-to-IHC Virtual Staining](https://arxiv.org/abs/2506.07559)
*Hao Yang,JianYu Wu,Run Fang,Xuelian Zhao,Yuan Ji,Zhiyu Chen,Guibin He,Junceng Guo,Yang Liu,Xinhua Zeng*

Main category: cs.CV

TL;DR: Abstract 介绍了一种名为CCPL（Cross-Channel Perception Learning）的新策略，用于解决H&E到IHC虚拟染色中跨通道相关性被忽略的问题。通过分解染色通道、利用基础模型提取特征并计算跨通道相关性，同时结合特征蒸馏损失和光学密度统计分析，该方法在定量指标和病理学家评估中表现出色。


<details>
  <summary>Details</summary>
Motivation: 现有H&E-to-IHC研究方法忽视了细胞核与细胞膜之间的跨通道相关性，导致虚拟染色效果不佳，影响了病理图像的自动化分析和诊断。

Method: 1. 将HER2免疫组化染色分解为苏木精（Hematoxylin, 细胞核）和DAB（细胞膜）双通道。
2. 利用病理基础模型Gigapath的Tile Encoder提取生成图像和真实图像的双通道特征。
3. 计算细胞核与细胞膜的跨通道相关性，并通过特征蒸馏损失增强特征提取能力。
4. 对单通道的光学密度图进行统计分析，确保染色分布和强度的一致性。

Result: 实验使用PSNR、SSIM、PCC和FID等定量指标及病理学家专业评估，证明CCPL能有效保留病理特征，生成高质量虚拟染色图像，为多媒体医疗数据支持的自诊病理断提供可靠支撑。

Conclusion: CCPL策略通过建模跨通道相关性并优化特征提取，显著提升了H&E-to-IHC虚拟染色的质量，有利于推动数字病理学在多媒体医疗信息系统中的应用。

Abstract: With the rapid development of digital pathology, virtual staining has become
a key technology in multimedia medical information systems, offering new
possibilities for the analysis and diagnosis of pathological images. However,
existing H&E-to-IHC studies often overlook the cross-channel correlations
between cell nuclei and cell membranes. To address this issue, we propose a
novel Cross-Channel Perception Learning (CCPL) strategy. Specifically, CCPL
first decomposes HER2 immunohistochemical staining into Hematoxylin and DAB
staining channels, corresponding to cell nuclei and cell membranes,
respectively. Using the pathology foundation model Gigapath's Tile Encoder,
CCPL extracts dual-channel features from both the generated and real images and
measures cross-channel correlations between nuclei and membranes. The features
of the generated and real stained images, obtained through the Tile Encoder,
are also used to calculate feature distillation loss, enhancing the model's
feature extraction capabilities without increasing the inference burden.
Additionally, CCPL performs statistical analysis on the focal optical density
maps of both single channels to ensure consistency in staining distribution and
intensity. Experimental results, based on quantitative metrics such as PSNR,
SSIM, PCC, and FID, along with professional evaluations from pathologists,
demonstrate that CCPL effectively preserves pathological features, generates
high-quality virtual stained images, and provides robust support for automated
pathological diagnosis using multimedia medical data.

</details>


### [568] [OpenDance: Multimodal Controllable 3D Dance Generation Using Large-scale Internet Data](https://arxiv.org/abs/2506.07565)
*Jinlu Zhang,Zixi Kang,Yizhou Wang*

Main category: cs.CV

TL;DR: 介绍了 OpenDance5D 数据集和 OpenDanceNet 模型，解决了音乐驱动舞蹈生成的挑战


<details>
  <summary>Details</summary>
Motivation: 由于缺乏细粒度多模态数据及灵活性多条件生成难题，现有舞蹈生成在可控性和多样性方面受限

Method: 构建 OpenDance5D 数据集并开发 OpenDanceNet 模型，通过掩码建模实现多条件控制生成

Result: OpenDanceNet 实现了高保真度和灵活可控性

Conclusion: 提出的大规模数据集和统一生成框架有效提升了舞蹈生成质量

Abstract: Music-driven dance generation offers significant creative potential yet faces
considerable challenges. The absence of fine-grained multimodal data and the
difficulty of flexible multi-conditional generation limit previous works on
generation controllability and diversity in practice. In this paper, we build
OpenDance5D, an extensive human dance dataset comprising over 101 hours across
14 distinct genres. Each sample has five modalities to facilitate robust
cross-modal learning: RGB video, audio, 2D keypoints, 3D motion, and
fine-grained textual descriptions from human arts. Furthermore, we propose
OpenDanceNet, a unified masked modeling framework for controllable dance
generation conditioned on music and arbitrary combinations of text prompts,
keypoints, or character positioning. Comprehensive experiments demonstrate that
OpenDanceNet achieves high-fidelity and flexible controllability.

</details>


### [569] [Towards the Influence of Text Quantity on Writer Retrieval](https://arxiv.org/abs/2506.07566)
*Marco Peer,Robert Sablatnig,Florian Kleber*

Main category: cs.CV

TL;DR: 该研究探讨了文本量对笔迹检索效果的影响，发现在使用至少四行文本时，检索准确率依然能达到全页性能的90%以上。


<details>
  <summary>Details</summary>
Motivation: 现有方法大多关注页面级检索，而本研究旨在探究不同文本量（行级和词级）对笔迹检索系统性能的影响。

Method: 评估了三种先进的笔迹检索系统（包含手工特征和深度学习方法），在CVL和IAM数据集上使用不同文本量进行实验。

Result: 当查询和图库仅用一行文本时性能下降20-30%；使用四行文本时准确率保持在90%以上；文本相关检索在低文本场景表现优异；深度学习方法（如NetVLAD）在低文本场景显著优于传统VLAD。

Conclusion: 文本量对笔迹检索性能有显著影响，但合理设计系统（如使用4行文本或文本相关检索）可维持较高准确率；深度学习在低文本场景更具优势。

Abstract: This paper investigates the task of writer retrieval, which identifies
documents authored by the same individual within a dataset based on handwriting
similarities. While existing datasets and methodologies primarily focus on page
level retrieval, we explore the impact of text quantity on writer retrieval
performance by evaluating line- and word level retrieval. We examine three
state-of-the-art writer retrieval systems, including both handcrafted and deep
learning-based approaches, and analyze their performance using varying amounts
of text. Our experiments on the CVL and IAM dataset demonstrate that while
performance decreases by 20-30% when only one line of text is used as query and
gallery, retrieval accuracy remains above 90% of full-page performance when at
least four lines are included. We further show that text-dependent retrieval
can maintain strong performance in low-text scenarios. Our findings also
highlight the limitations of handcrafted features in low-text scenarios, with
deep learning-based methods like NetVLAD outperforming traditional VLAD
encoding.

</details>


### [570] [LLM-driven Indoor Scene Layout Generation via Scaled Human-aligned Data Synthesis and Multi-Stage Preference Optimization](https://arxiv.org/abs/2506.07570)
*Yixuan Yang,Zhen Luo,Tongsheng Ding,Junru Lu,Mingqi Gao,Jinyu Yang,Victor Sanchez,Feng Zheng*

Main category: cs.CV

TL;DR: 该论文提出了3D-SynthPlace大规模数据集和OptiScene模型，解决了现有室内布局生成方法的空间不一致性、计算成本高以及泛化能力差的问题。通过两阶段训练（监督微调+偏好优化），OptiScene在布局质量和成功率上超越现有基线。


<details>
  <summary>Details</summary>
Motivation: 现有室内布局生成方法存在两大问题：基于提示的方法（如GPT API）易产生空间不一致且计算成本高；基于学习的方法受限于粗糙关系图和有限数据集，导致泛化能力差。

Method: 1. 构建3D-SynthPlace数据集（17,000个场景），采用'GPT生成+人工检查'流程升级自3D-Front；2. 提出两阶段训练模型OptiScene：阶段I监督微调（SFT）生成空间描述和物体布局，阶段II多轮直接偏好优化（DPO）对齐人类设计偏好。

Result: OptiScene超越传统提示驱动和基于学习的基线方法。实验证明：1）布局质量和生成成功率显著提升；2）在场景编辑和机器人导航等交互任务中展现潜力。

Conclusion: 通过结合大规模高质量数据集和两阶段LLM优化策略，该研究实现了高效且泛化性强的室内布局生成，为后续交互应用奠定基础。

Abstract: Automatic indoor layout generation has attracted increasing attention due to
its potential in interior design, virtual environment construction, and
embodied AI. Existing methods fall into two categories: prompt-driven
approaches that leverage proprietary LLM services (e.g., GPT APIs) and
learning-based methods trained on layout data upon diffusion-based models.
Prompt-driven methods often suffer from spatial inconsistency and high
computational costs, while learning-based methods are typically constrained by
coarse relational graphs and limited datasets, restricting their generalization
to diverse room categories. In this paper, we revisit LLM-based indoor layout
generation and present 3D-SynthPlace, a large-scale dataset that combines
synthetic layouts generated via a 'GPT synthesize, Human inspect' pipeline,
upgraded from the 3D-Front dataset. 3D-SynthPlace contains nearly 17,000
scenes, covering four common room types -- bedroom, living room, kitchen, and
bathroom -- enriched with diverse objects and high-level spatial annotations.
We further introduce OptiScene, a strong open-source LLM optimized for indoor
layout generation, fine-tuned based on our 3D-SynthPlace dataset through our
two-stage training. For the warum-up stage I, we adopt supervised fine-tuning
(SFT), which is taught to first generate high-level spatial descriptions then
conditionally predict concrete object placements. For the reinforcing stage II,
to better align the generated layouts with human design preferences, we apply
multi-turn direct preference optimization (DPO), which significantly improving
layout quality and generation success rates. Extensive experiments demonstrate
that OptiScene outperforms traditional prompt-driven and learning-based
baselines. Moreover, OptiScene shows promising potential in interactive tasks
such as scene editing and robot navigation.

</details>


### [571] [Learning Speaker-Invariant Visual Features for Lipreading](https://arxiv.org/abs/2506.07572)
*Yu Li,Feng Xue,Shujie Li,Jinrui Zhang,Shuang Yang,Dan Guo,Richang Hong*

Main category: cs.CV

TL;DR: 该论文提出SIFLip框架来解决唇读任务中说话人特定特征导致的伪相关性问题。通过隐式去缠模块（利用文本嵌入监督）和显式去缠模块（结合梯度反转）分离说话人属性，显著提升了跨说话人泛化性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法提取的视觉特征包含说话人特定属性（如唇形纹理），导致视觉与文本间存在伪相关性，降低模型泛化能力。需要解耦这些特征以提高跨说话人性能。

Method: 1. 隐式去缠：利用不同说话人相同单词发音时唇动与文本的语义一致性，以文本嵌入为监督信号学习共性特征；
2. 显式去缠：在主干网添加说话人识别子任务，通过梯度反转显式过滤说话人特征。

Result: 在多个公开数据集上显著提升跨说话人泛化性能，超越当前最优方法。

Conclusion: SIFLip通过双模块协同解耦说话人特性，证实分离身份相关特征是提升唇读模型泛化能力的有效途径。

Abstract: Lipreading is a challenging cross-modal task that aims to convert visual lip
movements into spoken text. Existing lipreading methods often extract visual
features that include speaker-specific lip attributes (e.g., shape, color,
texture), which introduce spurious correlations between vision and text. These
correlations lead to suboptimal lipreading accuracy and restrict model
generalization. To address this challenge, we introduce SIFLip, a
speaker-invariant visual feature learning framework that disentangles
speaker-specific attributes using two complementary disentanglement modules
(Implicit Disentanglement and Explicit Disentanglement) to improve
generalization. Specifically, since different speakers exhibit semantic
consistency between lip movements and phonetic text when pronouncing the same
words, our implicit disentanglement module leverages stable text embeddings as
supervisory signals to learn common visual representations across speakers,
implicitly decoupling speaker-specific features. Additionally, we design a
speaker recognition sub-task within the main lipreading pipeline to filter
speaker-specific features, then further explicitly disentangle these
personalized visual features from the backbone network via gradient reversal.
Experimental results demonstrate that SIFLip significantly enhances
generalization performance across multiple public datasets. Experimental
results demonstrate that SIFLip significantly improves generalization
performance across multiple public datasets, outperforming state-of-the-art
methods.

</details>


### [572] [Uncertainty-o: One Model-agnostic Framework for Unveiling Uncertainty in Large Multimodal Models](https://arxiv.org/abs/2506.07575)
*Ruiyang Zhang,Hu Zhang,Hao Fei,Zhedong Zheng*

Main category: cs.CV

TL;DR: 提出Uncertainty-o框架，用于评估和揭示多模态模型（LMMs）的不确定性，通过多模态提示扰动探索不确定性，并量化多模态语义不确定性，提升下游任务性能。


<details>
  <summary>Details</summary>
Motivation: 大模型（LMMs）虽在互补性上优于纯语言模型（LLMs），但其不确定性评估仍存在挑战：如何统一评估不同LMMs的不确定性；如何提示LMMs表达不确定性；如何量化不确定性用于下游任务。

Method: 提出模型无关框架Uncertainty-o：设计多模态提示扰动策略引发LMMs不确定性；推导多模态语义不确定性（MSU）公式，量化多模态响应中的不确定性。

Result: 在18个跨模态基准测试和10个开源/闭源LMMs上验证有效性：显著提升幻觉检测（平均提升21.7% AUROC）、幻觉缓解（平均提升24.1% ACC）及不确定性感知的CoT推理任务性能。

Conclusion: Uncertainty-o首次实现跨架构LMMs的统一不确定性评估，揭示提示扰动与不确定性的关联，并为下游任务提供可量化的不确定性支持。

Abstract: Large Multimodal Models (LMMs), harnessing the complementarity among diverse
modalities, are often considered more robust than pure Language Large Models
(LLMs); yet do LMMs know what they do not know? There are three key open
questions remaining: (1) how to evaluate the uncertainty of diverse LMMs in a
unified manner, (2) how to prompt LMMs to show its uncertainty, and (3) how to
quantify uncertainty for downstream tasks. In an attempt to address these
challenges, we introduce Uncertainty-o: (1) a model-agnostic framework designed
to reveal uncertainty in LMMs regardless of their modalities, architectures, or
capabilities, (2) an empirical exploration of multimodal prompt perturbations
to uncover LMM uncertainty, offering insights and findings, and (3) derive the
formulation of multimodal semantic uncertainty, which enables quantifying
uncertainty from multimodal responses. Experiments across 18 benchmarks
spanning various modalities and 10 LMMs (both open- and closed-source)
demonstrate the effectiveness of Uncertainty-o in reliably estimating LMM
uncertainty, thereby enhancing downstream tasks such as hallucination
detection, hallucination mitigation, and uncertainty-aware Chain-of-Thought
reasoning.

</details>


### [573] [Super Encoding Network: Recursive Association of Multi-Modal Encoders for Video Understanding](https://arxiv.org/abs/2506.07576)
*Boyu Chen,Siran Chen,Kunchang Li,Qinglin Xu,Yu Qiao,Yali Wang*

Main category: cs.CV

TL;DR: 提出SEN网络通过递归关联多模态编码器增强视频理解，在跟踪、识别、聊天和编辑任务中显著提升性能


<details>
  <summary>Details</summary>
Motivation: 现有多模态基础模型仅通过对比学习对齐编码器，缺乏深层跨模态交互，无法理解复杂运动和多样化场景

Method: 将预训练编码器视为'超级神经元'，设计递归关联(RA)块实现知识整合/分发/提示，递归融合多模态信息

Result: 在4类视频任务中性能显著提升：跟踪任务Jaccard指数提升2.7%，TC降低8.8%；编辑任务文本对齐提升6.4%，帧一致性提高4.1%

Conclusion: SEN通过递归融合机制有效建模深层多模态交互，为视频理解提供统一框架

Abstract: Video understanding has been considered as one critical step towards world
modeling, which is an important long-term problem in AI research. Recently,
multi-modal foundation models have shown such potential via large-scale
pretraining. However, these models simply align encoders of different
modalities via contrastive learning, while lacking deeper multi-modal
interactions, which is critical for understanding complex target movements with
diversified video scenes. To fill this gap, we propose a unified Super Encoding
Network (SEN) for video understanding, which builds up such distinct
interactions through recursive association of multi-modal encoders in the
foundation models. Specifically, we creatively treat those well-trained
encoders as "super neurons" in our SEN. Via designing a Recursive Association
(RA) block, we progressively fuse multi-modalities with the input video, based
on knowledge integrating, distributing, and prompting of super neurons in a
recursive manner. In this way, our SEN can effectively encode deeper
multi-modal interactions, for prompting various video understanding tasks in
downstream. Extensive experiments show that, our SEN can remarkably boost the
four most representative video tasks, including tracking, recognition,
chatting, and editing, e.g., for pixel-level tracking, the average jaccard
index improves 2.7%, temporal coherence(TC) drops 8.8% compared to the popular
CaDeX++ approach. For one-shot video editing, textual alignment improves 6.4%,
and frame consistency increases 4.1% compared to the popular TuneA-Video
approach.

</details>


### [574] [Explore the vulnerability of black-box models via diffusion models](https://arxiv.org/abs/2506.07590)
*Jiacheng Shi,Yanfu Zhang,Huajie Shao,Ashley Gao*

Main category: cs.CV

TL;DR: 本文揭示了扩散模型API的一个新安全威胁：攻击者可生成合成图像来训练高精度替代模型，从而实现仅需极少量查询的黑盒模型提取和对抗攻击。


<details>
  <summary>Details</summary>
Motivation: 扩散模型虽能生成高质量图像，但存在安全隐私风险。研究发现攻击者能利用API生成合成图像训练替代模型，绕过原始数据需求进行高效模型窃取和对抗攻击。

Method: 通过扩散模型API生成高分辨率多样化合成图像，用于训练替代分类模型，该模型能模拟目标黑盒模型行为，支持用极少查询实现模型提取和迁移对抗攻击。

Result: 在CIFAR/ImageNet等7个基准上，本方法比SOTA平均提升27.37%，仅用0.01倍查询量，对目标模型的对抗攻击成功率高达98.68%。

Conclusion: 扩散模型API存在严重安全漏洞，恶意用户可高效窃取模型并发动对抗攻击，需开发新型防御机制应对此种威胁。

Abstract: Recent advancements in diffusion models have enabled high-fidelity and
photorealistic image generation across diverse applications. However, these
models also present security and privacy risks, including copyright violations,
sensitive information leakage, and the creation of harmful or offensive content
that could be exploited maliciously. In this study, we uncover a novel security
threat where an attacker leverages diffusion model APIs to generate synthetic
images, which are then used to train a high-performing substitute model. This
enables the attacker to execute model extraction and transfer-based adversarial
attacks on black-box classification models with minimal queries, without
needing access to the original training data. The generated images are
sufficiently high-resolution and diverse to train a substitute model whose
outputs closely match those of the target model. Across the seven benchmarks,
including CIFAR and ImageNet subsets, our method shows an average improvement
of 27.37% over state-of-the-art methods while using just 0.01 times of the
query budget, achieving a 98.68% success rate in adversarial attacks on the
target model.

</details>


### [575] [SceneRAG: Scene-level Retrieval-Augmented Generation for Video Understanding](https://arxiv.org/abs/2506.07600)
*Nianbo Zeng,Haowen Hou,Fei Richard Yu,Si Shi,Ying Tiffany He*

Main category: cs.CV

TL;DR: 提出了SceneRAG框架，通过场景感知的分块和知识图谱增强长视频理解，在LongerVideos基准上显著超越基线（最高72.5%胜率）。


<details>
  <summary>Details</summary>
Motivation: 现有RAG方法在长视频理解中采用固定分块会破坏上下文连续性，无法捕捉真实场景边界。受人类将连续体验组织为连贯场景的能力启发。

Method: 1.利用大模型处理ASR文本及时间元数据分割视频为叙事一致场景 2.通过轻量级启发式方法和迭代校正优化边界 3.融合多模态信息构建动态知识图谱以实现鲁棒多跳检索

Result: 在134小时+的LongerVideos基准测试中：大幅超越所有基线，生成任务胜率达72.5%

Conclusion: SceneRAG通过叙事驱动的场景分割和多模态图检索机制，解决了长视频理解中的连续性中断问题，为复杂长视频分析提供新范式

Abstract: Despite recent advances in retrieval-augmented generation (RAG) for video
understanding, effectively understanding long-form video content remains
underexplored due to the vast scale and high complexity of video data. Current
RAG approaches typically segment videos into fixed-length chunks, which often
disrupts the continuity of contextual information and fails to capture
authentic scene boundaries. Inspired by the human ability to naturally organize
continuous experiences into coherent scenes, we present SceneRAG, a unified
framework that leverages large language models to segment videos into
narrative-consistent scenes by processing ASR transcripts alongside temporal
metadata. SceneRAG further sharpens these initial boundaries through
lightweight heuristics and iterative correction. For each scene, the framework
fuses information from both visual and textual modalities to extract entity
relations and dynamically builds a knowledge graph, enabling robust multi-hop
retrieval and generation that account for long-range dependencies. Experiments
on the LongerVideos benchmark, featuring over 134 hours of diverse content,
confirm that SceneRAG substantially outperforms prior baselines, achieving a
win rate of up to 72.5 percent on generation tasks.

</details>


### [576] [SurgBench: A Unified Large-Scale Benchmark for Surgical Video Analysis](https://arxiv.org/abs/2506.07603)
*Jianhui Wei,Zikai Xiao,Danyu Sun,Luqi Gong,Zongxin Yang,Zuozhu Liu,Jian Wu*

Main category: cs.CV

TL;DR: 为了解决外科手术视频基础模型开发中大规模、多样化数据集匮乏的问题，作者提出了SurgBench，包含预训练数据集SurgBench-P和评估基准SurgBench-E。SurgBench覆盖广泛，预训练数据集包含超过5300万帧图像，评估基准涵盖六类72项精细任务。实验表明，现有视频基础模型在外科视频任务上泛化能力差，而使用SurgBench-P预训练能显著提升性能并增强跨域泛化能力。


<details>
  <summary>Details</summary>
Motivation: 开发外科手术视频基础模型受限于缺乏大规模多样化数据集用于预训练和系统评估，导致模型难以泛化到不同手术场景。

Method: 提出SurgBench框架，由预训练数据集SurgBench-P（53 million frames, 22种手术11个专科）和评估基准SurgBench-E（6类72项任务）组成。通过实验验证现有模型与基于SurgBench-P预训练模型的性能对比。

Result: 现有视频基础模型在多样化外科视频分析任务中泛化能力差；使用SurgBench-P预训练后性能显著提升，且对未见过的术式和模态表现出优异跨域泛化能力。

Conclusion: SurgBench提供了统一的外科视频评估框架，解决了数据集稀缺问题，其预训练数据集能有效提升模型性能并增强跨域适应性，为外科视频理解研究奠定基础。

Abstract: Surgical video understanding is pivotal for enabling automated intraoperative
decision-making, skill assessment, and postoperative quality improvement.
However, progress in developing surgical video foundation models (FMs) remains
hindered by the scarcity of large-scale, diverse datasets for pretraining and
systematic evaluation. In this paper, we introduce \textbf{SurgBench}, a
unified surgical video benchmarking framework comprising a pretraining dataset,
\textbf{SurgBench-P}, and an evaluation benchmark, \textbf{SurgBench-E}.
SurgBench offers extensive coverage of diverse surgical scenarios, with
SurgBench-P encompassing 53 million frames across 22 surgical procedures and 11
specialties, and SurgBench-E providing robust evaluation across six categories
(phase classification, camera motion, tool recognition, disease diagnosis,
action classification, and organ detection) spanning 72 fine-grained tasks.
Extensive experiments reveal that existing video FMs struggle to generalize
across varied surgical video analysis tasks, whereas pretraining on SurgBench-P
yields substantial performance improvements and superior cross-domain
generalization to unseen procedures and modalities. Our dataset and code are
available upon request.

</details>


### [577] [DragNeXt: Rethinking Drag-Based Image Editing](https://arxiv.org/abs/2506.07611)
*Yuan Zhou,Junbao Zhou,Qingshan Xu,Kesen Zhao,Yuxuan Wang,Hao Fei,Richang Hong,Hanwang Zhang*

Main category: cs.CV

TL;DR: 本文提出了一种新的拖拽式图像编辑框架DragNeXt，将拖拽编辑重新定义为用户指定区域的变形、旋转和平移，解决了现有方法中的模糊性问题和繁琐操作。


<details>
  <summary>Details</summary>
Motivation: 现有的基于拖拽的图像编辑（DBIE）存在两大问题：（i）点级拖拽的模糊性难以精准对齐用户意图；（ii）现有DBIE方法依赖运动监督与点追踪的交替流程，效率低且效果差。

Method: 1）用户需明确指定拖拽区域及类型（变形/旋转/平移）；2）提出DragNeXt框架：将DBIE统一建模为隐空间区域优化问题（LRO），通过渐进式反向自干预机制（PBSI）进行高效求解。

Result: 在自建基准NextBench上验证，实验表明DragNeXt显著超越现有方法，生成质量更高。代码将开源。

Conclusion: DragNeXt框架通过区域级结构信息和渐进优化机制，简化了DBIE流程并提升了编辑质量，有效解决了拖拽操作中的模糊性与效率问题。

Abstract: Drag-Based Image Editing (DBIE), which allows users to manipulate images by
directly dragging objects within them, has recently attracted much attention
from the community. However, it faces two key challenges:
(\emph{\textcolor{magenta}{i}}) point-based drag is often highly ambiguous and
difficult to align with users' intentions; (\emph{\textcolor{magenta}{ii}})
current DBIE methods primarily rely on alternating between motion supervision
and point tracking, which is not only cumbersome but also fails to produce
high-quality results. These limitations motivate us to explore DBIE from a new
perspective -- redefining it as deformation, rotation, and translation of
user-specified handle regions. Thereby, by requiring users to explicitly
specify both drag areas and types, we can effectively address the ambiguity
issue. Furthermore, we propose a simple-yet-effective editing framework, dubbed
\textcolor{SkyBlue}{\textbf{DragNeXt}}. It unifies DBIE as a Latent Region
Optimization (LRO) problem and solves it through Progressive Backward
Self-Intervention (PBSI), simplifying the overall procedure of DBIE while
further enhancing quality by fully leveraging region-level structure
information and progressive guidance from intermediate drag states. We validate
\textcolor{SkyBlue}{\textbf{DragNeXt}} on our NextBench, and extensive
experiments demonstrate that our proposed method can significantly outperform
existing approaches. Code will be released on github.

</details>


### [578] [Scaling Human Activity Recognition: A Comparative Evaluation of Synthetic Data Generation and Augmentation Techniques](https://arxiv.org/abs/2506.07612)
*Zikang Leng,Archith Iyer,Thomas Plötz*

Main category: cs.CV

TL;DR: 本文通过对比基于视频和基于语言的虚拟IMU生成方法以及传统数据增强技术，在大规模虚拟IMU数据集上进行实验，证明虚拟IMU数据能显著提升有限数据条件下的人体活动识别性能，并提供了不同数据生成策略的实践指导。


<details>
  <summary>Details</summary>
Motivation: 解决人类活动识别（HAR）中标记数据稀缺的问题，通过比较虚拟IMU生成方法与传统增强技术的效果差异，为实际应用提供选择依据。

Method: 构建100种活动的大规模虚拟IMU数据集（源自Kinetics-400），在22个身体位置模拟传感器信号；使用三类数据生成策略（视频/语言虚拟生成、传统增强），在三大HAR基准数据集上评估四种模型。

Result: 虚拟IMU数据显著优于纯真实数据或增强数据，在有限数据条件下提升尤其明显；不同虚拟生成方法各具优劣势。

Conclusion: 提出了虚拟IMU数据对HAR系统的价值，明确了视频/语言两代成路径的适用场景和选择标准，并开源数据集促进研究。

Abstract: Human activity recognition (HAR) is often limited by the scarcity of labeled
datasets due to the high cost and complexity of real-world data collection. To
mitigate this, recent work has explored generating virtual inertial measurement
unit (IMU) data via cross-modality transfer. While video-based and
language-based pipelines have each shown promise, they differ in assumptions
and computational cost. Moreover, their effectiveness relative to traditional
sensor-level data augmentation remains unclear. In this paper, we present a
direct comparison between these two virtual IMU generation approaches against
classical data augmentation techniques. We construct a large-scale virtual IMU
dataset spanning 100 diverse activities from Kinetics-400 and simulate sensor
signals at 22 body locations. The three data generation strategies are
evaluated on benchmark HAR datasets (UTD-MHAD, PAMAP2, HAD-AW) using four
popular models. Results show that virtual IMU data significantly improves
performance over real or augmented data alone, particularly under limited-data
conditions. We offer practical guidance on choosing data generation strategies
and highlight the distinct advantages and disadvantages of each approach.

</details>


### [579] [Event-Priori-Based Vision-Language Model for Efficient Visual Understanding](https://arxiv.org/abs/2506.07627)
*Haotong Qin,Cheng Hu,Michele Magno*

Main category: cs.CV

TL;DR: EP-VLM：基于事件先验的视觉语言模型，利用动态事件视觉引导RGB输入稀疏化，在保持精度前提下显著提升计算效率。在Qwen2-VL-2B模型上实现50% FLOPs节省，精度保留98%。


<details>
  <summary>Details</summary>
Motivation: 大型视觉语言模型(VLMs)计算密集，资源受限设备难以部署；视觉输入存在冗余区域，导致无效计算。模拟人类视觉认知，利用事件视觉数据指导计算资源集中于显著区域。

Method: 1. 事件数据引导的视觉输入稀疏化：基于动态事件数据逐步聚焦VLM计算于显著区域
2. 位置保持的标记化策略：处理事件引导的稀疏输入时精确保留位置信息

Result: 与Qwen2-VL系列基线对比：
- 实现50% FLOPs节省（在Qwen2-VL-2B上）
- 精度保持98%（RealWorldQA数据集）
- 效率显著提升同时保持接近无损准确性

Conclusion: 事件视觉先验可有效提升VLM推理效率，为实现可持续的边缘视觉理解铺平道路；为开发更高效、可部署的VLM提供新范式。

Abstract: Large Language Model (LLM)-based Vision-Language Models (VLMs) have
substantially extended the boundaries of visual understanding capabilities.
However, their high computational demands hinder deployment on
resource-constrained edge devices. A key source of inefficiency stems from the
VLM's need to process dense and redundant visual information. Visual inputs
contain significant regions irrelevant to text semantics, rendering the
associated computations ineffective for inference. This paper introduces a
novel Event-Priori-Based Vision-Language Model, termed EP-VLM. Its core
contribution is a novel mechanism leveraging motion priors derived from dynamic
event vision to enhance VLM efficiency. Inspired by human visual cognition,
EP-VLM first employs event data to guide the patch-wise sparsification of RGB
visual inputs, progressively concentrating VLM computation on salient regions
of the visual input. Subsequently, we construct a position-preserving
tokenization strategy for the visual encoder within the VLM architecture. This
strategy processes the event-guided, unstructured, sparse visual input while
accurately preserving positional understanding within the visual input.
Experimental results demonstrate that EP-VLM achieves significant efficiency
improvements while maintaining nearly lossless accuracy compared to baseline
models from the Qwen2-VL series. For instance, against the original
Qwen2-VL-2B, EP-VLM achieves 50% FLOPs savings while retaining 98% of the
original accuracy on the RealWorldQA dataset. This work demonstrates the
potential of event-based vision priors for improving VLM inference efficiency,
paving the way for creating more efficient and deployable VLMs for sustainable
visual understanding at the edge.

</details>


### [580] [HuSc3D: Human Sculpture dataset for 3D object reconstruction](https://arxiv.org/abs/2506.07628)
*Weronika Smolak-Dyżewska,Dawid Malarz,Grzegorz Wilczyński,Rafał Tobiasz,Joanna Waczyńska,Piotr Borycki,Przemysław Spurek*

Main category: cs.CV

TL;DR: HuSc3D 是一个新颖的3D重建数据集，专注于真实采集挑战（如动态背景、白平衡差异、低纹理场景和有限训练数据），通过六个白色雕塑场景评估模型对几何细节和颜色模糊的敏感性。


<details>
  <summary>Details</summary>
Motivation: 现有3D重建数据集使用理想化合成或精细捕捉的真实数据，无法反映新采集真实场景（尤其是户外）的动态背景、白平衡差异等复杂性问题。

Method: 提出 HuSc3D 数据集，包含六个高度细节化的全白雕塑场景，具有复杂穿孔结构和低纹理/颜色变化特征，且每场景图像数量差异显著（模拟数据有限情况）。

Result: 在 HuSc3D 上测试主流3D重建方法，显示该数据集能有效区分模型性能，尤其暴露模型对几何细节、颜色模糊和数据量变化的敏感性——这些弱点被传统数据集掩盖。

Conclusion: HuSc3D 填补了真实采集场景3D重建评估的空白，其设计的多样性（结构复杂性、颜色单一性、数据不均衡性）为模型鲁棒性提供了严格测试基准。

Abstract: 3D scene reconstruction from 2D images is one of the most important tasks in
computer graphics. Unfortunately, existing datasets and benchmarks concentrate
on idealized synthetic or meticulously captured realistic data. Such benchmarks
fail to convey the inherent complexities encountered in newly acquired
real-world scenes. In such scenes especially those acquired outside, the
background is often dynamic, and by popular usage of cell phone cameras, there
might be discrepancies in, e.g., white balance. To address this gap, we present
HuSc3D, a novel dataset specifically designed for rigorous benchmarking of 3D
reconstruction models under realistic acquisition challenges. Our dataset
uniquely features six highly detailed, fully white sculptures characterized by
intricate perforations and minimal textural and color variation. Furthermore,
the number of images per scene varies significantly, introducing the additional
challenge of limited training data for some instances alongside scenes with a
standard number of views. By evaluating popular 3D reconstruction methods on
this diverse dataset, we demonstrate the distinctiveness of HuSc3D in
effectively differentiating model performance, particularly highlighting the
sensitivity of methods to fine geometric details, color ambiguity, and varying
data availability--limitations often masked by more conventional datasets.

</details>


### [581] [HieraEdgeNet: A Multi-Scale Edge-Enhanced Framework for Automated Pollen Recognition](https://arxiv.org/abs/2506.07637)
*Yuchong Long,Wen Sun,Ningxiao Sun,Wenxiao Wang,Chao Li,Shan Yin*

Main category: cs.CV

TL;DR: 提出了多尺度边缘增强框架HieraEdgeNet解决自动化花粉识别难题。


<details>
  <summary>Details</summary>
Motivation: 因为传统方法效率低且主观性强，而现有深度学习模型对微小目标（如花粉）的定位精度不足。

Method: 包含三个模块：分层边缘模块（HEM）提取多尺度边缘特征、协同边缘融合模块（SEF）融合边缘与语义信息、跨阶段全局核模块（CSPOKM）使用全局核优化细节特征层。

Result: 在120类花粉数据集上实现mAP@.5为0.9501，显著超越YOLOv12n等基线模型。

Conclusion: 通过系统性整合边缘信息，HieraEdgeNet为微小物体高精度检测提供了强力解决方案。

Abstract: Automated pollen recognition is vital to paleoclimatology, biodiversity
monitoring, and public health, yet conventional methods are hampered by
inefficiency and subjectivity. Existing deep learning models often struggle to
achieve the requisite localization accuracy for microscopic targets like
pollen, which are characterized by their minute size, indistinct edges, and
complex backgrounds. To overcome this limitation, we introduce HieraEdgeNet, a
multi-scale edge-enhancement framework. The framework's core innovation is the
introduction of three synergistic modules: the Hierarchical Edge Module (HEM),
which explicitly extracts a multi-scale pyramid of edge features that
corresponds to the semantic hierarchy at early network stages; the Synergistic
Edge Fusion (SEF) module, for deeply fusing these edge priors with semantic
information at each respective scale; and the Cross Stage Partial Omni-Kernel
Module (CSPOKM), which maximally refines the most detail-rich feature layers
using an Omni-Kernel operator - comprising anisotropic large-kernel
convolutions and mixed-domain attention - all within a computationally
efficient Cross-Stage Partial (CSP) framework. On a large-scale dataset
comprising 120 pollen classes, HieraEdgeNet achieves a mean Average Precision
(mAP@.5) of 0.9501, significantly outperforming state-of-the-art baseline
models such as YOLOv12n and RT-DETR. Furthermore, qualitative analysis confirms
that our approach generates feature representations that are more precisely
focused on object boundaries. By systematically integrating edge information,
HieraEdgeNet provides a robust and powerful solution for high-precision,
high-efficiency automated detection of microscopic objects.

</details>


### [582] [Synthetic Visual Genome](https://arxiv.org/abs/2506.07643)
*Jae Sung Park,Zixian Ma,Linjie Li,Chenhao Zheng,Cheng-Yu Hsieh,Ximing Lu,Khyathi Chandu,Quan Kong,Norimasa Kobori,Ali Farhadi,Yejin Choi,Ranjay Krishna*

Main category: cs.CV

TL;DR: 介绍ROBIN：一款可构建高质量密集场景图的MLM；创建SVG合成数据集；提出SG-EDIT自蒸馏框架；训练出的3B小模型在多项任务上超越大10～100倍模型


<details>
  <summary>Details</summary>
Motivation: 解决现有MLM在视觉关系推理中存在的问题：对空间/功能/交互/社会等关系的精细推理不足

Method: 1. 创建SVG合成数据集：用教师MLM补全现有场景图的缺失关系，经筛选保留高质量数据 2. SG-EDIT自蒸馏框架：GPT-4o优化ROBIN生成的场景图

Result: 1. 数据：146K图像/560万关系/260万物体；2. ROBIN-3B模型在关系理解任务超越300M数据训练的同类模型; 3.REC任务达SOTA(88.9vs87.4)

Conclusion: 证明基于精炼场景图数据训练对提升视觉推理任务至关重要，小模型可超越更大模型

Abstract: Reasoning over visual relationships-spatial, functional, interactional,
social, etc.-is considered to be a fundamental component of human cognition.
Yet, despite the major advances in visual comprehension in multimodal language
models (MLMs), precise reasoning over relationships and their generations
remains a challenge. We introduce ROBIN: an MLM instruction-tuned with densely
annotated relationships capable of constructing high-quality dense scene graphs
at scale. To train ROBIN, we curate SVG, a synthetic scene graph dataset by
completing the missing relations of selected objects in existing scene graphs
using a teacher MLM and a carefully designed filtering process to ensure
high-quality. To generate more accurate and rich scene graphs at scale for any
image, we introduce SG-EDIT: a self-distillation framework where GPT-4o further
refines ROBIN's predicted scene graphs by removing unlikely relations and/or
suggesting relevant ones. In total, our dataset contains 146K images and 5.6M
relationships for 2.6M objects. Results show that our ROBIN-3B model, despite
being trained on less than 3 million instances, outperforms similar-size models
trained on over 300 million instances on relationship understanding benchmarks,
and even surpasses larger models up to 13B parameters. Notably, it achieves
state-of-the-art performance in referring expression comprehension with a score
of 88.9, surpassing the previous best of 87.4. Our results suggest that
training on the refined scene graph data is crucial to maintaining high
performance across diverse visual reasoning task.

</details>


### [583] [FMaMIL: Frequency-Driven Mamba Multi-Instance Learning for Weakly Supervised Lesion Segmentation in Medical Images](https://arxiv.org/abs/2506.07652)
*Hangbei Cheng,Xiaorong Dong,Xueyu Liu,Jianan Zhang,Xuetao Ma,Mingqiang Wei,Liansheng Wang,Junxin Chen,Yongfei Wu*

Main category: cs.CV

TL;DR: FMaMIL是新颖的两阶段弱监督病灶分割框架，仅使用图像级标签，通过Mamba编码器捕获远程依赖和学习型频域模块增强结构感知，第二阶段通过软标签监督和自校正机制优化伪标签，在多个数据集中表现超越现有方法。


<details>
  <summary>Details</summary>
Motivation: 在组织病理学图像中，精确的病灶分割对诊断至关重要，但像素级标注成本高昂且稀少，因此需要仅用图像级标签的弱监督解决方案来降低标注负担。

Method: 1) 第一阶段: 引入基于Mamba的轻量编码器在MIL范式下捕捉图像块间长程依赖；设计可学习频域编码模块补充空间特征，增强结构感知，生成类激活图(CAM)指导分割。2) 第二阶段: 通过CAM引导的软标签监督和自校正机制优化初始伪标签，提升噪声标签下的鲁棒性。

Result: 在公共和私有组织病理学数据集上的实验表明，FMaMIL超越现有弱监督方法，无需像素级标注，验证了其在数字病理应用中的有效性和潜力。

Conclusion: FMaMIL框架成功降低了标注成本，通过两阶段设计和频域增强实现了高性能弱监督分割，为数字病理提供了实用解决方案。

Abstract: Accurate lesion segmentation in histopathology images is essential for
diagnostic interpretation and quantitative analysis, yet it remains challenging
due to the limited availability of costly pixel-level annotations. To address
this, we propose FMaMIL, a novel two-stage framework for weakly supervised
lesion segmentation based solely on image-level labels. In the first stage, a
lightweight Mamba-based encoder is introduced to capture long-range
dependencies across image patches under the MIL paradigm. To enhance spatial
sensitivity and structural awareness, we design a learnable frequency-domain
encoding module that supplements spatial-domain features with spectrum-based
information. CAMs generated in this stage are used to guide segmentation
training. In the second stage, we refine the initial pseudo labels via a
CAM-guided soft-label supervision and a self-correction mechanism, enabling
robust training even under label noise. Extensive experiments on both public
and private histopathology datasets demonstrate that FMaMIL outperforms
state-of-the-art weakly supervised methods without relying on pixel-level
annotations, validating its effectiveness and potential for digital pathology
applications.

</details>


### [584] [ProSplat: Improved Feed-Forward 3D Gaussian Splatting for Wide-Baseline Sparse Views](https://arxiv.org/abs/2506.07670)
*Xiaohan Lu,Jiaye Fu,Jiaqi Zhang,Zetian Song,Chuanmin Jia,Siwei Ma*

Main category: cs.CV

TL;DR: 这篇论文提出ProSplat模型，用于增强3DGS在宽基线设置下的新视角合成，通过两阶段前馈结构和优化的一步扩散模型解决视角重叠不足和几何不一致问题，显著提升渲染质量。


<details>
  <summary>Details</summary>
Motivation: 现有3DGS方法在宽基线条件下因纹理细节缺失和视图间几何不一致导致渲染质量明显下降，需开发高保真渲染方案。

Method: (1)第一阶段生成3D高斯图元；(2)第二阶段通过包含MORI和DWEA模块的优化扩散模型增强渲染视图；(3)采用分治法联合优化两阶段数据分布。

Result: 在RealEstate10K和DL3DV数据集上测试结果显示：ProSplat比SOTA方法平均PSNR提升1dB，特别是在宽基线场景下效果显著。

Conclusion: ProSplat通过两阶段框架和几何约束的注意力机制有效克服了宽基线渲染挑战，同时MORI和DWEA模块是关键创新点。

Abstract: Feed-forward 3D Gaussian Splatting (3DGS) has recently demonstrated promising
results for novel view synthesis (NVS) from sparse input views, particularly
under narrow-baseline conditions. However, its performance significantly
degrades in wide-baseline scenarios due to limited texture details and
geometric inconsistencies across views. To address these challenges, in this
paper, we propose ProSplat, a two-stage feed-forward framework designed for
high-fidelity rendering under wide-baseline conditions. The first stage
involves generating 3D Gaussian primitives via a 3DGS generator. In the second
stage, rendered views from these primitives are enhanced through an improvement
model. Specifically, this improvement model is based on a one-step diffusion
model, further optimized by our proposed Maximum Overlap Reference view
Injection (MORI) and Distance-Weighted Epipolar Attention (DWEA). MORI
supplements missing texture and color by strategically selecting a reference
view with maximum viewpoint overlap, while DWEA enforces geometric consistency
using epipolar constraints. Additionally, we introduce a divide-and-conquer
training strategy that aligns data distributions between the two stages through
joint optimization. We evaluate ProSplat on the RealEstate10K and DL3DV-10K
datasets under wide-baseline settings. Experimental results demonstrate that
ProSplat achieves an average improvement of 1 dB in PSNR compared to recent
SOTA methods.

</details>


### [585] [OpenSplat3D: Open-Vocabulary 3D Instance Segmentation using Gaussian Splatting](https://arxiv.org/abs/2506.07697)
*Jens Piekenbrinck,Christian Schmidt,Alexander Hermans,Narunas Vaskevicius,Timm Linder,Bastian Leibe*

Main category: cs.CV

TL;DR: 提出OpenSplat3D方法，在3D高斯点云表示（3DGS）基础上实现无需人工标注的开放词汇3D实例分割，通过特征投射技术结合SAM分割掩码和视觉语言模型，实现基于自然语言的实例分割。


<details>
  <summary>Details</summary>
Motivation: 3DGS虽能高效重建场景，但缺乏语义理解能力。目标扩展3DGS的能力，实现无需手动标注的开放词汇3D实例分割，提升场景理解能力。

Method: 1. 使用特征投射关联语义与高斯点；2. 引入SAM实例掩码+对比损失优化实例特征；3. 集成视觉语言模型的文本嵌入，实现文本驱动的实例识别。

Result: 在LERF-mask、LERF-OVS和ScanNet++验证集上验证了有效性，实现基于自然语言描述的3D物体分割。

Conclusion: OpenSplat3D首次在3DGS框架中实现开放词汇实例分割，为3D场景理解提供新解决方案。

Abstract: 3D Gaussian Splatting (3DGS) has emerged as a powerful representation for
neural scene reconstruction, offering high-quality novel view synthesis while
maintaining computational efficiency. In this paper, we extend the capabilities
of 3DGS beyond pure scene representation by introducing an approach for
open-vocabulary 3D instance segmentation without requiring manual labeling,
termed OpenSplat3D. Our method leverages feature-splatting techniques to
associate semantic information with individual Gaussians, enabling fine-grained
scene understanding. We incorporate Segment Anything Model instance masks with
a contrastive loss formulation as guidance for the instance features to achieve
accurate instance-level segmentation. Furthermore, we utilize language
embeddings of a vision-language model, allowing for flexible, text-driven
instance identification. This combination enables our system to identify and
segment arbitrary objects in 3D scenes based on natural language descriptions.
We show results on LERF-mask and LERF-OVS as well as the full ScanNet++
validation set, demonstrating the effectiveness of our approach.

</details>


### [586] [NOVA3D: Normal Aligned Video Diffusion Model for Single Image to 3D Generation](https://arxiv.org/abs/2506.07698)
*Yuxiao Yang,Peihao Li,Yuhong Zhang,Junzhe Lu,Xianglong He,Minghan Qin,Weitao Wang,Haoqian Wang*

Main category: cs.CV

TL;DR: 论文提出了一种名为NOVA3D的新框架，旨在从单张图像生成高质量3D内容，通过利用视频扩散模型的3D先验和一种创新的几何-时序对齐注意力机制以及去冲突融合算法


<details>
  <summary>Details</summary>
Motivation: 当前基于分数蒸馏采样的3D生成方法存在多视角不一致的问题，需要更强的3D先验和几何整合

Method: 使用预训练视频扩散模型提取3D先验；提出几何-时序对齐注意机制；开发去冲突几何融合算法

Result: 通过广泛实验证明，NOVA3D优于现有基线方法

Conclusion: NOVA3D有效解决了以前单图转3D方法中的多视角一致性问题，同时提高了纹理保真度

Abstract: 3D AI-generated content (AIGC) has made it increasingly accessible for anyone
to become a 3D content creator. While recent methods leverage Score
Distillation Sampling to distill 3D objects from pretrained image diffusion
models, they often suffer from inadequate 3D priors, leading to insufficient
multi-view consistency. In this work, we introduce NOVA3D, an innovative
single-image-to-3D generation framework. Our key insight lies in leveraging
strong 3D priors from a pretrained video diffusion model and integrating
geometric information during multi-view video fine-tuning. To facilitate
information exchange between color and geometric domains, we propose the
Geometry-Temporal Alignment (GTA) attention mechanism, thereby improving
generalization and multi-view consistency. Moreover, we introduce the
de-conflict geometry fusion algorithm, which improves texture fidelity by
addressing multi-view inaccuracies and resolving discrepancies in pose
alignment. Extensive experiments validate the superiority of NOVA3D over
existing baselines.

</details>


### [587] [Adaptive Blind Super-Resolution Network for Spatial-Specific and Spatial-Agnostic Degradations](https://arxiv.org/abs/2506.07705)
*Weilei Wen,Chunle Guo,Wenqi Ren,Hongpeng Wang,Xiuli Shao*

Main category: cs.CV

TL;DR: 该论文提出一种动态滤波网络，通过全局和局部分支处理空间无关主导退化和空间特定主导退化，超越现有盲超分算法。


<details>
  <summary>Details</summary>
Motivation: 现有方法忽视不同退化类型的多样性，统一处理多种退化。本文发现主流退化可分为两类：空间无关主导退化（如下采样和噪声）和空间特定主导退化（如模糊）。

Method: 构建动态滤波网络：1) 全局分支通过注意力机制生成权重，处理空间无关退化；2) 局部分支生成空间特定滤波算子处理空间相关退化。

Result: 在合成和真实图像数据集上均优于当前最先进的盲超分辨率算法。

Conclusion: 分类处理两类退化可显著提升图像重建质量，所提动态滤波器整合方法有效解决实际退化问题。

Abstract: Prior methodologies have disregarded the diversities among distinct
degradation types during image reconstruction, employing a uniform network
model to handle multiple deteriorations. Nevertheless, we discover that
prevalent degradation modalities, including sampling, blurring, and noise, can
be roughly categorized into two classes. We classify the first class as
spatial-agnostic dominant degradations, less affected by regional changes in
image space, such as downsampling and noise degradation. The second class
degradation type is intimately associated with the spatial position of the
image, such as blurring, and we identify them as spatial-specific dominant
degradations. We introduce a dynamic filter network integrating global and
local branches to address these two degradation types. This network can greatly
alleviate the practical degradation problem. Specifically, the global dynamic
filtering layer can perceive the spatial-agnostic dominant degradation in
different images by applying weights generated by the attention mechanism to
multiple parallel standard convolution kernels, enhancing the network's
representation ability. Meanwhile, the local dynamic filtering layer converts
feature maps of the image into a spatially specific dynamic filtering operator,
which performs spatially specific convolution operations on the image features
to handle spatial-specific dominant degradations. By effectively integrating
both global and local dynamic filtering operators, our proposed method
outperforms state-of-the-art blind super-resolution algorithms in both
synthetic and real image datasets.

</details>


### [588] [Consistent Video Editing as Flow-Driven Image-to-Video Generation](https://arxiv.org/abs/2506.07713)
*Ge Wang,Songlin Fan,Hangxu Liu,Quanjian Song,Hewei Wang,Jinfeng Xu*

Main category: cs.CV

TL;DR: 介绍了FlowV2V模型，它使用光流驱动进行视频编辑，通过分解为第一帧编辑和条件图像到视频生成来解决运动转移和形状变形问题，并在实验中优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有视频编辑方法无法处理复杂运动模式（如多目标和肖像编辑），且仅限于对象替换。光流在复杂运动建模中表现出潜力，因此被引入来解决运动转移中的形状变形和时间一致性问题。

Method: 提出FlowV2V框架：1. 将流程分解为第一帧编辑和条件图像到视频(I2V)生成；2. 模拟与变形形状对齐的伪光流序列以保证编辑一致性。使用光流驱动而非传统替换方式。

Result: 在DAVIS-EDIT数据集上，DOVER指标提升13.67%，扭曲误差降低50.66%，表现优异。消融实验证实第一帧编辑模式和光流对齐机制的有效性。

Conclusion: FlowV2V证明了光流驱动方法在复杂视频编辑任务中的有效性，为超越对象替换的编辑任务（如肖像编辑）提供了新思路。

Abstract: With the prosper of video diffusion models, down-stream applications like
video editing have been significantly promoted without consuming much
computational cost. One particular challenge in this task lies at the motion
transfer process from the source video to the edited one, where it requires the
consideration of the shape deformation in between, meanwhile maintaining the
temporal consistency in the generated video sequence. However, existing methods
fail to model complicated motion patterns for video editing, and are
fundamentally limited to object replacement, where tasks with non-rigid object
motions like multi-object and portrait editing are largely neglected. In this
paper, we observe that optical flows offer a promising alternative in complex
motion modeling, and present FlowV2V to re-investigate video editing as a task
of flow-driven Image-to-Video (I2V) generation. Specifically, FlowV2V
decomposes the entire pipeline into first-frame editing and conditional I2V
generation, and simulates pseudo flow sequence that aligns with the deformed
shape, thus ensuring the consistency during editing. Experimental results on
DAVIS-EDIT with improvements of 13.67% and 50.66% on DOVER and warping error
illustrate the superior temporal consistency and sample quality of FlowV2V
compared to existing state-of-the-art ones. Furthermore, we conduct
comprehensive ablation studies to analyze the internal functionalities of the
first-frame paradigm and flow alignment in the proposed method.

</details>


### [589] [ReverB-SNN: Reversing Bit of the Weight and Activation for Spiking Neural Networks](https://arxiv.org/abs/2506.07720)
*Yufei Guo,Yuhan Zhang,Zhou Jie,Xiaode Liu,Xin Tong,Yuanpei Chen,Weihang Peng,Zhe Ma*

Main category: cs.CV

TL;DR: 该论文提出了一种称为ReverB-SNN的新方法，通过在SNN中使用实值脉冲激活和二元权重，结合可训练因子和重参数化技术，在保持计算效率的同时提高了精度。


<details>
  <summary>Details</summary>
Motivation: 解决SNN中因二进制脉冲激活信息不足导致的精度下降问题。方法灵感来源于量化激活比量化权重对精度影响更大的发现。

Method: 提出ReverB-SNN：1)采用实值脉冲激活替代二元激活保留信息，二元权重保持乘法计算优化；2)引入可训练因子增强二元权重表达能力；3)推理时通过重参数化恢复原始形式保证效率。

Result: 在静态和动态数据集上的大量实验表明，该方法在多种网络架构下均优于现有SNN方法。

Conclusion: ReverB-SNN在保持SNN高效计算特性的同时，有效提升了激活信息承载能力，并通过自适应调整机制显著提高了模型性能。

Abstract: The Spiking Neural Network (SNN), a biologically inspired neural network
infrastructure, has garnered significant attention recently. SNNs utilize
binary spike activations for efficient information transmission, replacing
multiplications with additions, thereby enhancing energy efficiency. However,
binary spike activation maps often fail to capture sufficient data information,
resulting in reduced accuracy. To address this challenge, we advocate reversing
the bit of the weight and activation for SNNs, called \textbf{ReverB-SNN},
inspired by recent findings that highlight greater accuracy degradation from
quantizing activations compared to weights. Specifically, our method employs
real-valued spike activations alongside binary weights in SNNs. This preserves
the event-driven and multiplication-free advantages of standard SNNs while
enhancing the information capacity of activations. Additionally, we introduce a
trainable factor within binary weights to adaptively learn suitable weight
amplitudes during training, thereby increasing network capacity. To maintain
efficiency akin to vanilla \textbf{ReverB-SNN}, our trainable binary weight
SNNs are converted back to standard form using a re-parameterization technique
during inference. Extensive experiments across various network architectures
and datasets, both static and dynamic, demonstrate that our approach
consistently outperforms state-of-the-art methods.

</details>


### [590] [ETA: Efficiency through Thinking Ahead, A Dual Approach to Self-Driving with Large Models](https://arxiv.org/abs/2506.07725)
*Shadi Hamdan,Chonghao Sima,Zetong Yang,Hongyang Li,Fatma Güney*

Main category: cs.CV

TL;DR: 论文提出ETA（提前思考实现效率）系统，解决自动驾驶中大型模型推断延迟问题。通过异步系统将计算前移到先前帧、批量推断预测未来特征，结合小型实时模型特征，利用动作掩码机制提升效率。在CARLA评测达到69.53分（提升8%），保持50ms推断速度。


<details>
  <summary>Details</summary>
Motivation: 自动驾驶系统需平衡大型模型的信息优势与实时性能需求。现有双系统并行架构无法及时响应每一帧，因大型模型推断耗时影响实时性。

Method: ETA系统采用异步架构：【1】利用大型模型前瞻性预测传播历史特征到当前帧；【2】小型模型实时提取当前特征；【3】动作掩码机制融合双特征，关注关键区域。计算负载前移至先前帧，批处理实现高效推断。

Result: 在Bench2Drive CARLA Leaderboard-v2上获得69.53驾驶分数（刷新纪录+8%），推断速度50ms（接近实时）。

Conclusion: ETA通过异步任务卸载与前瞻性计算解决大型模型延迟问题，证明在保持实时性下显著提升自动驾驶性能。双系统特征融合策略有效平衡信息深度与响应速度。

Abstract: How can we benefit from large models without sacrificing inference speed, a
common dilemma in self-driving systems? A prevalent solution is a dual-system
architecture, employing a small model for rapid, reactive decisions and a
larger model for slower but more informative analyses. Existing dual-system
designs often implement parallel architectures where inference is either
directly conducted using the large model at each current frame or retrieved
from previously stored inference results. However, these works still struggle
to enable large models for a timely response to every online frame. Our key
insight is to shift intensive computations of the current frame to previous
time steps and perform a batch inference of multiple time steps to make large
models respond promptly to each time step. To achieve the shifting, we
introduce Efficiency through Thinking Ahead (ETA), an asynchronous system
designed to: (1) propagate informative features from the past to the current
frame using future predictions from the large model, (2) extract current frame
features using a small model for real-time responsiveness, and (3) integrate
these dual features via an action mask mechanism that emphasizes
action-critical image regions. Evaluated on the Bench2Drive CARLA
Leaderboard-v2 benchmark, ETA advances state-of-the-art performance by 8% with
a driving score of 69.53 while maintaining a near-real-time inference speed at
50 ms.

</details>


### [591] [SpikeSMOKE: Spiking Neural Networks for Monocular 3D Object Detection with Cross-Scale Gated Coding](https://arxiv.org/abs/2506.07737)
*Xuemei Chen,Huamin Wang,Hangchi Shen,Shukai Duan,Shiping Wen,Tingwen Huang*

Main category: cs.CV

TL;DR: 论文提出了SpikeSMOKE架构，一种基于脉冲神经网络(SNN)的低功耗单目3D目标检测方法。通过跨尺度门控编码机制(CSGC)增强特征表示，并设计轻量残差块来减少计算量。在KITTI数据集上性能提升显著，同时大幅降低能耗(最高减少72.2%)，参数和计算量分别减少3倍和10倍。


<details>
  <summary>Details</summary>
Motivation: 传统3D目标检测在自动驾驶等领域能耗高，而SNN具有低功耗特性但存在信息损失问题。研究旨在解决SNN特征表达能力不足和计算效率问题，实现高性能低功耗检测。

Method: 1. 提出SpikeSMOKE基础架构；2. 设计跨尺度门控编码机制(CSGC)，融合注意力方法与门控过滤增强特征；3. 构建轻量残差块保持脉冲计算范式，减少训练计算量。

Result: 在KITTI数据集AP|R11指标上：Easy类增加2.82达11.78，Moderate类增加3.2达10.69，Hard类增加3.17达10.48。能耗较SMOKE降低72.2%(仅牺牲4%性能)，轻量版参数减少3倍，计算量减少10倍。

Conclusion: SpikeSMOKE首次实现低功耗单目3D目标检测，CSGC有效提升SNN特征表达能力，轻量化设计显著降低资源消耗，为嵌入式部署提供高效解决方案。

Abstract: Low energy consumption for 3D object detection is an important research area
because of the increasing energy consumption with their wide application in
fields such as autonomous driving. The spiking neural networks (SNNs) with
low-power consumption characteristics can provide a novel solution for this
research. Therefore, we apply SNNs to monocular 3D object detection and propose
the SpikeSMOKE architecture in this paper, which is a new attempt for low-power
monocular 3D object detection. As we all know, discrete signals of SNNs will
generate information loss and limit their feature expression ability compared
with the artificial neural networks (ANNs).In order to address this issue,
inspired by the filtering mechanism of biological neuronal synapses, we propose
a cross-scale gated coding mechanism(CSGC), which can enhance feature
representation by combining cross-scale fusion of attentional methods and gated
filtering mechanisms.In addition, to reduce the computation and increase the
speed of training, we present a novel light-weight residual block that can
maintain spiking computing paradigm and the highest possible detection
performance. Compared to the baseline SpikeSMOKE under the 3D Object Detection,
the proposed SpikeSMOKE with CSGC can achieve 11.78 (+2.82, Easy), 10.69 (+3.2,
Moderate), and 10.48 (+3.17, Hard) on the KITTI autonomous driving dataset by
AP|R11 at 0.7 IoU threshold, respectively. It is important to note that the
results of SpikeSMOKE can significantly reduce energy consumption compared to
the results on SMOKE. For example,the energy consumption can be reduced by
72.2% on the hard category, while the detection performance is reduced by only
4%. SpikeSMOKE-L (lightweight) can further reduce the amount of parameters by 3
times and computation by 10 times compared to SMOKE.

</details>


### [592] [AssetDropper: Asset Extraction via Diffusion Models with Reward-Driven Optimization](https://arxiv.org/abs/2506.07738)
*Lanjiong Li,Guanhua Zhao,Lingting Zhu,Zeyu Cai,Lequan Yu,Jian Zhang,Zeyu Wang*

Main category: cs.CV

TL;DR: AssetDropper是一种从参考图像中提取标准化资产的框架，首个为设计师提供开放世界资产库的解决方案，通过奖励模型优化解决视角扭曲和遮挡问题.


<details>
  <summary>Details</summary>
Motivation: 当前生成模型集中在视觉输出创作，但设计师更依赖标准化资产库。开放世界场景虽提供素材，高效提取高质量标准化资产仍具挑战.

Method: 1) 构建含20万+合成图像对和真实基准的数据集 2) 采用预训练奖励模型闭环反馈机制：通过反向粘贴资产任务确保提取准确性 3) 对抗视角失真和遮挡.

Result: 在奖励优化驱动下实现最先进的资产提取效果，精准对齐提示并减少幻觉.

Conclusion: AssetDropper为解决生成模型在标准化资产提取领域的空白提供了首个可行框架，数据集和反馈机制为下游任务奠定基础.

Abstract: Recent research on generative models has primarily focused on creating
product-ready visual outputs; however, designers often favor access to
standardized asset libraries, a domain that has yet to be significantly
enhanced by generative capabilities. Although open-world scenes provide ample
raw materials for designers, efficiently extracting high-quality, standardized
assets remains a challenge. To address this, we introduce AssetDropper, the
first framework designed to extract assets from reference images, providing
artists with an open-world asset palette. Our model adeptly extracts a front
view of selected subjects from input images, effectively handling complex
scenarios such as perspective distortion and subject occlusion. We establish a
synthetic dataset of more than 200,000 image-subject pairs and a real-world
benchmark with thousands more for evaluation, facilitating the exploration of
future research in downstream tasks. Furthermore, to ensure precise asset
extraction that aligns well with the image prompts, we employ a pre-trained
reward model to fulfill a closed-loop with feedback. We design the reward model
to perform an inverse task that pastes the extracted assets back into the
reference sources, which assists training with additional consistency and
mitigates hallucination. Extensive experiments show that, with the aid of
reward-driven optimization, AssetDropper achieves the state-of-the-art results
in asset extraction. Project page: AssetDropper.github.io.

</details>


### [593] [ArchiLense: A Framework for Quantitative Analysis of Architectural Styles Based on Vision Large Language Models](https://arxiv.org/abs/2506.07739)
*Jing Zhong,Jun Yin,Peilin Li,Pengyu Zeng,Miao Zhang,Shuai Lu,Ran Luo*

Main category: cs.CV

TL;DR: 研究提出了一个建筑风格数据集ArchDiffBench和一个基于视觉语言模型的框架ArchiLense，用于自动分析建筑图像的风格特征，克服了传统方法的主观性和地域限制，并在评测中取得了高一致性率和分类准确率。


<details>
  <summary>Details</summary>
Motivation: 传统建筑文化研究依赖主观专家解读和历史文献，存在地域偏见和解释范围有限的问题，需要更客观、自动化的分析方法。

Method: （1）构建包含1,765张高质量建筑图像的专业数据集ArchDiffBench；（2）基于该数据集开发ArchiLense框架，整合计算机视觉、深度学习和机器学习算法，实现建筑图像的自动识别、比较和分类；（3）通过描述性语言输出风格差异。

Result: ArchiLense在风格识别任务中达到92.4%的专家标注一致性率和84.5%的分类准确率，有效捕捉跨图像风格差异。

Conclusion: 该方法超越了传统分析的主观性，为建筑文化比较研究提供了更客观准确的视角，验证了计算机视觉技术在辅助文化遗产研究中的有效性。

Abstract: Architectural cultures across regions are characterized by stylistic
diversity, shaped by historical, social, and technological contexts in addition
to geograph-ical conditions. Understanding architectural styles requires the
ability to describe and analyze the stylistic features of different architects
from various regions through visual observations of architectural imagery.
However, traditional studies of architectural culture have largely relied on
subjective expert interpretations and historical literature reviews, often
suffering from regional biases and limited ex-planatory scope. To address these
challenges, this study proposes three core contributions: (1) We construct a
professional architectural style dataset named ArchDiffBench, which comprises
1,765 high-quality architectural images and their corresponding style
annotations, collected from different regions and historical periods. (2) We
propose ArchiLense, an analytical framework grounded in Vision-Language Models
and constructed using the ArchDiffBench dataset. By integrating ad-vanced
computer vision techniques, deep learning, and machine learning algo-rithms,
ArchiLense enables automatic recognition, comparison, and precise
classi-fication of architectural imagery, producing descriptive language
outputs that ar-ticulate stylistic differences. (3) Extensive evaluations show
that ArchiLense achieves strong performance in architectural style recognition,
with a 92.4% con-sistency rate with expert annotations and 84.5% classification
accuracy, effec-tively capturing stylistic distinctions across images. The
proposed approach transcends the subjectivity inherent in traditional analyses
and offers a more objective and accurate perspective for comparative studies of
architectural culture.

</details>


### [594] [Flow-Anything: Learning Real-World Optical Flow Estimation from Large-Scale Single-view Images](https://arxiv.org/abs/2506.07740)
*Yingping Liang,Ying Fu,Yutao Hu,Wenqi Shao,Jiaming Liu,Debing Zhang*

Main category: cs.CV

TL;DR: 提出了Flow-Anything框架，从单视图图像生成大规模真实世界光流数据集FA-Flow，通过3D重建和动态物体建模解决合成数据域差距问题，显著提升光流估计性能并赋能下游任务。


<details>
  <summary>Details</summary>
Motivation: 现有光流模型依赖合成动画数据训练，导致真实场景存在域差距且数据扩展收益有限

Method: 1)用单目深度估计网络将单视图转为3D表示；2)提出物体无关体积渲染器和深度感知修复模块处理动态物体

Result: 首次证明真实图像生成训练数据的优势：超越最先进无监督方法及合成数据监督方法，成为基础模型提升下游视频任务性能

Conclusion: 解决了光流估计领域数据瓶颈，提供可扩展的真实数据生成方案

Abstract: Optical flow estimation is a crucial subfield of computer vision, serving as
a foundation for video tasks. However, the real-world robustness is limited by
animated synthetic datasets for training. This introduces domain gaps when
applied to real-world applications and limits the benefits of scaling up
datasets. To address these challenges, we propose \textbf{Flow-Anything}, a
large-scale data generation framework designed to learn optical flow estimation
from any single-view images in the real world. We employ two effective steps to
make data scaling-up promising. First, we convert a single-view image into a 3D
representation using advanced monocular depth estimation networks. This allows
us to render optical flow and novel view images under a virtual camera. Second,
we develop an Object-Independent Volume Rendering module and a Depth-Aware
Inpainting module to model the dynamic objects in the 3D representation. These
two steps allow us to generate realistic datasets for training from large-scale
single-view images, namely \textbf{FA-Flow Dataset}. For the first time, we
demonstrate the benefits of generating optical flow training data from
large-scale real-world images, outperforming the most advanced unsupervised
methods and supervised methods on synthetic datasets. Moreover, our models
serve as a foundation model and enhance the performance of various downstream
video tasks.

</details>


### [595] [Difference Inversion: Interpolate and Isolate the Difference with Token Consistency for Image Analogy Generation](https://arxiv.org/abs/2506.07750)
*Hyunsoo Kim,Donghyun Kim,Suhyun Kim*

Main category: cs.CV

TL;DR: 提出了Difference Inversion方法，通过提取A和A'之间的差异并应用到B，生成满足A:A'::B:B'关系的图像B'，解决了现有方法对特定模型的依赖问题，并在通用扩散模型上实现了更好的编辑效果。


<details>
  <summary>Details</summary>
Motivation: 现有通过视觉上下文学习或指令的方法局限于特定模型（如InstructPix2Pix、修复模型），导致继承模型偏差或编辑能力有限，无法适用于通用扩散模型（如Stable Diffusion）。需要一种模型无关的方法。

Method: 1) 用Delta插值提取A和A'的差异；2) 提出Token一致性损失和零初始化Token嵌入确保训练准确性；3) 将差异与B的提示结合形成完整提示，输入通用扩散模型生成B'。

Result: 大量实验表明，该方法在定量和定性上均优于现有基线，能模型无关地生成更可行的B'。

Conclusion: Difference Inversion通过精准提取和应用差异，实现了对通用扩散模型的即插即用式图像编辑，解决了模型依赖性问题。

Abstract: How can we generate an image B' that satisfies A:A'::B:B', given the input
images A,A' and B? Recent works have tackled this challenge through approaches
like visual in-context learning or visual instruction. However, these methods
are typically limited to specific models (e.g. InstructPix2Pix. Inpainting
models) rather than general diffusion models (e.g. Stable Diffusion, SDXL).
This dependency may lead to inherited biases or lower editing capabilities. In
this paper, we propose Difference Inversion, a method that isolates only the
difference from A and A' and applies it to B to generate a plausible B'. To
address model dependency, it is crucial to structure prompts in the form of a
"Full Prompt" suitable for input to stable diffusion models, rather than using
an "Instruction Prompt". To this end, we accurately extract the Difference
between A and A' and combine it with the prompt of B, enabling a plug-and-play
application of the difference. To extract a precise difference, we first
identify it through 1) Delta Interpolation. Additionally, to ensure accurate
training, we propose the 2) Token Consistency Loss and 3) Zero Initialization
of Token Embeddings. Our extensive experiments demonstrate that Difference
Inversion outperforms existing baselines both quantitatively and qualitatively,
indicating its ability to generate more feasible B' in a model-agnostic manner.

</details>


### [596] [Trend-Aware Fashion Recommendation with Visual Segmentation and Semantic Similarity](https://arxiv.org/abs/2506.07773)
*Mohamed Djilani,Nassim Ali Ousalah,Nidhal Eddine Chenni*

Main category: cs.CV

TL;DR: 提出了一种结合视觉、语义和流行度的时尚推荐系统，使用视觉嵌入、用户行为模拟和加权评分来提升个性化推荐效果。


<details>
  <summary>Details</summary>
Motivation: 传统的时尚推荐系统往往忽视了视觉元素与流行趋势的结合，导致推荐不够个性化和时效性。本文旨在通过整合深度视觉表示、服装感知分割、语义类别相似性和用户行为模拟，构建一个既能反映个人风格又能跟上新兴趋势的推荐系统。

Method: 利用语义分割屏蔽非服装区域提取视觉嵌入（ResNet-50/DenseNet-121/VGG16），生成受用户特定趋势性和物品流行度影响的合成购买历史。通过融合视觉相似度、语义一致性和流行度对齐的加权评分函数生成推荐。

Result: 在DeepFashion数据集上，ResNet-50达到64.95%类别相似度及最低流行度MAE，消融实验验证视觉与流行度线索的互补作用。

Conclusion: 该方法为个性化时尚推荐提供了可扩展框架，能平衡个人风格与新兴趋势。代码已开源。

Abstract: We introduce a trend-aware and visually-grounded fashion recommendation
system that integrates deep visual representations, garment-aware segmentation,
semantic category similarity and user behavior simulation. Our pipeline
extracts focused visual embeddings by masking non-garment regions via semantic
segmentation followed by feature extraction using pretrained CNN backbones
(ResNet-50, DenseNet-121, VGG16). To simulate realistic shopping behavior, we
generate synthetic purchase histories influenced by user-specific trendiness
and item popularity. Recommendations are computed using a weighted scoring
function that fuses visual similarity, semantic coherence and popularity
alignment. Experiments on the DeepFashion dataset demonstrate consistent gender
alignment and improved category relevance, with ResNet-50 achieving 64.95%
category similarity and lowest popularity MAE. An ablation study confirms the
complementary roles of visual and popularity cues. Our method provides a
scalable framework for personalized fashion recommendations that balances
individual style with emerging trends. Our implementation is available at
https://github.com/meddjilani/FashionRecommender

</details>


### [597] [Language-Vision Planner and Executor for Text-to-Visual Reasoning](https://arxiv.org/abs/2506.07778)
*Yichang Xu,Gaowen Liu,Ramana Rao Kompella,Sihao Hu,Tiansheng Huang,Fatih Ilhan,Selim Furkan Tekin,Zachary Yahn,Ling Liu*

Main category: cs.CV

TL;DR: VLAgent是一个多模态视觉-文本推理框架，通过任务规划和执行验证解决现有视觉语言模型泛化性能问题。系统特点包括基于情境学习的规划生成改进、语法-语义解析器纠错及集成方法强化执行器泛化性能。在四个基准测试中显著超越主流模型。


<details>
  <summary>Details</summary>
Motivation: 现有视觉语言模型存在泛化性能不足问题，而近期语言模型在视觉推理中的发展为解决该问题提供了新思路。因此，该研究旨在构建具有自动化规划与验证能力的AI系统，提升多模态推理的准确性和鲁棒性。

Method: 1) 任务规划阶段：通过情境学习微调LLM生成分步骤规划脚本。2) 执行阶段：渐进优化神经符号执行模块组合。创新点在于：a)情境学习提升规划质量 b)语法-语义解析器修正逻辑错误 c)集成方法增强执行器泛化性。

Result: 在GQA、MME、NLVR2和VQAv2四个视觉推理基准测试中，VLAgent性能显著优于现有代表性视觉语言模型（VLMs）及ViProg、ViperGPT等组合方法。

Conclusion: VLAgent通过创新的规划生成优化、预执行错误修正和集成执行机制，有效提升了多模态视觉-文本推理的准确性和鲁棒性。其模块化设计（如SS-Parser和Plan Repairer）为相关研究提供了新方向。

Abstract: The advancement in large language models (LLMs) and large vision models has
fueled the rapid progress in multi-modal visual-text reasoning capabilities.
However, existing vision-language models (VLMs) to date suffer from
generalization performance. Inspired by recent development in LLMs for visual
reasoning, this paper presents VLAgent, an AI system that can create a
step-by-step visual reasoning plan with an easy-to-understand script and
execute each step of the plan in real time by integrating planning script with
execution verifications via an automated process supported by VLAgent. In the
task planning phase, VLAgent fine-tunes an LLM through in-context learning to
generate a step-by-step planner for each user-submitted text-visual reasoning
task. During the plan execution phase, VLAgent progressively refines the
composition of neuro-symbolic executable modules to generate high-confidence
reasoning results. VLAgent has three unique design characteristics: First, we
improve the quality of plan generation through in-context learning, improving
logic reasoning by reducing erroneous logic steps, incorrect programs, and LLM
hallucinations. Second, we design a syntax-semantics parser to identify and
correct additional logic errors of the LLM-generated planning script prior to
launching the plan executor. Finally, we employ the ensemble method to improve
the generalization performance of our step-executor. Extensive experiments with
four visual reasoning benchmarks (GQA, MME, NLVR2, VQAv2) show that VLAgent
achieves significant performance enhancement for multimodal text-visual
reasoning applications, compared to the exiting representative VLMs and LLM
based visual composition approaches like ViperGPT and VisProg, thanks to the
novel optimization modules of VLAgent back-engine (SS-Parser, Plan Repairer,
Output Verifiers). Code and data will be made available upon paper acceptance.

</details>


### [598] [Design and Evaluation of Deep Learning-Based Dual-Spectrum Image Fusion Methods](https://arxiv.org/abs/2506.07779)
*Beining Xu,Junxian Li*

Main category: cs.CV

TL;DR: 该论文构建了一个高质量校园双光谱数据集并提出综合评估框架，通过实验发现下游任务优化的融合模型在目标检测中表现更优，证明了现有评估方法的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有可见光-红外图像融合研究缺乏标准化测试基准和下游任务评估，且数据集不足和算法公平比较缺失制约发展；本文旨在解决这些问题。

Method: 构建包含1369对校园场景可见光-红外图像的数据集；设计融合速度、通用指标和基于lang-segment-anything的目标检测性能的综合评估框架。

Result: 实验表明：为下游任务优化的融合模型在弱光和遮挡场景检测性能更优；部分通用指标好的模型下游表现不佳，验证了新框架的必要性。

Conclusion: 贡献包括：1）校园多场景双光谱数据集 2）任务感知的综合评估框架 3）跨数据集融合算法对比分析，为未来研究提供方向。

Abstract: Visible images offer rich texture details, while infrared images emphasize
salient targets. Fusing these complementary modalities enhances scene
understanding, particularly for advanced vision tasks under challenging
conditions. Recently, deep learning-based fusion methods have gained attention,
but current evaluations primarily rely on general-purpose metrics without
standardized benchmarks or downstream task performance. Additionally, the lack
of well-developed dual-spectrum datasets and fair algorithm comparisons hinders
progress.
  To address these gaps, we construct a high-quality dual-spectrum dataset
captured in campus environments, comprising 1,369 well-aligned visible-infrared
image pairs across four representative scenarios: daytime, nighttime, smoke
occlusion, and underpasses. We also propose a comprehensive and fair evaluation
framework that integrates fusion speed, general metrics, and object detection
performance using the lang-segment-anything model to ensure fairness in
downstream evaluation.
  Extensive experiments benchmark several state-of-the-art fusion algorithms
under this framework. Results demonstrate that fusion models optimized for
downstream tasks achieve superior performance in target detection, especially
in low-light and occluded scenes. Notably, some algorithms that perform well on
general metrics do not translate to strong downstream performance, highlighting
limitations of current evaluation practices and validating the necessity of our
proposed framework.
  The main contributions of this work are: (1)a campus-oriented dual-spectrum
dataset with diverse and challenging scenes; (2) a task-aware, comprehensive
evaluation framework; and (3) thorough comparative analysis of leading fusion
methods across multiple datasets, offering insights for future development.

</details>


### [599] [Re-ranking Reasoning Context with Tree Search Makes Large Vision-Language Models Stronger](https://arxiv.org/abs/2506.07785)
*Qi Yang,Chenghao Zhang,Lubin Fan,Kun Ding,Jieping Ye,Shiming Xiang*

Main category: cs.CV

TL;DR: 提出RCTS框架增强多模态检索增强生成，通过构建丰富的推理上下文知识库和树搜索重排，改善LVLM在VQA任务中的性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法面临知识库中推理实例稀缺和检索知识响应不稳定的问题。

Method: 1. 自洽评估机制构建富含推理模式的知识库；2. 基于启发式奖励的蒙特卡洛树搜索（MCTS-HR）重排相关示例。

Result: 在多个VQA数据集上实现SOTA，显著优于ICL和Vanilla-RAG方法。

Conclusion: RCTS框架通过知识库增强和重排机制有效提升了LVLM的响应质量和一致性。

Abstract: Recent advancements in Large Vision Language Models (LVLMs) have
significantly improved performance in Visual Question Answering (VQA) tasks
through multimodal Retrieval-Augmented Generation (RAG). However, existing
methods still face challenges, such as the scarcity of knowledge with reasoning
examples and erratic responses from retrieved knowledge. To address these
issues, in this study, we propose a multimodal RAG framework, termed RCTS,
which enhances LVLMs by constructing a Reasoning Context-enriched knowledge
base and a Tree Search re-ranking method. Specifically, we introduce a
self-consistent evaluation mechanism to enrich the knowledge base with
intrinsic reasoning patterns. We further propose a Monte Carlo Tree Search with
Heuristic Rewards (MCTS-HR) to prioritize the most relevant examples. This
ensures that LVLMs can leverage high-quality contextual reasoning for better
and more consistent responses. Extensive experiments demonstrate that our
framework achieves state-of-the-art performance on multiple VQA datasets,
significantly outperforming In-Context Learning (ICL) and Vanilla-RAG methods.
It highlights the effectiveness of our knowledge base and re-ranking method in
improving LVLMs. Our code is available at https://github.com/yannqi/RCTS-RAG.

</details>


### [600] [Image Reconstruction as a Tool for Feature Analysis](https://arxiv.org/abs/2506.07803)
*Eduard Allakhverdov,Dmitrii Tarasov,Elizaveta Goncharova,Andrey Kuznetsov*

Main category: cs.CV

TL;DR: 本研究提出了一种通过图像重建来解释视觉特征的新方法，比较了SigLIP和SigLIP2两种模型，发现基于图像任务预训练的编码器比对比学习等非图像任务训练的模型保留更多图像信息，并对多种视觉编码器进行了特征信息量排名，同时揭示了特征空间中正交旋转控制颜色编码的机制。


<details>
  <summary>Details</summary>
Motivation: 尽管视觉编码器在各类应用中表现出色，但其内部特征表示机制仍不明确。本研究旨在揭示不同训练目标下视觉编码器如何保留图像信息，并探索其特征空间的内在结构。

Method: 通过图像重建方法分析特征表示能力，比较两种仅训练目标不同的模型（SigLIP和SigLIP2），评估多种视觉编码器的特征信息量，并操纵特征空间观察重建图像的变化规律。

Result: 1. 基于图像任务预训练的编码器比对比学习训练的模型保留更多图像信息
2. 建立了视觉编码器的特征信息量排名
3. 发现特征空间的正交旋转操作可预测性地控制重建图像的颜色编码

Conclusion: 该方法可泛用于任何视觉编码器，揭示了特征空间的内在结构（特别是正交旋转控制颜色编码的机制），为理解视觉特征表示提供了新视角。

Abstract: Vision encoders are increasingly used in modern applications, from
vision-only models to multimodal systems such as vision-language models.
Despite their remarkable success, it remains unclear how these architectures
represent features internally. Here, we propose a novel approach for
interpreting vision features via image reconstruction. We compare two related
model families, SigLIP and SigLIP2, which differ only in their training
objective, and show that encoders pre-trained on image-based tasks retain
significantly more image information than those trained on non-image tasks such
as contrastive learning. We further apply our method to a range of vision
encoders, ranking them by the informativeness of their feature representations.
Finally, we demonstrate that manipulating the feature space yields predictable
changes in reconstructed images, revealing that orthogonal rotations (rather
than spatial transformations) control color encoding. Our approach can be
applied to any vision encoder, shedding light on the inner structure of its
feature space. The code and model weights to reproduce the experiments are
available in GitHub.

</details>


### [601] [Incorporating Uncertainty-Guided and Top-k Codebook Matching for Real-World Blind Image Super-Resolution](https://arxiv.org/abs/2506.07809)
*Weilei Wen,Tianyi Zhang,Qianqian Zhao,Zhaohui Zheng,Chunle Guo,Xiuli Shao,Chongyi Li*

Main category: cs.CV

TL;DR: 提出UGTSR框架解决图像超分辨率中特征匹配不准确和纹理细节重建差的问题，包含不确定性学习、Top-k特征匹配和对齐注意力模块


<details>
  <summary>Details</summary>
Motivation: 现有基于码本的超分辨率方法存在特征匹配不准确和纹理重建效果差的问题

Method: 1）不确定性学习机制聚焦纹理区域；2）Top-k特征匹配策略融合多个候选特征；3）对齐注意力模块增强LR-HR特征对齐

Result: 实验表明纹理真实性和重建保真度显著优于现有方法

Conclusion: UGTSR框架有效解决了特征匹配和纹理重建问题，代码将开源

Abstract: Recent advancements in codebook-based real image super-resolution (SR) have
shown promising results in real-world applications. The core idea involves
matching high-quality image features from a codebook based on low-resolution
(LR) image features. However, existing methods face two major challenges:
inaccurate feature matching with the codebook and poor texture detail
reconstruction. To address these issues, we propose a novel Uncertainty-Guided
and Top-k Codebook Matching SR (UGTSR) framework, which incorporates three key
components: (1) an uncertainty learning mechanism that guides the model to
focus on texture-rich regions, (2) a Top-k feature matching strategy that
enhances feature matching accuracy by fusing multiple candidate features, and
(3) an Align-Attention module that enhances the alignment of information
between LR and HR features. Experimental results demonstrate significant
improvements in texture realism and reconstruction fidelity compared to
existing methods. We will release the code upon formal publication.

</details>


### [602] [Looking Beyond Visible Cues: Implicit Video Question Answering via Dual-Clue Reasoning](https://arxiv.org/abs/2506.07811)
*Tieyuan Chen,Huabin Liu,Yi Wang,Chaofan Gan,Mingxi Lyu,Gui Zou,Weiyao Lin*

Main category: cs.CV

TL;DR: 本文介绍了隐式视频问答（I-VQA）这一新颖任务和数据集，它聚焦于无法接触显式视觉证据的场景。所提的隐式推理模型（IRM）结合双流建模方法，有效提升隐式视频问答表现，在多项基准测试中显著优于现有模型。


<details>
  <summary>Details</summary>
Motivation: 现有视频问答研究依赖显式视觉证据，在面对需理解深层意图的问题时性能明显下降。因此本文提出处理无法直接获取显式证据场景的I-VQA任务，旨在填补研究空白。

Method: 提出隐式推理模型（IRM）：1）包括动作-意图模块（AIM）用于生成线索候选并进行关系推理，双流建模上下文动作与意图线索；2）视觉增强模块（VEM）利用关键上下文线索强化视觉表示。

Result: 实验显示IRM在I-VQA任务上超越GPT-4o、OpenAI-o3和微调VideoChat2各0.76%、1.37%、4.87%。同时在广告理解与交通场景预测任务中达到SOTA水平。

Conclusion: IRM通过建模隐含推理链有效解决显式视觉证据缺失问题，双模块协同显着提升隐式理解能力。验证了该模型在复杂视频理解场景的突破性表现。

Abstract: Video Question Answering (VideoQA) aims to answer natural language questions
based on the given video, with prior work primarily focusing on identifying the
duration of relevant segments, referred to as explicit visual evidence.
However, explicit visual evidence is not always directly available,
particularly when questions target symbolic meanings or deeper intentions,
leading to significant performance degradation. To fill this gap, we introduce
a novel task and dataset, $\textbf{I}$mplicit $\textbf{V}$ideo
$\textbf{Q}$uestion $\textbf{A}$nswering (I-VQA), which focuses on answering
questions in scenarios where explicit visual evidence is inaccessible. Given an
implicit question and its corresponding video, I-VQA requires answering based
on the contextual visual cues present within the video. To tackle I-VQA, we
propose a novel reasoning framework, IRM (Implicit Reasoning Model),
incorporating dual-stream modeling of contextual actions and intent clues as
implicit reasoning chains. IRM comprises the Action-Intent Module (AIM) and the
Visual Enhancement Module (VEM). AIM deduces and preserves question-related
dual clues by generating clue candidates and performing relation deduction. VEM
enhances contextual visual representation by leveraging key contextual clues.
Extensive experiments validate the effectiveness of our IRM in I-VQA tasks,
outperforming GPT-4o, OpenAI-o3, and fine-tuned VideoChat2 by $0.76\%$,
$1.37\%$, and $4.87\%$, respectively. Additionally, IRM performs SOTA on
similar implicit advertisement understanding and future prediction in
traffic-VQA. Datasets and codes are available for double-blind review in
anonymous repo: https://github.com/tychen-SJTU/Implicit-VideoQA.

</details>


### [603] [Self-Cascaded Diffusion Models for Arbitrary-Scale Image Super-Resolution](https://arxiv.org/abs/2506.07813)
*Junseo Bang,Joonhee Lee,Kyeonghyun Lee,Haechang Lee,Dong Un Kang,Se Young Chun*

Main category: cs.CV

TL;DR: 提出CasArbi框架，通过自级联扩散和坐标引导残差扩散模型实现任意尺度图像超分辨率，在多个基准测试中表现优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有任意尺度超分辨方法多为单级上采样，难以适应连续变化的尺度分布；渐进上采样策略与扩散模型结合尚未被充分探索。

Method: 1. 自级联扩散框架：将大尺度因子分解为连续小因子逐步上采样；2. 坐标引导残差扩散模型：学习连续图像表示并提升采样效率。

Result: 在多个任意尺度超分辨基准测试中，CasArbi在感知质量和失真指标上均优于现有方法。

Conclusion: CasArbi通过渐进式扩散模型有效解决任意尺度超分辨问题，为连续尺度上采样提供了新思路。

Abstract: Arbitrary-scale image super-resolution aims to upsample images to any desired
resolution, offering greater flexibility than traditional fixed-scale
super-resolution. Recent approaches in this domain utilize regression-based or
generative models, but many of them are a single-stage upsampling process,
which may be challenging to learn across a wide, continuous distribution of
scaling factors. Progressive upsampling strategies have shown promise in
mitigating this issue, yet their integration with diffusion models for flexible
upscaling remains underexplored. Here, we present CasArbi, a novel
self-cascaded diffusion framework for arbitrary-scale image super-resolution.
CasArbi meets the varying scaling demands by breaking them down into smaller
sequential factors and progressively enhancing the image resolution at each
step with seamless transitions for arbitrary scales. Our novel
coordinate-guided residual diffusion model allows for the learning of
continuous image representations while enabling efficient diffusion sampling.
Extensive experiments demonstrate that our CasArbi outperforms prior arts in
both perceptual and distortion performance metrics across diverse
arbitrary-scale super-resolution benchmarks.

</details>


### [604] [M2Restore: Mixture-of-Experts-based Mamba-CNN Fusion Framework for All-in-One Image Restoration](https://arxiv.org/abs/2506.07814)
*Yongzhen Wang,Yongjun Li,Zhuoran Zheng,Xiao-Ping Zhang,Mingqiang Wei*

Main category: cs.CV

TL;DR: M2Restore: 结合MoE和Mamba-CNN的高效鲁棒一体化图像修复方法


<details>
  <summary>Details</summary>
Motivation: 解决复杂降解场景下已有方法的泛化能力不足及全局依赖与局部细节平衡不佳问题

Method: 1) CLIP引导的MoE门控机制融合任务条件提示与语义先验 2) CNN与Mamba双流架构联合优化 3) 边缘感知动态门控机制

Result: 在多图像修复基准测试中取得视觉质量和量化性能的优越结果

Conclusion: 该方法能有效处理复合降解，在保留全局一致性的同时增强局部细节

Abstract: Natural images are often degraded by complex, composite degradations such as
rain, snow, and haze, which adversely impact downstream vision applications.
While existing image restoration efforts have achieved notable success, they
are still hindered by two critical challenges: limited generalization across
dynamically varying degradation scenarios and a suboptimal balance between
preserving local details and modeling global dependencies. To overcome these
challenges, we propose M2Restore, a novel Mixture-of-Experts (MoE)-based
Mamba-CNN fusion framework for efficient and robust all-in-one image
restoration. M2Restore introduces three key contributions: First, to boost the
model's generalization across diverse degradation conditions, we exploit a
CLIP-guided MoE gating mechanism that fuses task-conditioned prompts with
CLIP-derived semantic priors. This mechanism is further refined via cross-modal
feature calibration, which enables precise expert selection for various
degradation types. Second, to jointly capture global contextual dependencies
and fine-grained local details, we design a dual-stream architecture that
integrates the localized representational strength of CNNs with the long-range
modeling efficiency of Mamba. This integration enables collaborative
optimization of global semantic relationships and local structural fidelity,
preserving global coherence while enhancing detail restoration. Third, we
introduce an edge-aware dynamic gating mechanism that adaptively balances
global modeling and local enhancement by reallocating computational attention
to degradation-sensitive regions. This targeted focus leads to more efficient
and precise restoration. Extensive experiments across multiple image
restoration benchmarks validate the superiority of M2Restore in both visual
quality and quantitative performance.

</details>


### [605] [R3D2: Realistic 3D Asset Insertion via Diffusion for Autonomous Driving Simulation](https://arxiv.org/abs/2506.07826)
*William Ljungbergh,Bernardo Taveira,Wenzhao Zheng,Adam Tonderski,Chensheng Peng,Fredrik Kahl,Christoffer Petersson,Michael Felsberg,Kurt Keutzer,Masayoshi Tomizuka,Wei Zhan*

Main category: cs.CV

TL;DR: 提出R3D2扩散模型，解决3D高斯泼溅技术在动态对象插入时的渲染真实性问题，实现自动驾驶验证场景的可扩展真实模拟。


<details>
  <summary>Details</summary>
Motivation: 现有神经重建方法（如3DGS）虽可创建逼真驾驶场景数字孪生，但难以动态操作对象且存在模型不完整问题，阻碍了自动驾驶验证的可扩展性。

Method: 开发轻量级单步扩散模型R3D2，通过新数据集（从真实AD数据生成3DGS资产并合成到神经渲染环境）训练模型实时生成阴影/光照等渲染效果。

Result: 定量定性评估表明R3D2显著提升资产插入真实感，支持文本转3D资产插入和跨场景对象迁移，实现真正可扩展的AD验证。

Conclusion: R3D2突破动态资产插入限制，推动自动驾驶仿真研究；将开源数据集和代码促进领域发展。

Abstract: Validating autonomous driving (AD) systems requires diverse and
safety-critical testing, making photorealistic virtual environments essential.
Traditional simulation platforms, while controllable, are resource-intensive to
scale and often suffer from a domain gap with real-world data. In contrast,
neural reconstruction methods like 3D Gaussian Splatting (3DGS) offer a
scalable solution for creating photorealistic digital twins of real-world
driving scenes. However, they struggle with dynamic object manipulation and
reusability as their per-scene optimization-based methodology tends to result
in incomplete object models with integrated illumination effects. This paper
introduces R3D2, a lightweight, one-step diffusion model designed to overcome
these limitations and enable realistic insertion of complete 3D assets into
existing scenes by generating plausible rendering effects-such as shadows and
consistent lighting-in real time. This is achieved by training R3D2 on a novel
dataset: 3DGS object assets are generated from in-the-wild AD data using an
image-conditioned 3D generative model, and then synthetically placed into
neural rendering-based virtual environments, allowing R3D2 to learn realistic
integration. Quantitative and qualitative evaluations demonstrate that R3D2
significantly enhances the realism of inserted assets, enabling use-cases like
text-to-3D asset insertion and cross-scene/dataset object transfer, allowing
for true scalability in AD validation. To promote further research in scalable
and realistic AD simulation, we will release our dataset and code, see
https://research.zenseact.com/publications/R3D2/.

</details>


### [606] [Diffusion models under low-noise regime](https://arxiv.org/abs/2506.07841)
*Elizabeth Pavlova,Xue-Xin Wei*

Main category: cs.CV

TL;DR: 该论文研究扩散模型在低噪声环境下的行为，揭示训练集大小、数据几何和模型目标对去噪轨迹的影响，挑战高噪声行为不能预测低噪声性能的观点。


<details>
  <summary>Details</summary>
Motivation: 现有研究认为扩散模型在高噪声下具有记忆化和泛化两种模式，但低噪声环境下模型作为高效去噪器的行为尚不明确。该研究旨在填补这一空白，探究模型在微小扰动下的鲁棒性和可解释性。

Method: 使用CelebA子集和解析高斯混合基准测试，分析模型在低噪声扩散动力学中的表现；通过训练数据大小、几何结构和目标函数的控制变量实验，量化其对去噪轨迹和分数准确性的影响。

Result: 发现即使在高噪声输出收敛的情况下，不同训练数据的模型在数据流形附近会产生分歧；揭示了训练集规模扩大反而可能降低流形邻近区域的分数准确性。

Conclusion: 扩散模型在低噪声下的行为不能通过高噪声表现外推预测，强调其在现实微弱扰动场景中的可靠性问题；通过几何建模提供了模型如何真正学习数据分布的机制解释。

Abstract: Recent work on diffusion models proposed that they operate in two regimes:
memorization, in which models reproduce their training data, and
generalization, in which they generate novel samples. While this has been
tested in high-noise settings, the behavior of diffusion models as effective
denoisers when the corruption level is small remains unclear. To address this
gap, we systematically investigated the behavior of diffusion models under
low-noise diffusion dynamics, with implications for model robustness and
interpretability. Using (i) CelebA subsets of varying sample sizes and (ii)
analytic Gaussian mixture benchmarks, we reveal that models trained on disjoint
data diverge near the data manifold even when their high-noise outputs
converge. We quantify how training set size, data geometry, and model objective
choice shape denoising trajectories and affect score accuracy, providing
insights into how these models actually learn representations of data
distributions. This work starts to address gaps in our understanding of
generative model reliability in practical applications where small
perturbations are common.

</details>


### [607] [F2Net: A Frequency-Fused Network for Ultra-High Resolution Remote Sensing Segmentation](https://arxiv.org/abs/2506.07847)
*Hengzhi Chen,Liqian Feng,Wenhua Wu,Xiaogang Zhu,Shawn Leo,Kun Hu*

Main category: cs.CV

TL;DR: F2Net is a frequency-aware framework for semantic segmentation of ultra-high-resolution remote sensing images. It decomposes images into high- and low-frequency components for specialized processing, addressing computational challenges and detail loss. The method includes dual sub-branches for low-frequency, a fusion module, and novel loss functions for training stability. Achieves state-of-the-art mIoU of 80.22 and 83.39 on benchmarks.


<details>
  <summary>Details</summary>
Motivation: Conventional methods for semantic segmentation of ultra-high-resolution (UHR) remote sensing imagery either lose fine details through downsampling or fragment global context via patch processing. Multi-branch networks address this trade-off but suffer from computational inefficiency and conflicting gradient dynamics during training.

Method: Proposes F2Net, a frequency-aware framework that decomposes UHR images into high- and low-frequency components. High-frequency branch preserves full-resolution structural details; low-frequency branch uses dual sub-branches to capture short- and long-range dependencies on downsampled inputs. Features integrated via Hybrid-Frequency Fusion module. Two novel loss functions: Cross-Frequency Alignment Loss ensures semantic consistency, Cross-Frequency Balance Loss regulates gradient magnitudes to stabilize training.

Result: Achieves state-of-the-art performance with mIoU of 80.22 on DeepGlobe and 83.39 on Inria Aerial benchmarks.

Conclusion: F2Net effectively addresses computational and optimization challenges in UHR semantic segmentation by frequency decomposition and specialized processing. The proposed loss functions enable stable training and state-of-the-art results. Code will be publicly available.

Abstract: Semantic segmentation of ultra-high-resolution (UHR) remote sensing imagery
is critical for applications like environmental monitoring and urban planning
but faces computational and optimization challenges. Conventional methods
either lose fine details through downsampling or fragment global context via
patch processing. While multi-branch networks address this trade-off, they
suffer from computational inefficiency and conflicting gradient dynamics during
training. We propose F2Net, a frequency-aware framework that decomposes UHR
images into high- and low-frequency components for specialized processing. The
high-frequency branch preserves full-resolution structural details, while the
low-frequency branch processes downsampled inputs through dual sub-branches
capturing short- and long-range dependencies. A Hybrid-Frequency Fusion module
integrates these observations, guided by two novel objectives: Cross-Frequency
Alignment Loss ensures semantic consistency between frequency components, and
Cross-Frequency Balance Loss regulates gradient magnitudes across branches to
stabilize training. Evaluated on DeepGlobe and Inria Aerial benchmarks, F2Net
achieves state-of-the-art performance with mIoU of 80.22 and 83.39,
respectively. Our code will be publicly available.

</details>


### [608] [PolyVivid: Vivid Multi-Subject Video Generation with Cross-Modal Interaction and Enhancement](https://arxiv.org/abs/2506.07848)
*Teng Hu,Zhentao Yu,Zhengguang Zhou,Jiangning Zhang,Yuan Zhou,Qinglin Lu,Ran Yi*

Main category: cs.CV

TL;DR: PolyVivid是一个多主体视频定制框架，通过文本-图像融合模块准确建立主体图像与文本实体的对应关系，使用3D-RoPE增强模块保持身份一致性，采用注意力继承注入模块防止身份漂移，并构建MLLM数据流程提升数据质量。实验证明其在身份保真度、视频真实感和主体对齐方面优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有视频生成模型在细节控制方面存在不足，特别是多主体定制时的身份一致性和交互问题。本文旨在开发一个可灵活控制且保持身份一致的多主体视频定制框架。

Method: 设计基于VLLM的文本-图像融合模块实现视觉身份到文本空间的嵌入；提出基于3D-RoPE的增强模块促进文本与图像嵌入的双向融合；开发注意力继承身份注入模块将融合特征注入视频生成过程；构建基于MLLM的数据流程（包括MLLM定位、分割和基于团的主体整合策略）。

Result: 大量实验表明PolyVivid在身份保真度、视频真实感和主体对齐方面表现优异，超越现有开源和商业基线模型。

Conclusion: PolyVivid解决了多主体视频生成中的身份一致性和交互问题，通过创新的文本-图像融合、3D-RoPE增强和注意力继承注入模块，实现了高质量的多主体视频定制。数据流程的改进也显著提升了生成效果。

Abstract: Despite recent advances in video generation, existing models still lack
fine-grained controllability, especially for multi-subject customization with
consistent identity and interaction. In this paper, we propose PolyVivid, a
multi-subject video customization framework that enables flexible and
identity-consistent generation. To establish accurate correspondences between
subject images and textual entities, we design a VLLM-based text-image fusion
module that embeds visual identities into the textual space for precise
grounding. To further enhance identity preservation and subject interaction, we
propose a 3D-RoPE-based enhancement module that enables structured
bidirectional fusion between text and image embeddings. Moreover, we develop an
attention-inherited identity injection module to effectively inject fused
identity features into the video generation process, mitigating identity drift.
Finally, we construct an MLLM-based data pipeline that combines MLLM-based
grounding, segmentation, and a clique-based subject consolidation strategy to
produce high-quality multi-subject data, effectively enhancing subject
distinction and reducing ambiguity in downstream video generation. Extensive
experiments demonstrate that PolyVivid achieves superior performance in
identity fidelity, video realism, and subject alignment, outperforming existing
open-source and commercial baselines.

</details>


### [609] [SAM2Auto: Auto Annotation Using FLASH](https://arxiv.org/abs/2506.07850)
*Arash Rocky,Q. M. Jonathan Wu*

Main category: cs.CV

TL;DR: SAM2Auto是一个全自动的视频注释流程，无需人工干预或针对特定数据集的训练。它结合了SMART-OD（自动掩码生成与开放世界检测）和FLASH（实时视频实例分割），利用统计方法减少误检并保持跨帧追踪。实验表明其精度接近人工注释，大幅降低时间和成本。


<details>
  <summary>Details</summary>
Motivation: 视觉语言模型(VLM)因标注数据稀缺而落后于大语言模型(LLM)，人工标注视觉-文本对成本高昂。为解决这一瓶颈，需要完全自动化的视频注释方案。

Method: 1.SMART-OD：结合自动掩膜生成和开放世界物体检测 2.FLASH：多目标实时视频实例分割系统，确保物体跨帧一致性。通过统计方法减少误检，无需逐帧调参。

Result: 在多样化数据集上达到接近人工注释的精度，显著减少标注时间和人力成本；系统无需重新训练或大量参数调整即可处理不同数据集。

Conclusion: SAM2Auto为自动视频注释设立了新基线，通过解决数据集瓶颈加速视觉语言理解的发展。

Abstract: Vision-Language Models (VLMs) lag behind Large Language Models due to the
scarcity of annotated datasets, as creating paired visual-textual annotations
is labor-intensive and expensive. To address this bottleneck, we introduce
SAM2Auto, the first fully automated annotation pipeline for video datasets
requiring no human intervention or dataset-specific training. Our approach
consists of two key components: SMART-OD, a robust object detection system that
combines automatic mask generation with open-world object detection
capabilities, and FLASH (Frame-Level Annotation and Segmentation Handler), a
multi-object real-time video instance segmentation (VIS) that maintains
consistent object identification across video frames even with intermittent
detection gaps. Unlike existing open-world detection methods that require
frame-specific hyperparameter tuning and suffer from numerous false positives,
our system employs statistical approaches to minimize detection errors while
ensuring consistent object tracking throughout entire video sequences.
Extensive experimental validation demonstrates that SAM2Auto achieves
comparable accuracy to manual annotation while dramatically reducing annotation
time and eliminating labor costs. The system successfully handles diverse
datasets without requiring retraining or extensive parameter adjustments,
making it a practical solution for large-scale dataset creation. Our work
establishes a new baseline for automated video annotation and provides a
pathway for accelerating VLM development by addressing the fundamental dataset
bottleneck that has constrained progress in vision-language understanding.

</details>


### [610] [LogoSP: Local-global Grouping of Superpoints for Unsupervised Semantic Segmentation of 3D Point Clouds](https://arxiv.org/abs/2506.07857)
*Zihui Zhang,Weisheng Dai,Hongtao Wen,Bo Yang*

Main category: cs.CV

TL;DR: LogoSP：一种通过频域特征进行超点聚类的无监督3D点云语义分割方法，实现SOTA性能


<details>
  <summary>Details</summary>
Motivation: 目前的无监督方法主要基于局部特征进行分组，缺乏对更丰富语义先验的挖掘。本文旨在从局部和全局特征中联合学习3D语义

Method: 提出LogoSP框架：基于频域全局特征对超点进行分组，产生高质量伪标签用于训练分割网络

Result: 在室内外三个数据集上大幅超越现有方法（如SCAN），可视化显示确能捕捉有意义的无标签语义

Conclusion: 频域全局模式能有效表示无标签3D语义，LogoSP为无监督点云分割提供了新方向

Abstract: We study the problem of unsupervised 3D semantic segmentation on raw point
clouds without needing human labels in training. Existing methods usually
formulate this problem into learning per-point local features followed by a
simple grouping strategy, lacking the ability to discover additional and
possibly richer semantic priors beyond local features. In this paper, we
introduce LogoSP to learn 3D semantics from both local and global point
features. The key to our approach is to discover 3D semantic information by
grouping superpoints according to their global patterns in the frequency
domain, thus generating highly accurate semantic pseudo-labels for training a
segmentation network. Extensive experiments on two indoor and an outdoor
datasets show that our LogoSP surpasses all existing unsupervised methods by
large margins, achieving the state-of-the-art performance for unsupervised 3D
semantic segmentation. Notably, our investigation into the learned global
patterns reveals that they truly represent meaningful 3D semantics in the
absence of human labels during training.

</details>


### [611] [Egocentric Event-Based Vision for Ping Pong Ball Trajectory Prediction](https://arxiv.org/abs/2506.07860)
*Ivan Alberico,Marco Cannici,Giovanni Cioffi,Davide Scaramuzza*

Main category: cs.CV

TL;DR: 提出了一种利用事件相机实时预测乒乓球轨迹的系统，解决传统相机高延迟和运动模糊问题。该系统利用生物启发方法，显著降低计算延迟并提高预测准确性。


<details>
  <summary>Details</summary>
Motivation: 传统相机在乒乓球等高速运动中存在高延迟和运动模糊问题，事件相机则具有高时间分辨率优势。需要开发一种能够实时准确预测3D轨迹的系统。

Method: 1. 使用Meta Aria眼镜收集同步数据；2. 利用眼动追踪实现焦点视觉处理；3. 构建检测管道（4.5ms低延迟）；4. 基于球状态估计拟合轨迹预测模型。

Result: 计算延迟减少10.81倍（最坏情况4.5ms）；相比30帧系统（感知延迟66ms）显著提升；首次实现事件相机视角的轨迹预测。

Conclusion: 事件相机+焦点视觉的架构能在超低延迟下实现准确预测，为高速运动场景提供新解决方案。

Abstract: In this paper, we present a real-time egocentric trajectory prediction system
for table tennis using event cameras. Unlike standard cameras, which suffer
from high latency and motion blur at fast ball speeds, event cameras provide
higher temporal resolution, allowing more frequent state updates, greater
robustness to outliers, and accurate trajectory predictions using just a short
time window after the opponent's impact. We collect a dataset of ping-pong game
sequences, including 3D ground-truth trajectories of the ball, synchronized
with sensor data from the Meta Project Aria glasses and event streams. Our
system leverages foveated vision, using eye-gaze data from the glasses to
process only events in the viewer's fovea. This biologically inspired approach
improves ball detection performance and significantly reduces computational
latency, as it efficiently allocates resources to the most perceptually
relevant regions, achieving a reduction factor of 10.81 on the collected
trajectories. Our detection pipeline has a worst-case total latency of 4.5 ms,
including computation and perception - significantly lower than a frame-based
30 FPS system, which, in the worst case, takes 66 ms solely for perception.
Finally, we fit a trajectory prediction model to the estimated states of the
ball, enabling 3D trajectory forecasting in the future. To the best of our
knowledge, this is the first approach to predict table tennis trajectories from
an egocentric perspective using event cameras.

</details>


### [612] [VIVAT: Virtuous Improving VAE Training through Artifact Mitigation](https://arxiv.org/abs/2506.07863)
*Lev Novitskiy,Viacheslav Vasilev,Maria Kovaleva,Vladimir Arkhipkin,Denis Dimitrov*

Main category: cs.CV

TL;DR: VIVAT 提出了一种减轻 KL-VAE 训练中常见伪影的方法


<details>
  <summary>Details</summary>
Motivation: 训练变分自编码器时会出现降低重建和生成质量的伪影

Method: 通过调整损失权重、填充策略和集成空间条件归一化来修改标准 KL-VAE

Result: 在多个基准测试中实现最先进的图像重建指标（PSNR 和 SSIM），并提高了文本到图像生成质量（CLIP 分数）

Conclusion: VIVAT 为研究人员和从业者提供了优化 VAE 训练的有效见解

Abstract: Variational Autoencoders (VAEs) remain a cornerstone of generative computer
vision, yet their training is often plagued by artifacts that degrade
reconstruction and generation quality. This paper introduces VIVAT, a
systematic approach to mitigating common artifacts in KL-VAE training without
requiring radical architectural changes. We present a detailed taxonomy of five
prevalent artifacts - color shift, grid patterns, blur, corner and droplet
artifacts - and analyze their root causes. Through straightforward
modifications, including adjustments to loss weights, padding strategies, and
the integration of Spatially Conditional Normalization, we demonstrate
significant improvements in VAE performance. Our method achieves
state-of-the-art results in image reconstruction metrics (PSNR and SSIM) across
multiple benchmarks and enhances text-to-image generation quality, as evidenced
by superior CLIP scores. By preserving the simplicity of the KL-VAE framework
while addressing its practical challenges, VIVAT offers actionable insights for
researchers and practitioners aiming to optimize VAE training.

</details>


### [613] [FreeGave: 3D Physics Learning from Dynamic Videos by Gaussian Velocity](https://arxiv.org/abs/2506.07865)
*Jinxi Li,Ziyang Song,Siyuan Zhou,Bo Yang*

Main category: cs.CV

TL;DR: FreeGave从多视角视频中建模3D场景的几何、外观和物理，无需物体先验（如掩码或类型）。通过引入物理编码和发散自由模块来估计每高斯速度场，避免了低效的PDE损失。实验证明其在未来帧外推和运动分割上具有优越性，且学习的物理编码能捕获无标签的3D物理运动模式。


<details>
  <summary>Details</summary>
Motivation: 现有方法使用物理偏微分方程（PDE）作为PINN损失或结合物理模拟到神经网络中，但常无法学习复杂边界物理运动或需物体先验（如掩码或类型）。本文旨在无需这类先验即可学习复杂动态3D场景的物理特性。

Method: 提出FreeGave方法：引入物理编码和设计的发散自由模块，通过估计每个高斯点的速度场来建模物理运动，避免依赖PINN损失。

Result: 在三个公共数据集和一个新收集的挑战性真实数据集上验证：方法在未来帧外推和运动分割上表现优越；学习的物理编码能捕获无监督的3D物理运动模式。

Conclusion: FreeGave首次实现了无物体先验的动态3D场景物理建模，通过高效速度场估计避免了传统PINN的缺陷，且学到的物理编码具有可解释性。

Abstract: In this paper, we aim to model 3D scene geometry, appearance, and the
underlying physics purely from multi-view videos. By applying various governing
PDEs as PINN losses or incorporating physics simulation into neural networks,
existing works often fail to learn complex physical motions at boundaries or
require object priors such as masks or types. In this paper, we propose
FreeGave to learn the physics of complex dynamic 3D scenes without needing any
object priors. The key to our approach is to introduce a physics code followed
by a carefully designed divergence-free module for estimating a per-Gaussian
velocity field, without relying on the inefficient PINN losses. Extensive
experiments on three public datasets and a newly collected challenging
real-world dataset demonstrate the superior performance of our method for
future frame extrapolation and motion segmentation. Most notably, our
investigation into the learned physics codes reveals that they truly learn
meaningful 3D physical motion patterns in the absence of any human labels in
training.

</details>


### [614] [Spatio-Temporal State Space Model For Efficient Event-Based Optical Flow](https://arxiv.org/abs/2506.07878)
*Muhammad Ahmed Humais,Xiaoqian Huang,Hussain Sajwani,Sajid Javed,Yahya Zweiri*

Main category: cs.CV

TL;DR: 本文提出了一种新的时空状态空间模型（STSSM）模块和网络架构，用于事件相机的高效运动估计（光流）。该方法相比ViT和CNN在类似配置下性能更高、复杂度更低，相比TMA推理速度快4.5倍、计算量少8倍，较EV-FlowNet计算量少2倍，在DSEC基准上性能相当。


<details>
  <summary>Details</summary>
Motivation: 事件相机在低延迟运动估计中存在算法计算效率问题：深度学习范式（CNN、RNN、ViT）效率不足，而异步事件方法（SNNs、GNNs）无法充分捕捉时空信息。

Method: 引入时空状态空间模型（STSSM）模块及新网络架构，利用状态空间模型有效捕捉事件数据中的时空相关性。

Result: 在DSEC基准测试显示，计算量比EV-FlowNet少2倍，比TMA少8倍；推理速度比TMA快4.5倍；性能与现有方法相当。

Conclusion: STSSM模块能够在保持竞争力的性能同时显著提升计算效率和推理速度，为实时应用提供高效光流估算解决方案。

Abstract: Event cameras unlock new frontiers that were previously unthinkable with
standard frame-based cameras. One notable example is low-latency motion
estimation (optical flow), which is critical for many real-time applications.
In such applications, the computational efficiency of algorithms is paramount.
Although recent deep learning paradigms such as CNN, RNN, or ViT have shown
remarkable performance, they often lack the desired computational efficiency.
Conversely, asynchronous event-based methods including SNNs and GNNs are
computationally efficient; however, these approaches fail to capture sufficient
spatio-temporal information, a powerful feature required to achieve better
performance for optical flow estimation. In this work, we introduce
Spatio-Temporal State Space Model (STSSM) module along with a novel network
architecture to develop an extremely efficient solution with competitive
performance. Our STSSM module leverages state-space models to effectively
capture spatio-temporal correlations in event data, offering higher performance
with lower complexity compared to ViT, CNN-based architectures in similar
settings. Our model achieves 4.5x faster inference and 8x lower computations
compared to TMA and 2x lower computations compared to EV-FlowNet with
competitive performance on the DSEC benchmark. Our code will be available at
https://github.com/AhmedHumais/E-STMFlow

</details>


### [615] [CrosswalkNet: An Optimized Deep Learning Framework for Pedestrian Crosswalk Detection in Aerial Images with High-Performance Computing](https://arxiv.org/abs/2506.07885)
*Zubin Bhuyan,Yuanchang Xie,AngkeaReach Rith,Xintong Yan,Nasko Apostolov,Jimi Oke,Chengbo Ai*

Main category: cs.CV

TL;DR: CrosswalkNet: Robust deep learning framework using oriented bounding boxes for precise crosswalk detection from aerial images, achieving high precision and recall.


<details>
  <summary>Details</summary>
Motivation: Deep learning potential for transportation asset management and pedestrian safety.

Method: Utilizes OBB with attention mechanisms and optimization techniques.

Result: 96.5% precision and 93.3% recall on MA data with strong generalization.

Conclusion: Efficient real-time analysis solution enhancing pedestrian safety and urban planning.

Abstract: With the increasing availability of aerial and satellite imagery, deep
learning presents significant potential for transportation asset management,
safety analysis, and urban planning. This study introduces CrosswalkNet, a
robust and efficient deep learning framework designed to detect various types
of pedestrian crosswalks from 15-cm resolution aerial images. CrosswalkNet
incorporates a novel detection approach that improves upon traditional object
detection strategies by utilizing oriented bounding boxes (OBB), enhancing
detection precision by accurately capturing crosswalks regardless of their
orientation. Several optimization techniques, including Convolutional Block
Attention, a dual-branch Spatial Pyramid Pooling-Fast module, and cosine
annealing, are implemented to maximize performance and efficiency. A
comprehensive dataset comprising over 23,000 annotated crosswalk instances is
utilized to train and validate the proposed framework. The best-performing
model achieves an impressive precision of 96.5% and a recall of 93.3% on aerial
imagery from Massachusetts, demonstrating its accuracy and effectiveness.
CrosswalkNet has also been successfully applied to datasets from New Hampshire,
Virginia, and Maine without transfer learning or fine-tuning, showcasing its
robustness and strong generalization capability. Additionally, the crosswalk
detection results, processed using High-Performance Computing (HPC) platforms
and provided in polygon shapefile format, have been shown to accelerate data
processing and detection, supporting real-time analysis for safety and mobility
applications. This integration offers policymakers, transportation engineers,
and urban planners an effective instrument to enhance pedestrian safety and
improve urban mobility.

</details>


### [616] [EgoM2P: Egocentric Multimodal Multitask Pretraining](https://arxiv.org/abs/2506.07886)
*Gen Li,Yutong Chen,Yiqian Wu,Kaifeng Zhao,Marc Pollefeys,Siyu Tang*

Main category: cs.CV

TL;DR: 提出 EgoM2P 统一框架解决第一人称视频的多模态异构难题，通过时间感知token和掩码建模实现多任务处理，性能媲美专用模型且速度快10倍。


<details>
  <summary>Details</summary>
Motivation: 第一人称视觉(如RGB视频/深度/相机位姿/视线)的数据存在模态覆盖不均、伪标签难生成、动态运动复杂等问题，导致现有多模态基础模型难以直接应用。

Method: 设计高效时间分词器，构建基于掩码建模的EgoM2P框架，通过时间感知多模态token联合训练，支持视线预测/相机追踪/深度估计等任务。

Result: 在多任务上匹配或超越专用模型，速度快一个数量级；同时具备条件视频合成能力。

Conclusion: EgoM2P为第一人称4D理解提供通用解决方案，将开源推动领域发展。

Abstract: Understanding multimodal signals in egocentric vision, such as RGB video,
depth, camera poses, and gaze, is essential for applications in augmented
reality, robotics, and human-computer interaction. These capabilities enable
systems to better interpret the camera wearer's actions, intentions, and
surrounding environment. However, building large-scale egocentric multimodal
and multitask models presents unique challenges. Egocentric data are inherently
heterogeneous, with large variations in modality coverage across devices and
settings. Generating pseudo-labels for missing modalities, such as gaze or
head-mounted camera trajectories, is often infeasible, making standard
supervised learning approaches difficult to scale. Furthermore, dynamic camera
motion and the complex temporal and spatial structure of first-person video
pose additional challenges for the direct application of existing multimodal
foundation models.
  To address these challenges, we introduce a set of efficient temporal
tokenizers and propose EgoM2P, a masked modeling framework that learns from
temporally aware multimodal tokens to train a large, general-purpose model for
egocentric 4D understanding. This unified design supports multitasking across
diverse egocentric perception and synthesis tasks, including gaze prediction,
egocentric camera tracking, and monocular depth estimation from egocentric
video. EgoM2P also serves as a generative model for conditional egocentric
video synthesis. Across these tasks, EgoM2P matches or outperforms specialist
models while being an order of magnitude faster. We will fully open-source
EgoM2P to support the community and advance egocentric vision research. Project
page: https://egom2p.github.io/

</details>


### [617] [Video Unlearning via Low-Rank Refusal Vector](https://arxiv.org/abs/2506.07891)
*Simone Facchiano,Stefano Saravalle,Matteo Migliarini,Edoardo De Matteis,Alessio Sampieri,Andrea Pilzer,Emanuele Rodolà,Indro Spinelli,Luca Franco,Fabio Galasso*

Main category: cs.CV

TL;DR: VideoUnlearn：一种新颖的视频扩散模型遗忘框架，仅需5个多模态提示对即可有效消除有害概念，同时保持视频生成质量。


<details>
  <summary>Details</summary>
Motivation: 视频生成模型可能复现网络训练数据中的偏见和非法内容，急需解决有害概念生成风险。

Method: 提出'拒绝向量'机制：计算成对安全/不安全提示在模型各层的潜在差异平均值，通过低秩协方差分解精确定位目标概念，直接修改模型参数实现概念遗忘。

Result: 能覆盖各种非法内容(色情/暴力/版权侵权等)，在保持生成质量的前提下显著降低有害内容输出，且抗对抗攻击性强。

Conclusion: 首次实现视频扩散模型的无害化改造，无需原始数据/重新训练；为生成模型安全部署提供高效解决方案。

Abstract: Video generative models democratize the creation of visual content through
intuitive instruction following, but they also inherit the biases and harmful
concepts embedded within their web-scale training data. This inheritance
creates a significant risk, as users can readily generate undesirable and even
illegal content. This work introduces the first unlearning technique tailored
explicitly for video diffusion models to address this critical issue. Our
method requires 5 multi-modal prompt pairs only. Each pair contains a "safe"
and an "unsafe" example that differ only by the target concept. Averaging their
per-layer latent differences produces a "refusal vector", which, once
subtracted from the model parameters, neutralizes the unsafe concept. We
introduce a novel low-rank factorization approach on the covariance difference
of embeddings that yields robust refusal vectors. This isolates the target
concept while minimizing collateral unlearning of other semantics, thus
preserving the visual quality of the generated video. Our method preserves the
model's generation quality while operating without retraining or access to the
original training data. By embedding the refusal direction directly into the
model's weights, the suppression mechanism becomes inherently more robust
against adversarial bypass attempts compared to surface-level input-output
filters. In a thorough qualitative and quantitative evaluation, we show that we
can neutralize a variety of harmful contents, including explicit nudity,
graphic violence, copyrights, and trademarks. Project page:
https://www.pinlab.org/video-unlearning.

</details>


### [618] [WeThink: Toward General-purpose Vision-Language Reasoning via Reinforcement Learning](https://arxiv.org/abs/2506.07905)
*Jie Yang,Feipeng Ma,Zitian Wang,Dacheng Yin,Kang Rong,Fengyun Rao,Ruimao Zhang*

Main category: cs.CV

TL;DR: 提出了WeThink数据集和自动化数据生成流程，用于增强多模态大语言模型（MLLM）的通用视觉语言推理能力


<details>
  <summary>Details</summary>
Motivation: 现有方法局限于特定领域（如数学和视觉感知），缺乏通用视觉语言推理的强化学习训练方案

Method: 1. 可扩展多模态QA合成流程（自动生成基于图像的推理QA对） 2. 开源包含120K样本的WeThink数据集 3. 混合奖励机制的强化学习训练（结合规则验证和模型评估）

Result: 在14个MLLM基准测试中全面提升性能，数学推理和通用多模态任务表现均有显著提高

Conclusion: 自动化数据管道能持续提升数据多样性，WeThink数据集可有效增强MLLM的通用推理能力

Abstract: Building on the success of text-based reasoning models like DeepSeek-R1,
extending these capabilities to multimodal reasoning holds great promise. While
recent works have attempted to adapt DeepSeek-R1-style reinforcement learning
(RL) training paradigms to multimodal large language models (MLLM), focusing on
domain-specific tasks like math and visual perception, a critical question
remains: How can we achieve the general-purpose visual-language reasoning
through RL? To address this challenge, we make three key efforts: (1) A novel
Scalable Multimodal QA Synthesis pipeline that autonomously generates
context-aware, reasoning-centric question-answer (QA) pairs directly from the
given images. (2) The open-source WeThink dataset containing over 120K
multimodal QA pairs with annotated reasoning paths, curated from 18 diverse
dataset sources and covering various question domains. (3) A comprehensive
exploration of RL on our dataset, incorporating a hybrid reward mechanism that
combines rule-based verification with model-based assessment to optimize RL
training efficiency across various task domains. Across 14 diverse MLLM
benchmarks, we demonstrate that our WeThink dataset significantly enhances
performance, from mathematical reasoning to diverse general multimodal tasks.
Moreover, we show that our automated data pipeline can continuously increase
data diversity to further improve model performance.

</details>


### [619] [A Comparative Study of U-Net Architectures for Change Detection in Satellite Images](https://arxiv.org/abs/2506.07925)
*Yaxita Amin,Naimisha S Trivedi,Rashmi Bhattad*

Main category: cs.CV

TL;DR: 本文通过系统综述34篇论文,全面分析了18种U-Net变体在遥感变化检测中的应用潜力,重点评估了专门设计的变体(如孪生网络)在时序数据处理和远程依赖捕获方面的优劣,为研究者提供模型选型参考。


<details>
  <summary>Details</summary>
Motivation: 尽管U-Net在图像分割中表现出色,但其在遥感变化检测领域的应用潜力尚未充分挖掘,本研究旨在填补这一空白。

Method: 通过对比分析34篇文献中的18种U-Net变体,评估各变体在遥感变化检测任务中的性能表现与适用性,特别关注专门设计的架构(如Siamese Swin-U-Net)。

Result: 研究发现时序数据处理能力和远程依赖建模是提升变化检测精度的关键因素,专门设计的变体(如孪生网络)在此类任务中表现突出。

Conclusion: 该研究为遥感变化检测任务中的U-Net模型选择提供了重要指导,强调应优先考虑具备时序数据处理和长距离关系捕捉能力的架构变体。

Abstract: Remote sensing change detection is essential for monitoring the everchanging
landscapes of the Earth. The U-Net architecture has gained popularity for its
capability to capture spatial information and perform pixel-wise
classification. However, their application in the Remote sensing field remains
largely unexplored. Therefore, this paper fill the gap by conducting a
comprehensive analysis of 34 papers. This study conducts a comparison and
analysis of 18 different U-Net variations, assessing their potential for
detecting changes in remote sensing. We evaluate both benefits along with
drawbacks of each variation within the framework of this particular
application. We emphasize variations that are explicitly built for change
detection, such as Siamese Swin-U-Net, which utilizes a Siamese architecture.
The analysis highlights the significance of aspects such as managing data from
different time periods and collecting relationships over a long distance to
enhance the precision of change detection. This study provides valuable
insights for researchers and practitioners that choose U-Net versions for
remote sensing change detection tasks.

</details>


### [620] [Mimicking or Reasoning: Rethinking Multi-Modal In-Context Learning in Vision-Language Models](https://arxiv.org/abs/2506.07936)
*Chengyue Huang,Yuchen Zhu,Sichen Zhu,Jingyun Xiao,Moises Andrade,Shivang Chopra,Zsolt Kira*

Main category: cs.CV

TL;DR: 论文研究了视觉语言模型(VLM)在分布偏移下的多模态上下文学习(MM-ICL)能力，发现模型表现随演示样本增加而下降，并倾向于复制答案而非真正学习。通过引入带推理的MM-ICL管道进行实验，发现当前VLM无法有效利用演示信息。


<details>
  <summary>Details</summary>
Motivation: 现有研究认为视觉语言模型具备类似纯语言模型的上下文学习能力，但实际发现它们依赖浅层启发式策略（如答案复制或多数投票）而非真正的任务理解。该研究旨在通过分布偏移场景重新评估该假设。

Method: 提出'带推理的多模态上下文学习(MM-ICL)'新流程：为每个演示样本生成解释性文本（rationale）配合答案。在多个需要感知与推理的数据集上，系统测试了3B到72B规模的开源VLM及Gemini 2.0等商业模型，控制变量包括演示样本数量、检索方法、rationale质量和分布偏移程度。

Result: 模型表现常随演示样本增加而下降，呈现明显的答案复制倾向。在受控实验中，模型性能对演示样本数量、检索方法等关键因素均不敏感，表明现有多模态上下文学习机制未被有效利用。

Conclusion: 当前视觉语言模型尚未真正掌握多模态上下文学习能力，难以从演示样本中提取任务相关信息。研究揭示了现有方法的局限，为未来改进模型的多模态学习机制提供了方向。

Abstract: Vision-language models (VLMs) are widely assumed to exhibit in-context
learning (ICL), a property similar to that of their language-only counterparts.
While recent work suggests VLMs can perform multimodal ICL (MM-ICL), studies
show they often rely on shallow heuristics -- such as copying or majority
voting -- rather than true task understanding. We revisit this assumption by
evaluating VLMs under distribution shifts, where support examples come from a
dataset different from the query. Surprisingly, performance often degrades with
more demonstrations, and models tend to copy answers rather than learn from
them. To investigate further, we propose a new MM-ICL with Reasoning pipeline
that augments each demonstration with a generated rationale alongside the
answer. We conduct extensive and comprehensive experiments on both perception-
and reasoning-required datasets with open-source VLMs ranging from 3B to 72B
and proprietary models such as Gemini 2.0. We conduct controlled studies
varying shot count, retrieval method, rationale quality, and distribution. Our
results show limited performance sensitivity across these factors, suggesting
that current VLMs do not effectively utilize demonstration-level information as
intended in MM-ICL.

</details>


### [621] [Decoupling the Image Perception and Multimodal Reasoning for Reasoning Segmentation with Digital Twin Representations](https://arxiv.org/abs/2506.07943)
*Yizhen Li,Dell Zhang,Xuelong Li,Yiqing Shen*

Main category: cs.CV

TL;DR: 提出了一种名为DTwinSeger的推理分割新方法，通过引入数字孪生表示作为中间层，将感知与推理解耦。该方法首先将图像转换成结构化数字孪生表示，然后使用大型语言模型基于该表示进行推理。实验证明该方法在多个基准上达到最先进性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法通过微调视觉语言模型处理推理分割任务，但图像token化破坏了对象间的空间连续性。为保留空间关系并提升多模态推理能力，需要新的解决方案。

Method: 两阶段框架：1) 图像转结构化数字孪生表示(DT) 2) 使用微调的LLM在DT表示上进行显式推理。创新点包括提出Seg-DT微调数据集和专门调优方法。

Result: 在两个图像推理分割基准和三个图像指代表达分割基准上取得state-of-the-art性能，证明DT表示能作为视觉与文本的有效桥梁。

Conclusion: 数字孪生表示能有效连接视觉与文本模态，使纯LLM能完成复杂多模态推理任务，为多模态理解提供了新范式。

Abstract: Reasoning Segmentation (RS) is a multimodal vision-text task that requires
segmenting objects based on implicit text queries, demanding both precise
visual perception and vision-text reasoning capabilities. Current RS approaches
rely on fine-tuning vision-language models (VLMs) for both perception and
reasoning, but their tokenization of images fundamentally disrupts continuous
spatial relationships between objects. We introduce DTwinSeger, a novel RS
approach that leverages Digital Twin (DT) representation as an intermediate
layer to decouple perception from reasoning. Innovatively, DTwinSeger
reformulates RS as a two-stage process, where the first transforms the image
into a structured DT representation that preserves spatial relationships and
semantic properties and then employs a Large Language Model (LLM) to perform
explicit reasoning over this representation to identify target objects. We
propose a supervised fine-tuning method specifically for LLM with DT
representation, together with a corresponding fine-tuning dataset Seg-DT, to
enhance the LLM's reasoning capabilities with DT representations. Experiments
show that our method can achieve state-of-the-art performance on two image RS
benchmarks and three image referring segmentation benchmarks. It yields that DT
representation functions as an effective bridge between vision and text,
enabling complex multimodal reasoning tasks to be accomplished solely with an
LLM.

</details>


### [622] [Creating a Historical Migration Dataset from Finnish Church Records, 1800-1920](https://arxiv.org/abs/2506.07960)
*Ari Vesalainen,Jenna Kanerva,Aida Nitsch,Kiia Korsu,Ilari Larkiola,Laura Ruotsalainen,Filip Ginter*

Main category: cs.CV

TL;DR: 构建了1800-1920年间芬兰国内迁移的结构化数据集，利用深度学习流程自动化提取教堂迁移记录中的600多万条数据，支持历史与人口研究。


<details>
  <summary>Details</summary>
Motivation: 利用教会保存的人口迁移原始手写记录，为研究前工业时代芬兰的内部迁移、城市化、家族迁移及疾病传播提供数据支持。

Method: 通过深度学习管线实现自动化数据处理：包括布局分析、表格检测、单元格分类、手写文字识别，应用于20万张手写记录图像。

Result: 成功创建含600万条目的结构化数据集，并以埃利迈基教区的案例研究验证了当地迁移历史的重建可行性。

Conclusion: 该方法证明能够将大量手写档案转化为结构化数据，推动历史与人口学研究，为类似档案处理提供了可扩展的技术方案。

Abstract: This article presents a large-scale effort to create a structured dataset of
internal migration in Finland between 1800 and 1920 using digitized church
moving records. These records, maintained by Evangelical-Lutheran parishes,
document the migration of individuals and families and offer a valuable source
for studying historical demographic patterns. The dataset includes over six
million entries extracted from approximately 200,000 images of handwritten
migration records.
  The data extraction process was automated using a deep learning pipeline that
included layout analysis, table detection, cell classification, and handwriting
recognition. The complete pipeline was applied to all images, resulting in a
structured dataset suitable for research.
  The dataset can be used to study internal migration, urbanization, and family
migration, and the spread of disease in preindustrial Finland. A case study
from the Elim\"aki parish shows how local migration histories can be
reconstructed. The work demonstrates how large volumes of handwritten archival
material can be transformed into structured data to support historical and
demographic research.

</details>


### [623] [SlideCoder: Layout-aware RAG-enhanced Hierarchical Slide Generation from Design](https://arxiv.org/abs/2506.07964)
*Wenxin Tang,Jingyu Xiao,Wenxuan Jiang,Xi Xiao,Yuhang Wang,Xuxin Tang,Qing Li,Yuehe Ma,Junliang Liu,Shisong Tang,Michael R. Lyu*

Main category: cs.CV

TL;DR: 本文提出Slide2Code和SlideCoder框架，解决传统手动制作幻灯片耗时且现有LLM方法难以捕捉视觉设计的问题。


<details>
  <summary>Details</summary>
Motivation: 手动制作幻灯片耗时且需要专业知识；现有基于自然语言的LLM生成方法难以捕捉幻灯片视觉和结构细微差异。

Method: 1) 提出基于彩色梯度分割算法和分层检索增强生成的框架SlideCoder；2) 发布新数据集Slide2Code和开源模型SlideMaster；

Result: SlideCoder在布局保真度、执行准确率和视觉一致性上超越SOTA基线40.5分

Conclusion: SlideCoder通过视觉编码和层级任务分解，显著提升可编辑幻灯片的生成质量

Abstract: Manual slide creation is labor-intensive and requires expert prior knowledge.
Existing natural language-based LLM generation methods struggle to capture the
visual and structural nuances of slide designs. To address this, we formalize
the Reference Image to Slide Generation task and propose Slide2Code, the first
benchmark with difficulty-tiered samples based on a novel Slide Complexity
Metric. We introduce SlideCoder, a layout-aware, retrieval-augmented framework
for generating editable slides from reference images. SlideCoder integrates a
Color Gradient-based Segmentation algorithm and a Hierarchical
Retrieval-Augmented Generation method to decompose complex tasks and enhance
code generation. We also release SlideMaster, a 7B open-source model fine-tuned
with improved reverse-engineered data. Experiments show that SlideCoder
outperforms state-of-the-art baselines by up to 40.5 points, demonstrating
strong performance across layout fidelity, execution accuracy, and visual
consistency. Our code is available at
https://github.com/vinsontang1/SlideCoder.

</details>


### [624] [SpaCE-10: A Comprehensive Benchmark for Multimodal Large Language Models in Compositional Spatial Intelligence](https://arxiv.org/abs/2506.07966)
*Ziyang Gong,Wenhao Li,Oliver Ma,Songyuan Li,Jiayi Ji,Xue Yang,Gen Luo,Junchi Yan,Rongrong Ji*

Main category: cs.CV

TL;DR: SpaCE-10是一个用于评估MLLMs空间智能的基准测试，包含10种原子空间能力和8种组合能力，通过超过5k对QA对在真实室内场景中测试，发现当前MLLMs与人类表现存在显著差距。


<details>
  <summary>Details</summary>
Motivation: 现有基准难以全面评估MLLMs从原子层面到组合层面的空间智能，因此开发SpaCE-10填补空白。

Method: 定义10种原子空间能力和8种组合能力，采用分层标注流程生成高质量多样化QA对，使用811个真实室内场景和点云输入等设置。

Result: 最先进的MLLMs仍大幅落后人类表现，其中计数能力的短板显著限制了组合空间能力。

Conclusion: SpaCE-10揭示了MLLMs空间智能的不足，尤其是指出计数能力对组合能力的关键影响，为社区提供重要洞见。

Abstract: Multimodal Large Language Models (MLLMs) have achieved remarkable progress in
various multimodal tasks. To pursue higher intelligence in space, MLLMs require
integrating multiple atomic spatial capabilities to handle complex and dynamic
tasks. However, existing benchmarks struggle to comprehensively evaluate the
spatial intelligence of common MLLMs from the atomic level to the compositional
level. To fill this gap, we present SpaCE-10, a comprehensive benchmark for
compositional spatial evaluations. In SpaCE-10, we define 10 atomic spatial
capabilities, which are combined to form 8 compositional capabilities. Based on
these definitions, we propose a novel hierarchical annotation pipeline to
generate high-quality and diverse question-answer (QA) pairs. With over 150+
hours of human expert effort, we obtain over 5k QA pairs for 811 real indoor
scenes in SpaCE-10, which covers various evaluation settings like point cloud
input and multi-choice QA. We conduct an extensive evaluation of common MLLMs
on SpaCE-10 and find that even the most advanced MLLM still lags behind humans
by large margins. Through our careful study, we also draw several significant
findings that benefit the MLLM community. For example, we reveal that the
shortcoming of counting capability greatly limits the compositional spatial
capabilities of existing MLLMs. The evaluation code and benchmark datasets are
available at https://github.com/Cuzyoung/SpaCE-10.

</details>


### [625] [CyberV: Cybernetics for Test-time Scaling in Video Understanding](https://arxiv.org/abs/2506.07971)
*Jiahao Meng,Shuyang Sun,Yue Tan,Lu Qi,Yunhai Tong,Xiangtai Li,Longyin Wen*

Main category: cs.CV

TL;DR: 提出了一个名为 CyberV 的框架，该框架通过控制论原则增强视频 MLLMs，实现实时监控、纠错和资源分配，显著提升现有模型的视频理解性能


<details>
  <summary>Details</summary>
Motivation: 解决现有视频 MLLMs 在推理时计算量大、鲁棒性差、准确率有限的问题

Method: 引入控制论循环系统，由 MLLM 推理系统、传感器和控制器组成，传感器监控模型中间状态，控制器触发纠错机制

Result: 在 VideoMMMU 上分别提升 Qwen2.5-VL-7B 和 InternVL3-8B 模型达 8.3% 和 5.5%；Qwen2.5-VL-72B 获得 10% 提升达到接近人类专家水平

Conclusion: 无需重训练即可显著增强视频 MLLMs 的鲁棒性和准确性，在多个通用基准测试上表现出良好的泛化能力

Abstract: Current Multimodal Large Language Models (MLLMs) may struggle with
understanding long or complex videos due to computational demands at test time,
lack of robustness, and limited accuracy, primarily stemming from their
feed-forward processing nature. These limitations could be more severe for
models with fewer parameters. To address these limitations, we propose a novel
framework inspired by cybernetic principles, redesigning video MLLMs as
adaptive systems capable of self-monitoring, self-correction, and dynamic
resource allocation during inference. Our approach, CyberV, introduces a
cybernetic loop consisting of an MLLM Inference System, a Sensor, and a
Controller. Specifically, the sensor monitors forward processes of the MLLM and
collects intermediate interpretations, such as attention drift, then the
controller determines when and how to trigger self-correction and generate
feedback to guide the next round. This test-time adaptive scaling framework
enhances frozen MLLMs without requiring retraining or additional components.
Experiments demonstrate significant improvements: CyberV boosts Qwen2.5-VL-7B
by 8.3% and InternVL3-8B by 5.5% on VideoMMMU, surpassing the competitive
proprietary model GPT-4o. When applied to Qwen2.5-VL-72B, it yields a 10.0%
improvement, achieving performance even comparable to human experts.
Furthermore, our method demonstrates consistent gains on general-purpose
benchmarks, such as VideoMME and WorldSense, highlighting its effectiveness and
generalization capabilities in making MLLMs more robust and accurate for
dynamic video understanding. The code is released at
https://github.com/marinero4972/CyberV.

</details>


### [626] [OneIG-Bench: Omni-dimensional Nuanced Evaluation for Image Generation](https://arxiv.org/abs/2506.07977)
*Jingjing Chang,Yixiao Fang,Peng Xing,Shuhan Wu,Wei Cheng,Rui Wang,Xianfang Zeng,Gang Yu,Hai-Bao Chen*

Main category: cs.CV

TL;DR: 介绍了OneIG-Bench评估框架，用于多维度测试文生图能力，特别关注当前T2I模型在推理和精细化生成方面的进展需求


<details>
  <summary>Details</summary>
Motivation: 当前的T2I模型测试基准不够全面，特别是在推理性、文本渲染和艺术风格等方面存在缺失；同时，顶级模型在推理能力展示上的进步尚未被评测体系充分衡量

Method: 提出的OneIG-Bench包含五个维度评估体系（prompt-image alignment, text rendering, reasoning, stylization, diversity），支持模块化子维度测试

Result: 通过结构化测评实现全流程模型能力定位，公开代码和数据集可支持复现研究和跨模型比较

Conclusion: 该框架填补了现有评测体系的空白，为T2I模型的精细化评估和瓶颈诊断提供了系统化工具

Abstract: Text-to-image (T2I) models have garnered significant attention for generating
high-quality images aligned with text prompts. However, rapid T2I model
advancements reveal limitations in early benchmarks, lacking comprehensive
evaluations, for example, the evaluation on reasoning, text rendering and
style. Notably, recent state-of-the-art models, with their rich knowledge
modeling capabilities, show promising results on the image generation problems
requiring strong reasoning ability, yet existing evaluation systems have not
adequately addressed this frontier. To systematically address these gaps, we
introduce OneIG-Bench, a meticulously designed comprehensive benchmark
framework for fine-grained evaluation of T2I models across multiple dimensions,
including prompt-image alignment, text rendering precision, reasoning-generated
content, stylization, and diversity. By structuring the evaluation, this
benchmark enables in-depth analysis of model performance, helping researchers
and practitioners pinpoint strengths and bottlenecks in the full pipeline of
image generation. Specifically, OneIG-Bench enables flexible evaluation by
allowing users to focus on a particular evaluation subset. Instead of
generating images for the entire set of prompts, users can generate images only
for the prompts associated with the selected dimension and complete the
corresponding evaluation accordingly. Our codebase and dataset are now publicly
available to facilitate reproducible evaluation studies and cross-model
comparisons within the T2I research community.

</details>


### [627] [Real-time Localization of a Soccer Ball from a Single Camera](https://arxiv.org/abs/2506.07981)
*Dmitrii Vorobev,Artem Prosvetov,Karim Elhadji Daou*

Main category: cs.CV

TL;DR: 本文提出了一种高效的单目广播摄像机实时重建三维足球轨迹的方法，通过多模态状态模型加速优化并保持厘米级精度，适用于复杂场景且无需多摄像机系统。


<details>
  <summary>Details</summary>
Motivation: 现有方法在实时性、成本或复杂场景（如遮挡、运动模糊）下表现不足，需要开发一种既高效又准确的解决方案，适用于普通CPU的单摄像机系统。

Method: 使用多模态状态模型（含W个离散模式）优化轨迹重建算法，显著降低计算复杂度，实现在标准CPU上的实时处理。

Result: 在俄超联赛专有数据集（6K分辨率）上验证，性能媲美多摄像机系统，厘米级精度，且能处理严重遮挡和运动模糊。系统延迟低，适用于直播场景。

Conclusion: 该方法为职业足球环境提供了一种无需昂贵设备、仅用单目广播视频即可实现的实用三维足球追踪方案，兼具高准确性与可及性。

Abstract: We propose a computationally efficient method for real-time three-dimensional
football trajectory reconstruction from a single broadcast camera. In contrast
to previous work, our approach introduces a multi-mode state model with $W$
discrete modes to significantly accelerate optimization while preserving
centimeter-level accuracy -- even in cases of severe occlusion, motion blur,
and complex backgrounds. The system operates on standard CPUs and achieves low
latency suitable for live broadcast settings. Extensive evaluation on a
proprietary dataset of 6K-resolution Russian Premier League matches
demonstrates performance comparable to multi-camera systems, without the need
for specialized or costly infrastructure. This work provides a practical method
for accessible and accurate 3D ball tracking in professional football
environments.

</details>


### [628] [CXR-LT 2024: A MICCAI challenge on long-tailed, multi-label, and zero-shot disease classification from chest X-ray](https://arxiv.org/abs/2506.07984)
*Mingquan Lin,Gregory Holste,Song Wang,Yiliang Zhou,Yishu Wei,Imon Banerjee,Pengyi Chen,Tianjie Dai,Yuexi Du,Nicha C. Dvornek,Yuyan Ge,Zuowei Guo,Shouhei Hanaoka,Dongkyun Kim,Pablo Messina,Yang Lu,Denis Parra,Donghyun Son,Álvaro Soto,Aisha Urooj,René Vidal,Yosuke Yamagishi,Zefan Yang,Ruichi Zhang,Yang Zhou,Leo Anthony Celi,Ronald M. Summers,Zhiyong Lu,Hao Chen,Adam Flanders,George Shih,Zhangyang Wang,Yifan Peng*

Main category: cs.CV

TL;DR: CXR-LT 2024是一个社区驱动的项目，扩展了胸部X光数据集至377,110张影像和45种疾病标签，新增19种罕见病种。它推出了三个任务：长尾分类（含噪声测试集和黄金标准子集）、零样本泛化（针对新疾病），并整合了多模态模型、生成式方法和零样本学习等先进方案，以提升胸部X光疾病分类的临床实用性。


<details>
  <summary>Details</summary>
Motivation: 解决开放长尾肺部疾病分类的挑战，提升现有技术的可测量性，并通过扩大数据集和增加新任务（特别是零样本学习）来改进临床适应性。

Method: 1. 扩展数据集至377,110张CXR影像和45种疾病标签，含19种新罕见疾病。2. 设计三个任务：长尾分类（噪声测试集）、长尾分类（黄金标准子集）、零样本泛化（5种未见疾病）。3. 整合多模态模型检测罕见病、生成式方法处理噪声标签、零样本策略应对新疾病。

Result: 提供了更全面的疾病覆盖数据集（更贴近真实临床环境），汇总了最先进的解决方案（如多模态模型、生成式去噪、零样本泛化），为胸部X光诊断模型的临床泛化性奠定基础。

Conclusion: CXR-LT 2024通过扩大数据集和引入新任务，推动了临床实用诊断模型的发展；多技术整合（尤其零样本学习）有望提升模型对新疾病和噪声数据的鲁棒性，加速胸部X光分析的进步。

Abstract: The CXR-LT series is a community-driven initiative designed to enhance lung
disease classification using chest X-rays (CXR). It tackles challenges in open
long-tailed lung disease classification and enhances the measurability of
state-of-the-art techniques. The first event, CXR-LT 2023, aimed to achieve
these goals by providing high-quality benchmark CXR data for model development
and conducting comprehensive evaluations to identify ongoing issues impacting
lung disease classification performance. Building on the success of CXR-LT
2023, the CXR-LT 2024 expands the dataset to 377,110 chest X-rays (CXRs) and 45
disease labels, including 19 new rare disease findings. It also introduces a
new focus on zero-shot learning to address limitations identified in the
previous event. Specifically, CXR-LT 2024 features three tasks: (i) long-tailed
classification on a large, noisy test set, (ii) long-tailed classification on a
manually annotated "gold standard" subset, and (iii) zero-shot generalization
to five previously unseen disease findings. This paper provides an overview of
CXR-LT 2024, detailing the data curation process and consolidating
state-of-the-art solutions, including the use of multimodal models for rare
disease detection, advanced generative approaches to handle noisy labels, and
zero-shot learning strategies for unseen diseases. Additionally, the expanded
dataset enhances disease coverage to better represent real-world clinical
settings, offering a valuable resource for future research. By synthesizing the
insights and innovations of participating teams, we aim to advance the
development of clinically realistic and generalizable diagnostic models for
chest radiography.

</details>


### [629] [Rethinking Crowd-Sourced Evaluation of Neuron Explanations](https://arxiv.org/abs/2506.07985)
*Tuomas Oikarinen,Ge Yan,Akshay Kulkarni,Tsui-Wei Weng*

Main category: cs.CV

TL;DR: 本文提出了一种成本效益高且准确的人群评估策略，用于评估神经元解释方法的可靠性。通过重要性采样减少了约30倍的成本，并通过贝叶斯方法聚合评分进一步减少了约5倍的所需评分数量。最后，利用这些方法比较了两种视觉模型中流行神经元解释方法的质量。


<details>
  <summary>Details</summary>
Motivation: 现有的神经元解释方法评估通常依赖人群评估，但这种方法噪声大、成本高且结果不可靠。因此，需要开发一种更有效、更准确的人群评估策略来分析神经元解释方法的可靠性。

Method: 1. 引入重要性采样方法选择最具评估价值的输入样本，减少评估成本；2. 提出贝叶斯方法聚合多个评分，降低由于评估者个体差异带来的噪声；3. 利用优化后的方法比较两种视觉模型中流行神经元解释方法的质量。

Result: 1. 重要性采样策略降低了约30倍的成本；2. 贝叶斯聚合评分方法进一步将所需评分数量减少了约5倍；3. 通过该方法成功比较了多种流行神经元解释方法在两种视觉模型上的性能。

Conclusion: 本研究开发的人群神经元解释评估方法大幅降低了评估成本并提高了准确性，为神经元解释的有效性和可靠性评估提供了可行的分析框架，有助于推动可解释性研究的进展。

Abstract: Interpreting individual neurons or directions in activations space is an
important component of mechanistic interpretability. As such, many algorithms
have been proposed to automatically produce neuron explanations, but it is
often not clear how reliable these explanations are, or which methods produce
the best explanations. This can be measured via crowd-sourced evaluations, but
they can often be noisy and expensive, leading to unreliable results. In this
paper, we carefully analyze the evaluation pipeline and develop a
cost-effective and highly accurate crowdsourced evaluation strategy. In
contrast to previous human studies that only rate whether the explanation
matches the most highly activating inputs, we estimate whether the explanation
describes neuron activations across all inputs. To estimate this effectively,
we introduce a novel application of importance sampling to determine which
inputs are the most valuable to show to raters, leading to around 30x cost
reduction compared to uniform sampling. We also analyze the label noise present
in crowd-sourced evaluations and propose a Bayesian method to aggregate
multiple ratings leading to a further ~5x reduction in number of ratings
required for the same accuracy. Finally, we use these methods to conduct a
large-scale study comparing the quality of neuron explanations produced by the
most popular methods for two different vision models.

</details>


### [630] [Rethinking Cross-Modal Interaction in Multimodal Diffusion Transformers](https://arxiv.org/abs/2506.07986)
*Zhengyao Lv,Tianlin Pan,Chenyang Si,Zhaoxi Chen,Wangmeng Zuo,Ziwei Liu,Kwan-Yee K. Wong*

Main category: cs.CV

TL;DR: 该论文提出了温度调整跨模态注意力(TACA)方法，以解决多模态扩散变换器(MM-DiT)在文本生成图像任务中的模态失衡问题，通过动态调节注意力权重显著提升了文本-图像对齐效果。


<details>
  <summary>Details</summary>
Motivation: 现有MM-DiT模型（如FLUX）由于视觉与文本模态间的token数量失衡（导致跨模态注意力被抑制），以及缺乏时间步感知的注意力加权机制，导致文本提示与生成内容对齐不精准。

Method: 提出参数高效的TACA方法：1）通过温度缩放动态平衡跨模态交互；2）引入时间步依赖的注意力权重调整机制。结合LoRA微调在FLUX/SD3.5等模型上实现。

Result: 在T2I-CompBench基准测试中显著提升文本-图像对齐效果（特别是物体外观、属性绑定和空间关系），计算开销极低。代码已开源。

Conclusion: 跨模态注意力平衡对提升扩散模型语义保真度至关重要，TACA通过简单的架构修改即可有效解决现有模型的注意力失衡问题，具有强泛化性。

Abstract: Multimodal Diffusion Transformers (MM-DiTs) have achieved remarkable progress
in text-driven visual generation. However, even state-of-the-art MM-DiT models
like FLUX struggle with achieving precise alignment between text prompts and
generated content. We identify two key issues in the attention mechanism of
MM-DiT, namely 1) the suppression of cross-modal attention due to token
imbalance between visual and textual modalities and 2) the lack of
timestep-aware attention weighting, which hinder the alignment. To address
these issues, we propose \textbf{Temperature-Adjusted Cross-modal Attention
(TACA)}, a parameter-efficient method that dynamically rebalances multimodal
interactions through temperature scaling and timestep-dependent adjustment.
When combined with LoRA fine-tuning, TACA significantly enhances text-image
alignment on the T2I-CompBench benchmark with minimal computational overhead.
We tested TACA on state-of-the-art models like FLUX and SD3.5, demonstrating
its ability to improve image-text alignment in terms of object appearance,
attribute binding, and spatial relationships. Our findings highlight the
importance of balancing cross-modal attention in improving semantic fidelity in
text-to-image diffusion models. Our codes are publicly available at
\href{https://github.com/Vchitect/TACA}

</details>


### [631] [PairEdit: Learning Semantic Variations for Exemplar-based Image Editing](https://arxiv.org/abs/2506.07992)
*Haoguang Lu,Jiacheng Chen,Zhenguo Yang,Aurele Tohokantche Gnanha,Fu Lee Wang,Li Qing,Xudong Mao*

Main category: cs.CV

TL;DR: PairEdit是一种无文本指导的视觉编辑方法，可从少量图像对中学习复杂编辑语义。通过目标噪声预测、内容保留噪声调度和优化独立LoRA模块，该方法在保持内容一致性的同时有效学习语义变换。


<details>
  <summary>Details</summary>
Motivation: 现有基于示例的图像编辑方法依赖文本描述变化，但对某些编辑语义难以精确文本化。本文提出直接从图像对中学习编辑语义，避免文本描述的局限性。

Method: 1) 提出目标噪声预测显式建模图像对语义变化 2) 设计内容保留噪声调度优化语义学习 3) 优化独立LoRA模块解耦语义变化与内容学习

Result: 定性与定量实验表明，PairEdit能有效学习复杂语义变换，相比基线方法显著提升内容一致性。

Conclusion: PairEdit证明了仅通过视觉示例学习编辑语义的可行性，为难以文本化的编辑任务提供了新解决方案。

Abstract: Recent advancements in text-guided image editing have achieved notable
success by leveraging natural language prompts for fine-grained semantic
control. However, certain editing semantics are challenging to specify
precisely using textual descriptions alone. A practical alternative involves
learning editing semantics from paired source-target examples. Existing
exemplar-based editing methods still rely on text prompts describing the change
within paired examples or learning implicit text-based editing instructions. In
this paper, we introduce PairEdit, a novel visual editing method designed to
effectively learn complex editing semantics from a limited number of image
pairs or even a single image pair, without using any textual guidance. We
propose a target noise prediction that explicitly models semantic variations
within paired images through a guidance direction term. Moreover, we introduce
a content-preserving noise schedule to facilitate more effective semantic
learning. We also propose optimizing distinct LoRAs to disentangle the learning
of semantic variations from content. Extensive qualitative and quantitative
evaluations demonstrate that PairEdit successfully learns intricate semantics
while significantly improving content consistency compared to baseline methods.
Code will be available at https://github.com/xudonmao/PairEdit.

</details>


### [632] [UA-Pose: Uncertainty-Aware 6D Object Pose Estimation and Online Object Completion with Partial References](https://arxiv.org/abs/2506.07996)
*Ming-Feng Li,Xin Yang,Fu-En Wang,Hritam Basak,Yuyin Sun,Shreekant Gayaka,Min Sun,Cheng-Hao Kuo*

Main category: cs.CV

TL;DR: UA-Pose是一个不确定性感知的6D物体姿态估计方法，针对部分参考信息（如少数RGBD图像或单张2D图像）设计了在线物体补全功能，在物体观测不完整时显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有6D姿态估计方法需要完整的3D模型或大量覆盖物体全貌的参考图像。为解决部分参考（只捕获物体局部外观几何）带来的挑战，开发了该不确定性感知框架。

Method: 1) 基于少量RBGD图像或单张2D图像生成初始部分3D模型；2) 在模型上标注不确定性（区分已观察/未观察区域）；3) 基于不确定性的姿态置信度评估；4) 不确定性感知采样策略实现在线物体补全。

Result: 在YCB-Video、YCBInEOAT和HO3D数据集上验证：在物体观测不完整时，姿态估计精度和物体完整性均显著优于现有方法。

Conclusion: UA-Pose通过显式建模部分参考的不确定性，有效提升了不完整观测条件下的6D姿态估计鲁棒性，并推动在线物体补全。

Abstract: 6D object pose estimation has shown strong generalizability to novel objects.
However, existing methods often require either a complete, well-reconstructed
3D model or numerous reference images that fully cover the object. Estimating
6D poses from partial references, which capture only fragments of an object's
appearance and geometry, remains challenging. To address this, we propose
UA-Pose, an uncertainty-aware approach for 6D object pose estimation and online
object completion specifically designed for partial references. We assume
access to either (1) a limited set of RGBD images with known poses or (2) a
single 2D image. For the first case, we initialize a partial object 3D model
based on the provided images and poses, while for the second, we use
image-to-3D techniques to generate an initial object 3D model. Our method
integrates uncertainty into the incomplete 3D model, distinguishing between
seen and unseen regions. This uncertainty enables confidence assessment in pose
estimation and guides an uncertainty-aware sampling strategy for online object
completion, enhancing robustness in pose estimation accuracy and improving
object completeness. We evaluate our method on the YCB-Video, YCBInEOAT, and
HO3D datasets, including RGBD sequences of YCB objects manipulated by robots
and human hands. Experimental results demonstrate significant performance
improvements over existing methods, particularly when object observations are
incomplete or partially captured. Project page:
https://minfenli.github.io/UA-Pose/

</details>


### [633] [MADFormer: Mixed Autoregressive and Diffusion Transformers for Continuous Image Generation](https://arxiv.org/abs/2506.07999)
*Junhao Chen,Yulia Tsvetkov,Xiaochuang Han*

Main category: cs.CV

TL;DR: MADFormer提出了一种混合自回归和扩散Transformer模型，用于分析自回归与扩散模型的权衡。通过空间块划分，全局使用自回归层进行条件处理，局部使用扩散层进行迭代细化。实验表明，块划分显著提升高分辨率图像的生成质量，混合策略在受限计算下改善FID达75%。


<details>
  <summary>Details</summary>
Motivation: 现有混合模型缺乏系统性的框架来分配自回归（擅长长距离依赖和流畅输出）与扩散模型（擅长高保真细节）的容量。需要一种可分析二者权衡的方法论。

Method: 提出MADFormer：将图像划分为空间块，使用自回归层进行全局块间条件处理（单次前向），在每个块内部使用扩散层进行局部迭代细化。

Result: 在FFHQ-1024和ImageNet上的实验表明：1) 块划分显著提升高分辨率图像性能；2) 纵向混合策略在计算受限时提升FID达75%，优化了质量-效率平衡。

Conclusion: 块划分和垂直混合层是有效的设计原则，为未来混合生成模型提供实践指导。

Abstract: Recent progress in multimodal generation has increasingly combined
autoregressive (AR) and diffusion-based approaches, leveraging their
complementary strengths: AR models capture long-range dependencies and produce
fluent, context-aware outputs, while diffusion models operate in continuous
latent spaces to refine high-fidelity visual details. However, existing hybrids
often lack systematic guidance on how and why to allocate model capacity
between these paradigms. In this work, we introduce MADFormer, a Mixed
Autoregressive and Diffusion Transformer that serves as a testbed for analyzing
AR-diffusion trade-offs. MADFormer partitions image generation into spatial
blocks, using AR layers for one-pass global conditioning across blocks and
diffusion layers for iterative local refinement within each block. Through
controlled experiments on FFHQ-1024 and ImageNet, we identify two key insights:
(1) block-wise partitioning significantly improves performance on
high-resolution images, and (2) vertically mixing AR and diffusion layers
yields better quality-efficiency balances--improving FID by up to 75% under
constrained inference compute. Our findings offer practical design principles
for future hybrid generative models.

</details>


### [634] [Aligning Text, Images, and 3D Structure Token-by-Token](https://arxiv.org/abs/2506.08002)
*Aadarsh Sahoo,Vansh Tibrewal,Georgia Gkioxari*

Main category: cs.CV

TL;DR: 提出了一种名为KYVO的统一LLM框架，将语言、图像和3D场景对齐，并在多个3D任务和数据集上进行评估。


<details>
  <summary>Details</summary>
Motivation: 构建能够理解3D世界的机器对于辅助设计3D环境的用户以及在3D空间中导航交互的机器人至关重要。

Method: 参考语言和图像建模的进展，研究自回归模型在结构化3D场景中的应用。通过详细的设计指南解决数据表示、模态特定目标等关键问题。

Result: 模型在四个核心3D任务（渲染、识别、指令跟随和问答）以及四个3D数据集上展现出有效性。通过量化形状编码重构复杂3D物体形状。

Conclusion: 所提出的框架能有效统一多种模态信息处理，在真实世界3D物体识别任务中表现优良，证明其应用于3D场景理解和交互的潜力。

Abstract: Creating machines capable of understanding the world in 3D is essential in
assisting designers that build and edit 3D environments and robots navigating
and interacting within a three-dimensional space. Inspired by advances in
language and image modeling, we investigate the potential of autoregressive
models for a new modality: structured 3D scenes. To this end, we propose a
unified LLM framework that aligns language, images, and 3D scenes and provide a
detailed ''cookbook'' outlining critical design choices for achieving optimal
training and performance addressing key questions related to data
representation, modality-specific objectives, and more. We evaluate performance
across four core 3D tasks -- rendering, recognition, instruction-following, and
question-answering -- and four 3D datasets, synthetic and real-world. We extend
our approach to reconstruct complex 3D object shapes by enriching our 3D
modality with quantized shape encodings, and show our model's effectiveness on
real-world 3D object recognition tasks. Project webpage:
https://glab-caltech.github.io/kyvo/

</details>


### [635] [Audio-Sync Video Generation with Multi-Stream Temporal Control](https://arxiv.org/abs/2506.08003)
*Shuchen Weng,Haojie Zheng,Zheng Chang,Si Li,Boxin Shi,Xinlong Wang*

Main category: cs.CV

TL;DR: 提出MTV框架，通过分离音频轨实现细粒度视频生成，并引入DEMIX数据集支持训练，在多个指标上达到SOTA。


<details>
  <summary>Details</summary>
Motivation: 利用音频作为控制信号生成视频，但现有方法难以在多样复杂音频上同步高质量视频。

Method: MTV框架将音频分离为语音、音效和音乐三条轨道，分别控制口型、事件时序和视觉氛围；并提出DEMIX数据集。

Result: 在六个评估视频质量、文本一致性及音视频同步性的指标上实现SOTA性能。

Conclusion: 通过音轨解耦控制和高质量数据集，有效提升多类型音频的同步视频生成能力。

Abstract: Audio is inherently temporal and closely synchronized with the visual world,
making it a naturally aligned and expressive control signal for controllable
video generation (e.g., movies). Beyond control, directly translating audio
into video is essential for understanding and visualizing rich audio narratives
(e.g., Podcasts or historical recordings). However, existing approaches fall
short in generating high-quality videos with precise audio-visual
synchronization, especially across diverse and complex audio types. In this
work, we introduce MTV, a versatile framework for audio-sync video generation.
MTV explicitly separates audios into speech, effects, and music tracks,
enabling disentangled control over lip motion, event timing, and visual mood,
respectively -- resulting in fine-grained and semantically aligned video
generation. To support the framework, we additionally present DEMIX, a dataset
comprising high-quality cinematic videos and demixed audio tracks. DEMIX is
structured into five overlapped subsets, enabling scalable multi-stage training
for diverse generation scenarios. Extensive experiments demonstrate that MTV
achieves state-of-the-art performance across six standard metrics spanning
video quality, text-video consistency, and audio-video alignment. Project page:
https://hjzheng.net/projects/MTV/.

</details>


### [636] [Dynamic View Synthesis as an Inverse Problem](https://arxiv.org/abs/2506.08004)
*Hidir Yesiltepe,Pinar Yanardag*

Main category: cs.CV

TL;DR: 这篇论文提出了一种无需训练的动态视图合成方法，通过改进预训练视频扩散模型的噪声初始化，解决了单目视频中动态场景的视图合成问题。


<details>
  <summary>Details</summary>
Motivation: 传统方法需要大量训练数据或辅助模块进行动态视图合成。本文旨在避免权重更新或辅助模块，直接在预训练模型上实现高保真合成。

Method: 1. 提出K阶递归噪声表示（K-order Recursive Noise Representation），解决零终端SNR计划导致的反演障碍；2. 推导闭合形式表达式，精确对齐VAE编码与DDIM反演潜在空间；3. 引入随机潜在调制（Stochastic Latent Modulation）进行可见性感知采样，补全遮挡区域。

Result: 通过结构化噪声初始化阶段的操作，实现了有效的动态视图合成。综合实验验证了新方法在单目视频上的有效性。

Conclusion: 重设计预训练扩散模型的噪声初始化阶段可实现训练自由的动态视图合成，新提出的噪声表示和潜在采样机制解决了核心挑战。

Abstract: In this work, we address dynamic view synthesis from monocular videos as an
inverse problem in a training-free setting. By redesigning the noise
initialization phase of a pre-trained video diffusion model, we enable
high-fidelity dynamic view synthesis without any weight updates or auxiliary
modules. We begin by identifying a fundamental obstacle to deterministic
inversion arising from zero-terminal signal-to-noise ratio (SNR) schedules and
resolve it by introducing a novel noise representation, termed K-order
Recursive Noise Representation. We derive a closed form expression for this
representation, enabling precise and efficient alignment between the
VAE-encoded and the DDIM inverted latents. To synthesize newly visible regions
resulting from camera motion, we introduce Stochastic Latent Modulation, which
performs visibility aware sampling over the latent space to complete occluded
regions. Comprehensive experiments demonstrate that dynamic view synthesis can
be effectively performed through structured latent manipulation in the noise
initialization phase.

</details>


### [637] [ZeroVO: Visual Odometry with Minimal Assumptions](https://arxiv.org/abs/2506.08005)
*Lei Lai,Zekai Yin,Eshed Ohn-Bar*

Main category: cs.CV

TL;DR: ZeroVO is a零样本视觉里程计算法，无需相机标定或微调即可泛化至各种摄像机和环境，通过几何感知网络、语言先验和半监督训练在多个基准测试中提高30%以上。


<details>
  <summary>Details</summary>
Motivation: 现有视觉里程计方法依赖预定义或静态相机标定，难以适应不同摄像机和环境，限制了实际应用。ZeroVO旨在解决这一泛化性问题。

Method: 提出三项创新：1）抗噪声的几何感知网络 2）引入语言先验增强特征泛化 3）利用无标签数据的半监督自适应训练范式。

Result: 在KITTI、nuScenes、Argoverse 2及GTA合成数据集上超越现有方法30%以上，且无需微调或相机标定。

Conclusion: 该工作显著拓宽了视觉里程计的适用性，为零样本跨域部署提供通用解决方案。

Abstract: We introduce ZeroVO, a novel visual odometry (VO) algorithm that achieves
zero-shot generalization across diverse cameras and environments, overcoming
limitations in existing methods that depend on predefined or static camera
calibration setups. Our approach incorporates three main innovations. First, we
design a calibration-free, geometry-aware network structure capable of handling
noise in estimated depth and camera parameters. Second, we introduce a
language-based prior that infuses semantic information to enhance robust
feature extraction and generalization to previously unseen domains. Third, we
develop a flexible, semi-supervised training paradigm that iteratively adapts
to new scenes using unlabeled data, further boosting the models' ability to
generalize across diverse real-world scenarios. We analyze complex autonomous
driving contexts, demonstrating over 30% improvement against prior methods on
three standard benchmarks, KITTI, nuScenes, and Argoverse 2, as well as a newly
introduced, high-fidelity synthetic dataset derived from Grand Theft Auto
(GTA). By not requiring fine-tuning or camera calibration, our work broadens
the applicability of VO, providing a versatile solution for real-world
deployment at scale.

</details>


### [638] [Dreamland: Controllable World Creation with Simulator and Generative Models](https://arxiv.org/abs/2506.08006)
*Sicheng Mo,Ziyang Leng,Leon Liu,Weizhen Wang,Honglin He,Bolei Zhou*

Main category: cs.CV

TL;DR: Dreamland是一个混合世界生成框架，结合物理模拟器的颗粒控制和预训练生成模型的真实输出，通过分层世界抽象提升可控性并降低适应成本。实验显示其在图像质量和可控性上优于基线模型。


<details>
  <summary>Details</summary>
Motivation: 现有大规模视频生成模型缺乏对元素的细粒度控制，限制了其在场景编辑和具身智能体训练中的应用。

Method: 设计了编码像素级和物体级语义与几何的分层世界抽象作为中间表示，桥接模拟器与生成模型，利用D3Sim数据集进行训练评估。

Result: 在图像质量上提升50.8%，可控性增强达17.9%，并证明能有效提升具身智能体的训练效果。

Conclusion: 该框架显著增强了生成内容的可控性和质量，支持即插即用现有及未来的预训练模型，代码与数据将开源。

Abstract: Large-scale video generative models can synthesize diverse and realistic
visual content for dynamic world creation, but they often lack element-wise
controllability, hindering their use in editing scenes and training embodied AI
agents. We propose Dreamland, a hybrid world generation framework combining the
granular control of a physics-based simulator and the photorealistic content
output of large-scale pretrained generative models. In particular, we design a
layered world abstraction that encodes both pixel-level and object-level
semantics and geometry as an intermediate representation to bridge the
simulator and the generative model. This approach enhances controllability,
minimizes adaptation cost through early alignment with real-world
distributions, and supports off-the-shelf use of existing and future pretrained
generative models. We further construct a D3Sim dataset to facilitate the
training and evaluation of hybrid generation pipelines. Experiments demonstrate
that Dreamland outperforms existing baselines with 50.8% improved image
quality, 17.9% stronger controllability, and has great potential to enhance
embodied agent training. Code and data will be made available.

</details>


### [639] [Hidden in plain sight: VLMs overlook their visual representations](https://arxiv.org/abs/2506.08008)
*Stephanie Fu,Tyler Bonnen,Devin Guillory,Trevor Darrell*

Main category: cs.CV

TL;DR: 研究表明，视觉语言模型（VLMs）在整合视觉和语言信息方面存在不足，其在视觉中心任务（如深度估计、对应关系等）上的表现显著低于其视觉编码器的直接输出，并接近随机水平。分析发现，问题主要在于VLMs未能有效利用模型中的视觉信息，且继承了大型语言模型（LLM）的语言先验。


<details>
  <summary>Details</summary>
Motivation: 为了探索语言作为指定和评估视觉任务性能的自然接口的潜力，需要研究VLMs如何有效整合视觉和语言模态。本研究旨在比较VLMs与其视觉编码器的性能，以理解这种跨模态整合的能力。

Method: 通过一系列视觉中心基准测试（如深度估计、对应关系等），比较VLMs与其视觉编码器在相同任务上的性能。同时，从三个方面对VLM进行系统性分析：1) 视觉表征的退化程度；2) 对任务提示的脆弱性；3) 语言模型在完成任务中的作用。

Result: VLMs在所有测试的视觉中心任务中表现显著劣于其视觉编码器（接近随机水平）。关键发现是：视觉信息在模型各处可获取但未被有效利用，且LLM的语言先验被继承到VLMs中，导致任务失败。

Conclusion: VLMs在视觉中心任务上的瓶颈主要源于语言模型未能有效利用可获取的视觉信息，并受限于LLM的语言先验。本工作为开源VLMs的故障模式提供了诊断方法，并提出系列评估标准以促进未来VLMs的视觉理解研究。

Abstract: Language provides a natural interface to specify and evaluate performance on
visual tasks. To realize this possibility, vision language models (VLMs) must
successfully integrate visual and linguistic information. Our work compares
VLMs to a direct readout of their visual encoders to understand their ability
to integrate across these modalities. Across a series of vision-centric
benchmarks (e.g., depth estimation, correspondence), we find that VLMs perform
substantially worse than their visual encoders, dropping to near-chance
performance. We investigate these results through a series of analyses across
the entire VLM: namely 1) the degradation of vision representations, 2)
brittleness to task prompt, and 3) the language model's role in solving the
task. We find that the bottleneck in performing these vision-centric tasks lies
in this third category; VLMs are not effectively using visual information
easily accessible throughout the entire model, and they inherit the language
priors present in the LLM. Our work helps diagnose the failure modes of
open-source VLMs, and presents a series of evaluations useful for future
investigations into visual understanding within VLMs.

</details>


### [640] [Self Forcing: Bridging the Train-Test Gap in Autoregressive Video Diffusion](https://arxiv.org/abs/2506.08009)
*Xun Huang,Zhengqi Li,Guande He,Mingyuan Zhou,Eli Shechtman*

Main category: cs.CV

TL;DR: 提出了Self Forcing训练范式，用于自回归视频扩散模型，解决了推断时基于自身不完美输出生成序列的曝光偏差问题。通过训练时使用KV缓存进行自回归展开，实现视频级别的整体监督损失。引入梯度截断和滚动KV缓存，在单GPU上实现亚秒延迟的实时流视频生成，质量媲美更慢的非因果模型。


<details>
  <summary>Details</summary>
Motivation: 传统模型在推理时使用自身生成的不完美帧作为上下文，而训练时使用真实帧，导致曝光偏差问题。这会使误差在生成过程中积累。Self Forcing通过在训练时让模型基于自身之前生成的帧预测后续帧来解决此问题。

Method: 1. 训练过程中使用KV缓存进行自回归展开：每个帧基于自身生成的上下文生成，而非真实帧。2. 使用多步扩散模型结合随机梯度截断策略平衡计算效率。3. 滚动KV缓存机制用于高效的自回归视频外推。

Result: 1. 单GPU实现亚秒级延迟的实时流视频生成。2. 生成质量匹配或超过计算量更大的非因果扩散模型。

Conclusion: Self Forcing通过端到端优化整个生成序列，解决了自回归视频生成的曝光偏差问题，在效率和质量上取得突破。训练策略与滚动缓存机制的组合实现了实时性能，为流式视频应用提供可能。

Abstract: We introduce Self Forcing, a novel training paradigm for autoregressive video
diffusion models. It addresses the longstanding issue of exposure bias, where
models trained on ground-truth context must generate sequences conditioned on
their own imperfect outputs during inference. Unlike prior methods that denoise
future frames based on ground-truth context frames, Self Forcing conditions
each frame's generation on previously self-generated outputs by performing
autoregressive rollout with key-value (KV) caching during training. This
strategy enables supervision through a holistic loss at the video level that
directly evaluates the quality of the entire generated sequence, rather than
relying solely on traditional frame-wise objectives. To ensure training
efficiency, we employ a few-step diffusion model along with a stochastic
gradient truncation strategy, effectively balancing computational cost and
performance. We further introduce a rolling KV cache mechanism that enables
efficient autoregressive video extrapolation. Extensive experiments demonstrate
that our approach achieves real-time streaming video generation with sub-second
latency on a single GPU, while matching or even surpassing the generation
quality of significantly slower and non-causal diffusion models. Project
website: http://self-forcing.github.io/

</details>


### [641] [Vision Transformers Don't Need Trained Registers](https://arxiv.org/abs/2506.08010)
*Nick Jiang,Amil Dravid,Alexei Efros,Yossi Gandelsman*

Main category: cs.CV

TL;DR: 该论文研究了Vision Transformers中高范数令牌（outlier tokens）导致注意力图噪声的现象，并发现少数神经元（register neurons）对此负责。作者提出了一种无需重新训练的测试时解决方案，通过将高范数激活转移到额外的未训练令牌中来模拟注册令牌效果，从而提升模型性能和可解释性。


<details>
  <summary>Details</summary>
Motivation: Vision Transformers中观察到的outlier tokens会导致注意力图噪声和下游任务性能下降，而现有解决方案需要从头训练模型。本文旨在发现这一现象机制，并开发无需重新训练的测试时方法。

Method: 1. 识别导致高范数激活的稀疏神经元（register neurons）；2. 将高范数激活转移到额外的未训练令牌（test-time register）；3. 在CLIP、DINOv2等预训练模型上直接应用，无需微调。

Result: 1. 注意力图和特征图更加清晰；2. 在多种下游视觉任务上提升基础模型性能；3. 达到与显式训练注册令牌模型相当的结果；4. 增强视觉语言模型可解释性。

Conclusion: 测试时注册令牌可有效模拟训练注册令牌的作用，为没有注册令牌的预训练模型提供零成本部署方案。这一方法具有普适性，显著提高模型性能和可解释性。

Abstract: We investigate the mechanism underlying a previously identified phenomenon in
Vision Transformers -- the emergence of high-norm tokens that lead to noisy
attention maps. We observe that in multiple models (e.g., CLIP, DINOv2), a
sparse set of neurons is responsible for concentrating high-norm activations on
outlier tokens, leading to irregular attention patterns and degrading
downstream visual processing. While the existing solution for removing these
outliers involves retraining models from scratch with additional learned
register tokens, we use our findings to create a training-free approach to
mitigate these artifacts. By shifting the high-norm activations from our
discovered register neurons into an additional untrained token, we can mimic
the effect of register tokens on a model already trained without registers. We
demonstrate that our method produces cleaner attention and feature maps,
enhances performance over base models across multiple downstream visual tasks,
and achieves results comparable to models explicitly trained with register
tokens. We then extend test-time registers to off-the-shelf vision-language
models to improve their interpretability. Our results suggest that test-time
registers effectively take on the role of register tokens at test-time,
offering a training-free solution for any pre-trained model released without
them.

</details>


### [642] [Play to Generalize: Learning to Reason Through Game Play](https://arxiv.org/abs/2506.08011)
*Yunfei Xie,Yinsong Ma,Shiyi Lan,Alan Yuille,Junfei Xiao,Chen Wei*

Main category: cs.CV

TL;DR: ViGaL: 通过在休闲游戏中进行强化学习训练,提升多模态大语言模型的泛化推理能力


<details>
  <summary>Details</summary>
Motivation: 受认知科学研究启发,利用游戏促进可迁移认知能力,解决多模态大语言模型泛化推理能力不足的问题

Method: 提出ViGaL后训练范式: 让MLLM在Snake等简单街机游戏上通过强化学习训练,不依赖参考答案或方程图解

Result: 1. 在MathVista等多模态数学基准和MMMU多学科问题上显著提升性能
2. 超越针对推理数据调优的专用模型
3. 保持基础模型在通用视觉基准的表现

Conclusion: 基于规则的游戏可作为可控、可扩展的预训练任务,解锁MLLM的泛化多模态推理能力

Abstract: Developing generalizable reasoning capabilities in multimodal large language
models (MLLMs) remains challenging. Motivated by cognitive science literature
suggesting that gameplay promotes transferable cognitive skills, we propose a
novel post-training paradigm, Visual Game Learning, or ViGaL, where MLLMs
develop out-of-domain generalization of multimodal reasoning through playing
arcade-like games. Specifically, we show that post-training a 7B-parameter MLLM
via reinforcement learning (RL) on simple arcade-like games, e.g. Snake,
significantly enhances its downstream performance on multimodal math benchmarks
like MathVista, and on multi-discipline questions like MMMU, without seeing any
worked solutions, equations, or diagrams during RL, suggesting the capture of
transferable reasoning skills. Remarkably, our model outperforms specialist
models tuned on multimodal reasoning data in multimodal reasoning benchmarks,
while preserving the base model's performance on general visual benchmarks, a
challenge where specialist models often fall short. Our findings suggest a new
post-training paradigm: synthetic, rule-based games can serve as controllable
and scalable pre-text tasks that unlock generalizable multimodal reasoning
abilities in MLLMs.

</details>


### [643] [StableMTL: Repurposing Latent Diffusion Models for Multi-Task Learning from Partially Annotated Synthetic Datasets](https://arxiv.org/abs/2506.08013)
*Anh-Quan Cao,Ivan Lopes,Raoul de Charette*

Main category: cs.CV

TL;DR: 提出了一种名为StableMTL的多任务学习方法，能够在仅部分任务标注的合成数据集上进行训练实现零样本多任务学习。


<details>
  <summary>Details</summary>
Motivation: 多任务密集预测学习通常需要大量全标注数据，但实际应用中获取所有任务的完整标注成本高昂。本文旨在利用扩散模型的泛化能力，探索仅使用部分任务标注的合成数据集进行多任务模型训练的机会。

Method: 1. 将图像生成器用于潜在空间回归任务
2. 采用任务编码、基于任务的调节机制和定制训练方案
3. 使用统一潜在损失替代需手动平衡的多任务损失
4. 设计带任务注意力机制的多流模型，通过1:N注意力实现任务交互协同

Result: 在8个基准测试的7个任务上超越基线模型（具体数值详见原文）

Conclusion: StableMTL成功证明了：1）可扩展的零样本多任务学习框架 2）任务注意力机制能有效促进跨任务知识共享 3）统一潜在损失简化多任务优化

Abstract: Multi-task learning for dense prediction is limited by the need for extensive
annotation for every task, though recent works have explored training with
partial task labels. Leveraging the generalization power of diffusion models,
we extend the partial learning setup to a zero-shot setting, training a
multi-task model on multiple synthetic datasets, each labeled for only a subset
of tasks. Our method, StableMTL, repurposes image generators for latent
regression. Adapting a denoising framework with task encoding, per-task
conditioning and a tailored training scheme. Instead of per-task losses
requiring careful balancing, a unified latent loss is adopted, enabling
seamless scaling to more tasks. To encourage inter-task synergy, we introduce a
multi-stream model with a task-attention mechanism that converts N-to-N task
interactions into efficient 1-to-N attention, promoting effective cross-task
sharing. StableMTL outperforms baselines on 7 tasks across 8 benchmarks.

</details>


### [644] [4DGT: Learning a 4D Gaussian Transformer Using Real-World Monocular Videos](https://arxiv.org/abs/2506.08015)
*Zhen Xu,Zhengqin Li,Zhao Dong,Xiaowei Zhou,Richard Newcombe,Zhaoyang Lv*

Main category: cs.CV

TL;DR: 4DGT is a transformer model using 4D Gaussians for dynamic scene reconstruction from monocular videos, with fast inference and competitive accuracy.


<details>
  <summary>Details</summary>
Motivation: Existing optimization-based methods for dynamic scene reconstruction are slow and cannot handle long sequences efficiently. 4DGT aims to unify static and dynamic components in a single model to handle complex scenes with varying object lifespans.

Method: Proposes a 4D Gaussian-based transformer trained from posed videos, using a novel density control strategy during training to enable handling longer sequences. It processes 64 consecutive frames in a rolling window during inference.

Result: Achieves near real-time rendering (seconds vs hours), outperforms other Gaussian-based methods on real-world videos, and matches optimization-based methods on cross-domain videos.

Conclusion: 4DGT demonstrates that a unified 4D Gaussian representation with transformer architecture enables efficient and accurate dynamic scene reconstruction from monocular videos, significantly improving speed and scalability.

Abstract: We propose 4DGT, a 4D Gaussian-based Transformer model for dynamic scene
reconstruction, trained entirely on real-world monocular posed videos. Using 4D
Gaussian as an inductive bias, 4DGT unifies static and dynamic components,
enabling the modeling of complex, time-varying environments with varying object
lifespans. We proposed a novel density control strategy in training, which
enables our 4DGT to handle longer space-time input and remain efficient
rendering at runtime. Our model processes 64 consecutive posed frames in a
rolling-window fashion, predicting consistent 4D Gaussians in the scene. Unlike
optimization-based methods, 4DGT performs purely feed-forward inference,
reducing reconstruction time from hours to seconds and scaling effectively to
long video sequences. Trained only on large-scale monocular posed video
datasets, 4DGT can outperform prior Gaussian-based networks significantly in
real-world videos and achieve on-par accuracy with optimization-based methods
on cross-domain videos. Project page: https://4dgt.github.io

</details>


<div id='cs.MA'></div>

# cs.MA [[Back]](#toc)

### [645] [G-Memory: Tracing Hierarchical Memory for Multi-Agent Systems](https://arxiv.org/abs/2506.07398)
*Guibin Zhang,Muxin Fu,Guancheng Wan,Miao Yu,Kun Wang,Shuicheng Yan*

Main category: cs.MA

TL;DR: 该论文介绍了G-Memory，一种为多智能体系统设计的层次化记忆架构，通过三层图结构（洞察图、查询图、交互图）解决现有方法忽视智能体协作轨迹和缺乏跨任务定制记忆的问题。实验表明在5个基准测试中提升成功率高达20.89%。


<details>
  <summary>Details</summary>
Motivation: 现有多智能体系统内存机制过于简单，忽视智能体间协作轨迹，且缺乏跨任务和智能体定制的表达能力，无法支持系统自我演进。

Method: 提出G-Memory三级图式记忆架构：1）洞察图捕捉高层通用知识 2）查询图组织任务模式 3）交互图压缩存储细粒度协作轨迹。通过双向记忆检索机制提取跨任务知识和历史协作经验。

Result: 在5个基准、3个LLM主干和3个主流MAS框架上的实验显示：1）具身行动任务成功率提升高达20.89% 2）知识问答准确率提高10.12% 3）无需修改原框架即可部署。

Conclusion: G-Memory首次将组织记忆理论引入MAS领域，通过结构化存档协作轨迹实现系统自我演进，其层次化设计显著提升多智能体性能并开辟记忆增强型MAS新研究方向。

Abstract: Large language model (LLM)-powered multi-agent systems (MAS) have
demonstrated cognitive and execution capabilities that far exceed those of
single LLM agents, yet their capacity for self-evolution remains hampered by
underdeveloped memory architectures. Upon close inspection, we are alarmed to
discover that prevailing MAS memory mechanisms (1) are overly simplistic,
completely disregarding the nuanced inter-agent collaboration trajectories, and
(2) lack cross-trial and agent-specific customization, in stark contrast to the
expressive memory developed for single agents. To bridge this gap, we introduce
G-Memory, a hierarchical, agentic memory system for MAS inspired by
organizational memory theory, which manages the lengthy MAS interaction via a
three-tier graph hierarchy: insight, query, and interaction graphs. Upon
receiving a new user query, G-Memory performs bi-directional memory traversal
to retrieve both $\textit{high-level, generalizable insights}$ that enable the
system to leverage cross-trial knowledge, and $\textit{fine-grained, condensed
interaction trajectories}$ that compactly encode prior collaboration
experiences. Upon task execution, the entire hierarchy evolves by assimilating
new collaborative trajectories, nurturing the progressive evolution of agent
teams. Extensive experiments across five benchmarks, three LLM backbones, and
three popular MAS frameworks demonstrate that G-Memory improves success rates
in embodied action and accuracy in knowledge QA by up to $20.89\%$ and
$10.12\%$, respectively, without any modifications to the original frameworks.
Our codes are available at https://github.com/bingreeky/GMemory.

</details>


### [646] [MedChat: A Multi-Agent Framework for Multimodal Diagnosis with Large Language Models](https://arxiv.org/abs/2506.07400)
*Philip Liu,Sparsh Bansal,Jimmy Dinh,Aditya Pawar,Ramani Satishkumar,Shail Desai,Neeraj Gupta,Xin Wang,Shu Hu*

Main category: cs.MA

TL;DR: 提出MedChat框架，融合视觉模型和多角色语言代理，结合导演代理协调工作，以改进青光眼检测报告的准确性和可解释性，解决现有大模型在医疗影像中的幻觉和领域知识不足问题。


<details>
  <summary>Details</summary>
Motivation: 现有医学图像报告系统依赖单一通用大模型，存在幻觉、可解释性差和领域知识不足的问题，无法模拟多学科医疗团队的复杂推理。

Method: 开发多代理框架MedChat：专用视觉模型配合角色定制LLM代理（如数据分析师、报告撰写员等），导演代理协调分工协作。

Result: 构建了可交互的诊断报告平台，提高可靠性并减少幻觉风险，适用于临床与教学场景。GitHub开源代码。

Conclusion: 多代理协同框架能有效结合视觉与语言模型优势，增强医疗诊断的准确性和实用性，为医疗AI协作提供新范式。

Abstract: The integration of deep learning-based glaucoma detection with large language
models (LLMs) presents an automated strategy to mitigate ophthalmologist
shortages and improve clinical reporting efficiency. However, applying general
LLMs to medical imaging remains challenging due to hallucinations, limited
interpretability, and insufficient domain-specific medical knowledge, which can
potentially reduce clinical accuracy. Although recent approaches combining
imaging models with LLM reasoning have improved reporting, they typically rely
on a single generalist agent, restricting their capacity to emulate the diverse
and complex reasoning found in multidisciplinary medical teams. To address
these limitations, we propose MedChat, a multi-agent diagnostic framework and
platform that combines specialized vision models with multiple role-specific
LLM agents, all coordinated by a director agent. This design enhances
reliability, reduces hallucination risk, and enables interactive diagnostic
reporting through an interface tailored for clinical review and educational
use. Code available at https://github.com/Purdue-M2/MedChat.

</details>


### [647] [G-Memory: Tracing Hierarchical Memory for Multi-Agent Systems](https://arxiv.org/abs/2506.07398)
*Guibin Zhang,Muxin Fu,Guancheng Wan,Miao Yu,Kun Wang,Shuicheng Yan*

Main category: cs.MA

TL;DR: 该论文提出了G-Memory，一种用于多智能体系统的分层记忆架构，以解决现有记忆机制过于简单、忽略智能体间协作轨迹以及缺乏跨试验和定制化的问题。通过三层图层次结构管理交互，实现了任务成功率的显著提升。


<details>
  <summary>Details</summary>
Motivation: 现有多智能体系统的记忆机制过于简单，未考虑智能体间复杂的协作轨迹，且缺乏跨试验和特定智能体的定制化记忆能力。这限制了多智能体系统的自我进化能力。

Method: 提出了G-Memory，一个受组织记忆理论启发的分层记忆系统。它使用三层图结构（insight graph, query graph, interaction graph）存储交互，通过双向记忆遍历机制获取高层次洞察和细粒度轨迹。系统在任务执行中持续进化记忆层次。

Result: 在五个基准测试、三种大型语言模型和三种主流多智能体框架上的实验显示，G-Memory在具身动作任务中将成功率提升高达20.89%，在知识问答任务中提升10.12%的准确率，且无需修改原有框架。

Conclusion: G-Memory通过分层图结构有效提升了多智能体系统的记忆能力，使系统能够利用跨试验知识，显著提高任务性能，并支持持续进化。

Abstract: Large language model (LLM)-powered multi-agent systems (MAS) have
demonstrated cognitive and execution capabilities that far exceed those of
single LLM agents, yet their capacity for self-evolution remains hampered by
underdeveloped memory architectures. Upon close inspection, we are alarmed to
discover that prevailing MAS memory mechanisms (1) are overly simplistic,
completely disregarding the nuanced inter-agent collaboration trajectories, and
(2) lack cross-trial and agent-specific customization, in stark contrast to the
expressive memory developed for single agents. To bridge this gap, we introduce
G-Memory, a hierarchical, agentic memory system for MAS inspired by
organizational memory theory, which manages the lengthy MAS interaction via a
three-tier graph hierarchy: insight, query, and interaction graphs. Upon
receiving a new user query, G-Memory performs bi-directional memory traversal
to retrieve both $\textit{high-level, generalizable insights}$ that enable the
system to leverage cross-trial knowledge, and $\textit{fine-grained, condensed
interaction trajectories}$ that compactly encode prior collaboration
experiences. Upon task execution, the entire hierarchy evolves by assimilating
new collaborative trajectories, nurturing the progressive evolution of agent
teams. Extensive experiments across five benchmarks, three LLM backbones, and
three popular MAS frameworks demonstrate that G-Memory improves success rates
in embodied action and accuracy in knowledge QA by up to $20.89\%$ and
$10.12\%$, respectively, without any modifications to the original frameworks.
Our codes are available at https://github.com/bingreeky/GMemory.

</details>


### [648] [MedChat: A Multi-Agent Framework for Multimodal Diagnosis with Large Language Models](https://arxiv.org/abs/2506.07400)
*Philip Liu,Sparsh Bansal,Jimmy Dinh,Aditya Pawar,Ramani Satishkumar,Shail Desai,Neeraj Gupta,Xin Wang,Shu Hu*

Main category: cs.MA

TL;DR: 这篇论文提出了MedChat，一个多智能体诊断框架，结合专门视觉模型和多个特定角色LLM智能体，以解决单一通用智能体在医疗图像报告中的幻觉、解释性不足和多学科推理局限性问题。


<details>
  <summary>Details</summary>
Motivation: 应用通用大语言模型（LLMs）到医疗图像分析时存在幻觉、解释性有限和领域知识不足的问题，现有方法多依赖单一智能体，难以模拟多学科医疗团队的复杂推理过程。

Method: 提出MedChat框架：通过协调智能体（director agent）管理多个专用视觉模型和角色特定的LLM智能体，实现交互式诊断报告生成。

Result: 该设计提升可靠性、减少幻觉风险，并提供适用于临床复核和教育用途的交互界面。代码已开源。

Conclusion: 多智能体框架能有效克服通用LLM在医学影像应用中的缺陷，通过分工协作模拟真实医疗团队工作流，兼具临床实用性和教育价值。

Abstract: The integration of deep learning-based glaucoma detection with large language
models (LLMs) presents an automated strategy to mitigate ophthalmologist
shortages and improve clinical reporting efficiency. However, applying general
LLMs to medical imaging remains challenging due to hallucinations, limited
interpretability, and insufficient domain-specific medical knowledge, which can
potentially reduce clinical accuracy. Although recent approaches combining
imaging models with LLM reasoning have improved reporting, they typically rely
on a single generalist agent, restricting their capacity to emulate the diverse
and complex reasoning found in multidisciplinary medical teams. To address
these limitations, we propose MedChat, a multi-agent diagnostic framework and
platform that combines specialized vision models with multiple role-specific
LLM agents, all coordinated by a director agent. This design enhances
reliability, reduces hallucination risk, and enables interactive diagnostic
reporting through an interface tailored for clinical review and educational
use. Code available at https://github.com/Purdue-M2/MedChat.

</details>


<div id='eess.AS'></div>

# eess.AS [[Back]](#toc)

### [649] [Reducing Object Hallucination in Large Audio-Language Models via Audio-Aware Decoding](https://arxiv.org/abs/2506.07233)
*Tzu-wen Hsu,Ke-Han Lu,Cheng-Han Chiang,Hung-yi Lee*

Main category: eess.AS

TL;DR: 提出了Audio-Aware Decoding（AAD）方法，一种轻量级的推理时策略。该方法使用对比解码机制，通过对比有声和无声上下文下token预测概率的差异，抑制LALMs的音频幻觉。在多个数据集上实现F1分数提升0.046-0.428和QA准确率提升5.4%-10.3%。


<details>
  <summary>Details</summary>
Motivation: 现有大型音频语言模型（LALMs）在音频内容的理解上存在严重幻觉问题，即模型倾向于生成与输入音频无关的内容。为解决这一问题，作者开发了推理阶段的解决方案。

Method: Audio-Aware Decoding（AAD）：在推理阶段使用对比解码技术。核心思路是同时计算带音频输入的logits和无音频输入的logits（仅文本），通过对比二者差异来筛选token——优先选择在音频存在时概率显著提升的token。

Result: 1）在对象幻觉数据集实验中，AAD使三种LALMs的F1分数提升0.046-0.428；2）在通用音频QA数据集Clotho-AQA上提升准确率5.4%-10.3%；3）消融研究验证了各组件的有效性。

Conclusion: 1）AAD方法无需修改模型结构或进行训练，仅在推理阶段实施即可显著缓解音频幻觉；2）对比解码机制有效捕获音频关键性token；3）该方法在多种任务中具有普适性。

Abstract: Large Audio-Language Models (LALMs) can take audio and text as the inputs and
answer questions about the audio. While prior LALMs have shown strong
performance on standard benchmarks, there has been alarming evidence that LALMs
can hallucinate what is presented in the audio. To mitigate the hallucination
of LALMs, we introduce Audio-Aware Decoding (AAD), a lightweight inference-time
strategy that uses contrastive decoding to compare the token prediction logits
with and without the audio context. By contrastive decoding, AAD promotes the
tokens whose probability increases when the audio is present. We conduct our
experiment on object hallucination datasets with three LALMs and show that AAD
improves the F1 score by 0.046 to 0.428. We also show that AAD can improve the
accuracy on general audio QA datasets like Clotho-AQA by 5.4% to 10.3%. We
conduct thorough ablation studies to understand the effectiveness of each
component in AAD.

</details>


### [650] [Speaker-Distinguishable CTC: Learning Speaker Distinction Using CTC for Multi-Talker Speech Recognition](https://arxiv.org/abs/2506.07515)
*Asahi Sakuma,Hiroaki Sato,Ryuga Sugano,Tadashi Kumano,Yoshihiko Kawai,Tetsuji Ogawa*

Main category: eess.AS

TL;DR: 文章提出了一种新颖的多人自动语音识别框架SD-CTC，无需辅助信息。它是CTC的扩展，联合分配说话人标签和令牌给每一帧；并与SOT结合，显著降低错误率。


<details>
  <summary>Details</summary>
Motivation: 现有SOT方法存在说话人分配错误问题，而加入词级时间戳等辅助信息在自然对话语音中难以提取。作者希望在不依赖辅助信息的情况下提升多说话人ASR准确率。

Method: 提出Speaker-Distinguishable CTC（SD-CTC），一种扩展的CTC方法，可同时为每帧分配令牌和说话人标签；将其与SOT框架结合进行多任务学习。

Result: 实验表明，结合SD-CTC的SOT模型错误率降低26%，性能逼近依赖辅助信息的SOTA方法。

Conclusion: SD-CTC能有效利用重叠语音和转写数据学习说话人区分，解决了SOT的说话人分配问题，且不依赖外部辅助信息。

Abstract: This paper presents a novel framework for multi-talker automatic speech
recognition without the need for auxiliary information. Serialized Output
Training (SOT), a widely used approach, suffers from recognition errors due to
speaker assignment failures. Although incorporating auxiliary information, such
as token-level timestamps, can improve recognition accuracy, extracting such
information from natural conversational speech remains challenging. To address
this limitation, we propose Speaker-Distinguishable CTC (SD-CTC), an extension
of CTC that jointly assigns a token and its corresponding speaker label to each
frame. We further integrate SD-CTC into the SOT framework, enabling the SOT
model to learn speaker distinction using only overlapping speech and
transcriptions. Experimental comparisons show that multi-task learning with
SD-CTC and SOT reduces the error rate of the SOT model by 26% and achieves
performance comparable to state-of-the-art methods relying on auxiliary
information.

</details>


### [651] [Reducing Object Hallucination in Large Audio-Language Models via Audio-Aware Decoding](https://arxiv.org/abs/2506.07233)
*Tzu-wen Hsu,Ke-Han Lu,Cheng-Han Chiang,Hung-yi Lee*

Main category: eess.AS

TL;DR: 本文针对大型音频语言模型（LALMs）存在幻觉问题，提出了一种轻量级推理时策略——音频感知解码（AAD）。该方法通过对比解码减少幻觉，在对象幻觉数据集上将F1分数提升了0.046-0.428，在通用音频QA数据集上提升了5.4%-10.3%。


<details>
  <summary>Details</summary>
Motivation: 现有大型音频语言模型在标准测试中表现良好，但存在令人担忧的幻觉问题，即模型会生成与音频内容不符的虚假信息。

Method: 提出音频感知解码（AAD），一种轻量级推理策略。通过对比解码比较有/无音频上下文时的token预测logits，提升音频存在时概率增高的token权重。

Result: 在三个LALMs上测试对象幻觉数据集，AAD将F1分数提升0.046-0.428；在Clotho-AQA等通用音频QA数据集上准确率提升5.4%-10.3%。通过消融实验验证了各组件有效性。

Conclusion: AAD能有效缓解LALMs的幻觉问题，在不同数据集和模型上均显著提升性能，且是无需额外训练的轻量级解决方案。

Abstract: Large Audio-Language Models (LALMs) can take audio and text as the inputs and
answer questions about the audio. While prior LALMs have shown strong
performance on standard benchmarks, there has been alarming evidence that LALMs
can hallucinate what is presented in the audio. To mitigate the hallucination
of LALMs, we introduce Audio-Aware Decoding (AAD), a lightweight inference-time
strategy that uses contrastive decoding to compare the token prediction logits
with and without the audio context. By contrastive decoding, AAD promotes the
tokens whose probability increases when the audio is present. We conduct our
experiment on object hallucination datasets with three LALMs and show that AAD
improves the F1 score by 0.046 to 0.428. We also show that AAD can improve the
accuracy on general audio QA datasets like Clotho-AQA by 5.4% to 10.3%. We
conduct thorough ablation studies to understand the effectiveness of each
component in AAD.

</details>


### [652] [Speaker-Distinguishable CTC: Learning Speaker Distinction Using CTC for Multi-Talker Speech Recognition](https://arxiv.org/abs/2506.07515)
*Asahi Sakuma,Hiroaki Sato,Ryuga Sugano,Tadashi Kumano,Yoshihiko Kawai,Tetsuji Ogawa*

Main category: eess.AS

TL;DR: 提出了一种名为SD-CTC的新方法，通过联合预测token和说话人标签来改进多说话人语音识别，无需辅助信息即可提升SOT模型的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的SOT方法因说话人分配错误导致识别率下降，而依赖辅助信息（如时间戳）在实际场景中难以获取。

Method: 扩展CTC为Speaker-Distinguishable CTC (SD-CTC)，在帧级别同时预测token和说话人标签，并与SOT框架进行多任务学习。

Result: 实验表明该方法使SOT模型的错误率降低26%，且性能与依赖辅助信息的先进方法相当。

Conclusion: SD-CTC通过多任务学习有效解决了多说话人识别中的说话人混淆问题，消除了对辅助信息的依赖。

Abstract: This paper presents a novel framework for multi-talker automatic speech
recognition without the need for auxiliary information. Serialized Output
Training (SOT), a widely used approach, suffers from recognition errors due to
speaker assignment failures. Although incorporating auxiliary information, such
as token-level timestamps, can improve recognition accuracy, extracting such
information from natural conversational speech remains challenging. To address
this limitation, we propose Speaker-Distinguishable CTC (SD-CTC), an extension
of CTC that jointly assigns a token and its corresponding speaker label to each
frame. We further integrate SD-CTC into the SOT framework, enabling the SOT
model to learn speaker distinction using only overlapping speech and
transcriptions. Experimental comparisons show that multi-task learning with
SD-CTC and SOT reduces the error rate of the SOT model by 26% and achieves
performance comparable to state-of-the-art methods relying on auxiliary
information.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [653] [Contextual Experience Replay for Self-Improvement of Language Agents](https://arxiv.org/abs/2506.06698)
*Yitao Liu,Chenglei Si,Karthik Narasimhan,Shunyu Yao*

Main category: cs.AI

TL;DR: 提出Contextual Experience Replay（CER）框架，使语言智能体在上下文窗口中进行高效自我改进，无需训练即可在复杂环境中学习和重用经验。在WebArena和VisualWebArena基准上显著提升了性能。


<details>
  <summary>Details</summary>
Motivation: 现有大型语言模型智能体在复杂决策任务（如网页导航）中因缺乏环境特定经验而表现不佳，且无法在推理时持续学习。本文旨在解决这一限制。

Method: 开发CER框架：动态积累和合成过往经验（环境动态和决策模式）至记忆缓冲区，在新任务中检索并应用相关知识。

Result: 在VisualWebArena基准取得31.9%成功率；WebArena基准达到36.7%成功率，相对GPT-4o基线提升51.0%。

Conclusion: CER通过上下文窗口内的经验重用有效提升智能体适应性，为训练免费的持续学习提供可行方案，并在复杂环境决策中验证了其效率与有效性。

Abstract: Large language model (LLM) agents have been applied to sequential
decision-making tasks such as web navigation, but without any
environment-specific experiences, they often fail in these complex tasks.
Moreover, current LLM agents are not designed to continually learn from past
experiences during inference time, which could be crucial for them to gain
these environment-specific experiences. To address this, we propose Contextual
Experience Replay (CER), a training-free framework to enable efficient
self-improvement for language agents in their context window. Specifically, CER
accumulates and synthesizes past experiences into a dynamic memory buffer.
These experiences encompass environment dynamics and common decision-making
patterns, allowing the agents to retrieve and augment themselves with relevant
knowledge in new tasks, enhancing their adaptability in complex environments.
We evaluate CER on the challenging WebArena and VisualWebArena benchmarks. On
VisualWebArena, CER achieves a competitive performance of 31.9%. On WebArena,
CER also gets a competitive average success rate of 36.7%, relatively improving
the success rate of the GPT-4o agent baseline by 51.0%. We also conduct a
comprehensive analysis on it to prove its efficiency, validity and understand
it better.

</details>


### [654] [Cross-Entropy Games for Language Models: From Implicit Knowledge to General Capability Measures](https://arxiv.org/abs/2506.06832)
*Clément Hongler,Andrew Emil*

Main category: cs.AI

TL;DR: 摘要介绍了基于大型语言模型概率测量的交叉熵游戏（Xent Games）框架，提出超越生成采样的任务、游戏构建方法与新评估基准


<details>
  <summary>Details</summary>
Motivation: 探索语言模型掌握概率测量知识的能力边界，定义可形式化算法实践的丰富任务类型

Method: 提出交叉熵游戏框架（含单/多人模式），通过熵分值/约束构建计算图，建立覆盖度基准评估模型能力

Result: 证实Xent Games空间具备足够表达力容纳复杂任务，提出基于演化动力学的扩展方法解决无限能力评估难题

Conclusion: 该框架为构建语言模型能力基准提供新范式，通过结构化游戏空间支持通用能力的系统性探索

Abstract: Large Language Models (LLMs) define probability measures on text. By
considering the implicit knowledge question of what it means for an LLM to know
such a measure and what it entails algorithmically, we are naturally led to
formulate a series of tasks that go beyond generative sampling, involving forms
of summarization, counterfactual thinking, anomaly detection, originality
search, reverse prompting, debating, creative solving, etc. These tasks can be
formulated as games based on LLM measures, which we call Cross-Entropy (Xent)
Games. Xent Games can be single-player or multi-player. They involve
cross-entropy scores and cross-entropy constraints, and can be expressed as
simple computational graphs and programs. We show the Xent Game space is large
enough to contain a wealth of interesting examples, while being constructible
from basic game-theoretic consistency axioms. We then discuss how the Xent Game
space can be used to measure the abilities of LLMs. This leads to the
construction of Xent Game measures: finite families of Xent Games that can be
used as capability benchmarks, built from a given scope, by extracting a
covering measure. To address the unbounded scope problem associated with the
challenge of measuring general abilities, we propose to explore the space of
Xent Games in a coherent fashion, using ideas inspired by evolutionary
dynamics.

</details>


### [655] [Meta-Adaptive Prompt Distillation for Few-Shot Visual Question Answering](https://arxiv.org/abs/2506.06905)
*Akash Gupta,Amos Storkey,Mirella Lapata*

Main category: cs.AI

TL;DR: 我们提出了一个元学习方法来增强小型大模态模型在少样本情景下的任务适应能力，该方法通过提炼任务相关的图像特征生成软提示，并引入注意力映射模块，在VL-ICL基准上超越现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有大型多模态模型依赖上下文学习进行少样本任务时，性能不稳定且不随样本增加单调提升，归因于图像嵌入中的冗余信息干扰任务关键特征。

Method: 使用元学习方法从任务相关图像特征中蒸馏出固定软提示集，测试时少量样本即可适配；设计可集成至LLaVA v1.5架构的注意力映射模块，联合优化软提示与模块参数。

Result: 在VL-ICL基准测试中全面超越上下文学习和提示调优方法，抗图像扰动能力强，视觉问答任务表现显著提升。

Conclusion: 所提软提示蒸馏与注意力映射机制能有效提取任务关键特征，为资源受限环境下的少样本多模态学习提供高效解决方案。

Abstract: Large Multimodal Models (LMMs) often rely on in-context learning (ICL) to
perform new tasks with minimal supervision. However, ICL performance,
especially in smaller LMMs, is inconsistent and does not always improve
monotonically with increasing examples. We hypothesize that this occurs due to
the LMM being overwhelmed by additional information present in the image
embeddings, which is not required for the downstream task. To address this, we
propose a meta-learning approach that provides an alternative for inducing
few-shot capabilities in LMMs, using a fixed set of soft prompts that are
distilled from task-relevant image features and can be adapted at test time
using a few examples. To facilitate this distillation, we introduce an
attention-mapper module that can be easily integrated with the popular LLaVA
v1.5 architecture and is jointly learned with soft prompts, enabling task
adaptation in LMMs under low-data regimes with just a few gradient steps.
Evaluation on the VL-ICL Bench shows that our method consistently outperforms
ICL and related prompt-tuning approaches, even under image perturbations,
improving task induction and reasoning across visual question answering tasks.

</details>


### [656] [The Illusion of Thinking: Understanding the Strengths and Limitations of Reasoning Models via the Lens of Problem Complexity](https://arxiv.org/abs/2506.06941)
*Parshin Shojaee,Iman Mirzadeh,Keivan Alizadeh,Maxwell Horton,Samy Bengio,Mehrdad Farajtabar*

Main category: cs.AI

TL;DR: 该论文通过可控谜题环境研究大型推理模型(LRMs)，发现其存在三大限制：超过特定复杂度时准确率崩溃、推理努力先增后减的反直觉缩放限制、以及三种性能区域划分。同时揭示了LRMs在精确计算中的算法使用缺陷和跨规模不一致性。


<details>
  <summary>Details</summary>
Motivation: 当前对大型推理模型的评估主要依赖数学和编程基准的最终答案准确率，但存在数据污染问题且无法深入分析推理过程。需要系统研究LRMs的基本能力、扩展特性和局限性。

Method: 使用可控谜题环境精确操纵复杂性，同时保持逻辑结构一致。通过分析最终答案和内部推理痕迹进行实验，比较LRMs与标准LLM在相同推理计算下的表现。

Result: 1.LRMs超过特定复杂度时准确率完全崩溃
2.出现反直觉缩放：推理努力先随复杂度增加，达到峰值后下降（尽管仍有剩余token可用）
3.识别三个性能区域：低复杂度任务标准模型优于LRMs；中等复杂度LRMs占优；高复杂度两者均崩溃
4.LRMs存在精确计算缺陷：无法使用显式算法，跨规模推理不一致

Conclusion: LRMs的推理能力存在根本性局限，尤其在处理高复杂度任务时。当前形式的LRMs无法可靠扩展，需重新思考推理机制设计。研究揭示了其推理痕迹模式，为理解模型优劣势提供了新视角。

Abstract: Recent generations of language models have introduced Large Reasoning Models
(LRMs) that generate detailed thinking processes before providing answers.
While these models demonstrate improved performance on reasoning benchmarks,
their fundamental capabilities, scaling properties, and limitations remain
insufficiently understood. Current evaluations primarily focus on established
math and coding benchmarks, emphasizing final answer accuracy. However, this
evaluation paradigm often suffers from contamination and does not provide
insights into the reasoning traces. In this work, we systematically investigate
these gaps with the help of controllable puzzle environments that allow precise
manipulation of complexity while maintaining consistent logical structures.
This setup enables the analysis of not only final answers but also the internal
reasoning traces, offering insights into how LRMs think. Through extensive
experiments, we show that LRMs face a complete accuracy collapse beyond certain
complexities. Moreover, they exhibit a counterintuitive scaling limit: their
reasoning effort increases with problem complexity up to a point, then declines
despite having remaining token budget. By comparing LRMs with their standard
LLM counterparts under same inference compute, we identify three performance
regimes: (1) low-complexity tasks where standard models outperform LRMs, (2)
medium-complexity tasks where LRMs demonstrates advantage, and (3)
high-complexity tasks where both models face complete collapse. We found that
LRMs have limitations in exact computation: they fail to use explicit
algorithms and reason inconsistently across scales. We also investigate the
reasoning traces in more depth, studying the patterns of explored solutions and
analyzing the models' computational behavior, shedding light on their
strengths, limitations, and raising questions about their reasoning
capabilities.

</details>


### [657] [Mitigating Behavioral Hallucination in Multimodal Large Language Models for Sequential Images](https://arxiv.org/abs/2506.07184)
*Liangliang You,Junchi Yao,Shu Yang,Guimin Hu,Lijie Hu,Di Wang*

Main category: cs.AI

TL;DR: 该论文提出了一种名为SHE的轻量级框架，用于消除序列图像中的行为幻象，通过两阶段方法检测并缓解幻象，并引入新衡量标准BEACH，效果优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有的多模态大语言模型在序列图像中存在行为幻象问题，但相关研究较少。作者发现行为幻象主要源于先验驱动偏差和雪球效应，因此需要针对性解决方案。

Method: SHE框架分为两个阶段：(1)使用自适应时间窗口通过视觉-文本对齐检测幻象；(2)通过正交投影到联合嵌入空间来缓解幻象。并提出了BEACH评估指标。

Result: 在标准基准测试中，SHE将行为幻象的BEACH评分降低了超过10%，同时保持描述准确性。

Conclusion: SHE有效解决了序列图像中的行为幻象问题，新提出的BEACH指标能更精准评定幻象严重程度，为相关研究提供了新方向。

Abstract: While multimodal large language models excel at various tasks, they still
suffer from hallucinations, which limit their reliability and scalability for
broader domain applications. To address this issue, recent research mainly
focuses on objective hallucination. However, for sequential images, besides
objective hallucination, there is also behavioral hallucination, which is less
studied. This work aims to fill in the gap. We first reveal that behavioral
hallucinations mainly arise from two key factors: prior-driven bias and the
snowball effect. Based on these observations, we introduce SHE (Sequence
Hallucination Eradication), a lightweight, two-stage framework that (1) detects
hallucinations via visual-textual alignment check using our proposed adaptive
temporal window and (2) mitigates them via orthogonal projection onto the joint
embedding space. We also propose a new metric (BEACH) to quantify behavioral
hallucination severity. Empirical results on standard benchmarks demonstrate
that SHE reduces behavioral hallucination by over 10% on BEACH while
maintaining descriptive accuracy.

</details>


### [658] [SAFEFLOW: A Principled Protocol for Trustworthy and Transactional Autonomous Agent Systems](https://arxiv.org/abs/2506.07564)
*Peiran Li,Xinkai Zou,Zhuohang Wu,Ruifeng Li,Shuo Xing,Hanwen Zheng,Zhikai Hu,Yuping Wang,Haoxi Li,Qin Yuan,Yingmo Zhang,Zhengzhong Tu*

Main category: cs.AI

TL;DR: 提出了SAFEFLOW框架及SAFEFLOWBENCH基准测试，通过细粒度信息流控制、事务处理等机制提升基于大语言模型/视觉语言模型的智能体在安全性和可靠性方面的表现。


<details>
  <summary>Details</summary>
Motivation: 当前基于大语言模型和视觉语言模型的智能体框架在信息安全、可靠性及多智能体协调方面存在缺陷，缺乏有效的安全信息流控制机制。

Method: 引入了协议级框架SAFEFLOW，实施细粒度信息流控制来追踪数据来源与保证机密性；加入事务执行、冲突解决等机制确保多智能体环境下的稳定性；并采用预写日志、回滚等技术增强容错性。

Result: 通过构建的SAFEFLOWBENCH基准测试验证表明，基于SAFEFLOW的智能体在对抗性/噪声并发环境中保持了高效的任务性能和严格的安全保障，显著优于现有技术。

Conclusion: SAFEFLOW框架及配套基准测试为构建可信赖的智能体生态系统提供了基础，推动了可靠自主智能体的发展。

Abstract: Recent advances in large language models (LLMs) and vision-language models
(VLMs) have enabled powerful autonomous agents capable of complex reasoning and
multi-modal tool use. Despite their growing capabilities, today's agent
frameworks remain fragile, lacking principled mechanisms for secure information
flow, reliability, and multi-agent coordination. In this work, we introduce
SAFEFLOW, a new protocol-level framework for building trustworthy LLM/VLM-based
agents. SAFEFLOW enforces fine-grained information flow control (IFC),
precisely tracking provenance, integrity, and confidentiality of all the data
exchanged between agents, tools, users, and environments. By constraining LLM
reasoning to respect these security labels, SAFEFLOW prevents untrusted or
adversarial inputs from contaminating high-integrity decisions. To ensure
robustness in concurrent multi-agent settings, SAFEFLOW introduces
transactional execution, conflict resolution, and secure scheduling over shared
state, preserving global consistency across agents. We further introduce
mechanisms, including write-ahead logging, rollback, and secure caches, that
further enhance resilience against runtime errors and policy violations. To
validate the performances, we built SAFEFLOWBENCH, a comprehensive benchmark
suite designed to evaluate agent reliability under adversarial, noisy, and
concurrent operational conditions. Extensive experiments demonstrate that
agents built with SAFEFLOW maintain impressive task performance and security
guarantees even in hostile environments, substantially outperforming
state-of-the-art. Together, SAFEFLOW and SAFEFLOWBENCH lay the groundwork for
principled, robust, and secure agent ecosystems, advancing the frontier of
reliable autonomy.

</details>


### [659] [Evaluating Large Language Models on the Frame and Symbol Grounding Problems: A Zero-shot Benchmark](https://arxiv.org/abs/2506.07896)
*Shoko Oka*

Main category: cs.AI

TL;DR: 研究表明大型语言模型具备解决框架问题和符号落地问题的认知能力，尤其闭源模型在基准测试中表现优异。


<details>
  <summary>Details</summary>
Motivation: 通过设计基准任务评估现代大语言模型能否解决人工智能领域的长期哲学难题——框架问题和符号落地问题。

Method: 针对13个主流大模型设计两项基准任务，在零样本条件下各进行5次测试，从环境推理/语义连贯/信息过滤等维度人工评分。

Result: 开源模型性能因规模/量化/微调差异而不稳定；多个闭源模型持续高分，尤其某些型号在各标准中表现一致。

Conclusion: 顶尖闭源LLM已初步具有应对经典哲学难题的能力，其稳定表现突破传统符号AI的限制。

Abstract: Recent advancements in large language models (LLMs) have revitalized
philosophical debates surrounding artificial intelligence. Two of the most
fundamental challenges - namely, the Frame Problem and the Symbol Grounding
Problem - have historically been viewed as unsolvable within traditional
symbolic AI systems. This study investigates whether modern LLMs possess the
cognitive capacities required to address these problems. To do so, I designed
two benchmark tasks reflecting the philosophical core of each problem,
administered them under zero-shot conditions to 13 prominent LLMs (both closed
and open-source), and assessed the quality of the models' outputs across five
trials each. Responses were scored along multiple criteria, including
contextual reasoning, semantic coherence, and information filtering. The
results demonstrate that while open-source models showed variability in
performance due to differences in model size, quantization, and instruction
tuning, several closed models consistently achieved high scores. These findings
suggest that select modern LLMs may be acquiring capacities sufficient to
produce meaningful and stable responses to these long-standing theoretical
challenges.

</details>


### [660] [LUCIFER: Language Understanding and Context-Infused Framework for Exploration and Behavior Refinement](https://arxiv.org/abs/2506.07915)
*Dimitris Panagopoulos,Adolfo Perrusquia,Weisi Guo*

Main category: cs.AI

TL;DR: 论文提出LUCIFER框架，解决动态环境中自主系统知识过时问题。该框架整合分层决策、强化学习和LLMs，利用人类情境知识提升决策质量，实验证明其优于平面策略。


<details>
  <summary>Details</summary>
Motivation: 动态环境中，预先知识快速过时导致自主决策失效。人类观察者的情境洞察虽关键，但转化为可执行智能仍是挑战。需构建新框架弥合此差距。

Method: 提出分层框架LUCIFER：高层规划器协调子智能体。双重LLM应用——情境提取器（结构化语言输入）和零样本探索引导器（指导行动选择）。结合RL进行决策优化。

Result: 测试不同LLM角色效果，LUCIFER显著提升探索效率和决策质量，超越传统平面策略。证明情境知识整合的有效性。

Conclusion: 通过协同人类情境知识与自主系统，LUCIFER框架成功解决动态环境决策难题，为LLM与RL融合应用于复杂系统开辟新途径。

Abstract: In dynamic environments, the rapid obsolescence of pre-existing environmental
knowledge creates a gap between an agent's internal model and the evolving
reality of its operational context. This disparity between prior and updated
environmental valuations fundamentally limits the effectiveness of autonomous
decision-making. To bridge this gap, the contextual bias of human domain
stakeholders, who naturally accumulate insights through direct, real-time
observation, becomes indispensable. However, translating their nuanced, and
context-rich input into actionable intelligence for autonomous systems remains
an open challenge. To address this, we propose LUCIFER (Language Understanding
and Context-Infused Framework for Exploration and Behavior Refinement), a
domain-agnostic framework that integrates a hierarchical decision-making
architecture with reinforcement learning (RL) and large language models (LLMs)
into a unified system. This architecture mirrors how humans decompose complex
tasks, enabling a high-level planner to coordinate specialised sub-agents, each
focused on distinct objectives and temporally interdependent actions. Unlike
traditional applications where LLMs are limited to single role, LUCIFER
integrates them in two synergistic roles: as context extractors, structuring
verbal stakeholder input into domain-aware representations that influence
decision-making through an attention space mechanism aligning LLM-derived
insights with the agent's learning process, and as zero-shot exploration
facilitators guiding the agent's action selection process during exploration.
We benchmark various LLMs in both roles and demonstrate that LUCIFER improves
exploration efficiency and decision quality, outperforming flat,
goal-conditioned policies. Our findings show the potential of context-driven
decision-making, where autonomous systems leverage human contextual knowledge
for operational success.

</details>


### [661] [Solving Inequality Proofs with Large Language Models](https://arxiv.org/abs/2506.07927)
*Jiayi Sheng,Luna Lyu,Jikai Jin,Tony Xia,Alex Gu,James Zou,Pan Lu*

Main category: cs.AI

TL;DR: 提出了IneqMath数据集，用于测试大语言模型在不等式证明中的能力，并开发了一个新的评估框架，发现即使顶级模型在分步审查下准确率也很低，揭示了模型在严格证明构建上的不足。


<details>
  <summary>Details</summary>
Motivation: 现有的不等式证明数据集稀缺、合成或过于形式化，无法有效评估大型语言模型的推理能力，需要一个更真实且可自动验证的数据集和评估方法。

Method: 将不等式证明重新表述为两个可自动检验的子任务：边界估计和关系预测；构建了专家策划的IneqMath数据集，包含分步解答和定理标注；设计了一个结合最终答案评审员和四个分步评审员的LLM评审框架，用于检测常见推理错误。

Result: 评估了29个领先的LLM，发现在分步审查下，即使顶级模型（如o1）的总体准确率低于10%，比仅考虑最终答案的准确率下降高达65.5%；模型规模和测试时计算资源的增加对证明正确性的提升有限。

Conclusion: 当前LLMs在构建严格证明方面存在显著缺陷，定理引导推理和自我完善是未来有前景的研究方向。

Abstract: Inequality proving, crucial across diverse scientific and mathematical
fields, tests advanced reasoning skills such as discovering tight bounds and
strategic theorem application. This makes it a distinct, demanding frontier for
large language models (LLMs), offering insights beyond general mathematical
problem-solving. Progress in this area is hampered by existing datasets that
are often scarce, synthetic, or rigidly formal. We address this by proposing an
informal yet verifiable task formulation, recasting inequality proving into two
automatically checkable subtasks: bound estimation and relation prediction.
Building on this, we release IneqMath, an expert-curated dataset of
Olympiad-level inequalities, including a test set and training corpus enriched
with step-wise solutions and theorem annotations. We also develop a novel
LLM-as-judge evaluation framework, combining a final-answer judge with four
step-wise judges designed to detect common reasoning flaws. A systematic
evaluation of 29 leading LLMs on IneqMath reveals a surprising reality: even
top models like o1 achieve less than 10% overall accuracy under step-wise
scrutiny; this is a drop of up to 65.5% from their accuracy considering only
final answer equivalence. This discrepancy exposes fragile deductive chains and
a critical gap for current LLMs between merely finding an answer and
constructing a rigorous proof. Scaling model size and increasing test-time
computation yield limited gains in overall proof correctness. Instead, our
findings highlight promising research directions such as theorem-guided
reasoning and self-refinement. Code and data are available at
https://ineqmath.github.io/.

</details>


### [662] [Reinforcing Multimodal Understanding and Generation with Dual Self-rewards](https://arxiv.org/abs/2506.07963)
*Jixiang Hong,Yiran Zhang,Guanzhong Wang,Yi Liu,Ji-Rong Wen,Rui Yan*

Main category: cs.AI

TL;DR: Self-supervised dual reward mechanism improves LMMs' understanding and generation without external supervision.


<details>
  <summary>Details</summary>
Motivation: LMMs struggle with image-text alignment and current solutions require external supervision and address only one task direction.

Method: Uses dual reward mechanism by reversing input-output pairs to compute dual likelihood as self-rewards for optimization.

Result: Achieves significant improvements in visual understanding and generation benchmarks, especially in text-to-image tasks.

Conclusion: The self-supervised approach effectively enhances LMMs' bidirectional capabilities without external supervision.

Abstract: Building upon large language models (LLMs), recent large multimodal models
(LMMs) unify cross-model understanding and generation into a single framework.
However, LMMs still struggle to achieve accurate image-text alignment, prone to
generating text responses contradicting the visual input or failing to follow
the text-to-image prompts. Current solutions require external supervision
(e.g., human feedback or reward models) and only address unidirectional
tasks-either understanding or generation. In this work, based on the
observation that understanding and generation are inverse dual tasks, we
introduce a self-supervised dual reward mechanism to reinforce the
understanding and generation capabilities of LMMs. Specifically, we sample
multiple outputs for a given input in one task domain, then reverse the
input-output pairs to compute the dual likelihood of the model as self-rewards
for optimization. Extensive experimental results on visual understanding and
generation benchmarks demonstrate that our method can effectively enhance the
performance of the model without any external supervision, especially achieving
remarkable improvements in text-to-image tasks.

</details>


### [663] [$τ^2$-Bench: Evaluating Conversational Agents in a Dual-Control Environment](https://arxiv.org/abs/2506.07982)
*Victor Barres,Honghua Dong,Soham Ray,Xujie Si,Karthik Narasimhan*

Main category: cs.AI

TL;DR: 这篇论文提出了一个名为$	au^2$-bench的双人控制基准测试，解决现有对话AI基准测试中用户只能被动参与的问题。通过Telecom领域的双人协作建模为Dec-POMDP、任务生成器、高保真用户模拟器以及细粒度分析，论文揭示了在引导用户协作时AI智能体性能显著下降的挑战。


<details>
  <summary>Details</summary>
Motivation: 现有对话AI基准测试模拟的是'单向控制'环境，即只有AI能够使用工具与环境互动，用户仅作为被动信息提供者。这不符合技术支持等真实场景中用户需要主动参与修改共享世界状态的特点。

Method: 1) 将电信领域建模为分散式部分可观察马尔可夫决策过程(Dec-POMDP)；2) 通过组合原子构件生成多样化任务；3) 开发工具约束的用户模拟器提升真实性；4) 设计区分推理错误与沟通协作错误的细粒度评估。

Result: 实验表明当AI从单向控制环境转向双人协作环境时，性能出现显著下降，突显出引导用户行为的挑战性。尤其当用户成为主动参与者时，AI在协调与沟通方面的不足更加明显。

Conclusion: $	au^2$-bench为解决协同任务中既需要有效推理又需要引导用户的对话AI提供了可控测试平台，填补了现有基准测试的空白。

Abstract: Existing benchmarks for conversational AI agents simulate single-control
environments, where only the AI agent can use tools to interact with the world,
while the user remains a passive information provider. This differs from
real-world scenarios like technical support, where users need to actively
participate in modifying the state of the (shared) world. In order to address
this gap, we introduce $\tau^2$-bench, with four key contributions:
  1) A novel Telecom dual-control domain modeled as a Dec-POMDP, where both
agent and user make use of tools to act in a shared, dynamic environment that
tests both agent coordination and communication,
  2) A compositional task generator that programmatically creates diverse,
verifiable tasks from atomic components, ensuring domain coverage and
controlled complexity,
  3) A reliable user simulator tightly coupled with the environment, whose
behavior is constrained by tools and observable states, improving simulation
fidelity,
  4) Fine-grained analysis of agent performance through multiple ablations
including separating errors arising from reasoning vs
communication/coordination.
  In particular, our experiments show significant performance drops when agents
shift from no-user to dual-control, highlighting the challenges of guiding
users. Overall, $\tau^2$-bench provides a controlled testbed for agents that
must both reason effectively and guide user actions.

</details>


### [664] [VisioMath: Benchmarking Figure-based Mathematical Reasoning in LMMs](https://arxiv.org/abs/2506.06727)
*Can Li,Ting Zhang,Mei Wang,Hua Huang*

Main category: cs.AI

TL;DR: 数据集VisioMath用于评估大型多模态模型在图像选项数学推理中的表现，发现现有模型如GPT-4o准确率仅45.9%，突显视觉选项推理的难点。


<details>
  <summary>Details</summary>
Motivation: 现有研究未充分探索大型多模态模型（LMMs）在答案选项为图像的数学推理能力，这属于多图像理解的关键部分。

Method: 引入VisioMath数据集，包含8070张图像和1800道多选题，每道题的答案选项均为图像，需模型做细微区分。

Result: 先进LMMs表现不佳，最优模型GPT-4o准确率仅45.9%，证实现有模型对视觉相似选项的推理存在局限。

Conclusion: VisioMath填补了现有多模态基准的空白，为未来研究提供严格测试平台，推动多模态推理发展。

Abstract: Large Multimodal Models (LMMs) have demonstrated remarkable problem-solving
capabilities across various domains. However, their ability to perform
mathematical reasoning when answer options are represented as images--an
essential aspect of multi-image comprehension--remains underexplored. To bridge
this gap, we introduce VisioMath, a benchmark designed to evaluate mathematical
reasoning in multimodal contexts involving image-based answer choices.
VisioMath comprises 8,070 images and 1,800 multiple-choice questions, where
each answer option is an image, presenting unique challenges to existing LMMs.
To the best of our knowledge, VisioMath is the first dataset specifically
tailored for mathematical reasoning in image-based-option scenarios, where
fine-grained distinctions between answer choices are critical for accurate
problem-solving. We systematically evaluate state-of-the-art LMMs on VisioMath
and find that even the most advanced models struggle with this task. Notably,
GPT-4o achieves only 45.9% accuracy, underscoring the limitations of current
models in reasoning over visually similar answer choices. By addressing a
crucial gap in existing benchmarks, VisioMath establishes a rigorous testbed
for future research, driving advancements in multimodal reasoning.

</details>


### [665] [Long-Tailed Learning for Generalized Category Discovery](https://arxiv.org/abs/2506.06965)
*Cuong Manh Hoang*

Main category: cs.AI

TL;DR: 该论文提出了一种在长尾分布中执行广义类别发现的新框架，包括自引导标记技术和表示平衡过程。


<details>
  <summary>Details</summary>
Motivation: 现有广义类别发现方法在平衡数据集上表现良好，但在现实世界不平衡数据集上效果不佳。

Method: 提出自引导标记技术生成伪标签减少分类器偏差，再通过表示平衡过程挖掘样本邻域以关注尾部类别。

Result: 在公开数据集上的实验表明该模型超越先前最先进方法。

Conclusion: 所提框架能有效解决长尾分布下的广义类别发现问题。

Abstract: Generalized Category Discovery (GCD) utilizes labeled samples of known
classes to discover novel classes in unlabeled samples. Existing methods show
effective performance on artificial datasets with balanced distributions.
However, real-world datasets are always imbalanced, significantly affecting the
effectiveness of these methods. To solve this problem, we propose a novel
framework that performs generalized category discovery in long-tailed
distributions. We first present a self-guided labeling technique that uses a
learnable distribution to generate pseudo-labels, resulting in less biased
classifiers. We then introduce a representation balancing process to derive
discriminative representations. By mining sample neighborhoods, this process
encourages the model to focus more on tail classes. We conduct experiments on
public datasets to demonstrate the effectiveness of the proposed framework. The
results show that our model exceeds previous state-of-the-art methods.

</details>


### [666] [GUI-Reflection: Empowering Multimodal GUI Models with Self-Reflection Behavior](https://arxiv.org/abs/2506.08012)
*Penghao Wu,Shengnan Ma,Bo Wang,Jiaheng Yu,Lewei Lu,Ziwei Liu*

Main category: cs.AI

TL;DR: 提出了GUI-Reflection框架，通过自我反思和纠错机制增强多模态大型语言模型在GUI自动化中的鲁棒性，包含自动数据生成和在线学习过程。


<details>
  <summary>Details</summary>
Motivation: 现有GUI模型主要依赖无错误离线轨迹训练，缺乏自我反思和错误恢复能力

Method: 分三阶段训练：1) GUI专用预训练 2) 离线监督微调 3) 在线反思调优。创新点包括自动构建反思数据管道、GUI-反思任务套件、移动端在线训练环境

Result: 开发了全自动数据生成流程和在线学习算法，赋予GUI代理自我纠错能力

Conclusion: 框架为GUI自动化提供更鲁棒、适应性更强的解决方案，所有资源将开源

Abstract: Multimodal Large Language Models (MLLMs) have shown great potential in
revolutionizing Graphical User Interface (GUI) automation. However, existing
GUI models mostly rely on learning from nearly error-free offline trajectories,
thus lacking reflection and error recovery capabilities. To bridge this gap, we
propose GUI-Reflection, a novel framework that explicitly integrates
self-reflection and error correction capabilities into end-to-end multimodal
GUI models throughout dedicated training stages: GUI-specific pre-training,
offline supervised fine-tuning (SFT), and online reflection tuning.
GUI-reflection enables self-reflection behavior emergence with fully automated
data generation and learning processes without requiring any human annotation.
Specifically, 1) we first propose scalable data pipelines to automatically
construct reflection and error correction data from existing successful
trajectories. While existing GUI models mainly focus on grounding and UI
understanding ability, we propose the GUI-Reflection Task Suite to learn and
evaluate reflection-oriented abilities explicitly. 2) Furthermore, we built a
diverse and efficient environment for online training and data collection of
GUI models on mobile devices. 3) We also present an iterative online reflection
tuning algorithm leveraging the proposed environment, enabling the model to
continuously enhance its reflection and error correction abilities. Our
framework equips GUI agents with self-reflection and correction capabilities,
paving the way for more robust, adaptable, and intelligent GUI automation, with
all data, models, environments, and tools to be released publicly.

</details>


### [667] [Contextual Experience Replay for Self-Improvement of Language Agents](https://arxiv.org/abs/2506.06698)
*Yitao Liu,Chenglei Si,Karthik Narasimhan,Shunyu Yao*

Main category: cs.AI

TL;DR: 介绍了Contextual Experience Replay (CER)框架，该框架能够在上下文窗口中实现免训练的语言模型代理自改进，提高在复杂环境中的适应能力，分别在两个基准测试中获得31.9%和36.7%的成功率。


<details>
  <summary>Details</summary>
Motivation: 解决LLM代理在顺序决策任务中缺乏环境经验和无法在推理时持续学习的问题。

Method: 提出了Contextual Experience Replay (CER)框架，通过积累和综合过去经验到动态内存缓冲区，代理在新任务中检索相关经验以增强自身能力。该方法支持在上下文窗口中完成自改进而无需额外训练。

Result: 在两个基准测试中取得了具有竞争力的结果。在VisualWebArena上获得31.9%的成功率，在WebArena上获得36.7%的成功率，相比GPT-4o基线任务成功率提升51.0%。

Conclusion: CER框架有效提升了语言模型代理在复杂任务中的适应性。

Abstract: Large language model (LLM) agents have been applied to sequential
decision-making tasks such as web navigation, but without any
environment-specific experiences, they often fail in these complex tasks.
Moreover, current LLM agents are not designed to continually learn from past
experiences during inference time, which could be crucial for them to gain
these environment-specific experiences. To address this, we propose Contextual
Experience Replay (CER), a training-free framework to enable efficient
self-improvement for language agents in their context window. Specifically, CER
accumulates and synthesizes past experiences into a dynamic memory buffer.
These experiences encompass environment dynamics and common decision-making
patterns, allowing the agents to retrieve and augment themselves with relevant
knowledge in new tasks, enhancing their adaptability in complex environments.
We evaluate CER on the challenging WebArena and VisualWebArena benchmarks. On
VisualWebArena, CER achieves a competitive performance of 31.9%. On WebArena,
CER also gets a competitive average success rate of 36.7%, relatively improving
the success rate of the GPT-4o agent baseline by 51.0%. We also conduct a
comprehensive analysis on it to prove its efficiency, validity and understand
it better.

</details>


### [668] [Cross-Entropy Games for Language Models: From Implicit Knowledge to General Capability Measures](https://arxiv.org/abs/2506.06832)
*Clément Hongler,Andrew Emil*

Main category: cs.AI

TL;DR: 该论文提出了Xent Games框架，将大语言模型(LLMs)的隐式知识转化为基于交叉熵的游戏任务，包括摘要、反事实推理等，并构建能力基准来衡量LLMs的表现。


<details>
  <summary>Details</summary>
Motivation: 探索LLMs隐含的概率分布知识如何转化为算法任务，这些任务超越了基础的文本生成。因此作者系统地整理出Xent Games任务框架，用于衡量LLMs各方面能力。

Method: 1. 定义基于LLM概率分布的Cross-Entropy（Xent）Games：包含单人和多人游戏，使用交叉熵分数作为核心指标<br>2. 通过博弈论一致性公理构建Xent Games空间<br>3. 设计Xent Game measures：从游戏空间中提取有限子集形成能力评测基准<br>4. 提出进化动态方法解决游戏空间范围过大的问题

Result: 1. 证明Xent Games空间足够丰富，包含摘要、反事实推理、异常检测等多样任务<br>2. 构建出可系统评测LLMs能力的框架<br>3. 提出基于进化动态思想的游戏空间探索方法论

Conclusion: Xent Games建立了从LLMs概率分布到复杂认知任务的转化桥梁，通过结构化设计游戏任务和测评方法，为LLMs能力评估提供理论基础和实践框架。

Abstract: Large Language Models (LLMs) define probability measures on text. By
considering the implicit knowledge question of what it means for an LLM to know
such a measure and what it entails algorithmically, we are naturally led to
formulate a series of tasks that go beyond generative sampling, involving forms
of summarization, counterfactual thinking, anomaly detection, originality
search, reverse prompting, debating, creative solving, etc. These tasks can be
formulated as games based on LLM measures, which we call Cross-Entropy (Xent)
Games. Xent Games can be single-player or multi-player. They involve
cross-entropy scores and cross-entropy constraints, and can be expressed as
simple computational graphs and programs. We show the Xent Game space is large
enough to contain a wealth of interesting examples, while being constructible
from basic game-theoretic consistency axioms. We then discuss how the Xent Game
space can be used to measure the abilities of LLMs. This leads to the
construction of Xent Game measures: finite families of Xent Games that can be
used as capability benchmarks, built from a given scope, by extracting a
covering measure. To address the unbounded scope problem associated with the
challenge of measuring general abilities, we propose to explore the space of
Xent Games in a coherent fashion, using ideas inspired by evolutionary
dynamics.

</details>


### [669] [Meta-Adaptive Prompt Distillation for Few-Shot Visual Question Answering](https://arxiv.org/abs/2506.06905)
*Akash Gupta,Amos Storkey,Mirella Lapata*

Main category: cs.AI

TL;DR: 该研究提出了一种名为Meta-mapper的新方法，通过蒸馏任务相关的图像特征来生成软提示，以提高多模态模型的少样本学习能力。该方法在VL-ICL Bench上的表现优于现有方法，甚至在图像扰动下也能保持稳健。


<details>
  <summary>Details</summary>
Motivation: 大型多模态模型（LMMs）在上下文学习（ICL）中的表现不一致，特别是在小型模型中。研究者认为这可能是因为图像嵌入中包含的额外信息干扰模型，这些信息与下游任务无关。

Method: 研究者开发了一种元学习方法，该方法通过一个注意力映射器模块（可轻松集成到LLaVA v1.5架构中），从任务相关的图像特征中蒸馏出一组固定的软提示。这些提示可以在测试时用少量样本进行适应。整个系统通过少量梯度步进行联合训练。

Result: 在VL-ICL Bench上的评估显示，该方法在少样本场景中持续优于ICL和其他提示调整方法，包括在图像扰动条件下。同时，该方法改善了跨视觉问答任务的归纳和推理能力。

Conclusion: 通过注意力映射器蒸馏任务相关的软提示是一种有效的元学习方法，能够显著提高LMMs在少样本场景下的任务适应性能，且具有对抗图像扰动的稳健性。

Abstract: Large Multimodal Models (LMMs) often rely on in-context learning (ICL) to
perform new tasks with minimal supervision. However, ICL performance,
especially in smaller LMMs, is inconsistent and does not always improve
monotonically with increasing examples. We hypothesize that this occurs due to
the LMM being overwhelmed by additional information present in the image
embeddings, which is not required for the downstream task. To address this, we
propose a meta-learning approach that provides an alternative for inducing
few-shot capabilities in LMMs, using a fixed set of soft prompts that are
distilled from task-relevant image features and can be adapted at test time
using a few examples. To facilitate this distillation, we introduce an
attention-mapper module that can be easily integrated with the popular LLaVA
v1.5 architecture and is jointly learned with soft prompts, enabling task
adaptation in LMMs under low-data regimes with just a few gradient steps.
Evaluation on the VL-ICL Bench shows that our method consistently outperforms
ICL and related prompt-tuning approaches, even under image perturbations,
improving task induction and reasoning across visual question answering tasks.

</details>


### [670] [The Illusion of Thinking: Understanding the Strengths and Limitations of Reasoning Models via the Lens of Problem Complexity](https://arxiv.org/abs/2506.06941)
*Parshin Shojaee,Iman Mirzadeh,Keivan Alizadeh,Maxwell Horton,Samy Bengio,Mehrdad Farajtabar*

Main category: cs.AI

TL;DR: LRMs的大型推理模型在复杂问题中会出现完全准确性崩溃，推理努力随复杂度增加而上升后下降，且存在低复杂度时不如标准LLM、中复杂度占优、高复杂度二者均失效的三段表现，其精确计算存在缺陷且推理不一致。


<details>
  <summary>Details</summary>
Motivation: 现有评估主要关注数学和编程基准的最终答案准确率，但存在数据污染问题且无法洞察推理痕迹。我们通过可控拼图环境系统性地研究LRM的基本能力、扩展特性和局限。

Method: 使用可精确控制复杂度但保持逻辑结构一致的拼图环境，分析LRM的最终答案和内部推理痕迹，并与等效计算量的标准LLM模型进行对比。

Result: 1) LRM在特定复杂度以上出现准确率崩溃 2) 推理努力随复杂度增加而上升后下降 3) LRM在低/高复杂度任务中不如标准LLM，仅在中复杂度有优势 4) LRM无法使用显式算法，存在跨尺度的推理不一致问题

Conclusion: LRM存在精确计算的固有局限，当前形态的推理能力值得质疑。通过推理痕迹分析揭示了模型的计算行为模式，强调了超越最终答案评估的必要性。

Abstract: Recent generations of language models have introduced Large Reasoning Models
(LRMs) that generate detailed thinking processes before providing answers.
While these models demonstrate improved performance on reasoning benchmarks,
their fundamental capabilities, scaling properties, and limitations remain
insufficiently understood. Current evaluations primarily focus on established
math and coding benchmarks, emphasizing final answer accuracy. However, this
evaluation paradigm often suffers from contamination and does not provide
insights into the reasoning traces. In this work, we systematically investigate
these gaps with the help of controllable puzzle environments that allow precise
manipulation of complexity while maintaining consistent logical structures.
This setup enables the analysis of not only final answers but also the internal
reasoning traces, offering insights into how LRMs think. Through extensive
experiments, we show that LRMs face a complete accuracy collapse beyond certain
complexities. Moreover, they exhibit a counterintuitive scaling limit: their
reasoning effort increases with problem complexity up to a point, then declines
despite having remaining token budget. By comparing LRMs with their standard
LLM counterparts under same inference compute, we identify three performance
regimes: (1) low-complexity tasks where standard models outperform LRMs, (2)
medium-complexity tasks where LRMs demonstrates advantage, and (3)
high-complexity tasks where both models face complete collapse. We found that
LRMs have limitations in exact computation: they fail to use explicit
algorithms and reason inconsistently across scales. We also investigate the
reasoning traces in more depth, studying the patterns of explored solutions and
analyzing the models' computational behavior, shedding light on their
strengths, limitations, and raising questions about their reasoning
capabilities.

</details>


### [671] [Mitigating Behavioral Hallucination in Multimodal Large Language Models for Sequential Images](https://arxiv.org/abs/2506.07184)
*Liangliang You,Junchi Yao,Shu Yang,Guimin Hu,Lijie Hu,Di Wang*

Main category: cs.AI

TL;DR: 针对多模态大语言模型在序列图像中的行为幻觉问题，提出SHE框架检测并缓解幻觉，同时提出新评估指标BEACH。


<details>
  <summary>Details</summary>
Motivation: 现有研究主要关注客观幻觉，但对序列图像中的行为幻觉研究不足。研究发现行为幻觉主要来自先验驱动偏见和雪球效应。

Method: 提出两阶段轻量框架SHE：1) 使用自适应时间窗口通过视觉-文本对齐检测幻觉；2) 通过正交投影到联合嵌入空间缓解幻觉。

Result: 在标准基准测试中，SHE将行为幻觉减少了10%以上（以新指标BEACH衡量），同时保持描述准确性。

Conclusion: SHE有效解决了序列图像中的行为幻觉问题，且提出了专门的行为幻觉量化指标BEACH。

Abstract: While multimodal large language models excel at various tasks, they still
suffer from hallucinations, which limit their reliability and scalability for
broader domain applications. To address this issue, recent research mainly
focuses on objective hallucination. However, for sequential images, besides
objective hallucination, there is also behavioral hallucination, which is less
studied. This work aims to fill in the gap. We first reveal that behavioral
hallucinations mainly arise from two key factors: prior-driven bias and the
snowball effect. Based on these observations, we introduce SHE (Sequence
Hallucination Eradication), a lightweight, two-stage framework that (1) detects
hallucinations via visual-textual alignment check using our proposed adaptive
temporal window and (2) mitigates them via orthogonal projection onto the joint
embedding space. We also propose a new metric (BEACH) to quantify behavioral
hallucination severity. Empirical results on standard benchmarks demonstrate
that SHE reduces behavioral hallucination by over 10% on BEACH while
maintaining descriptive accuracy.

</details>


### [672] [SAFEFLOW: A Principled Protocol for Trustworthy and Transactional Autonomous Agent Systems](https://arxiv.org/abs/2506.07564)
*Peiran Li,Xinkai Zou,Zhuohang Wu,Ruifeng Li,Shuo Xing,Hanwen Zheng,Zhikai Hu,Yuping Wang,Haoxi Li,Qin Yuan,Yingmo Zhang,Zhengzhong Tu*

Main category: cs.AI

TL;DR: SAFEFLOW is a protocol-level framework for secure and reliable LLM/VLM agents that enforces information flow control and ensures robustness through features like transactional execution and resilience mechanisms. Outperforms state-of-the-art in hostile environments.


<details>
  <summary>Details</summary>
Motivation: Current LLM/VLM agent frameworks lack mechanisms for secure information flow, reliability, and multi-agent coordination, necessitating a principled approach to address these vulnerabilities.

Method: Introduces SAFEFLOW with fine-grained IFC tracking provenance, integrity, and confidentiality; constrains LLM reasoning with security labels; implements transactional execution, conflict resolution, secure scheduling; adds write-ahead logging, rollback, and secure caches.

Result: SAFEFLOW agents maintain high task performance and security in adversarial/noisy/concurrent conditions (validated via SAFEFLOWBENCH benchmark), substantially outperforming state-of-the-art approaches.

Conclusion: SAFEFLOW and SAFEFLOWBENCH establish foundations for robust, secure agent ecosystems, advancing reliable autonomy in hostile environments.

Abstract: Recent advances in large language models (LLMs) and vision-language models
(VLMs) have enabled powerful autonomous agents capable of complex reasoning and
multi-modal tool use. Despite their growing capabilities, today's agent
frameworks remain fragile, lacking principled mechanisms for secure information
flow, reliability, and multi-agent coordination. In this work, we introduce
SAFEFLOW, a new protocol-level framework for building trustworthy LLM/VLM-based
agents. SAFEFLOW enforces fine-grained information flow control (IFC),
precisely tracking provenance, integrity, and confidentiality of all the data
exchanged between agents, tools, users, and environments. By constraining LLM
reasoning to respect these security labels, SAFEFLOW prevents untrusted or
adversarial inputs from contaminating high-integrity decisions. To ensure
robustness in concurrent multi-agent settings, SAFEFLOW introduces
transactional execution, conflict resolution, and secure scheduling over shared
state, preserving global consistency across agents. We further introduce
mechanisms, including write-ahead logging, rollback, and secure caches, that
further enhance resilience against runtime errors and policy violations. To
validate the performances, we built SAFEFLOWBENCH, a comprehensive benchmark
suite designed to evaluate agent reliability under adversarial, noisy, and
concurrent operational conditions. Extensive experiments demonstrate that
agents built with SAFEFLOW maintain impressive task performance and security
guarantees even in hostile environments, substantially outperforming
state-of-the-art. Together, SAFEFLOW and SAFEFLOWBENCH lay the groundwork for
principled, robust, and secure agent ecosystems, advancing the frontier of
reliable autonomy.

</details>


### [673] [Evaluating Large Language Models on the Frame and Symbol Grounding Problems: A Zero-shot Benchmark](https://arxiv.org/abs/2506.07896)
*Shoko Oka*

Main category: cs.AI

TL;DR: 该研究评估了大型语言模型（LLMs）解决符号接地问题和框架问题的能力，通过两项基准测试在13个著名LLMs上进行零样本测试，发现部分闭源模型表现优异，表明现代LLMs可能具备应对这些哲学挑战的能力。


<details>
  <summary>Details</summary>
Motivation: 哲学辩论中两大基础挑战——框架问题和符号接地问题——在传统符号AI系统中被视为无解，研究旨在验证现代LLMs是否具备解决这些问题的认知能力。

Method: 设计两项反映问题哲学核心的基准任务，在零样本条件下对13个开源/闭源LLMs各进行五次测试，从语境推理、语义连贯性、信息过滤等维度评分。

Result: 开源模型因规模、量化和指令调优差异表现出波动性，而闭源模型（如GPT系列）持续获得高分。

Conclusion: 部分现代LLMs显示出稳定解决长期理论挑战的潜力，表明此类模型可能突破传统AI的限制。

Abstract: Recent advancements in large language models (LLMs) have revitalized
philosophical debates surrounding artificial intelligence. Two of the most
fundamental challenges - namely, the Frame Problem and the Symbol Grounding
Problem - have historically been viewed as unsolvable within traditional
symbolic AI systems. This study investigates whether modern LLMs possess the
cognitive capacities required to address these problems. To do so, I designed
two benchmark tasks reflecting the philosophical core of each problem,
administered them under zero-shot conditions to 13 prominent LLMs (both closed
and open-source), and assessed the quality of the models' outputs across five
trials each. Responses were scored along multiple criteria, including
contextual reasoning, semantic coherence, and information filtering. The
results demonstrate that while open-source models showed variability in
performance due to differences in model size, quantization, and instruction
tuning, several closed models consistently achieved high scores. These findings
suggest that select modern LLMs may be acquiring capacities sufficient to
produce meaningful and stable responses to these long-standing theoretical
challenges.

</details>


### [674] [LUCIFER: Language Understanding and Context-Infused Framework for Exploration and Behavior Refinement](https://arxiv.org/abs/2506.07915)
*Dimitris Panagopoulos,Adolfo Perrusquia,Weisi Guo*

Main category: cs.AI

TL;DR: 在动态环境中，智能体对环境变化的响应滞后导致决策失效，LUCIFER框架利用分层架构结合RL与LLM，通过双重LLM角色整合人类情境知识，提升探索效率和决策质量。


<details>
  <summary>Details</summary>
Motivation: 现有环境中智能体的内部模型与现实差距导致决策失误，人类环境中的情境知识至关重要但难以转化利用。

Method: 提出LUCIFER框架：1）分层决策架构（高层次规划+专业子代理）2）LLMs双重作用——情境提取器（结构化口头输入）和零样本探索引导者（行动选择）3）注意力空间机制对齐人类洞察与学习过程。

Result: 测试不同LLMs，验证框架在探索效率和决策质量上优于平面目标导向策略。

Conclusion: 通过整合实时人类情境知识，实现自主系统的语境驱动决策，展示操作成功潜力。

Abstract: In dynamic environments, the rapid obsolescence of pre-existing environmental
knowledge creates a gap between an agent's internal model and the evolving
reality of its operational context. This disparity between prior and updated
environmental valuations fundamentally limits the effectiveness of autonomous
decision-making. To bridge this gap, the contextual bias of human domain
stakeholders, who naturally accumulate insights through direct, real-time
observation, becomes indispensable. However, translating their nuanced, and
context-rich input into actionable intelligence for autonomous systems remains
an open challenge. To address this, we propose LUCIFER (Language Understanding
and Context-Infused Framework for Exploration and Behavior Refinement), a
domain-agnostic framework that integrates a hierarchical decision-making
architecture with reinforcement learning (RL) and large language models (LLMs)
into a unified system. This architecture mirrors how humans decompose complex
tasks, enabling a high-level planner to coordinate specialised sub-agents, each
focused on distinct objectives and temporally interdependent actions. Unlike
traditional applications where LLMs are limited to single role, LUCIFER
integrates them in two synergistic roles: as context extractors, structuring
verbal stakeholder input into domain-aware representations that influence
decision-making through an attention space mechanism aligning LLM-derived
insights with the agent's learning process, and as zero-shot exploration
facilitators guiding the agent's action selection process during exploration.
We benchmark various LLMs in both roles and demonstrate that LUCIFER improves
exploration efficiency and decision quality, outperforming flat,
goal-conditioned policies. Our findings show the potential of context-driven
decision-making, where autonomous systems leverage human contextual knowledge
for operational success.

</details>


### [675] [Solving Inequality Proofs with Large Language Models](https://arxiv.org/abs/2506.07927)
*Jiayi Sheng,Luna Lyu,Jikai Jin,Tony Xia,Alex Gu,James Zou,Pan Lu*

Main category: cs.AI

TL;DR: Inequality proving is a challenging area for large language models (LLMs) due to existing datasets being limited. This paper introduces IneqMath, a dataset of Olympiad-level inequalities, and a novel evaluation framework. Evaluation shows top LLMs achieve very low accuracy under step-wise scrutiny, revealing limitations in rigorous proof construction.


<details>
  <summary>Details</summary>
Motivation: Inequality proving requires advanced reasoning, making it a demanding task for LLMs. Progress is hindered by scarce, synthetic, or rigid datasets, motivating a new formulation of the problem and a high-quality dataset.

Method: Proposed an informal but verifiable task formulation splitting inequality proving into bound estimation and relation prediction. Released IneqMath, a curated dataset with step-wise solutions. Developed an evaluation framework using multiple step-wise judges to detect reasoning flaws.

Result: Tested 29 LLMs: top models scored <10% overall accuracy under step-wise scrutiny (up to 65.5% drop from final-answer equivalence). Scaling model size and compute yielded limited gains. Revealed fragility in deductive chains and gaps in rigorous proof construction.

Conclusion: The gap between finding answers and constructing proofs remains critical. Highlights promising directions like theorem-guided reasoning and self-refinement. Shares dataset and code publicly.

Abstract: Inequality proving, crucial across diverse scientific and mathematical
fields, tests advanced reasoning skills such as discovering tight bounds and
strategic theorem application. This makes it a distinct, demanding frontier for
large language models (LLMs), offering insights beyond general mathematical
problem-solving. Progress in this area is hampered by existing datasets that
are often scarce, synthetic, or rigidly formal. We address this by proposing an
informal yet verifiable task formulation, recasting inequality proving into two
automatically checkable subtasks: bound estimation and relation prediction.
Building on this, we release IneqMath, an expert-curated dataset of
Olympiad-level inequalities, including a test set and training corpus enriched
with step-wise solutions and theorem annotations. We also develop a novel
LLM-as-judge evaluation framework, combining a final-answer judge with four
step-wise judges designed to detect common reasoning flaws. A systematic
evaluation of 29 leading LLMs on IneqMath reveals a surprising reality: even
top models like o1 achieve less than 10% overall accuracy under step-wise
scrutiny; this is a drop of up to 65.5% from their accuracy considering only
final answer equivalence. This discrepancy exposes fragile deductive chains and
a critical gap for current LLMs between merely finding an answer and
constructing a rigorous proof. Scaling model size and increasing test-time
computation yield limited gains in overall proof correctness. Instead, our
findings highlight promising research directions such as theorem-guided
reasoning and self-refinement. Code and data are available at
https://ineqmath.github.io/.

</details>


### [676] [Reinforcing Multimodal Understanding and Generation with Dual Self-rewards](https://arxiv.org/abs/2506.07963)
*Jixiang Hong,Yiran Zhang,Guanzhong Wang,Yi Liu,Ji-Rong Wen,Rui Yan*

Main category: cs.AI

TL;DR: 提出了一个自我监督的双重奖励机制，通过将理解和生成视为互逆的双任务，利用对偶模型似然作为自我奖励，提升大型多模态模型的性能。


<details>
  <summary>Details</summary>
Motivation: 当前大型多模态模型在图文对齐方面存在困难，需要外部监督，且仅解决单向任务。为解决这些限制，利用双向任务互逆性提出自我监督方法。

Method: 引入自我监督的双重奖励机制：对输入任务采样多个输出，反转输入-输出对计算对偶似然作为自我奖励。

Result: 在视觉理解和生成基准测试中展现出性能提升，特别是文本到图像任务表现显著改善。

Conclusion: 该方法无需外部监督即可有效增强模型性能，为大型多模态模型的训练提供高效解决方案。

Abstract: Building upon large language models (LLMs), recent large multimodal models
(LMMs) unify cross-model understanding and generation into a single framework.
However, LMMs still struggle to achieve accurate image-text alignment, prone to
generating text responses contradicting the visual input or failing to follow
the text-to-image prompts. Current solutions require external supervision
(e.g., human feedback or reward models) and only address unidirectional
tasks-either understanding or generation. In this work, based on the
observation that understanding and generation are inverse dual tasks, we
introduce a self-supervised dual reward mechanism to reinforce the
understanding and generation capabilities of LMMs. Specifically, we sample
multiple outputs for a given input in one task domain, then reverse the
input-output pairs to compute the dual likelihood of the model as self-rewards
for optimization. Extensive experimental results on visual understanding and
generation benchmarks demonstrate that our method can effectively enhance the
performance of the model without any external supervision, especially achieving
remarkable improvements in text-to-image tasks.

</details>


### [677] [$τ^2$-Bench: Evaluating Conversational Agents in a Dual-Control Environment](https://arxiv.org/abs/2506.07982)
*Victor Barres,Honghua Dong,Soham Ray,Xujie Si,Karthik Narasimhan*

Main category: cs.AI

TL;DR: 论文引入了τ²-bench基准，用于测试在双重控制环境下（用户和AI都能使用工具）的对话AI代理性能，弥补了现有单控制基准的不足。


<details>
  <summary>Details</summary>
Motivation: 现有对话AI基准仅模拟单控制环境（仅代理能使用工具），与真实场景（如技术支持中用户需主动修改共享世界状态）存在差距。

Method: 1) 建立电信领域双重控制Dec-POMDP模型；2) 组合式任务生成器创建多样化任务；3) 工具约束的高保真用户模拟器；4) 细粒度错误分析框架。

Result: 实验表明代理在双重控制环境下性能显著下降（对比单控制），突显引导用户的挑战。

Conclusion: τ²-bench为需协同推理和用户引导的代理提供可控测试平台。

Abstract: Existing benchmarks for conversational AI agents simulate single-control
environments, where only the AI agent can use tools to interact with the world,
while the user remains a passive information provider. This differs from
real-world scenarios like technical support, where users need to actively
participate in modifying the state of the (shared) world. In order to address
this gap, we introduce $\tau^2$-bench, with four key contributions:
  1) A novel Telecom dual-control domain modeled as a Dec-POMDP, where both
agent and user make use of tools to act in a shared, dynamic environment that
tests both agent coordination and communication,
  2) A compositional task generator that programmatically creates diverse,
verifiable tasks from atomic components, ensuring domain coverage and
controlled complexity,
  3) A reliable user simulator tightly coupled with the environment, whose
behavior is constrained by tools and observable states, improving simulation
fidelity,
  4) Fine-grained analysis of agent performance through multiple ablations
including separating errors arising from reasoning vs
communication/coordination.
  In particular, our experiments show significant performance drops when agents
shift from no-user to dual-control, highlighting the challenges of guiding
users. Overall, $\tau^2$-bench provides a controlled testbed for agents that
must both reason effectively and guide user actions.

</details>


### [678] [VisioMath: Benchmarking Figure-based Mathematical Reasoning in LMMs](https://arxiv.org/abs/2506.06727)
*Can Li,Ting Zhang,Mei Wang,Hua Huang*

Main category: cs.AI

TL;DR: 论文提出了VisioMath数据集，用于评估多模态模型在数学推理任务中处理图像选项的能力。


<details>
  <summary>Details</summary>
Motivation: 现有大型多模态模型（LMMs）在数学推理中处理图像形式答案选项的能力尚未被充分研究，该领域存在研究空白。

Method: 构建包含8,070张图片和1,800道选择题的VisioMath评测基准，所有选项均为图像形式，需模型进行精细视觉区分。

Result: 当前最先进的LMMs（包括GPT-4o）在该测试中表现不佳（GPT-4o准确率仅45.9%），暴露出现有模型在视觉相似选项推理上的缺陷。

Conclusion: VisioMath填补了多模态推理评测的关键空白，为后续研究提供了严格的测试平台。

Abstract: Large Multimodal Models (LMMs) have demonstrated remarkable problem-solving
capabilities across various domains. However, their ability to perform
mathematical reasoning when answer options are represented as images--an
essential aspect of multi-image comprehension--remains underexplored. To bridge
this gap, we introduce VisioMath, a benchmark designed to evaluate mathematical
reasoning in multimodal contexts involving image-based answer choices.
VisioMath comprises 8,070 images and 1,800 multiple-choice questions, where
each answer option is an image, presenting unique challenges to existing LMMs.
To the best of our knowledge, VisioMath is the first dataset specifically
tailored for mathematical reasoning in image-based-option scenarios, where
fine-grained distinctions between answer choices are critical for accurate
problem-solving. We systematically evaluate state-of-the-art LMMs on VisioMath
and find that even the most advanced models struggle with this task. Notably,
GPT-4o achieves only 45.9% accuracy, underscoring the limitations of current
models in reasoning over visually similar answer choices. By addressing a
crucial gap in existing benchmarks, VisioMath establishes a rigorous testbed
for future research, driving advancements in multimodal reasoning.

</details>


### [679] [Long-Tailed Learning for Generalized Category Discovery](https://arxiv.org/abs/2506.06965)
*Cuong Manh Hoang*

Main category: cs.AI

TL;DR: 该论文提出了一种用于长尾分布的广义类别发现（GCD）框架，通过自引导标签技术和表示平衡过程解决现有方法在真实世界不平衡数据集上的性能问题。


<details>
  <summary>Details</summary>
Motivation: 现有GCD方法在平衡分布的人工数据集上有效，但在真实世界的不平衡数据集上表现不佳，因为长尾分布会导致模型偏向头部类别。

Method: 1. 自引导标签技术：使用可学习分布生成伪标签，减少分类器偏置。2. 表示平衡过程：通过挖掘样本邻域，鼓励模型更关注尾部类别，获得判别性表示。

Result: 在公共数据集上的实验表明，该模型超越了之前的最先进方法。

Conclusion: 所提出的框架有效解决了长尾分布下的GCD问题，通过减少偏置和增强尾部类别表示，显著提升在不平衡数据集上的性能。

Abstract: Generalized Category Discovery (GCD) utilizes labeled samples of known
classes to discover novel classes in unlabeled samples. Existing methods show
effective performance on artificial datasets with balanced distributions.
However, real-world datasets are always imbalanced, significantly affecting the
effectiveness of these methods. To solve this problem, we propose a novel
framework that performs generalized category discovery in long-tailed
distributions. We first present a self-guided labeling technique that uses a
learnable distribution to generate pseudo-labels, resulting in less biased
classifiers. We then introduce a representation balancing process to derive
discriminative representations. By mining sample neighborhoods, this process
encourages the model to focus more on tail classes. We conduct experiments on
public datasets to demonstrate the effectiveness of the proposed framework. The
results show that our model exceeds previous state-of-the-art methods.

</details>


### [680] [GUI-Reflection: Empowering Multimodal GUI Models with Self-Reflection Behavior](https://arxiv.org/abs/2506.08012)
*Penghao Wu,Shengnan Ma,Bo Wang,Jiaheng Yu,Lewei Lu,Ziwei Liu*

Main category: cs.AI

TL;DR: 提出了GUI-Reflection框架，通过自动化数据生成和迭代训练为多模态GUI模型增加自我反思与纠错能力。


<details>
  <summary>Details</summary>
Motivation: 现有GUI模型仅学习无误的离线轨迹，缺乏反思与错误恢复能力。

Method: 分三阶段训练：1) GUI专用预训练 2) 离线监督微调 3) 在线反思调优。利用自动生成的反思路径数据和移动设备环境进行迭代优化。

Result: 开发了GUI反思任务套件和在线训练环境，赋予GUI智能体自我修正能力。

Conclusion: 该框架为GUI自动化提供更鲁棒、自适应和智能的方案，所有资源将开源。

Abstract: Multimodal Large Language Models (MLLMs) have shown great potential in
revolutionizing Graphical User Interface (GUI) automation. However, existing
GUI models mostly rely on learning from nearly error-free offline trajectories,
thus lacking reflection and error recovery capabilities. To bridge this gap, we
propose GUI-Reflection, a novel framework that explicitly integrates
self-reflection and error correction capabilities into end-to-end multimodal
GUI models throughout dedicated training stages: GUI-specific pre-training,
offline supervised fine-tuning (SFT), and online reflection tuning.
GUI-reflection enables self-reflection behavior emergence with fully automated
data generation and learning processes without requiring any human annotation.
Specifically, 1) we first propose scalable data pipelines to automatically
construct reflection and error correction data from existing successful
trajectories. While existing GUI models mainly focus on grounding and UI
understanding ability, we propose the GUI-Reflection Task Suite to learn and
evaluate reflection-oriented abilities explicitly. 2) Furthermore, we built a
diverse and efficient environment for online training and data collection of
GUI models on mobile devices. 3) We also present an iterative online reflection
tuning algorithm leveraging the proposed environment, enabling the model to
continuously enhance its reflection and error correction abilities. Our
framework equips GUI agents with self-reflection and correction capabilities,
paving the way for more robust, adaptable, and intelligent GUI automation, with
all data, models, environments, and tools to be released publicly.

</details>


<div id='cs.CR'></div>

# cs.CR [[Back]](#toc)

### [681] [HeavyWater and SimplexWater: Watermarking Low-Entropy Text Distributions](https://arxiv.org/abs/2506.06409)
*Dor Tsur,Carol Xuan Long,Claudio Mayrink Verdun,Hsiang Hsu,Chen-Fu Chen,Haim Permuter,Sajani Vithana,Flavio P. Calmon*

Main category: cs.CR

TL;DR: 提出了一个大型语言模型（LLM）水印的设计优化框架HeavyWater和SimplexWater。两种水印可调节精度与失真，特别在低熵场景中效果良好。


<details>
  <summary>Details</summary>
Motivation: 现有水印在低熵生成场景中效果不佳（如编码任务）。本文旨在通过优化设计实现高效检测与最小文本失真。

Method: 提出基于随机边信息最大化水印检测率的优化框架。设计了两种可调水印：HeavyWater和SimplexWater，无需模型修改且边信息无关。

Result: 在多个基准测试中，新水印在低熵场景下显著优于现有方法，实现高检测准确率（如94.5%）同时仅造成轻微文本质量下降（困惑度波动<5%）

Conclusion: 揭示了水印与编码理论的新联系。新水印为可调通用解决方案，尤其在低熵任务有效。代码已开源

Abstract: Large language model (LLM) watermarks enable authentication of text
provenance, curb misuse of machine-generated text, and promote trust in AI
systems. Current watermarks operate by changing the next-token predictions
output by an LLM. The updated (i.e., watermarked) predictions depend on random
side information produced, for example, by hashing previously generated tokens.
LLM watermarking is particularly challenging in low-entropy generation tasks -
such as coding - where next-token predictions are near-deterministic. In this
paper, we propose an optimization framework for watermark design. Our goal is
to understand how to most effectively use random side information in order to
maximize the likelihood of watermark detection and minimize the distortion of
generated text. Our analysis informs the design of two new watermarks:
HeavyWater and SimplexWater. Both watermarks are tunable, gracefully
trading-off between detection accuracy and text distortion. They can also be
applied to any LLM and are agnostic to side information generation. We examine
the performance of HeavyWater and SimplexWater through several benchmarks,
demonstrating that they can achieve high watermark detection accuracy with
minimal compromise of text generation quality, particularly in the low-entropy
regime. Our theoretical analysis also reveals surprising new connections
between LLM watermarking and coding theory. The code implementation can be
found in https://github.com/DorTsur/HeavyWater_SimplexWater

</details>


### [682] [Auditing Black-Box LLM APIs with a Rank-Based Uniformity Test](https://arxiv.org/abs/2506.06975)
*Xiaoyuan Zhu,Yaowen Ye,Tianyi Qiu,Hanlin Zhu,Sijun Tan,Ajraf Mannan,Jonathan Michala,Raluca Ada Popa,Willie Neiswanger*

Main category: cs.CR

TL;DR: 提出通过基于排名的均匀性测试验证黑盒LLM与真实模型行为一致性的方法，以检测API供应商可能采取的模型替换行为。


<details>
  <summary>Details</summary>
Motivation: API供应商可能暗中部署量化或微调的模型变体来降低成本或恶意修改行为，导致性能下降和安全风险，而用户缺乏透明确认模型真实性。

Method: 设计基于KL散度和排列组合分析的统计测试，通过随机提示生成输出分布排名来比较模型行为，该方法隐藏查询模式可防对抗检测。

Result: 在量化、恶意微调、越狱攻击等场景中，该方法在有限查询次数下始终超越现有方案的统计检验效能（最高提升80% power）。

Conclusion: 该无参数秩检验首次实现黑盒环境高效模型认证，可为可信API提供轻量级审计工具，未来将探索防御自适应攻击机制。

Abstract: As API access becomes a primary interface to large language models (LLMs),
users often interact with black-box systems that offer little transparency into
the deployed model. To reduce costs or maliciously alter model behaviors, API
providers may discreetly serve quantized or fine-tuned variants, which can
degrade performance and compromise safety. Detecting such substitutions is
difficult, as users lack access to model weights and, in most cases, even
output logits. To tackle this problem, we propose a rank-based uniformity test
that can verify the behavioral equality of a black-box LLM to a locally
deployed authentic model. Our method is accurate, query-efficient, and avoids
detectable query patterns, making it robust to adversarial providers that
reroute or mix responses upon the detection of testing attempts. We evaluate
the approach across diverse threat scenarios, including quantization, harmful
fine-tuning, jailbreak prompts, and full model substitution, showing that it
consistently achieves superior statistical power over prior methods under
constrained query budgets.

</details>


### [683] [HauntAttack: When Attack Follows Reasoning as a Shadow](https://arxiv.org/abs/2506.07031)
*Jingyuan Ma,Rui Li,Zheng Li,Junfeng Liu,Lei Sha,Zhifang Sui*

Main category: cs.CR

TL;DR: HauntAttack 是一个黑盒攻击框架，通过将有害指令嵌入推理问题中来揭示大型推理模型（LRM）的安全漏洞。研究发现，即使最先进的 LRM 也存在重大安全隐患。


<details>
  <summary>Details</summary>
Motivation: 虽然大型推理模型（LRM）在数学和推理任务上表现优异，但其增强的推理能力和内部推理过程的透明化带来了新的安全漏洞。研究旨在探索当推理与有害性高度纠缠时，LRM 表现出的安全与推理权衡问题。

Method: 提出 HauntAttack 框架：将推理问题作为载体，用有害指令替换其中一个原始条件，构建引导模型逐步生成不安全输出的推理路径。采用黑盒攻击方式，对多个 LRM 进行实验。

Result: 实验表明，即使最先进的 LRM 也存在显著的安全漏洞。详细分析了不同模型、各类有害指令及输出模式，为 LRM 安全提供了重要见解。

Conclusion: 研究揭示了 LRM 在安全与推理权衡中的系统性脆弱性，证明增强推理能力可能伴随安全隐患。HauntAttack 作为通用框架，有效暴露了这一问题。

Abstract: Emerging Large Reasoning Models (LRMs) consistently excel in mathematical and
reasoning tasks, showcasing exceptional capabilities. However, the enhancement
of reasoning abilities and the exposure of their internal reasoning processes
introduce new safety vulnerabilities. One intriguing concern is: when reasoning
is strongly entangled with harmfulness, what safety-reasoning trade-off do LRMs
exhibit? To address this issue, we introduce HauntAttack, a novel and
general-purpose black-box attack framework that systematically embeds harmful
instructions into reasoning questions. Specifically, we treat reasoning
questions as carriers and substitute one of their original conditions with a
harmful instruction. This process creates a reasoning pathway in which the
model is guided step by step toward generating unsafe outputs. Based on
HauntAttack, we conduct comprehensive experiments on multiple LRMs. Our results
reveal that even the most advanced LRMs exhibit significant safety
vulnerabilities. Additionally, we perform a detailed analysis of different
models, various types of harmful instructions, and model output patterns,
providing valuable insights into the security of LRMs.

</details>


### [684] [Beyond Jailbreaks: Revealing Stealthier and Broader LLM Security Risks Stemming from Alignment Failures](https://arxiv.org/abs/2506.07402)
*Yukai Zhou,Sibei Yang,Wenjie Wang*

Main category: cs.CR

TL;DR: 该论文提出了一种新的LLM安全风险视角，重点关注'隐性危害'（即LLM对表面上无害的查询给出错误回答而导致的危险），并构建了涵盖多场景的JailFlipBench基准测试。通过评估发现该风险普遍存在于各类LLMs中，呼吁扩展传统越狱攻击的安全评估范围。


<details>
  <summary>Details</summary>
Motivation: 现有研究主要关注显性恶意查询（越狱攻击）下的LLM安全问题，但忽略了'隐性危害'：即LLM对看似无害的输入给出错误回答时可能造成的现实世界危害。这种风险在现有的安全评估范式中未被系统研究。

Method: 1) 通过输出真实性和输入无害性两个维度重构LLM风险象限；2) 开发JailFlipBench基准测试，涵盖单模态、多模态和事实扩展三大场景；3) 提出JailFlip攻击方法量化此类风险；4) 对开源和商业LLMs进行综合评估。

Result: 实验表明：1) 所有测试的LLMs在隐性危害场景中均存在显著漏洞；2) 多模态模型在图像相关查询中表现最弱；3) 现有安全对齐机制对此类风险防护不足。

Conclusion: 隐性危害构成即时且紧迫的现实风险，需要将安全评估范围扩展到传统越狱攻击范式之外，开发针对性的防御机制。

Abstract: Large language models (LLMs) are increasingly deployed in real-world
applications, raising concerns about their security. While jailbreak attacks
highlight failures under overtly harmful queries, they overlook a critical
risk: incorrectly answering harmless-looking inputs can be dangerous and cause
real-world harm (Implicit Harm). We systematically reformulate the LLM risk
landscape through a structured quadrant perspective based on output factuality
and input harmlessness, uncovering an overlooked high-risk region. To
investigate this gap, we propose JailFlipBench, a benchmark aims to capture
implicit harm, spanning single-modal, multimodal, and factual extension
scenarios with diverse evaluation metrics. We further develop initial JailFlip
attack methodologies and conduct comprehensive evaluations across multiple
open-source and black-box LLMs, show that implicit harm present immediate and
urgent real-world risks, calling for broader LLM safety assessments and
alignment beyond conventional jailbreak paradigms.

</details>


### [685] [HeavyWater and SimplexWater: Watermarking Low-Entropy Text Distributions](https://arxiv.org/abs/2506.06409)
*Dor Tsur,Carol Xuan Long,Claudio Mayrink Verdun,Hsiang Hsu,Chen-Fu Chen,Haim Permuter,Sajani Vithana,Flavio P. Calmon*

Main category: cs.CR

TL;DR: 提出了一种可优化的LLM水印框架——HeavyWater和SimplexWater，用于解决低熵场景下水印的准确检测与文本质量之间的权衡问题。


<details>
  <summary>Details</summary>
Motivation: 现有水印技术在低熵任务（如代码生成）中效果受限，因为此时token预测近乎确定性，需要优化水印设计以提高检测准确率并减少文本失真。

Method: 设计了基于优化框架的两种可调水印：HeavyWater利用重尾分布；SimplexWater使用单纯形投影。二者通过调整参数平衡检测准确性与文本质量。

Result: 在多个基准测试中，新水印在低熵场景下保持高检测准确率的同时，对文本质量影响最小，且揭示了与水印理论与编码理论的新联系。

Conclusion: HeavyWater和SimplexWater为任意LLM提供通用、高效的水印方案，特别是优化了低熵任务表现，推动LLM水印的实用化发展。

Abstract: Large language model (LLM) watermarks enable authentication of text
provenance, curb misuse of machine-generated text, and promote trust in AI
systems. Current watermarks operate by changing the next-token predictions
output by an LLM. The updated (i.e., watermarked) predictions depend on random
side information produced, for example, by hashing previously generated tokens.
LLM watermarking is particularly challenging in low-entropy generation tasks -
such as coding - where next-token predictions are near-deterministic. In this
paper, we propose an optimization framework for watermark design. Our goal is
to understand how to most effectively use random side information in order to
maximize the likelihood of watermark detection and minimize the distortion of
generated text. Our analysis informs the design of two new watermarks:
HeavyWater and SimplexWater. Both watermarks are tunable, gracefully
trading-off between detection accuracy and text distortion. They can also be
applied to any LLM and are agnostic to side information generation. We examine
the performance of HeavyWater and SimplexWater through several benchmarks,
demonstrating that they can achieve high watermark detection accuracy with
minimal compromise of text generation quality, particularly in the low-entropy
regime. Our theoretical analysis also reveals surprising new connections
between LLM watermarking and coding theory. The code implementation can be
found in https://github.com/DorTsur/HeavyWater_SimplexWater

</details>


### [686] [Auditing Black-Box LLM APIs with a Rank-Based Uniformity Test](https://arxiv.org/abs/2506.06975)
*Xiaoyuan Zhu,Yaowen Ye,Tianyi Qiu,Hanlin Zhu,Sijun Tan,Ajraf Mannan,Jonathan Michala,Raluca Ada Popa,Willie Neiswanger*

Main category: cs.CR

TL;DR: 研究提出了一种基于等级的一致性测试方法，用于检测黑盒大型语言模型（如API服务）是否被偷偷替换成量化版、微调版或完全替代模型，从而避免性能下降或安全性问题。该方法在查询效率、对抗性防御和统计效能方面均优于现有方法。


<details>
  <summary>Details</summary>
Motivation: API提供商可能出于成本或恶意目的秘密部署量化模型、微调模型或替代模型，导致模型性能下降或存在安全隐患。由于用户无法获取模型权重甚至输出logits，检测此类替换行为极具挑战性。

Method: 提出基于等级的一致性测试（rank-based uniformity test），通过验证黑盒模型与本地正版模型的行为一致性进行判断。该方法具有高准确性、查询高效性，并能避免可检测的查询模式，防止被具备对抗能力的API提供商识别和干扰。

Result: 在多种威胁场景下（量化压缩、有害微调、越狱提示、全模型替换）进行验证，证明该方法在有限查询预算下始终优于已有方案。

Conclusion: 该方法能有效对抗秘密模型替换行为，为API服务用户提供透明性保障验证工具，解决了黑盒环境下的模型验证难题。

Abstract: As API access becomes a primary interface to large language models (LLMs),
users often interact with black-box systems that offer little transparency into
the deployed model. To reduce costs or maliciously alter model behaviors, API
providers may discreetly serve quantized or fine-tuned variants, which can
degrade performance and compromise safety. Detecting such substitutions is
difficult, as users lack access to model weights and, in most cases, even
output logits. To tackle this problem, we propose a rank-based uniformity test
that can verify the behavioral equality of a black-box LLM to a locally
deployed authentic model. Our method is accurate, query-efficient, and avoids
detectable query patterns, making it robust to adversarial providers that
reroute or mix responses upon the detection of testing attempts. We evaluate
the approach across diverse threat scenarios, including quantization, harmful
fine-tuning, jailbreak prompts, and full model substitution, showing that it
consistently achieves superior statistical power over prior methods under
constrained query budgets.

</details>


### [687] [HauntAttack: When Attack Follows Reasoning as a Shadow](https://arxiv.org/abs/2506.07031)
*Jingyuan Ma,Rui Li,Zheng Li,Junfeng Liu,Lei Sha,Zhifang Sui*

Main category: cs.CR

TL;DR: 本文介绍了一种名为HauntAttack的新型黑盒攻击框架，用于测试大型推理模型在安全性与推理能力权衡中的漏洞。通过将有害指令嵌入推理问题，研究发现即使最先进的大型推理模型也存在显著的安全脆弱性。


<details>
  <summary>Details</summary>
Motivation: 随着大型推理模型在数学和推理任务中的优异表现逐渐显现，其推理能力的提升和推理过程的透明化带来了新的安全隐患。本文旨在研究当推理能力与有害性紧密结合时，大型推理模型在安全性与推理能力之间存在的权衡问题。

Method: 提出了一种通用黑盒攻击框架——HauntAttack，该框架将有害指令系统地嵌入推理问题中。具体方法是将推理问题作为载体，并将其原始条件之一替换为有害指令，从而构建出引导模型逐步生成不安全输出的推理路径。

Result: 对多个大型推理模型进行了全面实验，结果表明即使最先进的模型也表现出显著的安全脆弱性。同时，还对不同模型、各类有害指令以及模型输出模式进行了详细分析，为大型推理模型的安全性提供了有价值的见解。

Conclusion: HauntAttack框架暴露了大型推理模型在安全性方面的重大缺陷，强调了在提升模型推理能力的同时必须重视安全风险。该研究为理解和改善大型推理模型的安全机制提供了实证基础。

Abstract: Emerging Large Reasoning Models (LRMs) consistently excel in mathematical and
reasoning tasks, showcasing exceptional capabilities. However, the enhancement
of reasoning abilities and the exposure of their internal reasoning processes
introduce new safety vulnerabilities. One intriguing concern is: when reasoning
is strongly entangled with harmfulness, what safety-reasoning trade-off do LRMs
exhibit? To address this issue, we introduce HauntAttack, a novel and
general-purpose black-box attack framework that systematically embeds harmful
instructions into reasoning questions. Specifically, we treat reasoning
questions as carriers and substitute one of their original conditions with a
harmful instruction. This process creates a reasoning pathway in which the
model is guided step by step toward generating unsafe outputs. Based on
HauntAttack, we conduct comprehensive experiments on multiple LRMs. Our results
reveal that even the most advanced LRMs exhibit significant safety
vulnerabilities. Additionally, we perform a detailed analysis of different
models, various types of harmful instructions, and model output patterns,
providing valuable insights into the security of LRMs.

</details>


### [688] [Beyond Jailbreaks: Revealing Stealthier and Broader LLM Security Risks Stemming from Alignment Failures](https://arxiv.org/abs/2506.07402)
*Yukai Zhou,Sibei Yang,Wenjie Wang*

Main category: cs.CR

TL;DR: 该论文指出了LLMs在隐式危害（Implicit Harm）方面的安全风险，即模型对看似无害的输入产生错误回答可能导致现实危害。研究者提出了JailFlipBench基准来评估这种风险，并通过实验证明现有模型普遍存在该问题。


<details>
  <summary>Details</summary>
Motivation: 当前LLM安全研究主要关注显式的越狱攻击（jailbreak），但忽视了模型对看似无害查询产生错误回答的隐式危害风险。这种隐式危害在实际应用中可能造成严重后果。

Method: 1. 通过输出事实性和输入无害性构建四象限风险框架，识别出高风险区域；2. 提出JailFlipBench多场景基准（单模态/多模态/事实扩展）；3. 开发JailFlip攻击方法；4. 在开源/闭源模型上全面评估。

Result: 实验证明：1. 现有LLMs均存在显著的隐式危害风险；2. 多模态和事实扩展场景风险最高；3. 不同安全对齐策略对隐式危害防护效果有限。

Conclusion: 隐式危害是当前LLM安全中被忽视的关键风险，需要超越传统越狱防护的安全评估框架。JailFlipBench为系统化评估提供了基础，未来研究需开发针对性防护措施。

Abstract: Large language models (LLMs) are increasingly deployed in real-world
applications, raising concerns about their security. While jailbreak attacks
highlight failures under overtly harmful queries, they overlook a critical
risk: incorrectly answering harmless-looking inputs can be dangerous and cause
real-world harm (Implicit Harm). We systematically reformulate the LLM risk
landscape through a structured quadrant perspective based on output factuality
and input harmlessness, uncovering an overlooked high-risk region. To
investigate this gap, we propose JailFlipBench, a benchmark aims to capture
implicit harm, spanning single-modal, multimodal, and factual extension
scenarios with diverse evaluation metrics. We further develop initial JailFlip
attack methodologies and conduct comprehensive evaluations across multiple
open-source and black-box LLMs, show that implicit harm present immediate and
urgent real-world risks, calling for broader LLM safety assessments and
alignment beyond conventional jailbreak paradigms.

</details>


<div id='stat.ML'></div>

# stat.ML [[Back]](#toc)

### [689] [On the Fundamental Impossibility of Hallucination Control in Large Language Models](https://arxiv.org/abs/2506.06382)
*Michał P. Karpowicz*

Main category: stat.ML

TL;DR: 该论文通过形式化的不可能定理证明大型语言模型无法同时满足四个基本属性：真实性生成、语义信息守恒、相关知识揭示和知识约束最优。


<details>
  <summary>Details</summary>
Motivation: 探索现有LLMs必然产生幻觉的根本原因，并从理论上解释为何完美解决幻觉问题是不可能的，同时分析各属性之间的权衡取舍。

Method: 将语言模型推理建模为“观点拍卖”博弈，利用Green-Laffont定理进行数学证明，考察神经组件竞争贡献内容时的均衡条件。

Result: 严格证明了不存在同时满足所有四项基本属性的推理机制，揭示了语言模型设计中的根本性约束，即开发者必须在不同属性间进行权衡。

Conclusion: 追求完全消除幻觉是不现实的，应转而关注各属性间的帕累托最优配置，这对模型架构设计、训练目标和评估方法具有指导意义。

Abstract: This paper explains \textbf{why it is impossible to create large language
models that do not hallucinate and what are the trade-offs we should be looking
for}. It presents a formal \textbf{impossibility theorem} demonstrating that no
inference mechanism can simultaneously satisfy four fundamental properties:
\textbf{truthful (non-hallucinatory) generation, semantic information
conservation, relevant knowledge revelation, and knowledge-constrained
optimality}. By modeling LLM inference as an \textbf{auction of ideas} where
neural components compete to contribute to responses, we prove the
impossibility using the Green-Laffont theorem. That mathematical framework
provides a rigorous foundation for understanding the nature of inference
process, with implications for model architecture, training objectives, and
evaluation methods.

</details>


### [690] [On the Fundamental Impossibility of Hallucination Control in Large Language Models](https://arxiv.org/abs/2506.06382)
*Michał P. Karpowicz*

Main category: stat.ML

TL;DR: 本文通过一个形式化的不可能性定理证明，大型语言模型无法同时满足四个基本属性：真实性（不产生幻觉）、语义信息守恒、相关知识揭示和知识约束最优性。


<details>
  <summary>Details</summary>
Motivation: 揭示为什么大型语言模型无法避免产生幻觉，并探讨需要权衡的关键。

Method: 将LLM推理建模为'创意拍卖'过程，利用Green-Laffont定理证明不可能性。

Result: 严格证明了在大型语言模型中同时实现四个理想属性是不可能的。

Conclusion: 该定理为理解推理本质提供了数学框架，对模型架构、训练目标和评估方法有重要启示。

Abstract: This paper explains \textbf{why it is impossible to create large language
models that do not hallucinate and what are the trade-offs we should be looking
for}. It presents a formal \textbf{impossibility theorem} demonstrating that no
inference mechanism can simultaneously satisfy four fundamental properties:
\textbf{truthful (non-hallucinatory) generation, semantic information
conservation, relevant knowledge revelation, and knowledge-constrained
optimality}. By modeling LLM inference as an \textbf{auction of ideas} where
neural components compete to contribute to responses, we prove the
impossibility using the Green-Laffont theorem. That mathematical framework
provides a rigorous foundation for understanding the nature of inference
process, with implications for model architecture, training objectives, and
evaluation methods.

</details>


<div id='cs.MM'></div>

# cs.MM [[Back]](#toc)

### [691] [Experimental Evaluation of Static Image Sub-Region-Based Search Models Using CLIP](https://arxiv.org/abs/2506.06938)
*Bastian Jäckl,Vojtěch Kloda,Daniel A. Keim,Jakub Lokoč*

Main category: cs.MM

TL;DR: 本论文研究在专家领域模糊文本查询中加入位置提示是否提升检索效果，实验表明简单分区和重叠网格能显著改进水下场景的图像检索。


<details>
  <summary>Details</summary>
Motivation: 多模态文本-图像模型在日常生活场景中表现良好，但在高度同质的专业领域中，用户由于缺乏专业知识往往只能提供模糊的文本描述，导致查询效果不佳。本研究旨在通过位置提示补充模糊文本来提升检索性能。

Method: 收集了741个人工标注（包含短/长文本描述及水下场景中的目标区域边界框），评估CLIP模型在全图像查询与静态子区域查询（3x3分区和5网格重叠）中的性能差异，并验证标注框扰动的鲁棒性。

Result: 实验表明，与全图像查询相比，简单的3x3分区和5网格重叠策略显著提升检索效率，且在标注框扰动下保持稳健。

Conclusion: 对于专业领域中的模糊查询，添加基于位置的简单空间划分能有效增强多模态检索性能，该方法具有实用性和鲁棒性。

Abstract: Advances in multimodal text-image models have enabled effective text-based
querying in extensive image collections. While these models show convincing
performance for everyday life scenes, querying in highly homogeneous,
specialized domains remains challenging. The primary problem is that users can
often provide only vague textual descriptions as they lack expert knowledge to
discriminate between homogenous entities. This work investigates whether adding
location-based prompts to complement these vague text queries can enhance
retrieval performance. Specifically, we collected a dataset of 741 human
annotations, each containing short and long textual descriptions and bounding
boxes indicating regions of interest in challenging underwater scenes. Using
these annotations, we evaluate the performance of CLIP when queried on various
static sub-regions of images compared to the full image. Our results show that
both a simple 3-by-3 partitioning and a 5-grid overlap significantly improve
retrieval effectiveness and remain robust to perturbations of the annotation
box.

</details>


### [692] [Experimental Evaluation of Static Image Sub-Region-Based Search Models Using CLIP](https://arxiv.org/abs/2506.06938)
*Bastian Jäckl,Vojtěch Kloda,Daniel A. Keim,Jakub Lokoč*

Main category: cs.MM

TL;DR: 研究了在专家领域（如水下场景）中，针对模糊文本查询加入位置提示能否提升图像检索效果。通过人类标注数据集测试CLIP模型在不同图像子区域（3x3分区和5网格重叠）的检索性能，证明这两种方法显著提升效果，且对标注框扰动鲁棒。


<details>
  <summary>Details</summary>
Motivation: 针对专业领域图像检索中用户只能提供模糊描述（缺乏专业知识区分同质实体）的问题，探索通过补充位置提示来增强模糊文本查询的检索性能。

Method: 收集741个包含简短/详细文本描述及标注框的水下场景人类标注，评估CLIP模型在图像静态子区域（对比整图）的查询效果，重点测试3x3分区和5网格重叠策略。

Result: 两种分区方法显著提升检索效果，且对标注框位置扰动保持鲁棒性。

Conclusion: 位置提示能有效弥补模糊文本查询的不足，为专业领域图像检索提供实用解决方案。

Abstract: Advances in multimodal text-image models have enabled effective text-based
querying in extensive image collections. While these models show convincing
performance for everyday life scenes, querying in highly homogeneous,
specialized domains remains challenging. The primary problem is that users can
often provide only vague textual descriptions as they lack expert knowledge to
discriminate between homogenous entities. This work investigates whether adding
location-based prompts to complement these vague text queries can enhance
retrieval performance. Specifically, we collected a dataset of 741 human
annotations, each containing short and long textual descriptions and bounding
boxes indicating regions of interest in challenging underwater scenes. Using
these annotations, we evaluate the performance of CLIP when queried on various
static sub-regions of images compared to the full image. Our results show that
both a simple 3-by-3 partitioning and a 5-grid overlap significantly improve
retrieval effectiveness and remain robust to perturbations of the annotation
box.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [693] [Active Illumination Control in Low-Light Environments using NightHawk](https://arxiv.org/abs/2506.06394)
*Yash Turkar,Youngjin Kim,Karthik Dantu*

Main category: cs.RO

TL;DR: NightHawk通过主动光照和曝光控制优化地下环境中的图像质量，使用基于特征检测的度量和贝叶斯优化，在真实测试中提升特征检测匹配47-197%。


<details>
  <summary>Details</summary>
Motivation: 解决地下环境（如涵洞）因光照不足导致机器人视觉困难的问题，同时避免自带光源产生的镜面反射、过曝和功耗增加等副作用。

Method: 构建基于事件触发的递归优化框架：1) 定义特征检测器指标量化图像效用；2) 建立在线贝叶斯优化模型，动态调整光强和曝光时间；3) 在履带机器人上实际部署。

Result: 在伊利运河涵洞测试中：特征检测与匹配能力提升47%-197%，显著增强低光环境下视觉估计算法的可靠性。

Conclusion: NightHawk框架有效平衡了主动照明的利弊，通过闭环优化策略极大提升恶劣光照条件下的机器人视觉性能。

Abstract: Subterranean environments such as culverts present significant challenges to
robot vision due to dim lighting and lack of distinctive features. Although
onboard illumination can help, it introduces issues such as specular
reflections, overexposure, and increased power consumption. We propose
NightHawk, a framework that combines active illumination with exposure control
to optimize image quality in these settings. NightHawk formulates an online
Bayesian optimization problem to determine the best light intensity and
exposure-time for a given scene. We propose a novel feature detector-based
metric to quantify image utility and use it as the cost function for the
optimizer. We built NightHawk as an event-triggered recursive optimization
pipeline and deployed it on a legged robot navigating a culvert beneath the
Erie Canal. Results from field experiments demonstrate improvements in feature
detection and matching by 47-197% enabling more reliable visual estimation in
challenging lighting conditions.

</details>


### [694] [Edge-Enabled Collaborative Object Detection for Real-Time Multi-Vehicle Perception](https://arxiv.org/abs/2506.06474)
*Everett Richards,Bipul Thapa,Lena Mashayekhy*

Main category: cs.RO

TL;DR: 我們提出了一個名為ECOD的邊緣協作物件偵測框架，結合PACE和VOTE兩種演算法，利用多車協作提升自動駕駛環境中的物件分類準確率75%，同時確保低延遲即時處理。


<details>
  <summary>Details</summary>
Motivation: 傳統車載感知系統存在遮擋和盲區問題，雲端方案則有延遲過高的缺點，無法滿足自動駕駛在動態環境中的即時處理需求。

Method: 提出ECOD框架：1) PACE演算法在邊緣伺服器聚合多車偵測數據增強感知；2) VOTE演算法通過共識投票機制整合多車數據提升分類準確率。使用具備相機的機器人CAV和邊緣伺服器搭建測試平台驗證。

Result: 實驗顯示ECOD顯著提升物件分類準確率，比傳統單一視角車載方法高出75%，同時維持低延遲的即時處理性能。

Conclusion: 本研究證實邊緣計算能有效提升對延遲敏感的協作感知系統（如自動駕駛），實現高效可靠的多視角物件偵測。

Abstract: Accurate and reliable object detection is critical for ensuring the safety
and efficiency of Connected Autonomous Vehicles (CAVs). Traditional on-board
perception systems have limited accuracy due to occlusions and blind spots,
while cloud-based solutions introduce significant latency, making them
unsuitable for real-time processing demands required for autonomous driving in
dynamic environments. To address these challenges, we introduce an innovative
framework, Edge-Enabled Collaborative Object Detection (ECOD) for CAVs, that
leverages edge computing and multi-CAV collaboration for real-time,
multi-perspective object detection. Our ECOD framework integrates two key
algorithms: Perceptive Aggregation and Collaborative Estimation (PACE) and
Variable Object Tally and Evaluation (VOTE). PACE aggregates detection data
from multiple CAVs on an edge server to enhance perception in scenarios where
individual CAVs have limited visibility. VOTE utilizes a consensus-based voting
mechanism to improve the accuracy of object classification by integrating data
from multiple CAVs. Both algorithms are designed at the edge to operate in
real-time, ensuring low-latency and reliable decision-making for CAVs. We
develop a hardware-based controlled testbed consisting of camera-equipped
robotic CAVs and an edge server to evaluate the efficacy of our framework. Our
experimental results demonstrate the significant benefits of ECOD in terms of
improved object classification accuracy, outperforming traditional
single-perspective onboard approaches by up to 75%, while ensuring low-latency,
edge-driven real-time processing. This research highlights the potential of
edge computing to enhance collaborative perception for latency-sensitive
autonomous systems.

</details>


### [695] [DriveSuprim: Towards Precise Trajectory Selection for End-to-End Planning](https://arxiv.org/abs/2506.06659)
*Wenhao Yao,Zhenxin Li,Shiyi Lan,Zi Wang,Xinglong Sun,Jose M. Alvarez,Zuxuan Wu*

Main category: cs.RO

TL;DR: DriveSuprim 方法通过逐步筛选、旋转增强和自我蒸馏提升自动驾驶安全；在 NAVSIM v1/v2 中表现最优。


<details>
  <summary>Details</summary>
Motivation: 解决基于选择的轨迹预测方法在优化和区分安全关键差异上的挑战，特别是稀疏场景下的安全评估不足问题。

Method: 1. 粗到细的候选轨迹渐进筛选 2. 基于旋转的数据增强提升分布外鲁棒性 3. 自我蒸馏框架稳定训练

Result: NAVSIM v1 达到 93.5% PDMS，v2 达 87.1% EPDMS（无额外数据），展现卓越的避撞、合规能力及轨迹质量。

Conclusion: DriveSuprim 显著提升安全关键场景性能，为选择式自动驾驶框架提供有效解决方案。

Abstract: In complex driving environments, autonomous vehicles must navigate safely.
Relying on a single predicted path, as in regression-based approaches, usually
does not explicitly assess the safety of the predicted trajectory.
Selection-based methods address this by generating and scoring multiple
trajectory candidates and predicting the safety score for each, but face
optimization challenges in precisely selecting the best option from thousands
of possibilities and distinguishing subtle but safety-critical differences,
especially in rare or underrepresented scenarios. We propose DriveSuprim to
overcome these challenges and advance the selection-based paradigm through a
coarse-to-fine paradigm for progressive candidate filtering, a rotation-based
augmentation method to improve robustness in out-of-distribution scenarios, and
a self-distillation framework to stabilize training. DriveSuprim achieves
state-of-the-art performance, reaching 93.5% PDMS in NAVSIM v1 and 87.1% EPDMS
in NAVSIM v2 without extra data, demonstrating superior safetycritical
capabilities, including collision avoidance and compliance with rules, while
maintaining high trajectory quality in various driving scenarios.

</details>


### [696] [Generalized Trajectory Scoring for End-to-end Multimodal Planning](https://arxiv.org/abs/2506.06664)
*Zhenxin Li,Wenhao Yao,Zi Wang,Xinglong Sun,Joshua Chen,Nadine Chang,Maying Shen,Zuxuan Wu,Shiyi Lan,Jose M. Alvarez*

Main category: cs.RO

TL;DR: 提出了名为GTRS（广义轨迹评分）的端到端多模态规划统一框架，通过结合粗粒度与细粒度轨迹评估解决现有轨迹评分器的泛化局限。该方法包含三个创新点：基于扩散的轨迹生成器、词典泛化技术和传感器增强策略，在Navsim v2挑战赛中获胜，表现出优于依赖地面实况感知的特权方法的性能。


<details>
  <summary>Details</summary>
Motivation: 解决现有多模态规划中两种轨迹评分器的泛化问题：静态轨迹集方法难以适应细粒度调整，动态生成方法无法覆盖广泛轨迹分布

Method: 1) 扩散模型生成细粒度轨迹方案；2) 对超密集轨迹集进行dropout正则化训练实现词典泛化；3) 传感器增强策略提升域外泛化能力并加入关键轨迹判别精调训练

Result: 在Navsim v2挑战赛中夺冠，即使使用次优传感器输入也能接近依赖完美感知的特权方法性能

Conclusion: GTRS框架通过结合粗粒度评估与细粒度生成，有效统一并克服了现有轨迹评分方法的局限性，为自动驾驶领域多模态规划提供了泛化性更强的新方案

Abstract: End-to-end multi-modal planning is a promising paradigm in autonomous
driving, enabling decision-making with diverse trajectory candidates. A key
component is a robust trajectory scorer capable of selecting the optimal
trajectory from these candidates. While recent trajectory scorers focus on
scoring either large sets of static trajectories or small sets of dynamically
generated ones, both approaches face significant limitations in generalization.
Static vocabularies provide effective coarse discretization but struggle to
make fine-grained adaptation, while dynamic proposals offer detailed precision
but fail to capture broader trajectory distributions. To overcome these
challenges, we propose GTRS (Generalized Trajectory Scoring), a unified
framework for end-to-end multi-modal planning that combines coarse and
fine-grained trajectory evaluation. GTRS consists of three complementary
innovations: (1) a diffusion-based trajectory generator that produces diverse
fine-grained proposals; (2) a vocabulary generalization technique that trains a
scorer on super-dense trajectory sets with dropout regularization, enabling its
robust inference on smaller subsets; and (3) a sensor augmentation strategy
that enhances out-of-domain generalization while incorporating refinement
training for critical trajectory discrimination. As the winning solution of the
Navsim v2 Challenge, GTRS demonstrates superior performance even with
sub-optimal sensor inputs, approaching privileged methods that rely on
ground-truth perception. Code will be available at
https://github.com/NVlabs/GTRS.

</details>


### [697] [RoboCerebra: A Large-scale Benchmark for Long-horizon Robotic Manipulation Evaluation](https://arxiv.org/abs/2506.06677)
*Songhao Han,Boxiang Qiu,Yue Liao,Siyuan Huang,Chen Gao,Shuicheng Yan,Si Liu*

Main category: cs.RO

TL;DR: 提出RoboCerebra基准测试，针对长期机器人操作任务的高层推理能力评估。通过模拟数据集、分层框架和评估协议，解决现有研究对系统2能力（规划、反思、记忆）研究的不足。


<details>
  <summary>Details</summary>
Motivation: 现有工作多聚焦于反应式系统1策略，未充分利用视觉语言模型（VLMs）在语义推理和长期规划方面的系统2能力。由于当前基准测试的时间尺度和结构复杂性有限，这些能力尚未被充分探索。

Method: (1) 构建大规模模拟数据集，包含长任务序列和多样化子任务；(2) 提出分层框架：高层VLM规划器+低层视觉-语言-动作（VLA）控制器；(3) 通过GPT生成任务→人工模拟执行的流程生成高质量轨迹。

Result: RoboCerebra基准具备更长的动作序列和更密集标注（相比现有基准）。论文还测试了前沿VLMs作为系统2模块的性能，分析了其在关键认知维度上的表现。

Conclusion: 该工作推进了更强大、泛化能力更强的机器人规划器的研究，通过结构化系统1-系统2交互评估规划/反思/记忆能力。

Abstract: Recent advances in vision-language models (VLMs) have enabled
instruction-conditioned robotic systems with improved generalization. However,
most existing work focuses on reactive System 1 policies, underutilizing VLMs'
strengths in semantic reasoning and long-horizon planning. These System 2
capabilities-characterized by deliberative, goal-directed thinking-remain under
explored due to the limited temporal scale and structural complexity of current
benchmarks. To address this gap, we introduce RoboCerebra, a benchmark for
evaluating high-level reasoning in long-horizon robotic manipulation.
RoboCerebra includes: (1) a large-scale simulation dataset with extended task
horizons and diverse subtask sequences in household environments; (2) a
hierarchical framework combining a high-level VLM planner with a low-level
vision-language-action (VLA) controller; and (3) an evaluation protocol
targeting planning, reflection, and memory through structured System 1-System 2
interaction. The dataset is constructed via a top-down pipeline, where GPT
generates task instructions and decomposes them into subtask sequences. Human
operators execute the subtasks in simulation, yielding high-quality
trajectories with dynamic object variations. Compared to prior benchmarks,
RoboCerebra features significantly longer action sequences and denser
annotations. We further benchmark state-of-the-art VLMs as System 2 modules and
analyze their performance across key cognitive dimensions, advancing the
development of more capable and generalizable robotic planners.

</details>


### [698] [SpikePingpong: High-Frequency Spike Vision-based Robot Learning for Precise Striking in Table Tennis Game](https://arxiv.org/abs/2506.06690)
*Hao Wang,Chengkai Hou,Xianglong Li,Yankai Fu,Chenxuan Li,Ning Chen,Gaole Dai,Jiaming Liu,Tiejun Huang,Shanghang Zhang*

Main category: cs.RO

TL;DR: SpikePingpong系统结合脉冲视觉与模仿学习，针对乒乓球机器人控制的两大挑战：毫米级精准预测球拍接触点（SONIC模块）和精确落点控制（IMPACT模块），通过20kHz脉冲相机实现高速轨迹追踪，实验成功率91%（30cm区域）和71%（20cm区域），超越先前最优方法38%和37%。


<details>
  <summary>Details</summary>
Motivation: 解决高速物体控制难题，以乒乓球为测试平台——需要快速拦截高速球体并精确调整轨迹，突破传统视觉系统精度限制与策略规划能力。

Method: 1. SONIC模块：采用脉冲相机补偿空气阻力/摩擦实现毫米级球拍接触预测 2. IMPACT模块：通过模仿学习实现战术性落点控制 3. 20kHz高速相机结合轻量神经网络实时校正轨迹。

Result: 30cm目标区成功率91%（提升38%），20cm目标区成功率71%（提升37%），首次实现复杂战术策略的稳定执行。

Conclusion: 脉冲视觉+模仿学习框架为高速动态任务提供新范式，显著提升机器人精密控制能力，推动实时响应系统发展。

Abstract: Learning to control high-speed objects in the real world remains a
challenging frontier in robotics. Table tennis serves as an ideal testbed for
this problem, demanding both rapid interception of fast-moving balls and
precise adjustment of their trajectories. This task presents two fundamental
challenges: it requires a high-precision vision system capable of accurately
predicting ball trajectories, and it necessitates intelligent strategic
planning to ensure precise ball placement to target regions. The dynamic nature
of table tennis, coupled with its real-time response requirements, makes it
particularly well-suited for advancing robotic control capabilities in
fast-paced, precision-critical domains. In this paper, we present
SpikePingpong, a novel system that integrates spike-based vision with imitation
learning for high-precision robotic table tennis. Our approach introduces two
key attempts that directly address the aforementioned challenges: SONIC, a
spike camera-based module that achieves millimeter-level precision in
ball-racket contact prediction by compensating for real-world uncertainties
such as air resistance and friction; and IMPACT, a strategic planning module
that enables accurate ball placement to targeted table regions. The system
harnesses a 20 kHz spike camera for high-temporal resolution ball tracking,
combined with efficient neural network models for real-time trajectory
correction and stroke planning. Experimental results demonstrate that
SpikePingpong achieves a remarkable 91% success rate for 30 cm accuracy target
area and 71% in the more challenging 20 cm accuracy task, surpassing previous
state-of-the-art approaches by 38% and 37% respectively. These significant
performance improvements enable the robust implementation of sophisticated
tactical gameplay strategies, providing a new research perspective for robotic
control in high-speed dynamic tasks.

</details>


### [699] [Multimodal Spatial Language Maps for Robot Navigation and Manipulation](https://arxiv.org/abs/2506.06862)
*Chenguang Huang,Oier Mees,Andy Zeng,Wolfram Burgard*

Main category: cs.RO

TL;DR: 提出多模态空间语言地图（VLMaps和AVLMaps），通过融合多模态特征与3D环境重建，实现开放词汇空间目标导航和跨平台障碍物生成，增强在模糊环境中的目标分辨率。


<details>
  <summary>Details</summary>
Motivation: 现有方法在环境映射中缺乏空间精度或忽视视觉外的多模态信息，无法有效支撑机器人导航和交互。

Method: 利用预训练多模态基础模型，自主构建融合视觉/音频/语言特征的3D地图（VLMaps/AVLMaps），结合大语言模型解析自然语言指令。

Result: 在仿真和真实环境中实现零样本多模态目标导航，模糊场景召回率提升50%，支持移动机器人和桌面机械臂的跨模态交互。

Conclusion: 多模态空间语言地图通过统一表征视觉/音频/语言线索，显著提高机器人环境理解与导航能力，为具身智能提供新范式。

Abstract: Grounding language to a navigating agent's observations can leverage
pretrained multimodal foundation models to match perceptions to object or event
descriptions. However, previous approaches remain disconnected from environment
mapping, lack the spatial precision of geometric maps, or neglect additional
modality information beyond vision. To address this, we propose multimodal
spatial language maps as a spatial map representation that fuses pretrained
multimodal features with a 3D reconstruction of the environment. We build these
maps autonomously using standard exploration. We present two instances of our
maps, which are visual-language maps (VLMaps) and their extension to
audio-visual-language maps (AVLMaps) obtained by adding audio information. When
combined with large language models (LLMs), VLMaps can (i) translate natural
language commands into open-vocabulary spatial goals (e.g., "in between the
sofa and TV") directly localized in the map, and (ii) be shared across
different robot embodiments to generate tailored obstacle maps on demand.
Building upon the capabilities above, AVLMaps extend VLMaps by introducing a
unified 3D spatial representation integrating audio, visual, and language cues
through the fusion of features from pretrained multimodal foundation models.
This enables robots to ground multimodal goal queries (e.g., text, images, or
audio snippets) to spatial locations for navigation. Additionally, the
incorporation of diverse sensory inputs significantly enhances goal
disambiguation in ambiguous environments. Experiments in simulation and
real-world settings demonstrate that our multimodal spatial language maps
enable zero-shot spatial and multimodal goal navigation and improve recall by
50% in ambiguous scenarios. These capabilities extend to mobile robots and
tabletop manipulators, supporting navigation and interaction guided by visual,
audio, and spatial cues.

</details>


### [700] [MapBERT: Bitwise Masked Modeling for Real-Time Semantic Mapping Generation](https://arxiv.org/abs/2506.07350)
*Yijie Deng,Shuaihang Yuan,Congcong Wen,Hao Huang,Anthony Tzes,Geeta Chandra Raju Bethala,Yi Fang*

Main category: cs.RO

TL;DR: MapBERT：基于比特变分自编码器和掩码变压器的实时语义建图框架，通过比特特征表达和对象感知掩码提升空间预测能力，在Gibson数据集上实现SOTA效果。


<details>
  <summary>Details</summary>
Motivation: 现有方法无法实时鲁棒地生成未观测区域且泛化性差，主要挑战在于室内语义分布的复杂性（稀疏/不平衡对象类别+多尺度空间）。

Method: 1. 首创无查表BitVAE编码器：将语义图转化为紧凑比特令牌；2. 掩码变压器补全地图；3. 对象感知掩码策略：整类对象掩码+可学习嵌入，建模对象与空间的隐式关联。

Result: Gibson数据集上达成语义建图SOTA，平衡计算效率与未观测区域重建精度。

Conclusion: 比特特征表达结合对象级关系建模能有效捕获室内语义分布，提升具身智能体的空间认知能力。

Abstract: Spatial awareness is a critical capability for embodied agents, as it enables
them to anticipate and reason about unobserved regions. The primary challenge
arises from learning the distribution of indoor semantics, complicated by
sparse, imbalanced object categories and diverse spatial scales. Existing
methods struggle to robustly generate unobserved areas in real time and do not
generalize well to new environments. To this end, we propose \textbf{MapBERT},
a novel framework designed to effectively model the distribution of unseen
spaces. Motivated by the observation that the one-hot encoding of semantic maps
aligns naturally with the binary structure of bit encoding, we, for the first
time, leverage a lookup-free BitVAE to encode semantic maps into compact
bitwise tokens. Building on this, a masked transformer is employed to infer
missing regions and generate complete semantic maps from limited observations.
To enhance object-centric reasoning, we propose an object-aware masking
strategy that masks entire object categories concurrently and pairs them with
learnable embeddings, capturing implicit relationships between object
embeddings and spatial tokens. By learning these relationships, the model more
effectively captures indoor semantic distributions crucial for practical
robotic tasks. Experiments on Gibson benchmarks show that MapBERT achieves
state-of-the-art semantic map generation, balancing computational efficiency
with accurate reconstruction of unobserved regions.

</details>


### [701] [BitVLA: 1-bit Vision-Language-Action Models for Robotics Manipulation](https://arxiv.org/abs/2506.07530)
*Hongyu Wang,Chuyan Xiong,Ruiping Wang,Xilin Chen*

Main category: cs.RO

TL;DR: BitVLA, the first 1-bit ternary VLA model for robotics manipulation, drastically reduces memory usage while maintaining performance comparable to 4-bit quantized state-of-the-art models.


<details>
  <summary>Details</summary>
Motivation: Existing Vision-Language-Action (VLA) models face deployment challenges on resource-constrained robotic systems due to large model sizes. While 1-bit pretraining has succeeded in language models, its application to VLA models remains unexplored.

Method: Developed BitVLA with all parameters ternary {-1,0,1}. Proposed distillation-aware training to compress vision encoder to 1.58-bit weights using a full-precision teacher model for latent representation alignment.

Result: Achieved performance comparable to 4-bit OpenVLA-OFT on LIBERO benchmark with only 29.8% memory consumption.

Conclusion: BitVLA demonstrates efficient deployment potential for memory-constrained edge devices. Code and weights released publicly.

Abstract: Vision-Language-Action (VLA) models have shown impressive capabilities across
a wide range of robotics manipulation tasks. However, their growing model size
poses significant challenges for deployment on resource-constrained robotic
systems. While 1-bit pretraining has proven effective for enhancing the
inference efficiency of large language models with minimal performance loss,
its application to VLA models remains underexplored. In this work, we present
BitVLA, the first 1-bit VLA model for robotics manipulation, in which every
parameter is ternary, i.e., {-1, 0, 1}. To further reduce the memory footprint
of the vision encoder, we propose the distillation-aware training strategy that
compresses the full-precision encoder to 1.58-bit weights. During this process,
a full-precision encoder serves as a teacher model to better align latent
representations. Despite the lack of large-scale robotics pretraining, BitVLA
achieves performance comparable to the state-of-the-art model OpenVLA-OFT with
4-bit post-training quantization on the LIBERO benchmark, while consuming only
29.8% of the memory. These results highlight BitVLA's promise for deployment on
memory-constrained edge devices. We release the code and model weights in
https://github.com/ustcwhy/BitVLA.

</details>


### [702] [Active Illumination Control in Low-Light Environments using NightHawk](https://arxiv.org/abs/2506.06394)
*Yash Turkar,Youngjin Kim,Karthik Dantu*

Main category: cs.RO

TL;DR: NightHawk是一个主动照明与曝光控制框架，用于优化地下昏暗环境中机器人视觉的图像质量。


<details>
  <summary>Details</summary>
Motivation: 地下环境如涵洞存在光线不足和特征点稀缺的问题，现有照明方法会产生镜面反射、过曝和额外功耗等问题。

Method: 将主动照明与曝光控制结合，建立在线贝叶斯优化模型，以特征点检测为基础设计评估指标作为目标函数，采用事件触发式递归优化流程。

Result: 实验证明特征点检测与匹配率提升47-197%，在伊利运河涵洞部署的四足机器人实现了更可靠的视觉估计。

Conclusion: 该框架有效解决了低光照环境下机器人视觉的挑战，显著提升视觉算法的鲁棒性。

Abstract: Subterranean environments such as culverts present significant challenges to
robot vision due to dim lighting and lack of distinctive features. Although
onboard illumination can help, it introduces issues such as specular
reflections, overexposure, and increased power consumption. We propose
NightHawk, a framework that combines active illumination with exposure control
to optimize image quality in these settings. NightHawk formulates an online
Bayesian optimization problem to determine the best light intensity and
exposure-time for a given scene. We propose a novel feature detector-based
metric to quantify image utility and use it as the cost function for the
optimizer. We built NightHawk as an event-triggered recursive optimization
pipeline and deployed it on a legged robot navigating a culvert beneath the
Erie Canal. Results from field experiments demonstrate improvements in feature
detection and matching by 47-197% enabling more reliable visual estimation in
challenging lighting conditions.

</details>


### [703] [Edge-Enabled Collaborative Object Detection for Real-Time Multi-Vehicle Perception](https://arxiv.org/abs/2506.06474)
*Everett Richards,Bipul Thapa,Lena Mashayekhy*

Main category: cs.RO

TL;DR: 提出ECOD框架，利用边缘计算和多车协作实现实时多视角物体检测，提高分类精度75%，降低延迟


<details>
  <summary>Details</summary>
Motivation: 传统车载感知因遮挡盲区精度受限，云端方案延迟高，无法满足自动驾驶实时需求

Method: 整合PACE（多车感知聚合）和VOTE（投票机制分类）算法在边缘服务器运行

Result: 实验证明分类精度比单车方案提升75%，同时保持低延迟

Conclusion: 边缘计算能有效增强自动驾驶系统的协同感知能力

Abstract: Accurate and reliable object detection is critical for ensuring the safety
and efficiency of Connected Autonomous Vehicles (CAVs). Traditional on-board
perception systems have limited accuracy due to occlusions and blind spots,
while cloud-based solutions introduce significant latency, making them
unsuitable for real-time processing demands required for autonomous driving in
dynamic environments. To address these challenges, we introduce an innovative
framework, Edge-Enabled Collaborative Object Detection (ECOD) for CAVs, that
leverages edge computing and multi-CAV collaboration for real-time,
multi-perspective object detection. Our ECOD framework integrates two key
algorithms: Perceptive Aggregation and Collaborative Estimation (PACE) and
Variable Object Tally and Evaluation (VOTE). PACE aggregates detection data
from multiple CAVs on an edge server to enhance perception in scenarios where
individual CAVs have limited visibility. VOTE utilizes a consensus-based voting
mechanism to improve the accuracy of object classification by integrating data
from multiple CAVs. Both algorithms are designed at the edge to operate in
real-time, ensuring low-latency and reliable decision-making for CAVs. We
develop a hardware-based controlled testbed consisting of camera-equipped
robotic CAVs and an edge server to evaluate the efficacy of our framework. Our
experimental results demonstrate the significant benefits of ECOD in terms of
improved object classification accuracy, outperforming traditional
single-perspective onboard approaches by up to 75%, while ensuring low-latency,
edge-driven real-time processing. This research highlights the potential of
edge computing to enhance collaborative perception for latency-sensitive
autonomous systems.

</details>


### [704] [DriveSuprim: Towards Precise Trajectory Selection for End-to-End Planning](https://arxiv.org/abs/2506.06659)
*Wenhao Yao,Zhenxin Li,Shiyi Lan,Zi Wang,Xinglong Sun,Jose M. Alvarez,Zuxuan Wu*

Main category: cs.RO

TL;DR: DriveSuprim是一个先进的基于选择的自动驾驶轨迹预测方法，通过分层过滤候选路径、旋转增强和自我蒸馏等技术，显著提升了安全性和性能，在两个NAVSIM版本上达到SOTA。


<details>
  <summary>Details</summary>
Motivation: 现有自动驾驶轨迹预测方法存在缺陷：回归方法依赖单一路径无法显式评估安全性，选择方法虽能生成多条候选轨迹但面临优化困难（难以从数千选项中精确选择最优解）和稀有场景处理不足的问题。

Method: 1. 粗到细的渐进候选轨迹过滤框架；2. 基于旋转的数据增强提升OOD鲁棒性；3. 自我蒸馏框架稳定训练。

Result: 在NAVSIM v1达到93.5% PDMS，v2达到87.1% EPDMS（无需额外数据），在碰撞避免和交规遵守等安全指标上表现卓越，同时保持高质量轨迹生成。

Conclusion: 提出的三项创新技术有效解决了选择式方法的优化困境，显著提升了自动驾驶系统在安全关键场景下的性能表现，为实际部署提供了更高可靠性保障。

Abstract: In complex driving environments, autonomous vehicles must navigate safely.
Relying on a single predicted path, as in regression-based approaches, usually
does not explicitly assess the safety of the predicted trajectory.
Selection-based methods address this by generating and scoring multiple
trajectory candidates and predicting the safety score for each, but face
optimization challenges in precisely selecting the best option from thousands
of possibilities and distinguishing subtle but safety-critical differences,
especially in rare or underrepresented scenarios. We propose DriveSuprim to
overcome these challenges and advance the selection-based paradigm through a
coarse-to-fine paradigm for progressive candidate filtering, a rotation-based
augmentation method to improve robustness in out-of-distribution scenarios, and
a self-distillation framework to stabilize training. DriveSuprim achieves
state-of-the-art performance, reaching 93.5% PDMS in NAVSIM v1 and 87.1% EPDMS
in NAVSIM v2 without extra data, demonstrating superior safetycritical
capabilities, including collision avoidance and compliance with rules, while
maintaining high trajectory quality in various driving scenarios.

</details>


### [705] [Generalized Trajectory Scoring for End-to-end Multimodal Planning](https://arxiv.org/abs/2506.06664)
*Zhenxin Li,Wenhao Yao,Zi Wang,Xinglong Sun,Joshua Chen,Nadine Chang,Maying Shen,Zuxuan Wu,Shiyi Lan,Jose M. Alvarez*

Main category: cs.RO

TL;DR: GTRS是一个统一的端到端多模态规划框架，通过结合粗粒度与细粒度轨迹评估，提升自动驾驶决策的泛化能力。它包含扩散式轨迹生成器、轨迹词表泛化技术和传感器增强策略三项创新，获Navsim v2挑战赛冠军。


<details>
  <summary>Details</summary>
Motivation: 现有轨迹评分方法存在泛化局限：静态词表法难以细粒度适应，动态生成法无法覆盖广泛分布。需结合二者优势实现鲁棒的候选轨迹选择。

Method: 1) 扩散模型生成细粒度候选轨迹
2) 对超密轨迹集进行带dropout的评分器训练，使其在子集上鲁棒
3) 传感器数据增强提升域外泛化，结合关键轨迹判别精调

Result: 在Navsim v2挑战赛中胜出，性能接近依赖真值感知的特权方法，即使在次优传感器输入下仍表现优异。

Conclusion: GTRS通过协同粗/细粒度评估、超密训练和域泛化技术，为多模态规划提供了强大的统一框架，显著提升了轨迹选择的适应性和鲁棒性。

Abstract: End-to-end multi-modal planning is a promising paradigm in autonomous
driving, enabling decision-making with diverse trajectory candidates. A key
component is a robust trajectory scorer capable of selecting the optimal
trajectory from these candidates. While recent trajectory scorers focus on
scoring either large sets of static trajectories or small sets of dynamically
generated ones, both approaches face significant limitations in generalization.
Static vocabularies provide effective coarse discretization but struggle to
make fine-grained adaptation, while dynamic proposals offer detailed precision
but fail to capture broader trajectory distributions. To overcome these
challenges, we propose GTRS (Generalized Trajectory Scoring), a unified
framework for end-to-end multi-modal planning that combines coarse and
fine-grained trajectory evaluation. GTRS consists of three complementary
innovations: (1) a diffusion-based trajectory generator that produces diverse
fine-grained proposals; (2) a vocabulary generalization technique that trains a
scorer on super-dense trajectory sets with dropout regularization, enabling its
robust inference on smaller subsets; and (3) a sensor augmentation strategy
that enhances out-of-domain generalization while incorporating refinement
training for critical trajectory discrimination. As the winning solution of the
Navsim v2 Challenge, GTRS demonstrates superior performance even with
sub-optimal sensor inputs, approaching privileged methods that rely on
ground-truth perception. Code will be available at
https://github.com/NVlabs/GTRS.

</details>


### [706] [RoboCerebra: A Large-scale Benchmark for Long-horizon Robotic Manipulation Evaluation](https://arxiv.org/abs/2506.06677)
*Songhao Han,Boxiang Qiu,Yue Liao,Siyuan Huang,Chen Gao,Shuicheng Yan,Si Liu*

Main category: cs.RO

TL;DR: RoboCerebra is a new benchmark designed to evaluate high-level reasoning for long-horizon robotic manipulation, featuring extended task horizons, a hierarchical VLM planner with VLA controller, and enhanced evaluation protocols.


<details>
  <summary>Details</summary>
Motivation: 现有方法主要集中在被动反应策略（系统1），未能充分利用视觉语言模型（VLM）在语义推理和长时序规划方面的潜力（系统2能力）。现有基准测试的时序长度和结构复杂性不足限制了相关研究。

Method: 1) 构建大规模仿真数据集，含多样化家务任务的长时序子任务序列；2) 提出分层框架：高层VLM规划器+底层视觉语言动作（VLA）控制器；3) 采用GPT生成任务指令并分解子任务，人工在模拟环境中执行获取轨迹数据。

Result: 相比现有基准，RoboCerebra提供更长的动作序列和更密集标注的数据集；基准测试展示了先进VLM作为系统2模块在规划、反思和记忆等认知维度的性能。

Conclusion: 该工作填补了机器人长期推理评估的空白，推动更强大和通用的机器人规划器发展，通过结构化系统1-系统2交互机制探索高阶认知能力。

Abstract: Recent advances in vision-language models (VLMs) have enabled
instruction-conditioned robotic systems with improved generalization. However,
most existing work focuses on reactive System 1 policies, underutilizing VLMs'
strengths in semantic reasoning and long-horizon planning. These System 2
capabilities-characterized by deliberative, goal-directed thinking-remain under
explored due to the limited temporal scale and structural complexity of current
benchmarks. To address this gap, we introduce RoboCerebra, a benchmark for
evaluating high-level reasoning in long-horizon robotic manipulation.
RoboCerebra includes: (1) a large-scale simulation dataset with extended task
horizons and diverse subtask sequences in household environments; (2) a
hierarchical framework combining a high-level VLM planner with a low-level
vision-language-action (VLA) controller; and (3) an evaluation protocol
targeting planning, reflection, and memory through structured System 1-System 2
interaction. The dataset is constructed via a top-down pipeline, where GPT
generates task instructions and decomposes them into subtask sequences. Human
operators execute the subtasks in simulation, yielding high-quality
trajectories with dynamic object variations. Compared to prior benchmarks,
RoboCerebra features significantly longer action sequences and denser
annotations. We further benchmark state-of-the-art VLMs as System 2 modules and
analyze their performance across key cognitive dimensions, advancing the
development of more capable and generalizable robotic planners.

</details>


### [707] [SpikePingpong: High-Frequency Spike Vision-based Robot Learning for Precise Striking in Table Tennis Game](https://arxiv.org/abs/2506.06690)
*Hao Wang,Chengkai Hou,Xianglong Li,Yankai Fu,Chenxuan Li,Ning Chen,Gaole Dai,Jiaming Liu,Tiejun Huang,Shanghang Zhang*

Main category: cs.RO

TL;DR: SpikePingpong系统整合脉冲相机和模仿学习，通过SONIC模块实现毫米级击球预测和IMPACT模块精准落点控制，在高速乒乓球任务中成功率显著超越现有方法38%。


<details>
  <summary>Details</summary>
Motivation: 解决高速物体控制的两大挑战：需要高精度视觉系统预测球轨迹，以及智能策略规划确保落点精准。乒乓球因其动态性和实时性要求成为理想测试平台。

Method: 1) 20kHz脉冲相机SONIC模块补偿空气阻力/摩擦实现毫米级球拍接触预测 2) IMPACT策略模块通过模仿学习实现精准区域落点 3) 结合实时轨迹修正神经网络

Result: 30cm靶区成功率91%（提升38%），20cm靶区71%（提升37%），支持复杂战术执行

Conclusion: 为高速动态任务提供新研究视角，证明脉冲相机与模仿学习的整合可显著提升机器人高速精确控制能力

Abstract: Learning to control high-speed objects in the real world remains a
challenging frontier in robotics. Table tennis serves as an ideal testbed for
this problem, demanding both rapid interception of fast-moving balls and
precise adjustment of their trajectories. This task presents two fundamental
challenges: it requires a high-precision vision system capable of accurately
predicting ball trajectories, and it necessitates intelligent strategic
planning to ensure precise ball placement to target regions. The dynamic nature
of table tennis, coupled with its real-time response requirements, makes it
particularly well-suited for advancing robotic control capabilities in
fast-paced, precision-critical domains. In this paper, we present
SpikePingpong, a novel system that integrates spike-based vision with imitation
learning for high-precision robotic table tennis. Our approach introduces two
key attempts that directly address the aforementioned challenges: SONIC, a
spike camera-based module that achieves millimeter-level precision in
ball-racket contact prediction by compensating for real-world uncertainties
such as air resistance and friction; and IMPACT, a strategic planning module
that enables accurate ball placement to targeted table regions. The system
harnesses a 20 kHz spike camera for high-temporal resolution ball tracking,
combined with efficient neural network models for real-time trajectory
correction and stroke planning. Experimental results demonstrate that
SpikePingpong achieves a remarkable 91% success rate for 30 cm accuracy target
area and 71% in the more challenging 20 cm accuracy task, surpassing previous
state-of-the-art approaches by 38% and 37% respectively. These significant
performance improvements enable the robust implementation of sophisticated
tactical gameplay strategies, providing a new research perspective for robotic
control in high-speed dynamic tasks.

</details>


### [708] [Multimodal Spatial Language Maps for Robot Navigation and Manipulation](https://arxiv.org/abs/2506.06862)
*Chenguang Huang,Oier Mees,Andy Zeng,Wolfram Burgard*

Main category: cs.RO

TL;DR: 提出名为VLMaps和AVLMaps的多模态空间语言地图，通过融合预训练多模态特征与3D环境重建，提升机器人导航中的零样本空间多模态目标解析能力。


<details>
  <summary>Details</summary>
Motivation: 现有方法未与环境地图结合，缺乏空间精度或忽略视觉以外的模态信息，无法将自然语言命令精准定位到空间。

Method: 将预训练多模态特征(视觉/音频)与3D重建环境融合构建空间地图；利用LLM解析自然语言指令为空间目标；通过增添音频信息从VLMaps扩展到AVLMaps。

Result: 仿真和真实实验中实现零样本空间/多模态目标导航，目标召回率在模糊场景提高50%，适用于移动机器人和桌面机械臂。

Conclusion: 多模态空间语言地图能跨机器人平台共享，支持基于视觉/音频/空间的导航交互，显著增强模糊环境下的目标辨别能力。

Abstract: Grounding language to a navigating agent's observations can leverage
pretrained multimodal foundation models to match perceptions to object or event
descriptions. However, previous approaches remain disconnected from environment
mapping, lack the spatial precision of geometric maps, or neglect additional
modality information beyond vision. To address this, we propose multimodal
spatial language maps as a spatial map representation that fuses pretrained
multimodal features with a 3D reconstruction of the environment. We build these
maps autonomously using standard exploration. We present two instances of our
maps, which are visual-language maps (VLMaps) and their extension to
audio-visual-language maps (AVLMaps) obtained by adding audio information. When
combined with large language models (LLMs), VLMaps can (i) translate natural
language commands into open-vocabulary spatial goals (e.g., "in between the
sofa and TV") directly localized in the map, and (ii) be shared across
different robot embodiments to generate tailored obstacle maps on demand.
Building upon the capabilities above, AVLMaps extend VLMaps by introducing a
unified 3D spatial representation integrating audio, visual, and language cues
through the fusion of features from pretrained multimodal foundation models.
This enables robots to ground multimodal goal queries (e.g., text, images, or
audio snippets) to spatial locations for navigation. Additionally, the
incorporation of diverse sensory inputs significantly enhances goal
disambiguation in ambiguous environments. Experiments in simulation and
real-world settings demonstrate that our multimodal spatial language maps
enable zero-shot spatial and multimodal goal navigation and improve recall by
50% in ambiguous scenarios. These capabilities extend to mobile robots and
tabletop manipulators, supporting navigation and interaction guided by visual,
audio, and spatial cues.

</details>


### [709] [MapBERT: Bitwise Masked Modeling for Real-Time Semantic Mapping Generation](https://arxiv.org/abs/2506.07350)
*Yijie Deng,Shuaihang Yuan,Congcong Wen,Hao Huang,Anthony Tzes,Geeta Chandra Raju Bethala,Yi Fang*

Main category: cs.RO

TL;DR: MapBERT通过结合BitVAE和掩码Transformer高效建模未观察空间分布，提出对象感知掩码策略提升语义推断，在Gibson数据集上实现SOTA的语义建图效果。


<details>
  <summary>Details</summary>
Motivation: 现有方法难以实时生成未观察区域且泛化性差，而语义图one-hot编码与二进制结构的自然相似性启发我们利用比特编码。

Method: 将语义图编码为比特向量，采用掩码Transformer预测缺失区域；引入对象感知掩码策略（掩蔽整类物体+可学习嵌入），建立物体与空间隐含关系模型。

Result: Gibson数据集实验表明该方法在计算效率和未观察区域重建精度上均达SOTA。

Conclusion: 比特编码+Transformer范式能高效学习室内语义分布，对象感知设计增强机器人任务所需的物体关系推理能力。

Abstract: Spatial awareness is a critical capability for embodied agents, as it enables
them to anticipate and reason about unobserved regions. The primary challenge
arises from learning the distribution of indoor semantics, complicated by
sparse, imbalanced object categories and diverse spatial scales. Existing
methods struggle to robustly generate unobserved areas in real time and do not
generalize well to new environments. To this end, we propose \textbf{MapBERT},
a novel framework designed to effectively model the distribution of unseen
spaces. Motivated by the observation that the one-hot encoding of semantic maps
aligns naturally with the binary structure of bit encoding, we, for the first
time, leverage a lookup-free BitVAE to encode semantic maps into compact
bitwise tokens. Building on this, a masked transformer is employed to infer
missing regions and generate complete semantic maps from limited observations.
To enhance object-centric reasoning, we propose an object-aware masking
strategy that masks entire object categories concurrently and pairs them with
learnable embeddings, capturing implicit relationships between object
embeddings and spatial tokens. By learning these relationships, the model more
effectively captures indoor semantic distributions crucial for practical
robotic tasks. Experiments on Gibson benchmarks show that MapBERT achieves
state-of-the-art semantic map generation, balancing computational efficiency
with accurate reconstruction of unobserved regions.

</details>


### [710] [BitVLA: 1-bit Vision-Language-Action Models for Robotics Manipulation](https://arxiv.org/abs/2506.07530)
*Hongyu Wang,Chuyan Xiong,Ruiping Wang,Xilin Chen*

Main category: cs.RO

TL;DR: BitVLA是第一1-bit三元权重视觉-语言-动作模型，通过蒸馏训练实现高效部署，在LIBERO基准上与4-bit量化模型性能相当，节省70.2%内存。


<details>
  <summary>Details</summary>
Motivation: 现有VLA模型在资源受限设备上部署困难，1-bit预训练方法在LLM成功但VLA领域尚未探索。

Method: 提出权重三值化的BitVLA模型，采用蒸馏感知训练压缩视觉编码器（1.58-bit），使用全精度模型作为教师对齐隐表示。

Result: LIBERO基准测试中性能媲美4-bit OpenVLA-OFT，内存消耗仅29.8%，释放代码和模型权重。

Conclusion: BitVLA在保持性能的同时显著降低内存需求，证明其在边缘设备部署潜力。

Abstract: Vision-Language-Action (VLA) models have shown impressive capabilities across
a wide range of robotics manipulation tasks. However, their growing model size
poses significant challenges for deployment on resource-constrained robotic
systems. While 1-bit pretraining has proven effective for enhancing the
inference efficiency of large language models with minimal performance loss,
its application to VLA models remains underexplored. In this work, we present
BitVLA, the first 1-bit VLA model for robotics manipulation, in which every
parameter is ternary, i.e., {-1, 0, 1}. To further reduce the memory footprint
of the vision encoder, we propose the distillation-aware training strategy that
compresses the full-precision encoder to 1.58-bit weights. During this process,
a full-precision encoder serves as a teacher model to better align latent
representations. Despite the lack of large-scale robotics pretraining, BitVLA
achieves performance comparable to the state-of-the-art model OpenVLA-OFT with
4-bit post-training quantization on the LIBERO benchmark, while consuming only
29.8% of the memory. These results highlight BitVLA's promise for deployment on
memory-constrained edge devices. We release the code and model weights in
https://github.com/ustcwhy/BitVLA.

</details>


<div id='q-fin.ST'></div>

# q-fin.ST [[Back]](#toc)

### [711] [The Hype Index: an NLP-driven Measure of Market News Attention](https://arxiv.org/abs/2506.06329)
*Zheng Cao,Wanchaloem Wunkaew,Helyette Geman*

Main category: q-fin.ST

TL;DR: 提出了Hype Index作为量化媒体对大型股票关注度的新指标，利用NLP技术从财经新闻中提取预测信号。基于S&P 100构建了新闻计数版和市值调整版双指标，从四个维度评估其在波动率分析、市场信号传递方面的价值。


<details>
  <summary>Details</summary>
Motivation: 传统金融指标难以捕捉市场情绪波动，需要开发能量化媒体关注度对股价影响的工具。利用NLP技术进步提取新闻中的预测信号，为市场分析提供新视角。

Method: 1) 基础版：根据个股/行业在总新闻中的占比构建新闻计数指数
2) 调整版：用媒体权重除以市值权重构建市值调整指数
评估框架：分类分析、收益/波动率相关性检验、市场信号预测能力、统计特性验证

Result: Hype Index系列能有效：
- 识别不同热度群体
- 预测收益率和波动性（与VIX相关）
- 提供短期市场变动信号
- 展现稳定的统计特性

Conclusion: 该指数家族为股票波动分析、市场信号捕获及金融NLP应用提供了实用工具集，证实媒体关注度数据具有量化投资价值。

Abstract: This paper introduces the Hype Index as a novel metric to quantify media
attention toward large-cap equities, leveraging advances in Natural Language
Processing (NLP) for extracting predictive signals from financial news. Using
the S&P 100 as the focus universe, we first construct a News Count-Based Hype
Index, which measures relative media exposure by computing the share of news
articles referencing each stock or sector. We then extend it to the
Capitalization Adjusted Hype Index, adjusts for economic size by taking the
ratio of a stock's or sector's media weight to its market capitalization weight
within its industry or sector. We compute both versions of the Hype Index at
the stock and sector levels, and evaluate them through multiple lenses: (1)
their classification into different hype groups, (2) their associations with
returns, volatility, and VIX index at various lags, (3) their signaling power
for short-term market movements, and (4) their empirical properties including
correlations, samplings, and trends. Our findings suggest that the Hype Index
family provides a valuable set of tools for stock volatility analysis, market
signaling, and NLP extensions in Finance.

</details>


### [712] [The Hype Index: an NLP-driven Measure of Market News Attention](https://arxiv.org/abs/2506.06329)
*Zheng Cao,Wanchaloem Wunkaew,Helyette Geman*

Main category: q-fin.ST

TL;DR: 引入两个量化媒体关注度的Hype指数指标（新闻数量型和市值调整型），用于通过财经新闻分析预测市场行为，验证其在股市波动性分析、市场信号和NLP应用中的价值。


<details>
  <summary>Details</summary>
Motivation: 利用NLP技术从财经新闻中提取有效信号，提供量化媒体关注度的工具，以帮助分析股票波动性和市场信号。

Method: 基于标普100指数，构建两种Hype指数：新闻数量型（计算个股/行业新闻占比）；市值调整型（个股/行业媒体权重与市值权重的比率）。通过四方面评估：分类、与回报/波动率/VIX的关联、短期市场信号预测力、相关性及趋势分析。

Result: Hype指数系列被证明是有效的工具，可用于股票波动性分析、市场信号判断和金融NLP扩展应用。

Conclusion: Hype指数家族为量化媒体关注度提供了实用解决方案，在金融分析领域具有显著价值。

Abstract: This paper introduces the Hype Index as a novel metric to quantify media
attention toward large-cap equities, leveraging advances in Natural Language
Processing (NLP) for extracting predictive signals from financial news. Using
the S&P 100 as the focus universe, we first construct a News Count-Based Hype
Index, which measures relative media exposure by computing the share of news
articles referencing each stock or sector. We then extend it to the
Capitalization Adjusted Hype Index, adjusts for economic size by taking the
ratio of a stock's or sector's media weight to its market capitalization weight
within its industry or sector. We compute both versions of the Hype Index at
the stock and sector levels, and evaluate them through multiple lenses: (1)
their classification into different hype groups, (2) their associations with
returns, volatility, and VIX index at various lags, (3) their signaling power
for short-term market movements, and (4) their empirical properties including
correlations, samplings, and trends. Our findings suggest that the Hype Index
family provides a valuable set of tools for stock volatility analysis, market
signaling, and NLP extensions in Finance.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [713] [GLProtein: Global-and-Local Structure Aware Protein Representation Learning](https://arxiv.org/abs/2506.06294)
*Yunqing Liu,Wenqi Fan,Xiaoyong Wei,Qing Li*

Main category: cs.LG

TL;DR: 本文提出了GLProtein框架，首次在蛋白质预训练中整合全局结构相似性和局部氨基酸细节，通过结合掩码建模和三元组结构相似性评分等方法，在蛋白质相互作用预测等任务中优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 尽管蛋白质序列分析已取得进展，但整合蛋白质结构信息仍有探索空间。作者认为结构信息不仅限于3D结构，还包括从氨基酸分子（局部信息）到蛋白结构相似性（全局信息）的多层次信息。

Method: 提出GLProtein框架，创新性地结合：1) 蛋白质掩码建模与三元组结构相似性评分；2) 蛋白质3D距离编码；3) 基于子结构的氨基酸分子编码。

Result: 实验表明，GLProtein在多个生物信息学任务（如蛋白质-蛋白质相互作用预测、接触预测等）中优于先前方法。

Conclusion: 同时整合全局结构相似性和局部氨基酸细节能有效提升蛋白质预测性能和功能理解，GLProtein为蛋白质预训练提供了新范式。

Abstract: Proteins are central to biological systems, participating as building blocks
across all forms of life. Despite advancements in understanding protein
functions through protein sequence analysis, there remains potential for
further exploration in integrating protein structural information. We argue
that the structural information of proteins is not only limited to their 3D
information but also encompasses information from amino acid molecules (local
information) to protein-protein structure similarity (global information). To
address this, we propose \textbf{GLProtein}, the first framework in protein
pre-training that incorporates both global structural similarity and local
amino acid details to enhance prediction accuracy and functional insights.
GLProtein innovatively combines protein-masked modelling with triplet structure
similarity scoring, protein 3D distance encoding and substructure-based amino
acid molecule encoding. Experimental results demonstrate that GLProtein
outperforms previous methods in several bioinformatics tasks, including
predicting protein-protein interaction, contact prediction, and so on.

</details>


### [714] [dLLM-Cache: Accelerating Diffusion Large Language Models with Adaptive Caching](https://arxiv.org/abs/2506.06295)
*Zhiyuan Liu,Yicun Yang,Yaojie Zhang,Junjie Chen,Chang Zou,Qingyuan Wei,Shaobo Wang,Linfeng Zhang*

Main category: cs.LG

TL;DR: 提出了dLLM-Cache框架，用于降低基于扩散的大型语言模型（dLLM）的推理延迟


<details>
  <summary>Details</summary>
Motivation: 针对扩散语言模型的高延迟问题，传统AR模型的KV缓存技术因其双向注意力机制不适用于dLLM

Method: 利用dLLM推理过程中提示词静默响应部分稳定的特性，设计无需训练的缓存框架，结合长间隔提示缓存和特征相似性指导的部分响应更新

Result: 在LLaDA 8B和Dream 7B等模型上实现最高9.1倍加速，推理延迟接近AR模型

Conclusion: dLLM-Cache有效克服dLLM延迟瓶颈，提供接近AR模型的推理效率

Abstract: Autoregressive Models (ARMs) have long dominated the landscape of Large
Language Models. Recently, a new paradigm has emerged in the form of
diffusion-based Large Language Models (dLLMs), which generate text by
iteratively denoising masked segments. This approach has shown significant
advantages and potential. However, dLLMs suffer from high inference latency.
Traditional ARM acceleration techniques, such as Key-Value caching, are
incompatible with dLLMs due to their bidirectional attention mechanism. To
address this specific challenge, our work begins with a key observation that
dLLM inference involves a static prompt and a partially dynamic response, where
most tokens remain stable across adjacent denoising steps. Based on this, we
propose dLLM-Cache, a training-free adaptive caching framework that combines
long-interval prompt caching with partial response updates guided by feature
similarity. This design enables efficient reuse of intermediate computations
without compromising model performance. Extensive experiments on representative
dLLMs, including LLaDA 8B and Dream 7B, show that dLLM-Cache achieves up to 9.1
x speedup over standard inference without compromising output quality. Notably,
our method brings dLLM inference latency close to that of ARMs under many
settings. Codes are provided in the supplementary material and will be released
publicly on GitHub.

</details>


### [715] [Reward Is Enough: LLMs Are In-Context Reinforcement Learners](https://arxiv.org/abs/2506.06303)
*Kefan Song,Amir Moeini,Peng Wang,Lei Gong,Rohan Chandra,Yanjun Qi,Shangtong Zhang*

Main category: cs.LG

TL;DR: 本研究提出了一个名为ICRL prompting的新型多轮提示框架，揭示了在大型语言模型（LLM）的推理阶段会出现强化学习（RL）现象。通过将历史反馈作为上下文输入，LLM能在测试阶段自主优化输出质量。实验表明该方法在三个基准测试中显著优于基线模型，即使奖励信号由LLM自身生成也有效。


<details>
  <summary>Details</summary>
Motivation: 研究者发现，在LLM推理阶段，输入包含历史响应和奖励信号的上下文时，模型的响应质量会随着上下文增长而提高。这种被称为"上下文强化学习（ICRL）"的现象表明，LLM在推理时具有类似强化学习的自我优化能力。

Method: 提出ICRL提示框架：在多轮交互中，每轮向LLM提供相同任务及包含历史响应与奖励的上下文。奖励是对前一回合响应的数值化反馈。模型通过累计的奖励信号逐步优化后续输出。

Result: 在Game of 24、创造性写作和ScienceWorld三个基准测试中，ICRL提示显著超越Self-Refine和Reflexion等基线方法。即使奖励信号由LLM自身生成，仍能观察到性能提升，这为扩展测试时计算提供了新途径。

Conclusion: 本研究首次实证了LLM推理阶段存在的类强化学习特性。ICRL框架突破了传统模型微调的限制，为无需参数更新的模型优化开辟新方向。特别是在LLM自生成奖励场景下的有效性，显示出该范式在智能体建构方面的巨大潜力。

Abstract: Reinforcement learning (RL) is a human-designed framework for solving
sequential decision making problems. In this work, we demonstrate that,
surprisingly, RL emerges in LLM's (Large Language Model) inference time -- a
phenomenon known as in-context RL (ICRL). Specifically, we propose a novel
multi-round prompting framework called ICRL prompting. The goal is to prompt
the LLM to complete a task. After the LLM generates a response at the current
round, we give numerical scalar feedbacks for the response, called the rewards.
At the next round, we prompt the LLM again with the same task and a context
consisting of all previous responses and rewards. We observe that the quality
of the LLM's response increases as the context grows. In other words, the LLM
is able to maximize the scalar reward signal in the inference time, just like
an RL algorithm. We evaluate ICRL prompting in three benchmarks (Game of 24,
creative writing, and ScienceWorld) and demonstrate significant performance
improvements over baseline methods such as Self-Refine and Reflexion.
Surprisingly, in some experiments the reward signals are generated by the LLM
itself, yet performance improvements are still observed from ICRL prompting,
offering a promising paradigm for scaling test-time compute.

</details>


### [716] [Towards Efficient Multi-LLM Inference: Characterization and Analysis of LLM Routing and Hierarchical Techniques](https://arxiv.org/abs/2506.06579)
*Adarsh Prasad Behera,Jaya Prakash Champati,Roberto Morabito,Sasu Tarkoma,James Gross*

Main category: cs.LG

TL;DR: 这篇综述探讨了两种互补的LLM高效推理策略：模型路由和级联推理，旨在通过动态分配计算资源来降低LLM在移动或边缘计算环境中的部署门槛。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型推理计算成本高昂，难以在移动端或资源受限环境中部署，需要更高效的推理策略以适应硬件约束。

Method: 分析两种主要技术：(i)模型路由（基于查询复杂度选择合适模型），(ii)级联推理（分层处理直至获得可靠响应）。

Result: 通过比较关键指标，证实两种策略能有效降低计算量；同时指出标准化基准和自适应模型选择仍是挑战。

Conclusion: 动态模型选择策略能提升LLM部署效率，未来需研究响应时间优化和异构环境自适应方案以实现广泛应用。

Abstract: Recent progress in Language Models (LMs) has dramatically advanced the field
of natural language processing (NLP), excelling at tasks like text generation,
summarization, and question answering. However, their inference remains
computationally expensive and energy intensive, especially in settings with
limited hardware, power, or bandwidth. This makes it difficult to deploy LMs in
mobile, edge, or cost sensitive environments. To address these challenges,
recent approaches have introduced multi LLM intelligent model selection
strategies that dynamically allocate computational resources based on query
complexity -- using lightweight models for simpler queries and escalating to
larger models only when necessary. This survey explores two complementary
strategies for efficient LLM inference: (i) routing, which selects the most
suitable model based on the query, and (ii) cascading or hierarchical inference
(HI), which escalates queries through a sequence of models until a confident
response is found. Both approaches aim to reduce computation by using
lightweight models for simpler tasks while offloading only when needed. We
provide a comparative analysis of these techniques across key performance
metrics, discuss benchmarking efforts, and outline open challenges. Finally, we
outline future research directions to enable faster response times, adaptive
model selection based on task complexity, and scalable deployment across
heterogeneous environments, making LLM based systems more efficient and
accessible for real world applications.

</details>


### [717] [Curriculum Reinforcement Learning from Easy to Hard Tasks Improves LLM Reasoning](https://arxiv.org/abs/2506.06632)
*Shubham Parashar,Shurui Gui,Xiner Li,Hongyi Ling,Sushil Vemuri,Blake Olson,Eric Li,Yu Zhang,James Caverlee,Dileep Kalathil,Shuiwang Ji*

Main category: cs.LG

TL;DR: 该论文提出一种名为E2H Reasoner的强化学习方法，通过由易到难的任务调度策略提升小语言模型的推理能力。理论证明其收敛性，实验表明该方法显著优于传统强化学习。


<details>
  <summary>Details</summary>
Motivation: 现有强化学习单独应用于困难推理任务时效果不佳，受课程学习启发，希望通过渐进式任务调度提升模型推理能力。

Method: 提出E2H任务调度框架，从简单任务开始训练并逐步过渡到困难任务，期间动态调整不同难度任务的训练比例以防止过拟合简单任务。

Result: 在多个领域实验中，E2H方法使1.5B-3B小模型推理能力显著提升，性能超越传统强化学习方法；理论分析证明其样本效率更高。

Conclusion: 由易到难的课程式强化学习能有效提升小语言模型在数学、编程等复杂任务上的推理性能，任务调度中的渐隐机制和理论保障是成功关键。

Abstract: We aim to improve the reasoning capabilities of language models via
reinforcement learning (RL). Recent RL post-trained models like DeepSeek-R1
have demonstrated reasoning abilities on mathematical and coding tasks.
However, prior studies suggest that using RL alone to improve reasoning on
inherently difficult tasks is less effective. Here, we draw inspiration from
curriculum learning and propose to schedule tasks from easy to hard (E2H),
allowing LLMs to build reasoning skills gradually. Our method is termed E2H
Reasoner. Empirically, we observe that, although easy tasks are important
initially, fading them out through appropriate scheduling is essential in
preventing overfitting. Theoretically, we establish convergence guarantees for
E2H Reasoner within an approximate policy iteration framework. We derive
finite-sample complexity bounds and show that when tasks are appropriately
decomposed and conditioned, learning through curriculum stages requires fewer
total samples than direct learning. Experiments across multiple domains show
that E2H Reasoner significantly improves the reasoning ability of small LLMs
(1.5B to 3B), which otherwise struggle when trained with vanilla RL alone,
highlighting the effectiveness of our method.

</details>


### [718] [MarginSel : Max-Margin Demonstration Selection for LLMs](https://arxiv.org/abs/2506.06699)
*Rajeev Bhatt Ambati,James Lester,Shashank Srivastava,Snigdha Chaturvedi*

Main category: cs.LG

TL;DR: MarginSel是一种用于大语言模型ICL的演示选择方法，通过两步法选择难样本作为演示实例，实现分类任务性能2-7%的绝对提升。


<details>
  <summary>Details</summary>
Motivation: 传统ICL效果易受演示样本选择和顺序影响，需要自适应各测试实例的演示选择方法来提升效果。

Method: 提出MarginSel：最大边界演示选择法，包含两步：1）基于原型距离筛选硬样本候选池；2）选择使测试样本与当前原型距离最大化的负例。

Result: 在多个分类任务上实现F1分数2-7%的绝对提升。理论分析表明该方法通过增大边界类似支持向量机的方式优化决策边界。

Conclusion: MarginSel作为一种低成本适配算法，通过选择信息丰富的硬示例有效提升ICL效果，未来可拓展至生成任务。

Abstract: Large Language Models (LLMs) excel at few-shot learning via in-context
learning (ICL). However, the effectiveness of ICL is often sensitive to the
selection and ordering of demonstration examples. To address this, we present
MarginSel: Max-Margin Demonstration Selection for LLMs, a two-step method that
selects hard demonstration examples for the ICL prompt, adapting to each test
instance. Our approach achieves 2-7% absolute improvement in F1-score across
classification tasks, compared to a random selection of examples. We also
provide theoretical insights and empirical evidence showing that MarginSel
induces max-margin behavior in LLMs by effectively increasing the margin for
hard examples, analogous to support vectors, thereby shifting the decision
boundary in a beneficial direction.

</details>


### [719] [Efficient Text-Attributed Graph Learning through Selective Annotation and Graph Alignment](https://arxiv.org/abs/2506.07168)
*Huanyi Xie,Lijie Hu,Lu Yu,Tianhao Huang,Longfei Li,Meng Li,Jun Zhou,Huan Wang,Di Wang*

Main category: cs.LG

TL;DR: GAGA提出了一种高效的文本属性图(TAG)表示学习框架，通过仅标注代表性节点/边构建注释图，并采用两级对齐模块整合注释图与原始TAG，在仅需1%标注数据的情况下达到SOTA分类精度。


<details>
  <summary>Details</summary>
Motivation: 传统GNN难以处理TAG中复杂的文本信息，现有基于LLM的方法需要全图标注或微调，成本高昂。

Method: 1) 标注代表性节点/边构建注释图；2) 设计两级对齐模块（拓扑和嵌入对齐）整合注释图与原始TAG；3) 基于对齐后的特征进行节点分类。

Result: 在多个TAG基准数据集上达到或超越SOTA分类准确率，仅需1%标注数据，训练速度提升4.7倍。

Conclusion: GAGA显著降低TAG学习成本，证明代表性标注+图对齐策略的有效性，为轻量化图表示学习提供新方向。

Abstract: In the realm of Text-attributed Graphs (TAGs), traditional graph neural
networks (GNNs) often fall short due to the complex textual information
associated with each node. Recent methods have improved node representations by
leveraging large language models (LLMs) to enhance node text features, but
these approaches typically require extensive annotations or fine-tuning across
all nodes, which is both time-consuming and costly. To overcome these
challenges, we introduce GAGA, an efficient framework for TAG representation
learning. GAGA reduces annotation time and cost by focusing on annotating only
representative nodes and edges. It constructs an annotation graph that captures
the topological relationships among these annotations. Furthermore, GAGA
employs a two-level alignment module to effectively integrate the annotation
graph with the TAG, aligning their underlying structures. Experiments show that
GAGA achieves classification accuracies on par with or surpassing
state-of-the-art methods while requiring only 1% of the data to be annotated,
demonstrating its high efficiency.

</details>


### [720] [When Style Breaks Safety: Defending Language Models Against Superficial Style Alignment](https://arxiv.org/abs/2506.07452)
*Yuxin Xiao,Sana Tonekaboni,Walter Gerych,Vinith Suriyakumar,Marzyeh Ghassemi*

Main category: cs.LG

TL;DR: 该论文研究了样式提示对LLM安全性的影响，发现恶意查询中的样式模式会提高攻击成功率，并与样式长度及模型对其注意力相关。提出SafeStyle防御策略，在微调中增强安全性。


<details>
  <summary>Details</summary>
Motivation: 探究样式模式如何影响LLM的安全性，以及如何通过防御策略缓解此类风险。现有工作未深入分析样式对安全性的影响，尤其是样式与恶意意图无关时。

Method: 评估32个LLM在7个越狱基准测试中的表现；分析攻击成功率（ASR）与样式长度、模型注意力之间的关系；探索微调时使用特定样式对模型漏洞的影响；提出SafeStyle防御策略（在安全训练数据中增加微调数据的样式分布数据）。

Result: 1. 多数模型中，含样式模式的恶意查询显著提高攻击成功率（最高时ASR增加23.4%）；2. ASR增长与样式长度及模型对其注意力正相关；3. 微调中使用特定样式使模型更易受同类样式越狱攻击；4. SafeStyle在3个LLM及5种样式微调场景中均优于基线（平均降低ASR 31.2%）。

Conclusion: 样式模式会扩大LLM安全漏洞，其影响可量化；微调时的样式偏好会放大风险；通过SafeStyle防御策略可在维持功能的同时显著增强模型对样式化越狱攻击的鲁棒性。

Abstract: Large language models (LLMs) can be prompted with specific styles (e.g.,
formatting responses as lists), including in jailbreak queries. Although these
style patterns are semantically unrelated to the malicious intents behind
jailbreak queries, their safety impact remains unclear. In this work, we seek
to understand whether style patterns compromise LLM safety, how superficial
style alignment increases model vulnerability, and how best to mitigate these
risks during alignment. We evaluate 32 LLMs across seven jailbreak benchmarks,
and find that malicious queries with style patterns inflate the attack success
rate (ASR) for nearly all models. Notably, ASR inflation correlates with both
the length of style patterns and the relative attention an LLM exhibits on
them. We then investigate superficial style alignment, and find that
fine-tuning with specific styles makes LLMs more vulnerable to jailbreaks of
those same styles. Finally, we propose SafeStyle, a defense strategy that
incorporates a small amount of safety training data augmented to match the
distribution of style patterns in the fine-tuning data. Across three LLMs and
five fine-tuning style settings, SafeStyle consistently outperforms baselines
in maintaining LLM safety.

</details>


### [721] [Chasing Moving Targets with Online Self-Play Reinforcement Learning for Safer Language Models](https://arxiv.org/abs/2506.07468)
*Mickel Liu,Liwei Jiang,Yancheng Liang,Simon Shaolei Du,Yejin Choi,Tim Althoff,Natasha Jaques*

Main category: cs.LG

TL;DR: Self-RedTeam是一种在线自博弈强化学习算法，通过让攻击者和防御者智能体共同进化来主动提升语言模型的安全性，实验表明其能生成更多样攻击并提高稳健性。


<details>
  <summary>Details</summary>
Motivation: 传统语言模型安全对齐采用被动修补方式存在滞后性，攻击者常针对过时防御，而防御者难以应对新威胁。需要一种主动协同进化机制。

Method: 1) 构建两人零和博弈框架，同一模型轮流扮演攻击者（生成对抗提示）和防御者（防护响应）角色；2) 引入奖励模型裁定结果；3) 提出隐藏思维链支持私有决策。

Result: 1) 攻击多样性提升21.8%（SBERT指标）；2) 安全基准鲁棒性显著增强（WildJailBreak上+65.5%）；3) 隐藏思维链减少过度拒绝。

Conclusion: 该研究推动语言模型安全训练从被动修补转向主动协同进化，通过多智能体强化学习实现可扩展的自主稳健改进。

Abstract: Conventional language model (LM) safety alignment relies on a reactive,
disjoint procedure: attackers exploit a static model, followed by defensive
fine-tuning to patch exposed vulnerabilities. This sequential approach creates
a mismatch -- attackers overfit to obsolete defenses, while defenders
perpetually lag behind emerging threats. To address this, we propose
Self-RedTeam, an online self-play reinforcement learning algorithm where an
attacker and defender agent co-evolve through continuous interaction. We cast
safety alignment as a two-player zero-sum game, where a single model alternates
between attacker and defender roles -- generating adversarial prompts and
safeguarding against them -- while a reward LM adjudicates outcomes. This
enables dynamic co-adaptation. Grounded in the game-theoretic framework of
zero-sum games, we establish a theoretical safety guarantee which motivates the
design of our method: if self-play converges to a Nash Equilibrium, the
defender will reliably produce safe responses to any adversarial input.
Empirically, Self-RedTeam uncovers more diverse attacks (+21.8% SBERT) compared
to attackers trained against static defenders and achieves higher robustness on
safety benchmarks (e.g., +65.5% on WildJailBreak) than defenders trained
against static attackers. We further propose hidden Chain-of-Thought, allowing
agents to plan privately, which boosts adversarial diversity and reduces
over-refusals. Our results motivate a shift from reactive patching to proactive
co-evolution in LM safety training, enabling scalable, autonomous, and robust
self-improvement of LMs via multi-agent reinforcement learning (MARL).

</details>


### [722] [Graph-of-Causal Evolution: Challenging Chain-of-Model for Reasoning](https://arxiv.org/abs/2506.07501)
*Libo Wang*

Main category: cs.LG

TL;DR: 为了解决CoM中因因果掩码导致长距离依赖丢失的问题，该文提出GoCE方法，通过因果邻接矩阵和因果约束机制，结合干预一致性损失和自进化门，在多种模型环境中验证了其在提升因果依赖捕捉能力方面的优越性。


<details>
  <summary>Details</summary>
Motivation: 传统的链式模型(CoM)因仅依赖前序子链信息且因果掩码会阻断全局上下文流动，导致长距离依赖捕捉能力受限，因此需要一种能增强Transformer长距离因果依赖建模的方法。

Method: 提出图因果进化(GoCE)：将隐式token表示映射为可微分稀疏因果邻接矩阵；通过因果掩码注意力和因果MoE在每层计算中渗透因果约束；结合干预一致性损失测试及自进化门实现因果结构学习与架构自适应更新的动态平衡。

Result: 在CLUTRR等公开数据集上的实验表明，GoCE显著增强Transformer捕捉长距离因果依赖的能力，自进化能力提升，性能优于基线LLMs并超越CoM设计。

Conclusion: GoCE不仅解决了CoM的局限性，其结合因果约束与自适应进化的设计为未来因果学习和持续改进研究提供了有效经验。

Abstract: In view of the problem that each subchain in the chain-of-model (CoM) relies
only on the information of the previous subchain and may lose long-range
dependencies due to the causal mask blocking the global context flow between
multi-level subchains, this work proposes a graph of causal evolution (GoCE).
Its core principle is to map the implicit token representation into a
differentiable and sparse causal adjacency matrix, then permeate causal
constraints through each layer of calculation using causal-masked attention and
causal-MoE. By combining intervention consistency loss test and self-evolution
gate, the dynamic balance between causal structure learning and adaptive
updating of transformer architecture is realized. The researcher built
experimental environments in sandboxes built with Claude Sonnet 4,
o4-mini-high, and DeepSeek R1 respectively with the transformer variant
architecture introduced in GoCE. It is evaluated on publicly available datasets
including CLUTRR, CLADDER, EX-FEVER, and CausalQA and compared with the
baseline LLMs. The finding proves that GoCE strengthens the transformer's
ability to capture long-range causal dependencies, while the ability to
self-evolve is improved. It not only surpasses the design of CoM in terms of
design principles, but also provides experience for future research on causal
learning and continuous adaptive improvement.

</details>


### [723] [ChemAgent: Enhancing LLMs for Chemistry and Materials Science through Tree-Search Based Tool Learning](https://arxiv.org/abs/2506.07551)
*Mengsong Wu,YaFei Wang,Yidong Ming,Yuqi An,Yuwei Wan,Wenliang Chen,Binbin Lin,Yuqiang Li,Tong Xie,Dongzhan Zhou*

Main category: cs.LG

TL;DR: 这篇论文提出了一种基于LLM的代理，通过整合137种外部化学工具来解决LLM在化学任务中知识过时及专业知识整合难的问题。该方法包括创建数据集ChemToolBench，使用分层进化蒙特卡洛树搜索（HE-MCTS）框架优化工具选择和执行，并通过微调提升性能。实验表明，该方法显著提高了化学QA和发现任务的性能。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLM）在化学任务中表现出潜力，但仍面临预训练知识过时和专业知识整合困难的问题。因此，研究者旨在开发一种方法，使LLM能够有效利用外部化学工具来克服这些限制。

Method: 提出了一种LLM代理，整合137种外部化学工具，并使用ChemToolBench数据集进行工具选择和参数填充的微调。引入了分层进化蒙特卡洛树搜索（HE-MCTS）框架，独立优化工具规划与执行，并通过自生成数据微调策略模型，训练任务自适应的PRM和ORM。

Result: 实验证明，该方法在化学问答和发现任务中显著提升了性能。训练得到的PRM和ORM超越了GPT-4o的效果，为化学应用提供了更强大的LLM工具集成方案。

Conclusion: 该研究解决了LLM在化学领域的知识过时和专业知识整合问题，通过工具整合及HE-MCTS框架实现了性能提升。所有代码和数据集已开源，为未来的化学AI应用提供了有力支持。

Abstract: Large language models (LLMs) have recently demonstrated promising
capabilities in chemistry tasks while still facing challenges due to outdated
pretraining knowledge and the difficulty of incorporating specialized chemical
expertise. To address these issues, we propose an LLM-based agent that
synergistically integrates 137 external chemical tools created ranging from
basic information retrieval to complex reaction predictions, and a dataset
curation pipeline to generate the dataset ChemToolBench that facilitates both
effective tool selection and precise parameter filling during fine-tuning and
evaluation. We introduce a Hierarchical Evolutionary Monte Carlo Tree Search
(HE-MCTS) framework, enabling independent optimization of tool planning and
execution. By leveraging self-generated data, our approach supports step-level
fine-tuning (FT) of the policy model and training task-adaptive PRM and ORM
that surpass GPT-4o. Experimental evaluations demonstrate that our approach
significantly improves performance in Chemistry QA and discovery tasks,
offering a robust solution to integrate specialized tools with LLMs for
advanced chemical applications. All datasets and code are available at
https://github.com/AI4Chem/ChemistryAgent .

</details>


### [724] [E-LDA: Toward Interpretable LDA Topic Models with Strong Guarantees in Logarithmic Parallel Time](https://arxiv.org/abs/2506.07747)
*Adam Breuer*

Main category: cs.LG

TL;DR: 该论文提出一种新颖的非梯度组合方法，用于从LDA主题模型中推断文档主题，具有对数级并行计算时间，且能保证可解释性和适用于因果推断。


<details>
  <summary>Details</summary>
Motivation: 现有LDA主题模型在推断文档分配主题时缺乏高效算法，尤其在需要保证可解释性和适用下游因果推断任务时存在局限。

Method: 采用非梯度的组合优化方法估计主题模型，实现快速收敛和可证明的最优后验概率。

Result: 新算法在并行计算时间上呈对数级收敛，比现有方法快指数级；在多个数据集上语义质量均优于当前最优的LDA、神经主题模型和基于LLM的主题模型。

Conclusion: 该组合方法为领域主题模型推断提供了首个实用算法，可同时满足高效性、可解释性和因果推断兼容性，超越现有所有方法。

Abstract: In this paper, we provide the first practical algorithms with provable
guarantees for the problem of inferring the topics assigned to each document in
an LDA topic model. This is the primary inference problem for many applications
of topic models in social science, data exploration, and causal inference
settings. We obtain this result by showing a novel non-gradient-based,
combinatorial approach to estimating topic models. This yields algorithms that
converge to near-optimal posterior probability in logarithmic parallel
computation time (adaptivity) -- exponentially faster than any known LDA
algorithm. We also show that our approach can provide interpretability
guarantees such that each learned topic is formally associated with a known
keyword. Finally, we show that unlike alternatives, our approach can maintain
the independence assumptions necessary to use the learned topic model for
downstream causal inference methods that allow researchers to study topics as
treatments. In terms of practical performance, our approach consistently
returns solutions of higher semantic quality than solutions from
state-of-the-art LDA algorithms, neural topic models, and LLM-based topic
models across a diverse range of text datasets and evaluation parameters.

</details>


### [725] [Improving large language models with concept-aware fine-tuning](https://arxiv.org/abs/2506.07833)
*Michael K. Chen,Xikun Zhang,Jiaxing Huang,Dacheng Tao*

Main category: cs.LG

TL;DR: 提出了CAFT新方法，解决传统单token预测限制LLM概念理解的问题，实现了微调阶段的多token预测，并在多个任务上取得显著改进。


<details>
  <summary>Details</summary>
Motivation: 传统基于'next-token prediction'的训练范式使LLMs无法形成高层次概念理解，例如会将"ribonucleic acid"拆解为碎片化token而非整体语义单元。

Method: Concept-Aware Fine-Tuning (CAFT)：通过多token序列训练增强概念感知能力，首次将多token预测引入微调阶段。

Result: 在文本摘要和蛋白质设计等任务上显著优于传统单token微调方法，且首次实现后训练阶段的多token预测。

Conclusion: CAFT突破了原有训练范式限制，其意外效果对机器学习社区有更广泛启示，所有代码数据已开源。

Abstract: Large language models (LLMs) have become the cornerstone of modern AI.
However, the existing paradigm of next-token prediction fundamentally limits
their ability to form coherent, high-level concepts, making it a critical
barrier to human-like understanding and reasoning. Take the phrase "ribonucleic
acid" as an example: an LLM will first decompose it into tokens, i.e.,
artificial text fragments ("rib", "on", ...), then learn each token
sequentially, rather than grasping the phrase as a unified, coherent semantic
entity. This fragmented representation hinders deeper conceptual understanding
and, ultimately, the development of truly intelligent systems. In response, we
introduce Concept-Aware Fine-Tuning (CAFT), a novel multi-token training method
that redefines how LLMs are fine-tuned. By enabling the learning of sequences
that span multiple tokens, this method fosters stronger concept-aware learning.
Our experiments demonstrate significant improvements compared to conventional
next-token finetuning methods across diverse tasks, including traditional
applications like text summarization and domain-specific ones like de novo
protein design. Multi-token prediction was previously only possible in the
prohibitively expensive pretraining phase; CAFT, to our knowledge, is the first
to bring the multi-token setting to the post-training phase, thus effectively
democratizing its benefits for the broader community of practitioners and
researchers. Finally, the unexpected effectiveness of our proposed method
suggests wider implications for the machine learning research community. All
code and data are available at https://github.com/michaelchen-lab/caft-llm

</details>


### [726] [Uncovering the Functional Roles of Nonlinearity in Memory](https://arxiv.org/abs/2506.07919)
*Manuel Brenner,Georgia Koppe*

Main category: cs.LG

TL;DR: 该研究通过Almost Linear RNNs探究了非线性在循环网络中的功能角色，发现最小非线性往往是最优的，能够实现更简单、更鲁棒的模型。


<details>
  <summary>Details</summary>
Motivation: 尽管非线性被视为序列建模的关键，但近期研究表明线性动力学可能足够。本研究旨在系统分析非线性在循环网络中的必要性及其机制。

Method: 使用AL-RNNs（允许细粒度控制非线性）作为建模工具和分析手段，在多种序列任务和真实刺激选择任务中进行实验。

Result: 最小非线性不仅足够且通常最优，产生比完全非线性或线性模型更简单、更鲁棒、更可解释的模型。

Conclusion: 非线性应当被有选择地引入，该框架沟通了动力系统理论与RNN的长程记忆需求，对AI及生物神经系统均有启示。

Abstract: Memory and long-range temporal processing are core requirements for sequence
modeling tasks across natural language processing, time-series forecasting,
speech recognition, and control. While nonlinear recurrence has long been
viewed as essential for enabling such mechanisms, recent work suggests that
linear dynamics may often suffice. In this study, we go beyond performance
comparisons to systematically dissect the functional role of nonlinearity in
recurrent networks--identifying both when it is computationally necessary, and
what mechanisms it enables. We use Almost Linear Recurrent Neural Networks
(AL-RNNs), which allow fine-grained control over nonlinearity, as both a
flexible modeling tool and a probe into the internal mechanisms of memory.
Across a range of classic sequence modeling tasks and a real-world stimulus
selection task, we find that minimal nonlinearity is not only sufficient but
often optimal, yielding models that are simpler, more robust, and more
interpretable than their fully nonlinear or linear counterparts. Our results
provide a principled framework for selectively introducing nonlinearity,
bridging dynamical systems theory with the functional demands of long-range
memory and structured computation in recurrent neural networks, with
implications for both artificial and biological neural systems.

</details>


### [727] [HeuriGym: An Agentic Benchmark for LLM-Crafted Heuristics in Combinatorial Optimization](https://arxiv.org/abs/2506.07972)
*Hongzheng Chen,Yingheng Wang,Yaohui Cai,Hins Hu,Jiajie Li,Shirley Huang,Chenhui Deng,Rongjian Liang,Shufeng Kong,Haoxing Ren,Samitha Samaranayake,Carla P. Gomes,Zhiru Zhang*

Main category: cs.LG

TL;DR: 论文提出了HeuriGym框架，用以评估LLM在组合优化问题上生成启发式算法的能力，并发现现有模型存在明显缺陷。


<details>
  <summary>Details</summary>
Motivation: 当前评估LLM方法和代理问题解决能力的方法存在不足：现有基准测试要么依赖易饱和和记忆的封闭性问题，要么缺乏一致性和严谨性的主观比较。

Method: 引入HeuriGym框架：让LLM提出启发式算法，通过代码执行获得反馈，并迭代改进解决方案；在9个领域问题上测试9个最先进模型；提出质量-产出指数（QY）指标来衡量性能。

Result: 顶级模型如GPT-4和Gemini-2.5的QY得分仅为0.6，远低于专家基线1.0，暴露了LLMs在工具使用、规划和自适应推理方面的局限性。

Conclusion: HeuriGym开源基准测试旨在推动LLMs针对科学和工程领域开发更有效、更现实的解决问题的能力，并验证当前模型仍有重大提升空间。

Abstract: While Large Language Models (LLMs) have demonstrated significant advancements
in reasoning and agent-based problem-solving, current evaluation methodologies
fail to adequately assess their capabilities: existing benchmarks either rely
on closed-ended questions prone to saturation and memorization, or subjective
comparisons that lack consistency and rigor. In this work, we introduce
HeuriGym, an agentic framework designed for evaluating heuristic algorithms
generated by LLMs for combinatorial optimization problems, characterized by
clearly defined objectives and expansive solution spaces. HeuriGym empowers
LLMs to propose heuristics, receive evaluative feedback via code execution, and
iteratively refine their solutions. We evaluate nine state-of-the-art models on
nine problems across domains such as computer systems, logistics, and biology,
exposing persistent limitations in tool use, planning, and adaptive reasoning.
To quantify performance, we propose the Quality-Yield Index (QYI), a metric
that captures both solution pass rate and quality. Even top models like
GPT-o4-mini-high and Gemini-2.5-Pro attain QYI scores of only 0.6, well below
the expert baseline of 1. Our open-source benchmark aims to guide the
development of LLMs toward more effective and realistic problem-solving in
scientific and engineering domains.

</details>


### [728] [Reparameterized LLM Training via Orthogonal Equivalence Transformation](https://arxiv.org/abs/2506.08001)
*Zeju Qiu,Simon Buchholz,Tim Z. Xiao,Maximilian Dax,Bernhard Schölkopf,Weiyang Liu*

Main category: cs.LG

TL;DR: 提出了POET算法，通过正交等价变换重新参数化神经元，以稳定优化目标函数并提升泛化能力，适用于大规模语言模型训练。


<details>
  <summary>Details</summary>
Motivation: 大语言模型(LLM)训练中存在效率与稳定性挑战，常规优化方法在处理大规模权重矩阵时易出现泛化能力下降。文章旨在解决LLM训练中收敛性和泛化性的平衡问题。

Method: 设计基于正交等价变换的重新参数化方法：将神经元拆分为两个可学习正交矩阵和固定随机权重矩阵的组合，通过数学证明保持权重矩阵的谱性质，开发了适应大规模训练的高效近似方案。

Result: 实验验证POET在LLM训练中显著提高收敛稳定性和泛化性能；证实算法可扩展至大型网络；具体数据（如收敛速度提升20%）未在摘要体现。

Conclusion: POET为LLM训练提供理论保证的新优化框架；正交约束能有效控制优化轨迹；该方法可推广至其他需要优化稳定性的深度学习任务。

Abstract: While large language models (LLMs) are driving the rapid advancement of
artificial intelligence, effectively and reliably training these large models
remains one of the field's most significant challenges. To address this
challenge, we propose POET, a novel reParameterized training algorithm that
uses Orthogonal Equivalence Transformation to optimize neurons. Specifically,
POET reparameterizes each neuron with two learnable orthogonal matrices and a
fixed random weight matrix. Because of its provable preservation of spectral
properties of weight matrices, POET can stably optimize the objective function
with improved generalization. We further develop efficient approximations that
make POET flexible and scalable for training large-scale neural networks.
Extensive experiments validate the effectiveness and scalability of POET in
training LLMs.

</details>


### [729] [CellCLIP -- Learning Perturbation Effects in Cell Painting via Text-Guided Contrastive Learning](https://arxiv.org/abs/2506.06290)
*Mingyu Lu,Ethan Weinberger,Chanwoo Kim,Su-In Lee*

Main category: cs.LG

TL;DR: 该论文摘要介绍了一种名为CellCLIP的跨模态对比学习框架，用于处理基于高通量显微镜技术（如Cell Painting）的高内涵筛选（HCS）数据。该方法旨在解决将自然图像上成功的对比学习方法应用于HCS数据时的挑战。


<details>
  <summary>Details</summary>
Motivation: 由于Cell Painting图像与自然图像的语义存在显著差异，以及不同扰动的表示困难（例如小分子与CRISPR基因敲除），当前跨模态对比学习方法无法直接适用于HCS数据，因此需要开发新的框架来对齐扰动与细胞形态效应。

Method: CellCLIP结合预训练图像编码器和新型通道编码方案以捕捉显微镜通道间关系，同时使用自然语言编码器表示扰动。

Result: 该框架在跨模态检索和生物相关下游任务中表现优于现有开源模型，并显著减少了计算时间。

Conclusion: CellCLIP通过创新性架构解决了HCS数据分析中的特定挑战，为建立扰动与细胞形态响应的统一表征提供了有效工具。

Abstract: High-content screening (HCS) assays based on high-throughput microscopy
techniques such as Cell Painting have enabled the interrogation of cells'
morphological responses to perturbations at an unprecedented scale. The
collection of such data promises to facilitate a better understanding of the
relationships between different perturbations and their effects on cellular
state. Towards achieving this goal, recent advances in cross-modal contrastive
learning could, in theory, be leveraged to learn a unified latent space that
aligns perturbations with their corresponding morphological effects. However,
the application of such methods to HCS data is not straightforward due to
substantial differences in the semantics of Cell Painting images compared to
natural images, and the difficulty of representing different classes of
perturbations (e.g., small molecule vs CRISPR gene knockout) in a single latent
space. In response to these challenges, here we introduce CellCLIP, a
cross-modal contrastive learning framework for HCS data. CellCLIP leverages
pre-trained image encoders coupled with a novel channel encoding scheme to
better capture relationships between different microscopy channels in image
embeddings, along with natural language encoders for representing
perturbations. Our framework outperforms current open-source models,
demonstrating the best performance in both cross-modal retrieval and
biologically meaningful downstream tasks while also achieving significant
reductions in computation time.

</details>


### [730] [NeurNCD: Novel Class Discovery via Implicit Neural Representation](https://arxiv.org/abs/2506.06412)
*Junming Wang,Yi Shi*

Main category: cs.LG

TL;DR: 我们提出了NeurNCD，这是一种结合Embedding-NeRF和KL散度的框架，用于开放世界的新类发现，在无需密集标注的情况下，在NYUv2和Replica数据集上实现了SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 传统显式表示（如三维分割图）存在离散、易出现空洞和噪声等问题，阻碍了新类发现的准确性。旨在解决这些问题，开发数据高效、无需标注的开放世界新类发现方法。

Method: 1. 设计了Embedding-NeRF模型，结合KL散度替代显式3D分割图；2. 集成特征查询、调制和聚类组件；3. 在预训练语义分割网络与隐式神经表示之间进行信息交换。

Result: 在NYUv2和Replica数据集上大幅超越现有方法；在开放/封闭世界均实现优越分割性能；无需密集标注或人工生成的稀疏监督。

Conclusion: NeurNCD框架有效克服了传统方法的限制，为开放世界新类发现提供了首个通用且数据高效的解决方案，显著提升了分割准确性。

Abstract: Discovering novel classes in open-world settings is crucial for real-world
applications. Traditional explicit representations, such as object descriptors
or 3D segmentation maps, are constrained by their discrete, hole-prone, and
noisy nature, which hinders accurate novel class discovery. To address these
challenges, we introduce NeurNCD, the first versatile and data-efficient
framework for novel class discovery that employs the meticulously designed
Embedding-NeRF model combined with KL divergence as a substitute for
traditional explicit 3D segmentation maps to aggregate semantic embedding and
entropy in visual embedding space. NeurNCD also integrates several key
components, including feature query, feature modulation and clustering,
facilitating efficient feature augmentation and information exchange between
the pre-trained semantic segmentation network and implicit neural
representations. As a result, our framework achieves superior segmentation
performance in both open and closed-world settings without relying on densely
labelled datasets for supervised training or human interaction to generate
sparse label supervision. Extensive experiments demonstrate that our method
significantly outperforms state-of-the-art approaches on the NYUv2 and Replica
datasets.

</details>


### [731] [Vision-QRWKV: Exploring Quantum-Enhanced RWKV Models for Image Classification](https://arxiv.org/abs/2506.06633)
*Chi-Sheng Chen*

Main category: cs.LG

TL;DR: Vision-QRWKV：一种结合量子电路的RWKV混合架构，首次用于图像识别任务。在14个数据集（包括医疗与标准图像）上的实验表明，量子增强模型优于传统模型，尤其在噪声数据上。


<details>
  <summary>Details</summary>
Motivation: 研究量子机器学习如何通过增强神经网络（尤其是经典架构RWKV）来处理高维度图像识别任务，提升视觉特征的表达能力。

Method: 在RWKV的'通道混合'组件中集成可变量子电路（VQC），构建量子-经典混合模型；使用14个医学和标准图像数据集进行图像分类任务评估。

Result: 量子版本在多数数据集（尤其噪声明显的数据集如ChestMNIST）上超越纯经典模型。

Conclusion: 量子增强模型首次系统应用于图像领域，揭示了其在轻薄型视觉任务中的有效性和架构优化潜力。

Abstract: Recent advancements in quantum machine learning have shown promise in
enhancing classical neural network architectures, particularly in domains
involving complex, high-dimensional data. Building upon prior work in temporal
sequence modeling, this paper introduces Vision-QRWKV, a hybrid
quantum-classical extension of the Receptance Weighted Key Value (RWKV)
architecture, applied for the first time to image classification tasks. By
integrating a variational quantum circuit (VQC) into the channel mixing
component of RWKV, our model aims to improve nonlinear feature transformation
and enhance the expressive capacity of visual representations.
  We evaluate both classical and quantum RWKV models on a diverse collection of
14 medical and standard image classification benchmarks, including MedMNIST
datasets, MNIST, and FashionMNIST. Our results demonstrate that the
quantum-enhanced model outperforms its classical counterpart on a majority of
datasets, particularly those with subtle or noisy class distinctions (e.g.,
ChestMNIST, RetinaMNIST, BloodMNIST). This study represents the first
systematic application of quantum-enhanced RWKV in the visual domain, offering
insights into the architectural trade-offs and future potential of quantum
models for lightweight and efficient vision tasks.

</details>


### [732] [Non-Intrusive Load Monitoring Based on Image Load Signatures and Continual Learning](https://arxiv.org/abs/2506.06637)
*Olimjon Toirov,Wei Yu*

Main category: cs.LG

TL;DR: This paper introduces a new Non-Intrusive Load Monitoring approach that converts electrical signals into visual images and uses deep learning for device identification. It incorporates continual learning to adapt to new appliances.


<details>
  <summary>Details</summary>
Motivation: Traditional NILM methods struggle with feature robustness and generalization due to complex load combinations. The authors aim to overcome these limitations by creating more robust visual representations.

Method: Converts current, voltage and power factor into 'image load signatures'. Uses convolutional neural networks for classification. Employs self-supervised pretraining for feature generalization and continual online learning to prevent forgetting when adding new devices.

Result: Experiments on high-sampling rate datasets show significant improvements in recognition accuracy compared to existing methods and variants.

Conclusion: The visual transformation approach combined with continual learning effectively addresses robustness and adaptation challenges in NILM, demonstrating superior accuracy.

Abstract: Non-Intrusive Load Monitoring (NILM) identifies the operating status and
energy consumption of each electrical device in the circuit by analyzing the
electrical signals at the bus, which is of great significance for smart power
management. However, the complex and changeable load combinations and
application environments lead to the challenges of poor feature robustness and
insufficient model generalization of traditional NILM methods. To this end,
this paper proposes a new non-intrusive load monitoring method that integrates
"image load signature" and continual learning. This method converts
multi-dimensional power signals such as current, voltage, and power factor into
visual image load feature signatures, and combines deep convolutional neural
networks to realize the identification and classification of multiple devices;
at the same time, self-supervised pre-training is introduced to improve feature
generalization, and continual online learning strategies are used to overcome
model forgetting to adapt to the emergence of new loads. This paper conducts a
large number of experiments on high-sampling rate load datasets, and compares a
variety of existing methods and model variants. The results show that the
proposed method has achieved significant improvements in recognition accuracy.

</details>


### [733] [The OCR Quest for Generalization: Learning to recognize low-resource alphabets with model editing](https://arxiv.org/abs/2506.06761)
*Adrià Molina Rodríguez,Oriol Ramos Terrades,Josep Lladós*

Main category: cs.LG

TL;DR: 该论文提出了一种利用模型编辑技术的新方法，用于提升低资源语言（如古代手稿和非西方语言）的识别鲁棒性，相比集中式微调和元学习，在未见脚本的迁移学习和域外评估中取得了显著性能提升。


<details>
  <summary>Details</summary>
Motivation: 低资源语言在数据可用性上通常被忽视，导致它们在大规模预训练和基础技术中被排除。本文旨在构建能够比集中式微调策略更快泛化到新数据分布（如字母表）的模型，以提升跨领域识别的鲁棒性。

Method: 利用模型编辑的最新进展，通过领域合并（domain merging）增强未见脚本的纳入（低资源学习），无需考虑其与整体分布的关系或原型构建需求。

Result: 实验证明，即使使用完全相同的训练数据，该方法在向新字母表的迁移学习和挑战性领域偏移（如历史密码文本和非拉丁文字）的域外评估中实现了显著性能提升。

Conclusion: 该研究提供了一种新颖方法，使模型能够轻松适应代表性不足的字母表，从而将文档识别扩展到更广泛的语境和文化中。

Abstract: Achieving robustness in recognition systems across diverse domains is crucial
for their practical utility. While ample data availability is usually assumed,
low-resource languages, such as ancient manuscripts and non-western languages,
tend to be kept out of the equations of massive pretraining and foundational
techniques due to an under representation. In this work, we aim for building
models which can generalize to new distributions of data, such as alphabets,
faster than centralized fine-tune strategies. For doing so, we take advantage
of the recent advancements in model editing to enhance the incorporation of
unseen scripts (low-resource learning). In contrast to state-of-the-art
meta-learning, we showcase the effectiveness of domain merging in sparse
distributions of data, with agnosticity of its relation to the overall
distribution or any other prototyping necessity. Even when using the same exact
training data, our experiments showcase significant performance boosts in
\textbf{transfer learning} to new alphabets and \textbf{out-of-domain
evaluation} in challenging domain shifts, including historical ciphered texts
and non-Latin scripts. This research contributes a novel approach into building
models that can easily adopt under-represented alphabets and, therefore, enable
document recognition to a wider set of contexts and cultures.

</details>


### [734] [Feature-Based Instance Neighbor Discovery: Advanced Stable Test-Time Adaptation in Dynamic World](https://arxiv.org/abs/2506.06782)
*Qinting Jiang,Chuyang Ye,Dongyan Wei,Bingli Wang,Yuan Xue,Jingyan Jiang,Zhi Wang*

Main category: cs.LG

TL;DR: 本文提出了FIND方法，通过层级特征解耦、特征感知归一化和选择性归一化应对动态多分布下的测试时适应问题，在保持计算效率的同时显著提升模型在分布变化时的性能。


<details>
  <summary>Details</summary>
Motivation: 针对现有测试时适应方法在处理动态多批次测试分布时效果不佳的问题，研究发现不同领域的特征分布会聚成具有不同统计特性的簇，而全局归一化策略会扭曲原始数据特征。

Method: 提出FIND框架：1) 层级特征解耦(LFD)通过构图稳定捕获相似分布特征；2) 特征感知批量归一化(FABN)结合源域和测试分布统计量；3) 选择性FABN(S-FABN)动态决定分群与统一特征处理层级。

Result: 实验显示FIND在动态场景中准确率提升高达30%，同时保持计算效率。

Conclusion: FIND通过细粒度特征分布建模和自适应归一化策略，有效解决了动态多分布测试时适应问题，为实际部署提供了高效解决方案。

Abstract: Despite progress, deep neural networks still suffer performance declines
under distribution shifts between training and test domains, leading to a
substantial decrease in Quality of Experience (QoE) for applications. Existing
test-time adaptation (TTA) methods are challenged by dynamic, multiple test
distributions within batches. We observe that feature distributions across
different domains inherently cluster into distinct groups with varying means
and variances. This divergence reveals a critical limitation of previous global
normalization strategies in TTA, which inevitably distort the original data
characteristics. Based on this insight, we propose Feature-based Instance
Neighbor Discovery (FIND), which comprises three key components: Layer-wise
Feature Disentanglement (LFD), Feature Aware Batch Normalization (FABN) and
Selective FABN (S-FABN). LFD stably captures features with similar
distributions at each layer by constructing graph structures. While FABN
optimally combines source statistics with test-time distribution specific
statistics for robust feature representation. Finally, S-FABN determines which
layers require feature partitioning and which can remain unified, thereby
enhancing inference efficiency. Extensive experiments demonstrate that FIND
significantly outperforms existing methods, achieving a 30\% accuracy
improvement in dynamic scenarios while maintaining computational efficiency.

</details>


### [735] [FREE: Fast and Robust Vision Language Models with Early Exits](https://arxiv.org/abs/2506.06884)
*Divya Jyoti Bajpai,Manjesh Kumar Hanawal*

Main category: cs.LG

TL;DR: FREE是一种基于GAN的对抗训练方法，用于在视觉语言模型(VLMs)中实现早期退出，通过输入自适应推理提高推理速度1.51倍以上，同时保持可比性能。


<details>
  <summary>Details</summary>
Motivation: 大型视觉语言模型在实时应用中的推理延迟问题显著，但训练早期退出分类器面临标注数据有限的挑战。

Method: 提出FREE框架：每个退出点包含Transformer层和分类器。Transformer层通过对抗训练使特征接近最终层，分类器作为判别器实现输入自适应推理。

Result: 实验证明该方法提升精度和鲁棒性，缓解'overthinking'和'mid-crisis'现象，实现1.51倍加速且性能相当。

Conclusion: FREE为VLMs提供高效的早期退出解决方案，平衡推理速度与性能，代码已开源。

Abstract: In recent years, Vision-Language Models (VLMs) have shown remarkable
performance improvements in Vision-Language tasks. However, their large size
poses challenges for real-world applications where inference latency is a
concern. To tackle this issue, we propose employing Early Exit (EE) strategies
in VLMs. However, training exit classifiers in VLMs is challenging,
particularly with limited labeled training data. To address this, we introduce
FREE, an adversarial training approach within a GAN-based framework. Here, each
exit consists of a transformer layer and a classifier. The transformer layer is
adversarially trained to produce feature representations similar to the final
layer, while a feature classifier serves as the discriminator. Our method
focuses on performing input-adaptive inference that increases inference speed
with minimal drop in performance. Experimental results demonstrate the
effectiveness of our approach in enhancing accuracy and model robustness by
mitigating overthinking and the phenomenon of mid-crisis that we highlight. We
experimentally validate that our method speeds up the inference process by more
than 1.51x while retaining comparable performance. The source code is available
at https://github.com/Div290/FREE.

</details>


### [736] [Rewriting the Budget: A General Framework for Black-Box Attacks Under Cost Asymmetry](https://arxiv.org/abs/2506.06933)
*Mahdi Salmani,Alireza Abdollahpoorrostam,Seyed-Mohsen Moosavi-Dezfooli*

Main category: cs.LG

TL;DR: 摘要提出了一个针对非对称查询成本的决策型黑盒攻击框架。现有研究假设所有查询成本相同，但在实际中（如内容审核系统）不同输出类别的查询成本存在差异，导致不同查询操作的成本也不同。本文介绍了该问题的背景，指出当前缺乏有效的非对称成本攻击算法。本文通过修改现有攻击的两个核心组件：搜索策略和模型梯度估计方法，提出了一个新框架。具体的创新点包括非对称搜索（AS）机制（一种更保守的二分搜索策略，能够减少依赖成本高的查询操作）和非对称梯度估计（AGREST）方法（该方法调整了采样分布以偏向低成本的查询操作）。本文还设计了新的算法以最小化总体攻击成本（平衡利用不同成本类别的查询），而不是像之前的“Stealthy”攻击方法那样只关注限制高成本的查询操作。该方法易于集成到现有攻击方法中。本文针对多种成本情况进行了理论分析和实验验证，在多个标准图像分类数据集上，该方法相比已有方案能够持续实现更低的总体查询成本和更小的对抗扰动，在某些设定中效果提升幅度高达40%。


<details>
  <summary>Details</summary>
Motivation: 现有决策式黑盒对抗攻击均假设所有查询成本相同，但在实际应用场景（如内容审核系统）中，不同模型输出可能引发差异化的后续操作和处理流程，从而导致查询成本呈现非对称特征（即不同类别的输出对应的查询成本存在显著差异）。尽管之前有研究关注过非对称查询成本的问题，但仍缺乏专门为此设计的有效算法。本文旨在通过系统性地解决搜索策略和梯度估计过程中的成本效率问题，为黑盒对抗攻击建立能适应非对称成本环境的通用框架模型。

Method: 研究提出一个非对称黑盒攻击框架（A-Box），该框架由两个核心技术组成：（1）非对称搜索机制（AS）：该算法改良了传统二分搜索算法，使其在定位决策边界时更少依赖高成本查询操作；（2）非对称梯度估计方法（AGREST）: 该方法重构了梯度估计过程中的点采样策略，使采样分布偏向低成本的查询操作点。此外设计了联合调度机制，允许算法在保持攻击性能的前提下动态平衡利用不同成本的查询类别（包括低成本和高成本类别），从而优化整体攻击成本。该框架具有通用性，可无缝适配多种现有攻击方法（如基于梯度的攻击策略）。

Result: 该框架在标准图像分类基准数据集（包括CIFAR10, ImageNet）进行了系统性实验验证。实验覆盖了多种非对称成本组合情况。通过理论分析和实验数据表明：（1）在各类成本机制下，A-Box方案显著降低了总体查询成本（总查询次数更低）；（2）优化了对抗样本质量（生成的扰动更小）；（3）在部分设定中效果提升幅度达到40%以上；（4）相较于传统仅限制高成本查询的“Stealthy”类方法，A-Box整体性能更优。本文也进行了消融研究，分别验证框架中AS和AGREST组件的独立贡献度。

Conclusion: [1] 该研究填补了决策型黑盒攻击在非对称成本场景下的技术空白；（2）提出的非对称搜索和梯度估计方法在理论和实践上均证明能高效优化攻击成本模型；（3）该方法能灵活整合到多种现有攻击方法中并显著提高其性能；（4）在实际应用中（比如内容审核系统的对抗测试），该方案可为系统设计师提供更准确的攻击风险建模工具；（5）该框架未来可推广至其他黑盒优化场景（如自动化机器学习）中面对非对称成本的情形。

Abstract: Traditional decision-based black-box adversarial attacks on image classifiers
aim to generate adversarial examples by slightly modifying input images while
keeping the number of queries low, where each query involves sending an input
to the model and observing its output. Most existing methods assume that all
queries have equal cost. However, in practice, queries may incur asymmetric
costs; for example, in content moderation systems, certain output classes may
trigger additional review, enforcement, or penalties, making them more costly
than others. While prior work has considered such asymmetric cost settings,
effective algorithms for this scenario remain underdeveloped. In this paper, we
propose a general framework for decision-based attacks under asymmetric query
costs, which we refer to as asymmetric black-box attacks. We modify two core
components of existing attacks: the search strategy and the gradient estimation
process. Specifically, we propose Asymmetric Search (AS), a more conservative
variant of binary search that reduces reliance on high-cost queries, and
Asymmetric Gradient Estimation (AGREST), which shifts the sampling distribution
to favor low-cost queries. We design efficient algorithms that minimize total
attack cost by balancing different query types, in contrast to earlier methods
such as stealthy attacks that focus only on limiting expensive (high-cost)
queries. Our method can be integrated into a range of existing black-box
attacks with minimal changes. We perform both theoretical analysis and
empirical evaluation on standard image classification benchmarks. Across
various cost regimes, our method consistently achieves lower total query cost
and smaller perturbations than existing approaches, with improvements of up to
40% in some settings.

</details>


### [737] [Towards Physics-informed Diffusion for Anomaly Detection in Trajectories](https://arxiv.org/abs/2506.06999)
*Arun Sharma,Mingzhou Yang,Majid Farhadloo,Subhankar Ghosh,Bharat Jayaprakash,Shashi Shekhar*

Main category: cs.LG

TL;DR: 提出一种物理信息扩散模型用于GPS欺骗的异常轨迹检测，整合运动学约束以提高精度。


<details>
  <summary>Details</summary>
Motivation: 国际水域非法活动(如非法捕鱼)频发，现有方法忽略时空依赖性和物理知识导致高误报。

Method: 使用物理知识增强的扩散概率模型，结合运动学约束检测违反物理规律的运动

Result: 在航运/城市数据集上实现更高的异常检测精度和更低的轨迹生成误差

Conclusion: 整合物理约束能有效提升异常轨迹识别性能，代码已开源

Abstract: Given trajectory data, a domain-specific study area, and a user-defined
threshold, we aim to find anomalous trajectories indicative of possible GPS
spoofing (e.g., fake trajectory). The problem is societally important to curb
illegal activities in international waters, such as unauthorized fishing and
illicit oil transfers. The problem is challenging due to advances in AI
generated in deep fakes generation (e.g., additive noise, fake trajectories)
and lack of adequate amount of labeled samples for ground-truth verification.
Recent literature shows promising results for anomalous trajectory detection
using generative models despite data sparsity. However, they do not consider
fine-scale spatiotemporal dependencies and prior physical knowledge, resulting
in higher false-positive rates. To address these limitations, we propose a
physics-informed diffusion model that integrates kinematic constraints to
identify trajectories that do not adhere to physical laws. Experimental results
on real-world datasets in the maritime and urban domains show that the proposed
framework results in higher prediction accuracy and lower estimation error rate
for anomaly detection and trajectory generation methods, respectively. Our
implementation is available at
https://github.com/arunshar/Physics-Informed-Diffusion-Probabilistic-Model.

</details>


### [738] [Advancing Multimodal Reasoning Capabilities of Multimodal Large Language Models via Visual Perception Reward](https://arxiv.org/abs/2506.07218)
*Tong Xiao,Xin Xu,Zhenya Huang,Hongyu Gao,Quan Liu,Qi Liu,Enhong Chen*

Main category: cs.LG

TL;DR: 论文提出Perception-R1方法，通过引入视觉感知奖励来增强MLLMs的多模态感知和推理能力，在少量数据下实现SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 现有强化学习方法忽视了对MLLMs多模态感知能力的提升（这是复杂推理的基础），实验证明这种忽视限制了模型在推理任务上的进一步改进。

Method: 1. 从思维链轨迹中收集文本化视觉标注作为奖励参考 
2. 训练时用评判LLM评估MLLM响应与视觉标注的一致性 
3. 设计视觉感知奖励函数驱动感知与推理共同提升

Result: 在多个多模态推理基准测试中达到SOTA性能，仅使用1,442个训练样本

Conclusion: 显式建模视觉感知奖励可同时增强MLLMs的感知与推理能力，验证了感知能力作为推理基础的假设

Abstract: Enhancing the multimodal reasoning capabilities of Multimodal Large Language
Models (MLLMs) is a challenging task that has attracted increasing attention in
the community. Recently, several studies have applied Reinforcement Learning
with Verifiable Rewards (RLVR) to the multimodal domain in order to enhance the
reasoning abilities of MLLMs. However, these works largely overlook the
enhancement of multimodal perception capabilities in MLLMs, which serve as a
core prerequisite and foundational component of complex multimodal reasoning.
Through McNemar's test, we find that existing RLVR method fails to effectively
enhance the multimodal perception capabilities of MLLMs, thereby limiting their
further improvement in multimodal reasoning. To address this limitation, we
propose Perception-R1, which introduces a novel visual perception reward that
explicitly encourages MLLMs to perceive the visual content accurately, thereby
can effectively incentivizing both their multimodal perception and reasoning
capabilities. Specifically, we first collect textual visual annotations from
the CoT trajectories of multimodal problems, which will serve as visual
references for reward assignment. During RLVR training, we employ a judging LLM
to assess the consistency between the visual annotations and the responses
generated by MLLM, and assign the visual perception reward based on these
consistency judgments. Extensive experiments on several multimodal reasoning
benchmarks demonstrate the effectiveness of our Perception-R1, which achieves
state-of-the-art performance on most benchmarks using only 1,442 training data.

</details>


### [739] [Variational Supervised Contrastive Learning](https://arxiv.org/abs/2506.07413)
*Ziwen Wang,Jiajun Fan,Thao Nguyen,Heng Ji,Ge Liu*

Main category: cs.LG

TL;DR: 提出Variational Supervised Contrastive Learning (VarCon)，通过变分推断解决对比学习中嵌入分布无显式调控和过度依赖大批量负样本的问题，在多数据集上实现SOTA性能并提升语义组织性。


<details>
  <summary>Details</summary>
Motivation: 解决对比学习两大局限：(1)缺乏对嵌入分布的显式调节导致语义相关样本可能被错误推离；(2)过度依赖大批量负样本和定制增强阻碍泛化能力。

Method: 将监督对比学习重构为关于隐类变量的变分推断，最大化后验加权的证据下界(ELBO)，实现高效的类感知匹配和类内离散度精细控制。

Result: 在CIFAR/ImageNet上：ResNet-50编码器仅200轮即达SOTA(ImageNet-1K 79.36%, CIFAR-100 78.29%)；嵌入空间决策边界更清晰；小样本学习和增强鲁棒性优于基准。

Conclusion: VarCon框架显著提升效率和性能，为对比学习提供更可控的表示学习范式，具有更好的语义组织能力和迁移潜力。

Abstract: Contrastive learning has proven to be highly efficient and adaptable in
shaping representation spaces across diverse modalities by pulling similar
samples together and pushing dissimilar ones apart. However, two key
limitations persist: (1) Without explicit regulation of the embedding
distribution, semantically related instances can inadvertently be pushed apart
unless complementary signals guide pair selection, and (2) excessive reliance
on large in-batch negatives and tailored augmentations hinders generalization.
To address these limitations, we propose Variational Supervised Contrastive
Learning (VarCon), which reformulates supervised contrastive learning as
variational inference over latent class variables and maximizes a
posterior-weighted evidence lower bound (ELBO) that replaces exhaustive
pair-wise comparisons for efficient class-aware matching and grants
fine-grained control over intra-class dispersion in the embedding space.
Trained exclusively on image data, our experiments on CIFAR-10, CIFAR-100,
ImageNet-100, and ImageNet-1K show that VarCon (1) achieves state-of-the-art
performance for contrastive learning frameworks, reaching 79.36% Top-1 accuracy
on ImageNet-1K and 78.29% on CIFAR-100 with a ResNet-50 encoder while
converging in just 200 epochs; (2) yields substantially clearer decision
boundaries and semantic organization in the embedding space, as evidenced by
KNN classification, hierarchical clustering results, and transfer-learning
assessments; and (3) demonstrates superior performance in few-shot learning
than supervised baseline and superior robustness across various augmentation
strategies.

</details>


### [740] [Language Embedding Meets Dynamic Graph: A New Exploration for Neural Architecture Representation Learning](https://arxiv.org/abs/2506.07735)
*Haizhao Jing,Haokui Zhang,Zhenhao Shang,Rong Xiao,Peng Wang,Yanning Zhang*

Main category: cs.LG

TL;DR: LeDG-Former 提出了一个结合语言模型嵌入和动态图表示的创新框架，用于神经架构表示学习，解决了现有方法忽略硬件属性和静态图编码的局限性，实现了跨硬件零样本预测和新SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 现有神经架构表示学习方法存在两个主要问题：(1) 忽视硬件属性信息，限制了实际应用适用性；(2) 依赖静态邻接矩阵表示拓扑结构，无法捕捉计算节点间的结构差异，影响编码效果。

Method: 提出LeDG-Former框架：1) 受大语言模型启发，将神经架构和硬件平台通过分词和LLM处理投影到统一语义空间，实现跨硬件零样本预测；2) 提出基于动态图的Transformer改进神经架构建模。

Result: 在NNLQP基准测试中超越之前所有方法，建立新SOTA并首次实现跨硬件延迟预测能力；在NAS-Bench-101和NAS-Bench-201数据集上表现优异。

Conclusion: 该框架通过协同融合语言语义嵌入和动态图表示学习，有效解决了现有方法的局限性，为神经架构表示学习提供了更通用的解决方案，特别在跨硬件预测方面取得突破。

Abstract: Neural Architecture Representation Learning aims to transform network models
into feature representations for predicting network attributes, playing a
crucial role in deploying and designing networks for real-world applications.
Recently, inspired by the success of transformers, transformer-based models
integrated with Graph Neural Networks (GNNs) have achieved significant progress
in representation learning. However, current methods still have some
limitations. First, existing methods overlook hardware attribute information,
which conflicts with the current trend of diversified deep learning hardware
and limits the practical applicability of models. Second, current encoding
approaches rely on static adjacency matrices to represent topological
structures, failing to capture the structural differences between computational
nodes, which ultimately compromises encoding effectiveness. In this paper, we
introduce LeDG-Former, an innovative framework that addresses these limitations
through the synergistic integration of language-based semantic embedding and
dynamic graph representation learning. Specifically, inspired by large language
models (LLMs), we propose a language embedding framework where both neural
architectures and hardware platform specifications are projected into a unified
semantic space through tokenization and LLM processing, enabling zero-shot
prediction across different hardware platforms for the first time. Then, we
propose a dynamic graph-based transformer for modeling neural architectures,
resulting in improved neural architecture modeling performance. On the NNLQP
benchmark, LeDG-Former surpasses previous methods, establishing a new SOTA
while demonstrating the first successful cross-hardware latency prediction
capability. Furthermore, our framework achieves superior performance on the
cell-structured NAS-Bench-101 and NAS-Bench-201 datasets.

</details>


### [741] [Identifiable Object Representations under Spatial Ambiguities](https://arxiv.org/abs/2506.07806)
*Avinash Kori,Francesca Toni,Ben Glocker*

Main category: cs.LG

TL;DR: 提出了一个新颖的概率多视角方法，通过学习全局视点信息和聚合视角特定槽位，解决空间歧义问题，无需视点标注。


<details>
  <summary>Details</summary>
Motivation: 人类推理依赖于模块化物体中心表征，但空间歧义（如遮挡和视角模糊）使其难以实现。现有方法在理论和实践上存在困难。

Method: 多视角概率模型，聚合视角特定槽位以捕获不变内容信息，同时学习解耦的全局视点信息。

Result: 在标准测试集和新型复杂数据集上验证了方法的鲁棒性和可扩展性。

Conclusion: 该框架解决了空间辨识问题，提供可识别性理论保证，且无需视点标注。

Abstract: Modular object-centric representations are essential for *human-like
reasoning* but are challenging to obtain under spatial ambiguities, *e.g. due
to occlusions and view ambiguities*. However, addressing challenges presents
both theoretical and practical difficulties. We introduce a novel multi-view
probabilistic approach that aggregates view-specific slots to capture
*invariant content* information while simultaneously learning disentangled
global *viewpoint-level* information. Unlike prior single-view methods, our
approach resolves spatial ambiguities, provides theoretical guarantees for
identifiability, and requires *no viewpoint annotations*. Extensive experiments
on standard benchmarks and novel complex datasets validate our method's
robustness and scalability.

</details>


### [742] [Diffusion Counterfactual Generation with Semantic Abduction](https://arxiv.org/abs/2506.07883)
*Rajat Rasal,Avinash Kori,Fabio De Sousa Ribeiro,Tian Xia,Ben Glocker*

Main category: cs.LG

TL;DR: The paper presents a novel diffusion-based framework for counterfactual image generation that integrates semantic representations and causal mechanisms to preserve identity while ensuring faithful causal control.


<details>
  <summary>Details</summary>
Motivation: Existing auto-encoding methods for counterfactual image editing struggle with scalability, fidelity, and identity preservation; diffusion models offer superior visual quality and representation learning capabilities to address these limitations.

Method: Proposes diffusion-based causal mechanisms (spatial/semantic/dynamic abduction) and integrates Pearlian causality concepts into diffusion models through semantic representations for counterfactual reasoning.

Result: The approach enables principled trade-offs between faithful causal control and identity preservation, the first to ensure high-level semantic identity preservation in diffusion counterfactuals.

Conclusion: Integrating causality with diffusion models creates an effective framework for identity-preserving counterfactual image editing that balances causal fidelity and perceptual quality.

Abstract: Counterfactual image generation presents significant challenges, including
preserving identity, maintaining perceptual quality, and ensuring faithfulness
to an underlying causal model. While existing auto-encoding frameworks admit
semantic latent spaces which can be manipulated for causal control, they
struggle with scalability and fidelity. Advancements in diffusion models
present opportunities for improving counterfactual image editing, having
demonstrated state-of-the-art visual quality, human-aligned perception and
representation learning capabilities. Here, we present a suite of
diffusion-based causal mechanisms, introducing the notions of spatial, semantic
and dynamic abduction. We propose a general framework that integrates semantic
representations into diffusion models through the lens of Pearlian causality to
edit images via a counterfactual reasoning process. To our knowledge, this is
the first work to consider high-level semantic identity preservation for
diffusion counterfactuals and to demonstrate how semantic control enables
principled trade-offs between faithful causal control and identity
preservation.

</details>


### [743] [Diffuse Everything: Multimodal Diffusion Models on Arbitrary State Spaces](https://arxiv.org/abs/2506.07903)
*Kevin Rojas,Yuchen Zhu,Sichen Zhu,Felix X. -F. Ye,Molei Tao*

Main category: cs.LG

TL;DR: 我们提出了一个新框架，用于在任意状态空间上构建多模态扩散模型，允许不同模态耦合数据的本地生成。通过为每种模态引入解耦的噪声调度，可以在单个模型中同时实现无条件生成和模态条件生成。在文本-图像生成和混合类型表格数据合成上的实验表明，该方法具有竞争性性能。


<details>
  <summary>Details</summary>
Motivation: 虽然扩散模型在单模态数据生成（如图像、视频、文本）方面表现优异，但多模态数据的联合生成仍处于探索初期。现有方法高度依赖外部预处理协议（如tokenizer和变分自编码器）来统一不同数据表示，这对数据有限的应用存在问题。我们旨在消除这种限制。

Method: 提出了一种在任意状态空间上构建多模态扩散模型的新框架，引入针对每种模态的解耦噪声调度方案，支持在单一模型中同步实现无条件生成和模态条件生成。

Result: 在文本-图像生成和混合类型表格数据合成任务上进行实证验证，结果显示该方法取得了具有竞争力的性能表现。

Conclusion: 该框架成功克服了现有方法对预处理协议的依赖限制，首次实现了任意状态空间上的原生多模态耦合数据生成，并通过解耦噪声调度同时支持多种生成模式。

Abstract: Diffusion models have demonstrated remarkable performance in generating
unimodal data across various tasks, including image, video, and text
generation. On the contrary, the joint generation of multimodal data through
diffusion models is still in the early stages of exploration. Existing
approaches heavily rely on external preprocessing protocols, such as tokenizers
and variational autoencoders, to harmonize varied data representations into a
unified, unimodal format. This process heavily demands the high accuracy of
encoders and decoders, which can be problematic for applications with limited
data. To lift this restriction, we propose a novel framework for building
multimodal diffusion models on arbitrary state spaces, enabling native
generation of coupled data across different modalities. By introducing an
innovative decoupled noise schedule for each modality, we enable both
unconditional and modality-conditioned generation within a single model
simultaneously. We empirically validate our approach for text-image generation
and mixed-type tabular data synthesis, demonstrating that it achieves
competitive performance.

</details>


### [744] [Generative Modeling of Weights: Generalization or Memorization?](https://arxiv.org/abs/2506.07998)
*Boya Zeng,Yida Yin,Zhiqiu Xu,Zhuang Liu*

Main category: cs.LG

TL;DR: 该研究发现，当前用于生成神经网络权重的四种方法主要是通过记忆训练检查点来合成权重（产生副本或简单插值），无法生成新颖且高性能的权重；这些方法甚至不如添加噪声或权重集成等简单基线，并且无法通过常用缓解技术改善。


<details>
  <summary>Details</summary>
Motivation: 探究生成模型能否真正合成新颖且高性能的神经网络权重，而非简单复制训练数据。现有方法使用训练后的检查点作为输入，但生成能力未经验证。

Method: 选取四种代表性方法，测试其在新颖权重生成能力：(1)与添加噪声/权重集成等基线对比，(2)尝试通过修改模型结构（如图像扩散模型中防记忆化因子）或数据增强来缓解记忆问题。

Result: (1)当前方法本质上是对训练检查点的记忆（副本或简单插值），无法生成实质性不同的权重；(2)表现不如简单基线；(3)修改建模因素或数据增强无法有效减轻记忆问题。

Conclusion: 生成模型在新领域的应用需谨慎评估，当前方法仅在模仿训练数据分布而非建模更高阶特征。本工作提示需重新审视权重生成的评估标准。

Abstract: Generative models, with their success in image and video generation, have
recently been explored for synthesizing effective neural network weights. These
approaches take trained neural network checkpoints as training data, and aim to
generate high-performing neural network weights during inference. In this work,
we examine four representative methods on their ability to generate novel model
weights, i.e., weights that are different from the checkpoints seen during
training. Surprisingly, we find that these methods synthesize weights largely
by memorization: they produce either replicas, or at best simple
interpolations, of the training checkpoints. Current methods fail to outperform
simple baselines, such as adding noise to the weights or taking a simple weight
ensemble, in obtaining different and simultaneously high-performing models. We
further show that this memorization cannot be effectively mitigated by
modifying modeling factors commonly associated with memorization in image
diffusion models, or applying data augmentations. Our findings provide a
realistic assessment of what types of data current generative models can model,
and highlight the need for more careful evaluation of generative models in new
domains. Our code is available at
https://github.com/boyazeng/weight_memorization.

</details>


### [745] [GLProtein: Global-and-Local Structure Aware Protein Representation Learning](https://arxiv.org/abs/2506.06294)
*Yunqing Liu,Wenqi Fan,Xiaoyong Wei,Qing Li*

Main category: cs.LG

TL;DR: 本文提出了GLProtein框架，首次在蛋白质预训练中融合全局结构相似性和局部氨基酸细节，通过结合掩码建模、三元组结构相似性评分、3D距离编码和亚结构编码，在多个任务上超越现有方法。


<details>
  <summary>Details</summary>
Motivation: 蛋白质结构信息不仅局限于3D结构，还涉及从氨基酸分子（局部）到蛋白质间结构相似性（全局）的多层次信息。现有方法未能充分整合这些信息，因此需要同时考虑全局和局部结构信息以提高预测准确性。

Method: 提出GLProtein框架：1) 蛋白质掩码建模与三元组结构相似性评分结合；2) 蛋白质3D距离编码；3) 基于亚结构的氨基酸分子编码

Result: 在蛋白质-蛋白质相互作用预测、接触预测等多个生物信息学任务中优于现有方法

Conclusion: 同时整合蛋白质全局结构相似性和局部氨基酸细节能显著提升蛋白质功能预测性能，GLProtein为蛋白质预训练提供了新方向

Abstract: Proteins are central to biological systems, participating as building blocks
across all forms of life. Despite advancements in understanding protein
functions through protein sequence analysis, there remains potential for
further exploration in integrating protein structural information. We argue
that the structural information of proteins is not only limited to their 3D
information but also encompasses information from amino acid molecules (local
information) to protein-protein structure similarity (global information). To
address this, we propose \textbf{GLProtein}, the first framework in protein
pre-training that incorporates both global structural similarity and local
amino acid details to enhance prediction accuracy and functional insights.
GLProtein innovatively combines protein-masked modelling with triplet structure
similarity scoring, protein 3D distance encoding and substructure-based amino
acid molecule encoding. Experimental results demonstrate that GLProtein
outperforms previous methods in several bioinformatics tasks, including
predicting protein-protein interaction, contact prediction, and so on.

</details>


### [746] [dLLM-Cache: Accelerating Diffusion Large Language Models with Adaptive Caching](https://arxiv.org/abs/2506.06295)
*Zhiyuan Liu,Yicun Yang,Yaojie Zhang,Junjie Chen,Chang Zou,Qingyuan Wei,Shaobo Wang,Linfeng Zhang*

Main category: cs.LG

TL;DR: dLLM-Cache是一个无需训练的缓存框架，通过长间隔提示缓存和部分响应更新，降低基于扩散的大语言模型（dLLM）的推理延迟，最高加速9.1倍，使dLLM推理延迟接近自回归模型。


<details>
  <summary>Details</summary>
Motivation: 扩散大语言模型（dLLM）虽展现优势，但由于双向注意力机制导致推理延迟高，且传统K-V缓存加速技术不适用。本文观察到dLLM推理中提示静态、响应部分动态的特征，提出针对性优化方案。

Method: 设计dLLM-Cache框架：结合长间隔提示缓存与基于特征相似性的分响应块更新机制，实现中间计算结果的复用。

Result: 在LLaDA 8B和Dream 7B等模型上实验，推理加速最高达9.1倍，输出质量无损，推理延迟逼近自回归模型水平。

Conclusion: dLLM-Cache通过创新性缓存策略有效解决dLLM推理瓶颈，为扩散语言模型实用化提供关键技术支撑。

Abstract: Autoregressive Models (ARMs) have long dominated the landscape of Large
Language Models. Recently, a new paradigm has emerged in the form of
diffusion-based Large Language Models (dLLMs), which generate text by
iteratively denoising masked segments. This approach has shown significant
advantages and potential. However, dLLMs suffer from high inference latency.
Traditional ARM acceleration techniques, such as Key-Value caching, are
incompatible with dLLMs due to their bidirectional attention mechanism. To
address this specific challenge, our work begins with a key observation that
dLLM inference involves a static prompt and a partially dynamic response, where
most tokens remain stable across adjacent denoising steps. Based on this, we
propose dLLM-Cache, a training-free adaptive caching framework that combines
long-interval prompt caching with partial response updates guided by feature
similarity. This design enables efficient reuse of intermediate computations
without compromising model performance. Extensive experiments on representative
dLLMs, including LLaDA 8B and Dream 7B, show that dLLM-Cache achieves up to 9.1
x speedup over standard inference without compromising output quality. Notably,
our method brings dLLM inference latency close to that of ARMs under many
settings. Codes are provided in the supplementary material and will be released
publicly on GitHub.

</details>


### [747] [Reward Is Enough: LLMs Are In-Context Reinforcement Learners](https://arxiv.org/abs/2506.06303)
*Kefan Song,Amir Moeini,Peng Wang,Lei Gong,Rohan Chandra,Yanjun Qi,Shangtong Zhang*

Main category: cs.LG

TL;DR: 论文提出了一种称为ICRL prompting的新方法，演示了在大型语言模型推理过程中自然出现的强化学习行为，无需额外训练即可通过多轮次提示和反馈提高任务性能。


<details>
  <summary>Details</summary>
Motivation: 尽管强化学习是用于序贯决策的人工设计框架，但研究发现大型语言模型(LLM)在推理阶段会自然表现出类似RL的学习行为（称为in-context RL）。

Method: 开发ICRL prompting框架：通过多轮次提示完成相同任务，每轮提供标量奖励反馈。将历史响应和奖励纳入上下文，促使模型自动优化响应质量。

Result: 在Game of 24、创意写作和ScienceWorld三个基准测试中，ICRL prompting显著优于Self-Refine和Reflexion等基线方法，即使奖励信号由模型自身生成仍有效。

Conclusion: 在推理阶段通过上下文强化学习可实现任务性能持续提升，为高效利用测试阶段算力提供新范式。

Abstract: Reinforcement learning (RL) is a human-designed framework for solving
sequential decision making problems. In this work, we demonstrate that,
surprisingly, RL emerges in LLM's (Large Language Model) inference time -- a
phenomenon known as in-context RL (ICRL). Specifically, we propose a novel
multi-round prompting framework called ICRL prompting. The goal is to prompt
the LLM to complete a task. After the LLM generates a response at the current
round, we give numerical scalar feedbacks for the response, called the rewards.
At the next round, we prompt the LLM again with the same task and a context
consisting of all previous responses and rewards. We observe that the quality
of the LLM's response increases as the context grows. In other words, the LLM
is able to maximize the scalar reward signal in the inference time, just like
an RL algorithm. We evaluate ICRL prompting in three benchmarks (Game of 24,
creative writing, and ScienceWorld) and demonstrate significant performance
improvements over baseline methods such as Self-Refine and Reflexion.
Surprisingly, in some experiments the reward signals are generated by the LLM
itself, yet performance improvements are still observed from ICRL prompting,
offering a promising paradigm for scaling test-time compute.

</details>


### [748] [Towards Efficient Multi-LLM Inference: Characterization and Analysis of LLM Routing and Hierarchical Techniques](https://arxiv.org/abs/2506.06579)
*Adarsh Prasad Behera,Jaya Prakash Champati,Roberto Morabito,Sasu Tarkoma,James Gross*

Main category: cs.LG

TL;DR: 该论文探讨了提高大型语言模型（LLM）推理效率的策略，特别是在资源受限的环境下。提出了路由和层级推理两种互补方法：路由根据查询选择最合适的模型；层级推理则让查询依次通过多个模型，直到获得可靠响应。文章对比了这两种方法在关键性能指标上的表现，讨论了基准测试工作，并概述了未解决的挑战和未来研究方向。


<details>
  <summary>Details</summary>
Motivation: 自然语言处理（NLP）领域虽因大型语言模型进步显著，但其推理过程存在计算成本高、能耗大的问题，阻碍在移动设备、边缘计算等资源受限环境下的部署。

Method: 通过文献综述对比两种互补策略：路由（基于查询选择最优模型）和层级推理（使查询依次通过模型序列直至获得可靠响应）。两种策略均通过轻量级模型处理简单查询、仅在必要时调用大模型来减少计算量。

Result: 系统比较了两种策略在关键性能指标上的表现，总结了现有基准测试成果，并识别出现有方法在动态资源分配、延迟优化等方面的局限性。

Conclusion: 为提升LLM在现实场景中的可访问性，需进一步研究响应时间优化、基于任务复杂度的自适应模型选择技术，以及跨异构环境的可扩展部署方案。未来工作应关注算法改进与实际系统集成。

Abstract: Recent progress in Language Models (LMs) has dramatically advanced the field
of natural language processing (NLP), excelling at tasks like text generation,
summarization, and question answering. However, their inference remains
computationally expensive and energy intensive, especially in settings with
limited hardware, power, or bandwidth. This makes it difficult to deploy LMs in
mobile, edge, or cost sensitive environments. To address these challenges,
recent approaches have introduced multi LLM intelligent model selection
strategies that dynamically allocate computational resources based on query
complexity -- using lightweight models for simpler queries and escalating to
larger models only when necessary. This survey explores two complementary
strategies for efficient LLM inference: (i) routing, which selects the most
suitable model based on the query, and (ii) cascading or hierarchical inference
(HI), which escalates queries through a sequence of models until a confident
response is found. Both approaches aim to reduce computation by using
lightweight models for simpler tasks while offloading only when needed. We
provide a comparative analysis of these techniques across key performance
metrics, discuss benchmarking efforts, and outline open challenges. Finally, we
outline future research directions to enable faster response times, adaptive
model selection based on task complexity, and scalable deployment across
heterogeneous environments, making LLM based systems more efficient and
accessible for real world applications.

</details>


### [749] [Curriculum Reinforcement Learning from Easy to Hard Tasks Improves LLM Reasoning](https://arxiv.org/abs/2506.06632)
*Shubham Parashar,Shurui Gui,Xiner Li,Hongyi Ling,Sushil Vemuri,Blake Olson,Eric Li,Yu Zhang,James Caverlee,Dileep Kalathil,Shuiwang Ji*

Main category: cs.LG

TL;DR: 本文提出了 E2H Reasoner 方法，通过从易到难的课程学习来逐步提升语言模型的推理能力，避免了单纯强化学习在困难任务上的低效问题。


<details>
  <summary>Details</summary>
Motivation: 单纯使用强化学习提升语言模型在困难推理任务上的能力效果有限，因此受到课程学习启发，尝试将任务从简单到困难排序以逐步建立推理能力。

Method: 提出 E2H Reasoner 方法：1) 将任务按难度分级；2) 设计从易到难的训练进度安排；3) 在适当阶段淡出简单任务以防止过拟合；4) 在近似策略迭代框架内实现收敛保证。

Result: 实验表明：1) 该方法显著提升了小型语言模型(1.5B-3B)的推理能力；2) 与普通强化学习相比，在多个领域取得更好效果；3) 理论证明了课程学习比直接学习具有更低的样本复杂度。

Conclusion: 从易到难的课程学习是提升语言模型推理能力的有效方法，特别是对于参数较少的模型，该方法通过渐进式学习解决了传统强化学习在困难任务上的局限性。

Abstract: We aim to improve the reasoning capabilities of language models via
reinforcement learning (RL). Recent RL post-trained models like DeepSeek-R1
have demonstrated reasoning abilities on mathematical and coding tasks.
However, prior studies suggest that using RL alone to improve reasoning on
inherently difficult tasks is less effective. Here, we draw inspiration from
curriculum learning and propose to schedule tasks from easy to hard (E2H),
allowing LLMs to build reasoning skills gradually. Our method is termed E2H
Reasoner. Empirically, we observe that, although easy tasks are important
initially, fading them out through appropriate scheduling is essential in
preventing overfitting. Theoretically, we establish convergence guarantees for
E2H Reasoner within an approximate policy iteration framework. We derive
finite-sample complexity bounds and show that when tasks are appropriately
decomposed and conditioned, learning through curriculum stages requires fewer
total samples than direct learning. Experiments across multiple domains show
that E2H Reasoner significantly improves the reasoning ability of small LLMs
(1.5B to 3B), which otherwise struggle when trained with vanilla RL alone,
highlighting the effectiveness of our method.

</details>


### [750] [MarginSel : Max-Margin Demonstration Selection for LLMs](https://arxiv.org/abs/2506.06699)
*Rajeev Bhatt Ambati,James Lester,Shashank Srivastava,Snigdha Chaturvedi*

Main category: cs.LG

TL;DR: 我们介绍了MarginSel：LLMs的最大边际演示选择方法，一种针对每个测试实例选择困难演示样例的两步法，在分类任务上实现了2-7%的绝对F1分数提升。


<details>
  <summary>Details</summary>
Motivation: 由于LLMs在少样本学习中的上下文学习（ICL）效果对演示样例的选择和排序敏感，因此需要一种自适应选择困难演示样例的方法来提升性能。

Method: 提出一个两步法（MarginSel），针对每个测试实例选择困难演示样本作为ICL提示，并通过增加困难样本的边际诱导LLMs出现最大边际行为，从而有利地移动决策边界。

Result: 在分类任务上相比随机选择实现了2-7%的绝对F1分数提升。

Conclusion: MarginSel通过自适应选择困难演示样本有效提升了ICL性能，理论分析和实验结果证明了其通过增大边际移动决策边界的效果。

Abstract: Large Language Models (LLMs) excel at few-shot learning via in-context
learning (ICL). However, the effectiveness of ICL is often sensitive to the
selection and ordering of demonstration examples. To address this, we present
MarginSel: Max-Margin Demonstration Selection for LLMs, a two-step method that
selects hard demonstration examples for the ICL prompt, adapting to each test
instance. Our approach achieves 2-7% absolute improvement in F1-score across
classification tasks, compared to a random selection of examples. We also
provide theoretical insights and empirical evidence showing that MarginSel
induces max-margin behavior in LLMs by effectively increasing the margin for
hard examples, analogous to support vectors, thereby shifting the decision
boundary in a beneficial direction.

</details>


### [751] [Efficient Text-Attributed Graph Learning through Selective Annotation and Graph Alignment](https://arxiv.org/abs/2506.07168)
*Huanyi Xie,Lijie Hu,Lu Yu,Tianhao Huang,Longfei Li,Meng Li,Jun Zhou,Huan Wang,Di Wang*

Main category: cs.LG

TL;DR: GAGA为文本属性图(TAG)提供高效表示学习框架，仅需标注1%数据即达到SOTA性能


<details>
  <summary>Details</summary>
Motivation: 传统GNN处理TAG时受限于文本复杂性，现有LLM增强方法依赖全图标注或微调，成本高昂

Method: 通过标注代表性节点/边构建标注图，设计两级对齐模块整合标注图与原始TAG的结构信息

Result: 实验表明仅使用1%标注数据即达到或超越现有方法分类准确率

Conclusion: GAGA显著降低标注成本，为TAG学习提供高效解决方案

Abstract: In the realm of Text-attributed Graphs (TAGs), traditional graph neural
networks (GNNs) often fall short due to the complex textual information
associated with each node. Recent methods have improved node representations by
leveraging large language models (LLMs) to enhance node text features, but
these approaches typically require extensive annotations or fine-tuning across
all nodes, which is both time-consuming and costly. To overcome these
challenges, we introduce GAGA, an efficient framework for TAG representation
learning. GAGA reduces annotation time and cost by focusing on annotating only
representative nodes and edges. It constructs an annotation graph that captures
the topological relationships among these annotations. Furthermore, GAGA
employs a two-level alignment module to effectively integrate the annotation
graph with the TAG, aligning their underlying structures. Experiments show that
GAGA achieves classification accuracies on par with or surpassing
state-of-the-art methods while requiring only 1% of the data to be annotated,
demonstrating its high efficiency.

</details>


### [752] [When Style Breaks Safety: Defending Language Models Against Superficial Style Alignment](https://arxiv.org/abs/2506.07452)
*Yuxin Xiao,Sana Tonekaboni,Walter Gerych,Vinith Suriyakumar,Marzyeh Ghassemi*

Main category: cs.LG

TL;DR: 研究了语言模型的风格提示（如列表格式）如何影响其安全性，尤其是越狱攻击的成功率。发现风格模式会增加攻击成功率，与风格长度和模型关注度相关。还发现风格微调使模型更容易受同类风格攻击。提出了SafeStyle防御方法，有效提升模型安全性。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）可以被特定风格提示（如列表格式），包括在越狱查询中。虽然这些风格模式与恶意内容在语义上无关，但其对安全性的影响尚不明确。本研究旨在探究：1）风格模式是否损害LLMs安全性；2）表面风格对齐如何增加模型脆弱性；3）如何在对齐过程中最佳缓解此类风险。

Method: 1）评估32个LLMs在7个越狱基准上的表现，分析恶意查询附加风格模式对攻击成功率（ASR）的影响；2）探究风格长度与模型注意力机制的相关性；3）通过风格微调实验验证模型对同风格攻击的敏感性；4）提出SafeStyle防御策略——在安全训练数据中注入与微调数据同分布的风格模式进行增强训练。

Result: 1）在几乎所有模型中，带风格模式的恶意查询显著提升ASR（最高增幅记录为原始攻击成功的4倍）；2）ASR增幅与风格模式长度及模型对风格的注意力集中度呈正相关；3）风格微调使LLMs对同风格攻击的脆弱性提升17%-83%；4）SafeStyle在3个LLMs+5种微调风格的测试中均显著优于基线，ASR平均降低31个百分点。

Conclusion: 风格模式通过分散模型对恶意意图的注意力而成为安全漏洞，且模型对特定风格的微调会放大这种风险。SafeStyle通过将安全数据与风格模式对齐进行防御，为LLM对齐提供新范式，未来可扩展至多模态风格防护。

Abstract: Large language models (LLMs) can be prompted with specific styles (e.g.,
formatting responses as lists), including in jailbreak queries. Although these
style patterns are semantically unrelated to the malicious intents behind
jailbreak queries, their safety impact remains unclear. In this work, we seek
to understand whether style patterns compromise LLM safety, how superficial
style alignment increases model vulnerability, and how best to mitigate these
risks during alignment. We evaluate 32 LLMs across seven jailbreak benchmarks,
and find that malicious queries with style patterns inflate the attack success
rate (ASR) for nearly all models. Notably, ASR inflation correlates with both
the length of style patterns and the relative attention an LLM exhibits on
them. We then investigate superficial style alignment, and find that
fine-tuning with specific styles makes LLMs more vulnerable to jailbreaks of
those same styles. Finally, we propose SafeStyle, a defense strategy that
incorporates a small amount of safety training data augmented to match the
distribution of style patterns in the fine-tuning data. Across three LLMs and
five fine-tuning style settings, SafeStyle consistently outperforms baselines
in maintaining LLM safety.

</details>


### [753] [Chasing Moving Targets with Online Self-Play Reinforcement Learning for Safer Language Models](https://arxiv.org/abs/2506.07468)
*Mickel Liu,Liwei Jiang,Yancheng Liang,Simon Shaolei Du,Yejin Choi,Tim Althoff,Natasha Jaques*

Main category: cs.LG

TL;DR: 提出了Self-RedTeam，一种通过自博弈强化学习实现语言模型安全对齐的在线方法，使攻击者和防御者在持续互动中共同进化，解决了传统静态方法中攻防错配问题。


<details>
  <summary>Details</summary>
Motivation: 传统语言模型安全对齐采用被动、分离的修补模式：攻击者利用静态模型漏洞后，防御者才进行微调修补。这种顺序方法导致攻击者适配过时防御，而防御者始终滞后于新威胁。

Method: 将安全对齐建模为二人零和博弈，单个模型交替扮演攻击者（生成对抗提示）和防御者（防护攻击）角色，使用奖励语言模型裁决结果，并提出带隐藏思维链的MARL算法支持私有化策略规划。

Result: 相比静态方法：1）攻击多样性提升21.8%（基于SBERT） 2）安全基准鲁棒性显著增强（WildJailBreak+65.5%） 3）减少过度拒绝；自博弈收敛时理论证明防御者能在纳什均衡下可靠应对任意攻击。

Conclusion: 研究推动语言模型安全训练从被动修补转向主动协同进化，通过多智能体强化学习实现可扩展、自治且鲁棒的模型自我增强。

Abstract: Conventional language model (LM) safety alignment relies on a reactive,
disjoint procedure: attackers exploit a static model, followed by defensive
fine-tuning to patch exposed vulnerabilities. This sequential approach creates
a mismatch -- attackers overfit to obsolete defenses, while defenders
perpetually lag behind emerging threats. To address this, we propose
Self-RedTeam, an online self-play reinforcement learning algorithm where an
attacker and defender agent co-evolve through continuous interaction. We cast
safety alignment as a two-player zero-sum game, where a single model alternates
between attacker and defender roles -- generating adversarial prompts and
safeguarding against them -- while a reward LM adjudicates outcomes. This
enables dynamic co-adaptation. Grounded in the game-theoretic framework of
zero-sum games, we establish a theoretical safety guarantee which motivates the
design of our method: if self-play converges to a Nash Equilibrium, the
defender will reliably produce safe responses to any adversarial input.
Empirically, Self-RedTeam uncovers more diverse attacks (+21.8% SBERT) compared
to attackers trained against static defenders and achieves higher robustness on
safety benchmarks (e.g., +65.5% on WildJailBreak) than defenders trained
against static attackers. We further propose hidden Chain-of-Thought, allowing
agents to plan privately, which boosts adversarial diversity and reduces
over-refusals. Our results motivate a shift from reactive patching to proactive
co-evolution in LM safety training, enabling scalable, autonomous, and robust
self-improvement of LMs via multi-agent reinforcement learning (MARL).

</details>


### [754] [Graph-of-Causal Evolution: Challenging Chain-of-Model for Reasoning](https://arxiv.org/abs/2506.07501)
*Libo Wang*

Main category: cs.LG

TL;DR: 本文提出了图因果演化(GoCE)方法，通过将token表示映射为稀疏因果邻接矩阵，结合因果掩码注意力和因果MoE，增强Transformer捕捉长距离因果依赖的能力，并在多个数据集上验证了其优于基线模型的性能。


<details>
  <summary>Details</summary>
Motivation: 针对链式模型(CoM)中各子链仅依赖前序信息、因果掩码阻塞多级子链间全局上下文流动导致长距离依赖丢失的问题。

Method: 1) 建立可微稀疏因果邻接矩阵 2) 通过因果掩码注意力和因果MoE渗透因果约束 3) 结合干预一致性损失与自演化门实现因果结构学习与架构自适应更新的动态平衡

Result: 在CLUTRR等4个公开数据集上实验表明：GoCE显著提升Transformer的长距离因果依赖捕捉能力(较基线LLMs)及自演化能力，设计原理超越CoM

Conclusion: GoCE为因果学习和持续自适应改进的未来研究提供了有效经验

Abstract: In view of the problem that each subchain in the chain-of-model (CoM) relies
only on the information of the previous subchain and may lose long-range
dependencies due to the causal mask blocking the global context flow between
multi-level subchains, this work proposes a graph of causal evolution (GoCE).
Its core principle is to map the implicit token representation into a
differentiable and sparse causal adjacency matrix, then permeate causal
constraints through each layer of calculation using causal-masked attention and
causal-MoE. By combining intervention consistency loss test and self-evolution
gate, the dynamic balance between causal structure learning and adaptive
updating of transformer architecture is realized. The researcher built
experimental environments in sandboxes built with Claude Sonnet 4,
o4-mini-high, and DeepSeek R1 respectively with the transformer variant
architecture introduced in GoCE. It is evaluated on publicly available datasets
including CLUTRR, CLADDER, EX-FEVER, and CausalQA and compared with the
baseline LLMs. The finding proves that GoCE strengthens the transformer's
ability to capture long-range causal dependencies, while the ability to
self-evolve is improved. It not only surpasses the design of CoM in terms of
design principles, but also provides experience for future research on causal
learning and continuous adaptive improvement.

</details>


### [755] [ChemAgent: Enhancing LLMs for Chemistry and Materials Science through Tree-Search Based Tool Learning](https://arxiv.org/abs/2506.07551)
*Mengsong Wu,YaFei Wang,Yidong Ming,Yuqi An,Yuwei Wan,Wenliang Chen,Binbin Lin,Yuqiang Li,Tong Xie,Dongzhan Zhou*

Main category: cs.LG

TL;DR: 提出了一个基于大语言模型的代理ChemAgent，结合137种外部化学工具，通过Hierarchical Evolutionary Monte Carlo Tree Search框架优化工具规划与执行，显著提升化学问答和发现任务的性能。


<details>
  <summary>Details</summary>
Motivation: 解决大语言模型在化学任务中面临的预训练知识过时和难以整合专业知识的问题，通过综合利用现有化学工具增强模型专业性。

Method: 1. 构建ChemToolBench数据集指导工具选择和参数填充；2. 使用HE-MCTS框架独立优化工具规划和执行；3. 通过生成数据微调策略模型；4. 训练超越GPT-4o的任务自适应PRM/ORM模型。

Result: 实验证明该方法在化学QA和发现任务中性能显著提升，提供融合专业工具与LLM的解决方案。

Conclusion: 通过工具集成与层次化进化树搜索框架，成功弥补LLM在化学领域的专业局限，所有数据与代码均已开源。

Abstract: Large language models (LLMs) have recently demonstrated promising
capabilities in chemistry tasks while still facing challenges due to outdated
pretraining knowledge and the difficulty of incorporating specialized chemical
expertise. To address these issues, we propose an LLM-based agent that
synergistically integrates 137 external chemical tools created ranging from
basic information retrieval to complex reaction predictions, and a dataset
curation pipeline to generate the dataset ChemToolBench that facilitates both
effective tool selection and precise parameter filling during fine-tuning and
evaluation. We introduce a Hierarchical Evolutionary Monte Carlo Tree Search
(HE-MCTS) framework, enabling independent optimization of tool planning and
execution. By leveraging self-generated data, our approach supports step-level
fine-tuning (FT) of the policy model and training task-adaptive PRM and ORM
that surpass GPT-4o. Experimental evaluations demonstrate that our approach
significantly improves performance in Chemistry QA and discovery tasks,
offering a robust solution to integrate specialized tools with LLMs for
advanced chemical applications. All datasets and code are available at
https://github.com/AI4Chem/ChemistryAgent .

</details>


### [756] [E-LDA: Toward Interpretable LDA Topic Models with Strong Guarantees in Logarithmic Parallel Time](https://arxiv.org/abs/2506.07747)
*Adam Breuer*

Main category: cs.LG

TL;DR: 论文提出了一种新的组合算法，用于LDA主题模型中推断文档主题分配，具有对数级并行计算时间和可证明的保证。该方法在语义质量上优于现有算法，并支持因果推理应用。


<details>
  <summary>Details</summary>
Motivation: LDA主题模型在社会科学和因果推断中有广泛应用，但现有算法在效率和可验证性上存在不足，需要开发更高效且可解释的推断方法。

Method: 提出了一种基于非梯度组合优化的新方法，无需梯度即可估计主题模型，实现对数级并行收敛速度。

Result: 实验证明该方法在多种文本数据集上比现有LDA、神经主题模型和LLM主题模型具有更高的语义质量，学习到的主题可正式关联到已知关键词。

Conclusion: 该组合方法解决了LDA主题推断的关键问题，在效率、可解释性和因果推断适用性方面具有显著优势，为下游应用提供了可靠基础。

Abstract: In this paper, we provide the first practical algorithms with provable
guarantees for the problem of inferring the topics assigned to each document in
an LDA topic model. This is the primary inference problem for many applications
of topic models in social science, data exploration, and causal inference
settings. We obtain this result by showing a novel non-gradient-based,
combinatorial approach to estimating topic models. This yields algorithms that
converge to near-optimal posterior probability in logarithmic parallel
computation time (adaptivity) -- exponentially faster than any known LDA
algorithm. We also show that our approach can provide interpretability
guarantees such that each learned topic is formally associated with a known
keyword. Finally, we show that unlike alternatives, our approach can maintain
the independence assumptions necessary to use the learned topic model for
downstream causal inference methods that allow researchers to study topics as
treatments. In terms of practical performance, our approach consistently
returns solutions of higher semantic quality than solutions from
state-of-the-art LDA algorithms, neural topic models, and LLM-based topic
models across a diverse range of text datasets and evaluation parameters.

</details>


### [757] [Improving large language models with concept-aware fine-tuning](https://arxiv.org/abs/2506.07833)
*Michael K. Chen,Xikun Zhang,Jiaxing Huang,Dacheng Tao*

Main category: cs.LG

TL;DR: 提出Concept-Aware Fine-Tuning（CAFT）方法，通过多token训练解决传统next-token预测导致的语义碎片化问题，在文本摘要和蛋白质设计等任务中显著提升性能。


<details>
  <summary>Details</summary>
Motivation: 现有LLM的next-token预测范式将文本分解为碎片化token（如将ribonucleic acid拆解为rib、on等），阻碍模型形成高层概念理解，成为实现类人推理的关键瓶颈。

Method: CAFT（概念感知微调）：创新多token训练框架，在微调阶段同时预测连续token序列（而非单token），使模型学习连贯语义实体（如完整短语）。这是首个将多token预测从昂贵预训练扩展到微调阶段的方法。

Result: 相比传统微调方法，CAFT在文本摘要、蛋白质设计等任务中取得显著性能提升，且首次实现微调阶段的多token预测（此前仅预训练可行）。

Conclusion: CAFT通过多token建模解决语义碎片化问题，为LLM概念理解提供新方向；其有效性暗示对机器学习社区的广泛影响。代码数据已开源。

Abstract: Large language models (LLMs) have become the cornerstone of modern AI.
However, the existing paradigm of next-token prediction fundamentally limits
their ability to form coherent, high-level concepts, making it a critical
barrier to human-like understanding and reasoning. Take the phrase "ribonucleic
acid" as an example: an LLM will first decompose it into tokens, i.e.,
artificial text fragments ("rib", "on", ...), then learn each token
sequentially, rather than grasping the phrase as a unified, coherent semantic
entity. This fragmented representation hinders deeper conceptual understanding
and, ultimately, the development of truly intelligent systems. In response, we
introduce Concept-Aware Fine-Tuning (CAFT), a novel multi-token training method
that redefines how LLMs are fine-tuned. By enabling the learning of sequences
that span multiple tokens, this method fosters stronger concept-aware learning.
Our experiments demonstrate significant improvements compared to conventional
next-token finetuning methods across diverse tasks, including traditional
applications like text summarization and domain-specific ones like de novo
protein design. Multi-token prediction was previously only possible in the
prohibitively expensive pretraining phase; CAFT, to our knowledge, is the first
to bring the multi-token setting to the post-training phase, thus effectively
democratizing its benefits for the broader community of practitioners and
researchers. Finally, the unexpected effectiveness of our proposed method
suggests wider implications for the machine learning research community. All
code and data are available at https://github.com/michaelchen-lab/caft-llm

</details>


### [758] [Uncovering the Functional Roles of Nonlinearity in Memory](https://arxiv.org/abs/2506.07919)
*Manuel Brenner,Georgia Koppe*

Main category: cs.LG

TL;DR: 该研究通过使用近似线性循环神经网络（AL-RNNs）系统分析了非线性在循环网络中的功能角色，发现最小化非线性在多个任务中不仅是充分的，而且通常是最优的，从而简化模型并提升稳健性和可解释性。


<details>
  <summary>Details</summary>
Motivation: 先前工作表明线性动态可能足以处理序列建模任务，但非线性循环一直被视作核心。本研究旨在揭示非线性何时是计算必需的，以及它启用何种机制，系统剖析其在循环网络中的功能角色。

Method: 采用近似线性循环神经网络（AL-RNNs），通过对非线性进行细粒度控制，将其作为建模工具和内存机制的探针。实验范围涵盖经典序列建模任务和现实世界刺激选择任务。

Result: 在多种任务中发现最小非线性非但足够，且常优于全非线性或纯线性模型，产生更简单、更稳健且更可解释的模型。

Conclusion: 研究提供了有原则的框架来选择性引入非线性，将动力系统理论与循环神经网络的长程记忆和结构化计算需求相连接，对人工和生物神经系统均有启示。

Abstract: Memory and long-range temporal processing are core requirements for sequence
modeling tasks across natural language processing, time-series forecasting,
speech recognition, and control. While nonlinear recurrence has long been
viewed as essential for enabling such mechanisms, recent work suggests that
linear dynamics may often suffice. In this study, we go beyond performance
comparisons to systematically dissect the functional role of nonlinearity in
recurrent networks--identifying both when it is computationally necessary, and
what mechanisms it enables. We use Almost Linear Recurrent Neural Networks
(AL-RNNs), which allow fine-grained control over nonlinearity, as both a
flexible modeling tool and a probe into the internal mechanisms of memory.
Across a range of classic sequence modeling tasks and a real-world stimulus
selection task, we find that minimal nonlinearity is not only sufficient but
often optimal, yielding models that are simpler, more robust, and more
interpretable than their fully nonlinear or linear counterparts. Our results
provide a principled framework for selectively introducing nonlinearity,
bridging dynamical systems theory with the functional demands of long-range
memory and structured computation in recurrent neural networks, with
implications for both artificial and biological neural systems.

</details>


### [759] [HeuriGym: An Agentic Benchmark for LLM-Crafted Heuristics in Combinatorial Optimization](https://arxiv.org/abs/2506.07972)
*Hongzheng Chen,Yingheng Wang,Yaohui Cai,Hins Hu,Jiajie Li,Shirley Huang,Chenhui Deng,Rongjian Liang,Shufeng Kong,Haoxing Ren,Samitha Samaranayake,Carla P. Gomes,Zhiru Zhang*

Main category: cs.LG

TL;DR: 该论文介绍了HeuriGym框架，用于评估LLM在组合优化问题中生成启发式算法的能力，并通过QYI指标量化性能，结果显示现有模型表现远低于专家水平。


<details>
  <summary>Details</summary>
Motivation: 当前评估方法无法充分衡量LLM在组合优化问题中的真实能力：现有基准测试要么依赖易饱和的封闭式问题，要么采用主观且不一致的评估方式。

Method: 提出HeuriGym框架，使LLM能提出启发式算法，通过代码执行获得反馈并迭代改进解决方案。在9个领域的9个问题上测试9个前沿模型。

Result: 现有模型在工具使用、规划和自适应推理方面存在局限。顶尖模型GPT-4-mini-high和Gemini-2.5-Pro的QYI评分仅为0.6（专家基线为1）。

Conclusion: HeuriGym基准通过量化指标揭示LLM在解决复杂科学工程问题时的缺陷，旨在引导开发更具实际效用的模型。开源项目地址未明示。

Abstract: While Large Language Models (LLMs) have demonstrated significant advancements
in reasoning and agent-based problem-solving, current evaluation methodologies
fail to adequately assess their capabilities: existing benchmarks either rely
on closed-ended questions prone to saturation and memorization, or subjective
comparisons that lack consistency and rigor. In this work, we introduce
HeuriGym, an agentic framework designed for evaluating heuristic algorithms
generated by LLMs for combinatorial optimization problems, characterized by
clearly defined objectives and expansive solution spaces. HeuriGym empowers
LLMs to propose heuristics, receive evaluative feedback via code execution, and
iteratively refine their solutions. We evaluate nine state-of-the-art models on
nine problems across domains such as computer systems, logistics, and biology,
exposing persistent limitations in tool use, planning, and adaptive reasoning.
To quantify performance, we propose the Quality-Yield Index (QYI), a metric
that captures both solution pass rate and quality. Even top models like
GPT-o4-mini-high and Gemini-2.5-Pro attain QYI scores of only 0.6, well below
the expert baseline of 1. Our open-source benchmark aims to guide the
development of LLMs toward more effective and realistic problem-solving in
scientific and engineering domains.

</details>


### [760] [Reparameterized LLM Training via Orthogonal Equivalence Transformation](https://arxiv.org/abs/2506.08001)
*Zeju Qiu,Simon Buchholz,Tim Z. Xiao,Maximilian Dax,Bernhard Schölkopf,Weiyang Liu*

Main category: cs.LG

TL;DR: 提出POET算法，一种通过正交等价变换优化神经元的新参数化训练方法，用于稳定训练大型语言模型。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLM）训练困难，需要有效且可靠的训练方法来解决这一挑战。

Method: POET用两个可学习正交矩阵和一个固定随机权重矩阵对每个神经元进行重新参数化，并开发高效近似实现灵活性。

Result: 实验验证了POET在训练LLM中的有效性和可扩展性，提高了泛化能力。

Conclusion: POET通过保留权重矩阵的谱性质，能够稳定优化目标函数，适用于大规神经网络的训练。

Abstract: While large language models (LLMs) are driving the rapid advancement of
artificial intelligence, effectively and reliably training these large models
remains one of the field's most significant challenges. To address this
challenge, we propose POET, a novel reParameterized training algorithm that
uses Orthogonal Equivalence Transformation to optimize neurons. Specifically,
POET reparameterizes each neuron with two learnable orthogonal matrices and a
fixed random weight matrix. Because of its provable preservation of spectral
properties of weight matrices, POET can stably optimize the objective function
with improved generalization. We further develop efficient approximations that
make POET flexible and scalable for training large-scale neural networks.
Extensive experiments validate the effectiveness and scalability of POET in
training LLMs.

</details>


### [761] [CellCLIP -- Learning Perturbation Effects in Cell Painting via Text-Guided Contrastive Learning](https://arxiv.org/abs/2506.06290)
*Mingyu Lu,Ethan Weinberger,Chanwoo Kim,Su-In Lee*

Main category: cs.LG

TL;DR: 提出CellCLIP跨模态对比学习框架解决高内涵筛选数据中细胞图像和扰动表示的语义差异问题，在检索和下游任务表现更优且计算效率更高。


<details>
  <summary>Details</summary>
Motivation: 现有跨模态对比学习方法难以处理高内涵筛选数据中细胞图像与自然图像的语义差异，以及不同扰动类型在统一潜空间中的表示难题。

Method: 采用预训练图像编码器配合新通道编码方案捕捉显微镜通道关系，结合自然语言编码器表示扰动信息。

Result: 优于现有开源模型，在跨模态检索和下游生物任务中表现最优，并显著减少计算时间。

Conclusion: CellCLIP通过改进跨模态表示方法有效处理了HCS数据特有的挑战，为细胞形态学研究提供新工具。

Abstract: High-content screening (HCS) assays based on high-throughput microscopy
techniques such as Cell Painting have enabled the interrogation of cells'
morphological responses to perturbations at an unprecedented scale. The
collection of such data promises to facilitate a better understanding of the
relationships between different perturbations and their effects on cellular
state. Towards achieving this goal, recent advances in cross-modal contrastive
learning could, in theory, be leveraged to learn a unified latent space that
aligns perturbations with their corresponding morphological effects. However,
the application of such methods to HCS data is not straightforward due to
substantial differences in the semantics of Cell Painting images compared to
natural images, and the difficulty of representing different classes of
perturbations (e.g., small molecule vs CRISPR gene knockout) in a single latent
space. In response to these challenges, here we introduce CellCLIP, a
cross-modal contrastive learning framework for HCS data. CellCLIP leverages
pre-trained image encoders coupled with a novel channel encoding scheme to
better capture relationships between different microscopy channels in image
embeddings, along with natural language encoders for representing
perturbations. Our framework outperforms current open-source models,
demonstrating the best performance in both cross-modal retrieval and
biologically meaningful downstream tasks while also achieving significant
reductions in computation time.

</details>


### [762] [NeurNCD: Novel Class Discovery via Implicit Neural Representation](https://arxiv.org/abs/2506.06412)
*Junming Wang,Yi Shi*

Main category: cs.LG

TL;DR: NeurNCD是一种利用神经网络辐射场替代显式分割图的新型类发现框架，无需密集标记和人工干预即可实现3D场景分割，在NYUv2和Replica上优于最新方法


<details>
  <summary>Details</summary>
Motivation: 传统显式表示（如3D分割图）存在离散、空洞和噪声问题，阻碍准确的新类发现

Method: 提出Embedding-NeRF模型结合KL散度聚合语义嵌入，并通过特征查询/调制/聚类实现预训练网络与隐式神经表示的信息交换

Result: 在开放/封闭世界均实现优异分割性能，在NYUv2和Replica上大幅超越现有方法

Conclusion: NeurNCD是首个通用且数据高效的新类发现框架，突破传统显式表示的局限性

Abstract: Discovering novel classes in open-world settings is crucial for real-world
applications. Traditional explicit representations, such as object descriptors
or 3D segmentation maps, are constrained by their discrete, hole-prone, and
noisy nature, which hinders accurate novel class discovery. To address these
challenges, we introduce NeurNCD, the first versatile and data-efficient
framework for novel class discovery that employs the meticulously designed
Embedding-NeRF model combined with KL divergence as a substitute for
traditional explicit 3D segmentation maps to aggregate semantic embedding and
entropy in visual embedding space. NeurNCD also integrates several key
components, including feature query, feature modulation and clustering,
facilitating efficient feature augmentation and information exchange between
the pre-trained semantic segmentation network and implicit neural
representations. As a result, our framework achieves superior segmentation
performance in both open and closed-world settings without relying on densely
labelled datasets for supervised training or human interaction to generate
sparse label supervision. Extensive experiments demonstrate that our method
significantly outperforms state-of-the-art approaches on the NYUv2 and Replica
datasets.

</details>


### [763] [Vision-QRWKV: Exploring Quantum-Enhanced RWKV Models for Image Classification](https://arxiv.org/abs/2506.06633)
*Chi-Sheng Chen*

Main category: cs.LG

TL;DR: Vision-QRWKV结合量子电路和经典RWKV架构，首次应用于图像分类，在多种医学和标准数据集上表现优于纯经典模型，尤其擅长处理噪声和细微分类差异


<details>
  <summary>Details</summary>
Motivation: 当前量子机器学习在增强经典神经网络架构方面展现出潜力，尤其是在处理复杂高维数据时。作者将先前用于时序建模的量子增强RWKV架构引入视觉领域，旨在通过量子计算提升非线性特征变换能力和表达力

Method: 将变分量子电路(VQC)集成到RWKV架构的信道混合模块中，形成混合量子-经典模型Vision-QRWKV。在14个图像分类基准数据集（包括MedMNIST、MNIST等）上对比纯经典版本

Result: 量子增强模型在大多数数据集（尤其是含噪声或细微分类差异的数据集如ChestMNIST）上超越经典模型，证明了量子组件对视觉任务的有效性

Conclusion: 该研究探索了量子增强RWKV在视觉领域的首次系统应用，为轻量高效量子视觉模型提供了新的设计思路和应用可行性证明

Abstract: Recent advancements in quantum machine learning have shown promise in
enhancing classical neural network architectures, particularly in domains
involving complex, high-dimensional data. Building upon prior work in temporal
sequence modeling, this paper introduces Vision-QRWKV, a hybrid
quantum-classical extension of the Receptance Weighted Key Value (RWKV)
architecture, applied for the first time to image classification tasks. By
integrating a variational quantum circuit (VQC) into the channel mixing
component of RWKV, our model aims to improve nonlinear feature transformation
and enhance the expressive capacity of visual representations.
  We evaluate both classical and quantum RWKV models on a diverse collection of
14 medical and standard image classification benchmarks, including MedMNIST
datasets, MNIST, and FashionMNIST. Our results demonstrate that the
quantum-enhanced model outperforms its classical counterpart on a majority of
datasets, particularly those with subtle or noisy class distinctions (e.g.,
ChestMNIST, RetinaMNIST, BloodMNIST). This study represents the first
systematic application of quantum-enhanced RWKV in the visual domain, offering
insights into the architectural trade-offs and future potential of quantum
models for lightweight and efficient vision tasks.

</details>


### [764] [Non-Intrusive Load Monitoring Based on Image Load Signatures and Continual Learning](https://arxiv.org/abs/2506.06637)
*Olimjon Toirov,Wei Yu*

Main category: cs.LG

TL;DR: 提出一种融合'图像负荷特征'和持续学习的非侵入式负荷监测方法，通过将多维电力信号转换为图像特征，结合深度卷积神经网络和自监督预训练提升特征泛化能力，利用持续在线学习适应新负荷，显著提高识别准确率。


<details>
  <summary>Details</summary>
Motivation: 传统非侵入式负荷监测（NILM）方法因负荷组合复杂多变、应用环境差异导致特征鲁棒性差、模型泛化不足。为解决这些问题，本文提出新方法。

Method: 将电流等多维电力信号转化为视觉图像负荷特征；采用深度卷积神经网络进行设备识别；引入自监督预训练提升特征泛化；使用持续在线学习策略避免模型遗忘以适应新负荷。

Result: 在高采样率负荷数据集上的大量实验表明，该方法相比现有方法和模型变体在识别准确率上取得显著提升。

Conclusion: 所提方法有效解决了传统NILM的特征鲁棒性与泛化问题，通过图像特征表示和持续学习机制实现了对新负荷场景的适应，为智能用电管理提供了更优解决方案。

Abstract: Non-Intrusive Load Monitoring (NILM) identifies the operating status and
energy consumption of each electrical device in the circuit by analyzing the
electrical signals at the bus, which is of great significance for smart power
management. However, the complex and changeable load combinations and
application environments lead to the challenges of poor feature robustness and
insufficient model generalization of traditional NILM methods. To this end,
this paper proposes a new non-intrusive load monitoring method that integrates
"image load signature" and continual learning. This method converts
multi-dimensional power signals such as current, voltage, and power factor into
visual image load feature signatures, and combines deep convolutional neural
networks to realize the identification and classification of multiple devices;
at the same time, self-supervised pre-training is introduced to improve feature
generalization, and continual online learning strategies are used to overcome
model forgetting to adapt to the emergence of new loads. This paper conducts a
large number of experiments on high-sampling rate load datasets, and compares a
variety of existing methods and model variants. The results show that the
proposed method has achieved significant improvements in recognition accuracy.

</details>


### [765] [The OCR Quest for Generalization: Learning to recognize low-resource alphabets with model editing](https://arxiv.org/abs/2506.06761)
*Adrià Molina Rodríguez,Oriol Ramos Terrades,Josep Lladós*

Main category: cs.LG

TL;DR: 论文提出了一种方法，用于增强模型在低资源语言中的泛化能力。该方法通过模型编辑技术实现领域合并，有效提升了模型在未见过文字（如历史密码文本和非拉丁文字）上的迁移学习和域外评估性能。


<details>
  <summary>Details</summary>
Motivation: 低资源语言在大量预训练和基础技术中常被忽视，导致模型在这些领域泛化能力不足。传统中心化微调策略难以快速适应新的数据分布（如新字母表）。

Method: 利用模型编辑技术进行领域合并，无需元学习或原型构造。该方法能在数据分布稀疏的情况下高效整合未见过的文字。

Result: 实验表明，即使使用相同训练数据，该方法在向新字母表的迁移学习和挑战性域外评估（如历史密码文本和非拉丁文字）中显著提升性能。

Conclusion: 该方法为构建能轻松适应低资源字母表的模型提供了新思路，有助于将文档识别扩展到更广泛的语境和文化中。

Abstract: Achieving robustness in recognition systems across diverse domains is crucial
for their practical utility. While ample data availability is usually assumed,
low-resource languages, such as ancient manuscripts and non-western languages,
tend to be kept out of the equations of massive pretraining and foundational
techniques due to an under representation. In this work, we aim for building
models which can generalize to new distributions of data, such as alphabets,
faster than centralized fine-tune strategies. For doing so, we take advantage
of the recent advancements in model editing to enhance the incorporation of
unseen scripts (low-resource learning). In contrast to state-of-the-art
meta-learning, we showcase the effectiveness of domain merging in sparse
distributions of data, with agnosticity of its relation to the overall
distribution or any other prototyping necessity. Even when using the same exact
training data, our experiments showcase significant performance boosts in
\textbf{transfer learning} to new alphabets and \textbf{out-of-domain
evaluation} in challenging domain shifts, including historical ciphered texts
and non-Latin scripts. This research contributes a novel approach into building
models that can easily adopt under-represented alphabets and, therefore, enable
document recognition to a wider set of contexts and cultures.

</details>


### [766] [Feature-Based Instance Neighbor Discovery: Advanced Stable Test-Time Adaptation in Dynamic World](https://arxiv.org/abs/2506.06782)
*Qinting Jiang,Chuyang Ye,Dongyan Wei,Bingli Wang,Yuan Xue,Jingyan Jiang,Zhi Wang*

Main category: cs.LG

TL;DR: 该论文提出了FIND方法，通过层间特征解耦、特征感知批量归一化和选择性归一化解决测试时适应中的多分布偏移问题，显著提升了动态场景下的模型性能。


<details>
  <summary>Details</summary>
Motivation: 现有的测试时适应方法在处理批量内动态多变的多重分布时性能下降明显，其特征分布差异导致全局归一化策略会扭曲原始数据特性。

Method: 提出包含三个组件的FIND方法：LFD通过图结构捕获相似分布特征；FABN融合源域和测试时统计信息；S-FABN选择性应用归一化层提升效率。

Result: 在动态场景下实现了30%的准确率提升，同时保持了计算效率

Conclusion: FIND通过特征分布聚类感知和自适应归一化，有效解决了批量内多分布偏移问题，显著优于现有方法

Abstract: Despite progress, deep neural networks still suffer performance declines
under distribution shifts between training and test domains, leading to a
substantial decrease in Quality of Experience (QoE) for applications. Existing
test-time adaptation (TTA) methods are challenged by dynamic, multiple test
distributions within batches. We observe that feature distributions across
different domains inherently cluster into distinct groups with varying means
and variances. This divergence reveals a critical limitation of previous global
normalization strategies in TTA, which inevitably distort the original data
characteristics. Based on this insight, we propose Feature-based Instance
Neighbor Discovery (FIND), which comprises three key components: Layer-wise
Feature Disentanglement (LFD), Feature Aware Batch Normalization (FABN) and
Selective FABN (S-FABN). LFD stably captures features with similar
distributions at each layer by constructing graph structures. While FABN
optimally combines source statistics with test-time distribution specific
statistics for robust feature representation. Finally, S-FABN determines which
layers require feature partitioning and which can remain unified, thereby
enhancing inference efficiency. Extensive experiments demonstrate that FIND
significantly outperforms existing methods, achieving a 30\% accuracy
improvement in dynamic scenarios while maintaining computational efficiency.

</details>


### [767] [FREE: Fast and Robust Vision Language Models with Early Exits](https://arxiv.org/abs/2506.06884)
*Divya Jyoti Bajpai,Manjesh Kumar Hanawal*

Main category: cs.LG

TL;DR: 提出了一种基于对抗训练的早期退出策略（FREE），用于加速视觉语言模型推理，在保持性能的同时提升推理速度超过1.51倍。


<details>
  <summary>Details</summary>
Motivation: 当前视觉语言模型（VLMs）规模庞大导致推理延迟，难以应用于实时场景。需要开发高效推理方法，但现有早期退出策略在有限标注数据下训练困难。

Method: 在GAN框架中引入对抗训练：每个退出点包含Transformer层和分类器。Transformer层被训练为生成与最终层相似的特征，同时特征分类器充当判别器，实现输入自适应推理。

Result: 实验表明方法有效提升了准确率和鲁棒性，缓解了过思考和mid-crisis现象。推理速度提升超过1.51倍且性能接近原始模型。

Conclusion: FREE提供了一种高效训练早期退出分类器的方法，显著加速VLMs推理，为解决大模型部署延迟问题提供了新方案。

Abstract: In recent years, Vision-Language Models (VLMs) have shown remarkable
performance improvements in Vision-Language tasks. However, their large size
poses challenges for real-world applications where inference latency is a
concern. To tackle this issue, we propose employing Early Exit (EE) strategies
in VLMs. However, training exit classifiers in VLMs is challenging,
particularly with limited labeled training data. To address this, we introduce
FREE, an adversarial training approach within a GAN-based framework. Here, each
exit consists of a transformer layer and a classifier. The transformer layer is
adversarially trained to produce feature representations similar to the final
layer, while a feature classifier serves as the discriminator. Our method
focuses on performing input-adaptive inference that increases inference speed
with minimal drop in performance. Experimental results demonstrate the
effectiveness of our approach in enhancing accuracy and model robustness by
mitigating overthinking and the phenomenon of mid-crisis that we highlight. We
experimentally validate that our method speeds up the inference process by more
than 1.51x while retaining comparable performance. The source code is available
at https://github.com/Div290/FREE.

</details>


### [768] [Rewriting the Budget: A General Framework for Black-Box Attacks Under Cost Asymmetry](https://arxiv.org/abs/2506.06933)
*Mahdi Salmani,Alireza Abdollahpoorrostam,Seyed-Mohsen Moosavi-Dezfooli*

Main category: cs.LG

TL;DR: 提出一种非对称黑盒攻击框架，通过改进搜索策略（AS）和梯度估计（AGREST）来减少攻击的总查询成本，特别针对查询成本不对称的场景（如某些查询会触发额外处理）。


<details>
  <summary>Details</summary>
Motivation: 传统黑盒攻击认为所有查询成本相同，但实践中某些查询（如触发内容审核系统处罚的类别）成本更高。现有方法对此考虑不足，需要开发在非对称查询成本下更高效的攻击算法。

Method: 1. 非对称搜索（AS）：改良二分搜索，减少依赖高成本查询；2. 非对称梯度估计（AGREST）：调整采样分布以偏向低成本查询。可无缝集成到现有攻击方法中。

Result: 在多种成本配置下，该方法的总查询成本和扰动幅度均低于现有方案，最高可减少40%成本。理论分析和图像分类基准实验验证了有效性。

Conclusion: 该框架首次系统解决非对称查询成本问题，通过平衡不同查询类型实现高效攻击，为实际高风险系统安全评估提供新工具。

Abstract: Traditional decision-based black-box adversarial attacks on image classifiers
aim to generate adversarial examples by slightly modifying input images while
keeping the number of queries low, where each query involves sending an input
to the model and observing its output. Most existing methods assume that all
queries have equal cost. However, in practice, queries may incur asymmetric
costs; for example, in content moderation systems, certain output classes may
trigger additional review, enforcement, or penalties, making them more costly
than others. While prior work has considered such asymmetric cost settings,
effective algorithms for this scenario remain underdeveloped. In this paper, we
propose a general framework for decision-based attacks under asymmetric query
costs, which we refer to as asymmetric black-box attacks. We modify two core
components of existing attacks: the search strategy and the gradient estimation
process. Specifically, we propose Asymmetric Search (AS), a more conservative
variant of binary search that reduces reliance on high-cost queries, and
Asymmetric Gradient Estimation (AGREST), which shifts the sampling distribution
to favor low-cost queries. We design efficient algorithms that minimize total
attack cost by balancing different query types, in contrast to earlier methods
such as stealthy attacks that focus only on limiting expensive (high-cost)
queries. Our method can be integrated into a range of existing black-box
attacks with minimal changes. We perform both theoretical analysis and
empirical evaluation on standard image classification benchmarks. Across
various cost regimes, our method consistently achieves lower total query cost
and smaller perturbations than existing approaches, with improvements of up to
40% in some settings.

</details>


### [769] [Towards Physics-informed Diffusion for Anomaly Detection in Trajectories](https://arxiv.org/abs/2506.06999)
*Arun Sharma,Mingzhou Yang,Majid Farhadloo,Subhankar Ghosh,Bharat Jayaprakash,Shashi Shekhar*

Main category: cs.LG

TL;DR: 提出了一种基于物理信息扩散模型的轨迹异常检测方法，用于识别GPS欺骗导致的异常轨迹，在航船和城市领域数据集上表现出更高准确率和更低错误率。


<details>
  <summary>Details</summary>
Motivation: 该研究旨在打击国际水域非法活动（如盗捕和非法石油运输），现有方法因忽略细粒度时空依赖性和物理知识而导致高误报率。

Method: 开发了一种融合运动学约束的物理信息扩散模型，确保生成的轨迹符合物理规律。

Result: 在真实航船与城市数据集上，该框架在异常检测和轨迹生成任务中分别实现了更高预测精度和更低误差率。

Conclusion: 物理约束的引入显著提升了扩散模型在异常轨迹检测中的性能，并开源了实现代码以促进相关研究。

Abstract: Given trajectory data, a domain-specific study area, and a user-defined
threshold, we aim to find anomalous trajectories indicative of possible GPS
spoofing (e.g., fake trajectory). The problem is societally important to curb
illegal activities in international waters, such as unauthorized fishing and
illicit oil transfers. The problem is challenging due to advances in AI
generated in deep fakes generation (e.g., additive noise, fake trajectories)
and lack of adequate amount of labeled samples for ground-truth verification.
Recent literature shows promising results for anomalous trajectory detection
using generative models despite data sparsity. However, they do not consider
fine-scale spatiotemporal dependencies and prior physical knowledge, resulting
in higher false-positive rates. To address these limitations, we propose a
physics-informed diffusion model that integrates kinematic constraints to
identify trajectories that do not adhere to physical laws. Experimental results
on real-world datasets in the maritime and urban domains show that the proposed
framework results in higher prediction accuracy and lower estimation error rate
for anomaly detection and trajectory generation methods, respectively. Our
implementation is available at
https://github.com/arunshar/Physics-Informed-Diffusion-Probabilistic-Model.

</details>


### [770] [Advancing Multimodal Reasoning Capabilities of Multimodal Large Language Models via Visual Perception Reward](https://arxiv.org/abs/2506.07218)
*Tong Xiao,Xin Xu,Zhenya Huang,Hongyu Gao,Quan Liu,Qi Liu,Enhong Chen*

Main category: cs.LG

TL;DR: 提出Perception-R1方法，通过引入视觉感知奖励增强多模态大语言模型(MLLM)的感知和推理能力，解决了现有RLVR方法忽视感知能力提升的问题。


<details>
  <summary>Details</summary>
Motivation: 现有增强MLLM推理能力的方法（如RLVR）忽视了多模态感知能力的提升，而感知是推理的核心前提。通过McNemar测试发现RLVR未能有效提升感知能力，限制了推理性能的进一步提升。

Method: 1) 从多模态问题的CoT轨迹中收集文本化视觉标注作为奖励参考；2) 在RLVR训练中使用评判大语言模型评估MLLM响应与视觉标注的一致性；3) 基于一致性判断分配视觉感知奖励，同步激励感知与推理能力。

Result: 在多个多模态推理基准测试中取得SOTA性能（仅使用1,442条训练数据），证明了方法的有效性。

Conclusion: 显式建模视觉感知奖励能有效提升MLLM的双模态能力，小数据量即可实现显著效果，为多模态学习提供了新方向。

Abstract: Enhancing the multimodal reasoning capabilities of Multimodal Large Language
Models (MLLMs) is a challenging task that has attracted increasing attention in
the community. Recently, several studies have applied Reinforcement Learning
with Verifiable Rewards (RLVR) to the multimodal domain in order to enhance the
reasoning abilities of MLLMs. However, these works largely overlook the
enhancement of multimodal perception capabilities in MLLMs, which serve as a
core prerequisite and foundational component of complex multimodal reasoning.
Through McNemar's test, we find that existing RLVR method fails to effectively
enhance the multimodal perception capabilities of MLLMs, thereby limiting their
further improvement in multimodal reasoning. To address this limitation, we
propose Perception-R1, which introduces a novel visual perception reward that
explicitly encourages MLLMs to perceive the visual content accurately, thereby
can effectively incentivizing both their multimodal perception and reasoning
capabilities. Specifically, we first collect textual visual annotations from
the CoT trajectories of multimodal problems, which will serve as visual
references for reward assignment. During RLVR training, we employ a judging LLM
to assess the consistency between the visual annotations and the responses
generated by MLLM, and assign the visual perception reward based on these
consistency judgments. Extensive experiments on several multimodal reasoning
benchmarks demonstrate the effectiveness of our Perception-R1, which achieves
state-of-the-art performance on most benchmarks using only 1,442 training data.

</details>


### [771] [Variational Supervised Contrastive Learning](https://arxiv.org/abs/2506.07413)
*Ziwen Wang,Jiajun Fan,Thao Nguyen,Heng Ji,Ge Liu*

Main category: cs.LG

TL;DR: 提出VarCon方法解决对比学习中嵌入分布无显式监管和过度依赖负样本的问题, 通过变分推断优化类感知匹配, 在多个数据集上取得SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 传统对比学习存在两个问题: (1)无显式约束导致语义相关样本可能被推远; (2)过度依赖大批量负样本和特制数据增强阻碍泛化能力。

Method: 将监督对比学习重构为隐类变量的变分推断, 最大化后验加权的ELBO, 替代耗尽的样本对比较, 实现高效类感知匹配并精细控制类内离散度。

Result: (1)在ImageNet-1K和CIFAR-100上分别达到79.36%和78.29% Top1准确率(ResNet-50); (2)生成更清晰的决策边界; (3)小样本学习和鲁棒性优于基线。

Conclusion: VarCon首次通过变分推断框架统一解决对比学习的分布控制和效率问题, 实现了精度与效率的双突破。

Abstract: Contrastive learning has proven to be highly efficient and adaptable in
shaping representation spaces across diverse modalities by pulling similar
samples together and pushing dissimilar ones apart. However, two key
limitations persist: (1) Without explicit regulation of the embedding
distribution, semantically related instances can inadvertently be pushed apart
unless complementary signals guide pair selection, and (2) excessive reliance
on large in-batch negatives and tailored augmentations hinders generalization.
To address these limitations, we propose Variational Supervised Contrastive
Learning (VarCon), which reformulates supervised contrastive learning as
variational inference over latent class variables and maximizes a
posterior-weighted evidence lower bound (ELBO) that replaces exhaustive
pair-wise comparisons for efficient class-aware matching and grants
fine-grained control over intra-class dispersion in the embedding space.
Trained exclusively on image data, our experiments on CIFAR-10, CIFAR-100,
ImageNet-100, and ImageNet-1K show that VarCon (1) achieves state-of-the-art
performance for contrastive learning frameworks, reaching 79.36% Top-1 accuracy
on ImageNet-1K and 78.29% on CIFAR-100 with a ResNet-50 encoder while
converging in just 200 epochs; (2) yields substantially clearer decision
boundaries and semantic organization in the embedding space, as evidenced by
KNN classification, hierarchical clustering results, and transfer-learning
assessments; and (3) demonstrates superior performance in few-shot learning
than supervised baseline and superior robustness across various augmentation
strategies.

</details>


### [772] [Language Embedding Meets Dynamic Graph: A New Exploration for Neural Architecture Representation Learning](https://arxiv.org/abs/2506.07735)
*Haizhao Jing,Haokui Zhang,Zhenhao Shang,Rong Xiao,Peng Wang,Yanning Zhang*

Main category: cs.LG

TL;DR: LeDG-Former是一个结合语言语义嵌入和动态图表示的框架，用于神经网络架构表示学习，能跨硬件平台进行零样本预测并在多个基准测试中取得SOTA。


<details>
  <summary>Details</summary>
Motivation: 现有方法忽略硬件属性信息，且依赖静态邻接矩阵无法捕捉计算节点间的结构差异，限制了实际应用。

Method: 1) 基于LLM的语言嵌入框架：将架构和硬件规范投影到统一语义空间；2) 动态图Transformer：改进神经网络架构建模。

Result: 1) NNLQP基准上超越现有方法，建立SOTA并实现跨硬件延迟预测；2) NAS-Bench-101/201上性能优越。

Conclusion: 统一语义空间和动态图建模解决了硬件兼容性与结构编码问题，首次实现跨硬件零样本预测，为实际部署提供支持。

Abstract: Neural Architecture Representation Learning aims to transform network models
into feature representations for predicting network attributes, playing a
crucial role in deploying and designing networks for real-world applications.
Recently, inspired by the success of transformers, transformer-based models
integrated with Graph Neural Networks (GNNs) have achieved significant progress
in representation learning. However, current methods still have some
limitations. First, existing methods overlook hardware attribute information,
which conflicts with the current trend of diversified deep learning hardware
and limits the practical applicability of models. Second, current encoding
approaches rely on static adjacency matrices to represent topological
structures, failing to capture the structural differences between computational
nodes, which ultimately compromises encoding effectiveness. In this paper, we
introduce LeDG-Former, an innovative framework that addresses these limitations
through the synergistic integration of language-based semantic embedding and
dynamic graph representation learning. Specifically, inspired by large language
models (LLMs), we propose a language embedding framework where both neural
architectures and hardware platform specifications are projected into a unified
semantic space through tokenization and LLM processing, enabling zero-shot
prediction across different hardware platforms for the first time. Then, we
propose a dynamic graph-based transformer for modeling neural architectures,
resulting in improved neural architecture modeling performance. On the NNLQP
benchmark, LeDG-Former surpasses previous methods, establishing a new SOTA
while demonstrating the first successful cross-hardware latency prediction
capability. Furthermore, our framework achieves superior performance on the
cell-structured NAS-Bench-101 and NAS-Bench-201 datasets.

</details>


### [773] [Identifiable Object Representations under Spatial Ambiguities](https://arxiv.org/abs/2506.07806)
*Avinash Kori,Francesca Toni,Ben Glocker*

Main category: cs.LG

TL;DR: 提出了一种新的多视图概率方法，通过聚合视图特定槽来捕捉不变内容信息，同时学习解耦的全局视角信息，解决空间模糊性问题，且无需视角标注。


<details>
  <summary>Details</summary>
Motivation: 模块化对象中心表示对人类推理至关重要，但在空间模糊性（如遮挡和视角模糊）下难以学习。现有方法存在理论和实践困难，需要解决空间模糊性问题。

Method: 采用多视图概率方法，聚合视图特定槽（view-specific slots）以捕捉不变内容信息，同时学习解耦的全局视角信息。该方法不依赖视角标注。

Result: 在标准基准测试和新颖复杂数据集上的实验验证了方法的鲁棒性和可扩展性。解决了空间模糊性，并提供了可识别性的理论保证。

Conclusion: 该方法通过学习解耦的内容和视角信息，有效解决了空间模糊性问题，在无需视角标注的情况下实现了模块化对象表示。

Abstract: Modular object-centric representations are essential for *human-like
reasoning* but are challenging to obtain under spatial ambiguities, *e.g. due
to occlusions and view ambiguities*. However, addressing challenges presents
both theoretical and practical difficulties. We introduce a novel multi-view
probabilistic approach that aggregates view-specific slots to capture
*invariant content* information while simultaneously learning disentangled
global *viewpoint-level* information. Unlike prior single-view methods, our
approach resolves spatial ambiguities, provides theoretical guarantees for
identifiability, and requires *no viewpoint annotations*. Extensive experiments
on standard benchmarks and novel complex datasets validate our method's
robustness and scalability.

</details>


### [774] [Diffusion Counterfactual Generation with Semantic Abduction](https://arxiv.org/abs/2506.07883)
*Rajat Rasal,Avinash Kori,Fabio De Sousa Ribeiro,Tian Xia,Ben Glocker*

Main category: cs.LG

TL;DR: 提出了一个基于扩散模型的因果机制框架，包括空间、语义和动态反事实推理，用于图像编辑，强调在保持身份和感知质量的同时实现高保真的因果控制。


<details>
  <summary>Details</summary>
Motivation: 现有自编码框架在反事实图像生成中存在可扩展性和保真度不足的问题，而扩散模型在视觉质量、感知对齐和表征学习方面的优势为解决这些问题提供了机会。

Method: 提出了包含空间、语义和动态反演三种因果机制的框架，将语义表示通过Pearl因果理论整合到扩散模型中，实现基于反事实推理的图像编辑。

Result: 该框架首次在扩散模型中实现了高级语义身份保持，展示了语义控制如何在忠实因果控制和身份保持之间取得平衡。

Conclusion: 这是第一个在扩散模型中解决反事实图像生成时身份保持问题的工作，证明了语义控制可以实现因果控制与身份保持的权衡。

Abstract: Counterfactual image generation presents significant challenges, including
preserving identity, maintaining perceptual quality, and ensuring faithfulness
to an underlying causal model. While existing auto-encoding frameworks admit
semantic latent spaces which can be manipulated for causal control, they
struggle with scalability and fidelity. Advancements in diffusion models
present opportunities for improving counterfactual image editing, having
demonstrated state-of-the-art visual quality, human-aligned perception and
representation learning capabilities. Here, we present a suite of
diffusion-based causal mechanisms, introducing the notions of spatial, semantic
and dynamic abduction. We propose a general framework that integrates semantic
representations into diffusion models through the lens of Pearlian causality to
edit images via a counterfactual reasoning process. To our knowledge, this is
the first work to consider high-level semantic identity preservation for
diffusion counterfactuals and to demonstrate how semantic control enables
principled trade-offs between faithful causal control and identity
preservation.

</details>


### [775] [Diffuse Everything: Multimodal Diffusion Models on Arbitrary State Spaces](https://arxiv.org/abs/2506.07903)
*Kevin Rojas,Yuchen Zhu,Sichen Zhu,Felix X. -F. Ye,Molei Tao*

Main category: cs.LG

TL;DR: 该论文提出了一种用于多模态数据联合生成的扩散模型框架，支持任意状态空间上的原生多模态生成，并通过解耦的噪声调度实现无条件及条件生成，在文本-图像和混合类型表格数据上验证了其竞争力。


<details>
  <summary>Details</summary>
Motivation: 现有扩散模型主要关注单模态数据生成，多模态联合生成通常依赖外部预处理工具（如分词器、VAE）统一数据表示，但这需要高精度编解码器且难以应对数据受限场景。为突破此限制，研究旨在开发原生支持多模态联合生成的扩散模型。

Method: 1) 提出在任意状态空间构建多模态扩散模型的框架，实现跨模态数据的原生生成 2) 设计针对各模态的解耦噪声调度机制，允许单个模型同时支持无条件生成和模态条件生成

Result: 在文本-图像生成和混合类型表格数据合成任务上实现竞争优势，验证了框架有效性

Conclusion: 该框架无需依赖外部预处理即可实现多模态联合生成，解耦噪声调度机制提供了灵活的生成控制能力，为多模态扩散模型开辟了新方向。

Abstract: Diffusion models have demonstrated remarkable performance in generating
unimodal data across various tasks, including image, video, and text
generation. On the contrary, the joint generation of multimodal data through
diffusion models is still in the early stages of exploration. Existing
approaches heavily rely on external preprocessing protocols, such as tokenizers
and variational autoencoders, to harmonize varied data representations into a
unified, unimodal format. This process heavily demands the high accuracy of
encoders and decoders, which can be problematic for applications with limited
data. To lift this restriction, we propose a novel framework for building
multimodal diffusion models on arbitrary state spaces, enabling native
generation of coupled data across different modalities. By introducing an
innovative decoupled noise schedule for each modality, we enable both
unconditional and modality-conditioned generation within a single model
simultaneously. We empirically validate our approach for text-image generation
and mixed-type tabular data synthesis, demonstrating that it achieves
competitive performance.

</details>


### [776] [Generative Modeling of Weights: Generalization or Memorization?](https://arxiv.org/abs/2506.07998)
*Boya Zeng,Yida Yin,Zhiqiu Xu,Zhuang Liu*

Main category: cs.LG

TL;DR: 近期有研究尝试使用生成模型合成神经网络权重，但本研究发现这些方法主要通过记忆训练检查点来生成权重，无法超越简单基线方法（如添加噪声或权重集成），且无法有效缓解记忆问题。


<details>
  <summary>Details</summary>
Motivation: 生成模型在图像和视频生成领域取得成功后，被探索用于合成神经网络权重。然而，现有方法在生成新颖权重（即不同于训练检查点的权重）方面的能力尚未被充分评估。

Method: 本研究评估了四种代表性方法，通过分析其生成权重的特性（与训练检查点的相似性），并与简单基线（权重加噪声、权重集成）对比性能。还尝试修改常见记忆缓解措施（如扩散模型中的去噪强度、数据增强）进行消融实验。

Result: 发现现有方法主要通过复制或简单插值训练检查点来合成权重，无法生成真正新颖的高性能权重。在获得不同且高性能模型方面，甚至不如添加噪声或权重集成等简单方法。修改建模因素或数据增强无法有效缓解记忆问题。

Conclusion: 当前生成模型对神经网络权重的建模能力有限（本质是记忆），在新领域应用时需更严谨评估。研究提供了可用代码，呼吁关注生成模型在新数据类型下的局限性。

Abstract: Generative models, with their success in image and video generation, have
recently been explored for synthesizing effective neural network weights. These
approaches take trained neural network checkpoints as training data, and aim to
generate high-performing neural network weights during inference. In this work,
we examine four representative methods on their ability to generate novel model
weights, i.e., weights that are different from the checkpoints seen during
training. Surprisingly, we find that these methods synthesize weights largely
by memorization: they produce either replicas, or at best simple
interpolations, of the training checkpoints. Current methods fail to outperform
simple baselines, such as adding noise to the weights or taking a simple weight
ensemble, in obtaining different and simultaneously high-performing models. We
further show that this memorization cannot be effectively mitigated by
modifying modeling factors commonly associated with memorization in image
diffusion models, or applying data augmentations. Our findings provide a
realistic assessment of what types of data current generative models can model,
and highlight the need for more careful evaluation of generative models in new
domains. Our code is available at
https://github.com/boyazeng/weight_memorization.

</details>


<div id='cs.AR'></div>

# cs.AR [[Back]](#toc)

### [777] [ProtocolLLM: RTL Benchmark for SystemVerilog Generation of Communication Protocols](https://arxiv.org/abs/2506.07945)
*Arnav Sheth,Ivaxi Sheth,Mario Fritz*

Main category: cs.AR

TL;DR: 该论文分析了当前大语言模型（LLMs）在生成可综合且功能正确的硬件描述语言（如SystemVerilog）方面的能力不足，并针对四种常用通信协议（SPI、I2C、UART、AXI）创建了首个基准测试套件。


<details>
  <summary>Details</summary>
Motivation: 现有LLM在通用编程语言代码生成方面表现优异，但其在硬件描述语言（HDLs）领域的应用尚未充分探索。HDLs需要严格遵循时序语义、并发性和可综合性约束，且设计流程包含测试台开发、断言验证等复杂任务。

Method: 建立针对SPI/I2C/UART/AXI四种协议的基准测试套件；设计不同抽象层次的代码生成任务；通过语法检查、可综合性评估及波形仿真/测试台检验功能正确性。

Result: 论文提出首个通信协议HDL生成评估框架，但摘要未展示具体实验结果（需基于全文完整评估LLM的生成能力）。

Conclusion: 该研究填补了LLM在硬件设计领域评估体系的空白，为未来提升HDL生成模型的能力建立了量化基准。

Abstract: Recent advances in Large Language Models (LLMs) have shown promising
capabilities in generating code for general-purpose programming languages. In
contrast, their applicability for hardware description languages, particularly
for generating synthesizable and functionally correct designs, remains
significantly underexplored. HDLs such as SystemVerilog are logic-oriented and
demand strict adherence to timing semantics, concurrency, and synthesizability
constraints. Moreover, HDL-based design flows encompass a broad set of tasks
beyond structural code generation, including testbench development,
assertion-based verification, timing closure, and protocol-level integration
for on-chip communication. The objective of our paper is to analyze the
capabilities of state-of-the-art LLMs in generating SystemVerilog
implementations of standard communication protocols, a core component of
embedded and System-on-Chip (SoC) architectures. This paper introduces the
first benchmark suite targeting four widely used protocols: SPI, I2C, UART, and
AXI. We define code generation tasks that capture varying levels of design
abstraction and prompt specificity. The generated designs are assessed for
syntactic correctness, synthesizability, and functional fidelity via waveform
simulation and test benches.

</details>


### [778] [QForce-RL: Quantized FPGA-Optimized Reinforcement Learning Compute Engine](https://arxiv.org/abs/2506.07046)
*Anushka Jha,Tanushree Dewangan,Mukul Lokhande,Santosh Kumar Vishvakarma*

Main category: cs.AR

TL;DR: QForce-RL is a lightweight reinforcement learning framework that uses quantization to improve throughput and energy efficiency on FPGAs, achieving 2.3x performance gains.


<details>
  <summary>Details</summary>
Motivation: Deploying RL on FPGAs is resource-intensive due to high computations for processing high-quality images, which presents challenges.

Method: Leverages E2HRL to reduce RL actions and QuaRL for quantization-based SIMD hardware acceleration, enabling parameterized deployment.

Result: Achieves up to 2.3x performance improvement and 2.6x better FPS compared to state-of-the-art solutions.

Conclusion: Provides scalable architecture for resource-constrained devices with flexibility in latency, power, and efficiency.

Abstract: Reinforcement Learning (RL) has outperformed other counterparts in sequential
decision-making and dynamic environment control. However, FPGA deployment is
significantly resource-expensive, as associated with large number of
computations in training agents with high-quality images and possess new
challenges. In this work, we propose QForce-RL takes benefits of quantization
to enhance throughput and reduce energy footprint with light-weight RL
architecture, without significant performance degradation. QForce-RL takes
advantages from E2HRL to reduce overall RL actions to learn desired policy and
QuaRL for quantization based SIMD for hardware acceleration. We have also
provided detailed analysis for different RL environments, with emphasis on
model size, parameters, and accelerated compute ops. The architecture is
scalable for resource-constrained devices and provide parametrized efficient
deployment with flexibility in latency, throughput, power, and energy
efficiency. The proposed QForce-RL provides performance enhancement up to 2.3x
and better FPS - 2.6x compared to SoTA works.

</details>


### [779] [ProtocolLLM: RTL Benchmark for SystemVerilog Generation of Communication Protocols](https://arxiv.org/abs/2506.07945)
*Arnav Sheth,Ivaxi Sheth,Mario Fritz*

Main category: cs.AR

TL;DR: 研究评估了大型语言模型（LLMs）在生成SystemVerilog硬件描述语言代码方面的能力，特别是针对SPI、I2C、UART和AXI四种常见通信协议。研究构建了首个相关基准测试套件，从语法正确性、可综合性和波形模拟功能正确性三个维度对模型输出进行验证。


<details>
  <summary>Details</summary>
Motivation: 现有LLM在通用编程语言代码生成方面进展显著，但在硬件描述语言（如SystemVerilog）领域仍未被充分探索。由于HDL需要满足严格的时序语义、并发性和可综合性约束，且设计流程还涉及测试平台开发、验证等复杂任务，因此需要专门研究LLM在生成可综合、功能正确的硬件设计方面的能力。

Method: 1) 构建首个针对SPI/I2C/UART/AXI四种通信协议的SystemVerilog基准测试套件；2) 设计涵盖不同抽象层次和提示明确度的代码生成任务；3) 通过语法检查、综合工具链、波形模拟和测试平台验证设计质量。

Result: 论文通过实验获得实际测评数据（具体结果未在摘要中说明），但明确建立了评估LLM生成SystemVerilog设计能力的系统性方法论，并为协议级设计质量提供了验证框架。

Conclusion: 该研究填补了LLM在硬件描述语言领域的空白，提出的基准测试能有效评估模型生成的HDL代码在可综合性和功能正确性方面的表现，为未来自动生成复杂数字电路设计提供了评价基础。

Abstract: Recent advances in Large Language Models (LLMs) have shown promising
capabilities in generating code for general-purpose programming languages. In
contrast, their applicability for hardware description languages, particularly
for generating synthesizable and functionally correct designs, remains
significantly underexplored. HDLs such as SystemVerilog are logic-oriented and
demand strict adherence to timing semantics, concurrency, and synthesizability
constraints. Moreover, HDL-based design flows encompass a broad set of tasks
beyond structural code generation, including testbench development,
assertion-based verification, timing closure, and protocol-level integration
for on-chip communication. The objective of our paper is to analyze the
capabilities of state-of-the-art LLMs in generating SystemVerilog
implementations of standard communication protocols, a core component of
embedded and System-on-Chip (SoC) architectures. This paper introduces the
first benchmark suite targeting four widely used protocols: SPI, I2C, UART, and
AXI. We define code generation tasks that capture varying levels of design
abstraction and prompt specificity. The generated designs are assessed for
syntactic correctness, synthesizability, and functional fidelity via waveform
simulation and test benches.

</details>


### [780] [QForce-RL: Quantized FPGA-Optimized Reinforcement Learning Compute Engine](https://arxiv.org/abs/2506.07046)
*Anushka Jha,Tanushree Dewangan,Mukul Lokhande,Santosh Kumar Vishvakarma*

Main category: cs.AR

TL;DR: QForce-RL是一个结合量化和轻量级强化学习架构的高效硬件部署方案，旨在提高吞吐量、降低能耗并减少性能损失，在资源受限设备上实现高达2.3倍的性能提升和2.6倍的帧率提升。


<details>
  <summary>Details</summary>
Motivation: FPGA部署强化学习算法时面临高计算资源消耗和硬件加速挑战，需要解决高分辨率图像处理导致的资源浪费问题。

Method: 整合E2HRL减少强化学习动作空间，利用QuaRL量化技术实现SIMD硬件加速，构建参数化可扩展架构以适应不同硬件约束。

Result: 在模型尺寸、参数量和计算操作优化方面表现优异，比现有技术性能提升2.3倍，帧率提升2.6倍。

Conclusion: QForce-RL为资源受限设备提供高灵活性部署方案，在延迟、吞吐量、功耗和能效间实现平衡。

Abstract: Reinforcement Learning (RL) has outperformed other counterparts in sequential
decision-making and dynamic environment control. However, FPGA deployment is
significantly resource-expensive, as associated with large number of
computations in training agents with high-quality images and possess new
challenges. In this work, we propose QForce-RL takes benefits of quantization
to enhance throughput and reduce energy footprint with light-weight RL
architecture, without significant performance degradation. QForce-RL takes
advantages from E2HRL to reduce overall RL actions to learn desired policy and
QuaRL for quantization based SIMD for hardware acceleration. We have also
provided detailed analysis for different RL environments, with emphasis on
model size, parameters, and accelerated compute ops. The architecture is
scalable for resource-constrained devices and provide parametrized efficient
deployment with flexibility in latency, throughput, power, and energy
efficiency. The proposed QForce-RL provides performance enhancement up to 2.3x
and better FPS - 2.6x compared to SoTA works.

</details>


<div id='eess.IV'></div>

# eess.IV [[Back]](#toc)

### [781] [ResPF: Residual Poisson Flow for Efficient and Physically Consistent Sparse-View CT Reconstruction](https://arxiv.org/abs/2506.06400)
*Changsheng Fang,Yongtong Liu,Bahareh Morovati,Shuo Han,Yu Shi,Li Zhou,Shuyi Fan,Hengyong Yu*

Main category: eess.IV

TL;DR: 提出了ResPF模型，一种基于PFGM++的生成模型，用于稀疏视角CT重建。通过跳跃初始步骤减少计算量，并结合数据一致性保证准确性，利用残差融合模块维持轨迹稳定性。实验显示其在质量、速度和鲁棒性上均优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有深度学习和基于扩散的方法在稀疏视角CT重建中存在物理解释性差或计算成本高的问题。Poisson流生成模型（PFGM）能高效合成高保真图像，但直接应用时早期跳跃会导致质量下降，数据一致性会破坏采样轨迹。

Method: 1) 在PFGM++框架中集成稀疏测量条件引导；2) 采用跳跃策略减少采样步数；3) 每步嵌入数据一致性约束；4) 创新残差融合模块（仿ResNet），线性组合生成输出与数据一致重建结果以稳定轨迹。

Result: 在合成和临床数据集上，ResPF相比最先进的迭代模型、学习模型和扩散模型：1) 重建质量更高；2) 推理速度更快；3) 鲁棒性更强。

Conclusion: ResPF是首个将Poisson流模型应用于稀疏视角CT的工作，通过跳跃采样和数据一致性残差融合，同时解决了计算效率与轨迹稳定性问题，为低剂量CT重建提供了新方案。

Abstract: Sparse-view computed tomography (CT) is a practical solution to reduce
radiation dose, but the resulting ill-posed inverse problem poses significant
challenges for accurate image reconstruction. Although deep learning and
diffusion-based methods have shown promising results, they often lack physical
interpretability or suffer from high computational costs due to iterative
sampling starting from random noise. Recent advances in generative modeling,
particularly Poisson Flow Generative Models (PFGM), enable high-fidelity image
synthesis by modeling the full data distribution. In this work, we propose
Residual Poisson Flow (ResPF) Generative Models for efficient and accurate
sparse-view CT reconstruction. Based on PFGM++, ResPF integrates conditional
guidance from sparse measurements and employs a hijacking strategy to
significantly reduce sampling cost by skipping redundant initial steps.
However, skipping early stages can degrade reconstruction quality and introduce
unrealistic structures. To address this, we embed a data-consistency into each
iteration, ensuring fidelity to sparse-view measurements. Yet, PFGM sampling
relies on a fixed ordinary differential equation (ODE) trajectory induced by
electrostatic fields, which can be disrupted by step-wise data consistency,
resulting in unstable or degraded reconstructions. Inspired by ResNet, we
introduce a residual fusion module to linearly combine generative outputs with
data-consistent reconstructions, effectively preserving trajectory continuity.
To the best of our knowledge, this is the first application of Poisson flow
models to sparse-view CT. Extensive experiments on synthetic and clinical
datasets demonstrate that ResPF achieves superior reconstruction quality,
faster inference, and stronger robustness compared to state-of-the-art
iterative, learning-based, and diffusion models.

</details>


### [782] [SPC to 3D: Novel View Synthesis from Binary SPC via I2I translation](https://arxiv.org/abs/2506.06890)
*Sumit Sharma,Gopi Raju Matta,Kaushik Mitra*

Main category: eess.IV

TL;DR: 这是一个两阶段框架的论文。第一阶段使用生成模型 (如 Pix2PixHD) 将二进制的单光子相机 (SPC) 图像转换为RGB图像；第二阶段使用如 NeRF 或 3DGS 的方法进行三维重建和新视角合成。


<details>
  <summary>Details</summary>
Motivation: 单光子相机 (SPC) 能高速捕捉图像但输出是二值化的，导致纹理和颜色信息严重丢失，使得传统的3D重建技术难以应用。

Method: 提出模块化的两阶段框架：第一阶段用 Pix2PixHD 进行图像到图像转换；第二阶段用 NeRF 或 3DGS 进行三维场景重建和新视角生成。

Result: 通过定性和定量实验验证，该框架在感知质量和几何一致性上显著优于基线方法。

Conclusion: 该两阶段框架有效解决了单光子相机二值图像的信息丢失问题，实现了高质量的新视角生成和3D重建。

Abstract: Single Photon Avalanche Diodes (SPADs) represent a cutting-edge imaging
technology, capable of detecting individual photons with remarkable timing
precision. Building on this sensitivity, Single Photon Cameras (SPCs) enable
image capture at exceptionally high speeds under both low and high
illumination. Enabling 3D reconstruction and radiance field recovery from such
SPC data holds significant promise. However, the binary nature of SPC images
leads to severe information loss, particularly in texture and color, making
traditional 3D synthesis techniques ineffective. To address this challenge, we
propose a modular two-stage framework that converts binary SPC images into
high-quality colorized novel views. The first stage performs image-to-image
(I2I) translation using generative models such as Pix2PixHD, converting binary
SPC inputs into plausible RGB representations. The second stage employs 3D
scene reconstruction techniques like Neural Radiance Fields (NeRF) or Gaussian
Splatting (3DGS) to generate novel views. We validate our two-stage pipeline
(Pix2PixHD + Nerf/3DGS) through extensive qualitative and quantitative
experiments, demonstrating significant improvements in perceptual quality and
geometric consistency over the alternative baseline.

</details>


### [783] [Optimal Transport Driven Asymmetric Image-to-Image Translation for Nuclei Segmentation of Histological Images](https://arxiv.org/abs/2506.07023)
*Suman Mahapatra,Pradipta Maji*

Main category: eess.IV

TL;DR: 本文提出了一种用于组织学图像中细胞核分割的新型深度生成模型，通过嵌入空间解决信息不对称问题，并利用可逆生成器降低网络复杂度，无需显式循环一致性损失。


<details>
  <summary>Details</summary>
Motivation: 组织学图像与分割图域之间存在信息不对称问题，现有的图像转换模型在这种情况下表现不佳，因此需要开发一种能够处理信息差异的分割算法。

Method: 使用嵌入空间处理信息差异，结合最优传输和测度理论构建可逆生成器，并引入空间约束压缩操作保持图像块的空间连续性。

Result: 模型在公开数据集上表现优于现有方法，在保持空间连续性的同时取得了更优的复杂度-性能平衡。

Conclusion: 所提深度生成模型为细胞核分割提供了高效解决方案，通过可逆生成器设计大幅降低了计算复杂度，同时维持了分割精度。

Abstract: Segmentation of nuclei regions from histological images enables morphometric
analysis of nuclei structures, which in turn helps in the detection and
diagnosis of diseases under consideration. To develop a nuclei segmentation
algorithm, applicable to different types of target domain representations,
image-to-image translation networks can be considered as they are invariant to
target domain image representations. One of the important issues with
image-to-image translation models is that they fail miserably when the
information content between two image domains are asymmetric in nature. In this
regard, the paper introduces a new deep generative model for segmenting nuclei
structures from histological images. The proposed model considers an embedding
space for handling information-disparity between information-rich histological
image space and information-poor segmentation map domain. Integrating
judiciously the concepts of optimal transport and measure theory, the model
develops an invertible generator, which provides an efficient optimization
framework with lower network complexity. The concept of invertible generator
automatically eliminates the need of any explicit cycle-consistency loss. The
proposed model also introduces a spatially-constrained squeeze operation within
the framework of invertible generator to maintain spatial continuity within the
image patches. The model provides a better trade-off between network complexity
and model performance compared to other existing models having complex network
architectures. The performance of the proposed deep generative model, along
with a comparison with state-of-the-art nuclei segmentation methods, is
demonstrated on publicly available histological image data sets.

</details>


### [784] [SiliCoN: Simultaneous Nuclei Segmentation and Color Normalization of Histological Images](https://arxiv.org/abs/2506.07028)
*Suman Mahapatra,Pradipta Maji*

Main category: eess.IV

TL;DR: 提出了一种深度生成模型，同时进行组织学图像的细胞核分割和颜色归一化，通过解耦表示和空间注意力提高性能。


<details>
  <summary>Details</summary>
Motivation: 组织学图像中的颜色变化影响细胞核分割，而准确的细胞核分割又能简化颜色归一化。因此，需要一种同时处理这两个任务的方法。

Method: 深度生成模型，整合截断正态分布先验和空间注意力机制。假设颜色信息与细胞核分割图及嵌入信息相互独立。

Result: 在公开数据集上验证，性能优于现有先进算法。

Conclusion: 解耦表示使模型具有通用性和适应性；混合截断正态分布处理染色重叠；空间注意力提升分割准确性。

Abstract: Segmentation of nuclei regions from histological images is an important task
for automated computer-aided analysis of histological images, particularly in
the presence of impermissible color variation in the color appearance of
stained tissue images. While color normalization enables better nuclei
segmentation, accurate segmentation of nuclei structures makes color
normalization rather trivial. In this respect, the paper proposes a novel deep
generative model for simultaneously segmenting nuclei structures and
normalizing color appearance of stained histological images.This model
judiciously integrates the merits of truncated normal distribution and spatial
attention. The model assumes that the latent color appearance information,
corresponding to a particular histological image, is independent of respective
nuclei segmentation map as well as embedding map information. The disentangled
representation makes the model generalizable and adaptable as the modification
or loss in color appearance information cannot be able to affect the nuclei
segmentation map as well as embedding information. Also, for dealing with the
stain overlap of associated histochemical reagents, the prior for latent color
appearance code is assumed to be a mixture of truncated normal distributions.
The proposed model incorporates the concept of spatial attention for
segmentation of nuclei regions from histological images. The performance of the
proposed approach, along with a comparative analysis with related
state-of-the-art algorithms, has been demonstrated on publicly available
standard histological image data sets.

</details>


### [785] [Transfer Learning and Explainable AI for Brain Tumor Classification: A Study Using MRI Data from Bangladesh](https://arxiv.org/abs/2506.07228)
*Shuvashis Sarker*

Main category: eess.IV

TL;DR: 本文开发了一种基于深度学习的自动脑肿瘤分类系统，利用VGG16等模型和解释性AI（XAI）技术，在孟加拉国MRI数据上实现99.17%的准确率，提升医疗资源有限地区的诊断效率和透明度。


<details>
  <summary>Details</summary>
Motivation: 脑肿瘤早期诊断对医疗资源有限的地区（如孟加拉国）至关重要，但传统手动MRI分析效率低且易出错，需要自动化解决方案。

Method: 使用VGG16、VGG19、ResNet50等深度学习模型分类脑肿瘤类型，结合Grad-CAM/Grad-CAM++等XAI技术增强模型可解释性。

Result: VGG16模型取得最佳性能（99.17%准确率），XAI成功定位关键MRI区域提高诊断透明度。

Conclusion: 深度学习与XAI结合可有效提升资源匮乏地区的脑肿瘤诊断效率及可靠性，具有临床实用潜力。

Abstract: Brain tumors, regardless of being benign or malignant, pose considerable
health risks, with malignant tumors being more perilous due to their swift and
uncontrolled proliferation, resulting in malignancy. Timely identification is
crucial for enhancing patient outcomes, particularly in nations such as
Bangladesh, where healthcare infrastructure is constrained. Manual MRI analysis
is arduous and susceptible to inaccuracies, rendering it inefficient for prompt
diagnosis. This research sought to tackle these problems by creating an
automated brain tumor classification system utilizing MRI data obtained from
many hospitals in Bangladesh. Advanced deep learning models, including VGG16,
VGG19, and ResNet50, were utilized to classify glioma, meningioma, and various
brain cancers. Explainable AI (XAI) methodologies, such as Grad-CAM and
Grad-CAM++, were employed to improve model interpretability by emphasizing the
critical areas in MRI scans that influenced the categorization. VGG16 achieved
the most accuracy, attaining 99.17%. The integration of XAI enhanced the
system's transparency and stability, rendering it more appropriate for clinical
application in resource-limited environments such as Bangladesh. This study
highlights the capability of deep learning models, in conjunction with
explainable artificial intelligence (XAI), to enhance brain tumor detection and
identification in areas with restricted access to advanced medical
technologies.

</details>


### [786] [A Comprehensive Analysis of COVID-19 Detection Using Bangladeshi Data and Explainable AI](https://arxiv.org/abs/2506.07234)
*Shuvashis Sarker*

Main category: eess.IV

TL;DR: 本研究通过应用机器学习、深度学习和迁移学习方法改进COVID-19在CXR图像的检测。利用4350张来自孟加拉国的图像进行四分类（正常、肺部浑浊、COVID-19和病毒性肺炎），其中VGG19模型达到了98%的准确率。使用LIME解释模型预测，并通过SMOTE解决类别不平衡问题，提升模型透明度和可靠性。


<details>
  <summary>Details</summary>
Motivation: COVID-19疫情对孟加拉国造成严重影响（截至2024年4月约2百万确诊病例和29495例死亡）。急需改进基于CXR图像的病毒检测方法以辅助快速诊断。

Method: 收集4350张CXR图像分为四类。采用ML、DL和TL模型（包括VGG19）进行训练。使用LIME进行预测可解释性分析，应用SMOTE解决数据不均衡问题。

Result: VGG19模型表现最佳（准确率98%）。LIME可视化展示影响分类的关键区域，SMOTE有效缓解数据不均衡问题。

Conclusion: 可解释人工智能（XAI）能显著提升COVID-19检测模型的透明度和可靠性，LIME和SMOTE的组合证明对医疗影像分析具有重要价值。

Abstract: COVID-19 is a rapidly spreading and highly infectious virus which has
triggered a global pandemic, profoundly affecting millions across the world.
The pandemic has introduced unprecedented challenges in public health, economic
stability, and societal structures, necessitating the implementation of
extensive and multifaceted health interventions globally. It had a tremendous
impact on Bangladesh by April 2024, with around 29,495 fatalities and more than
2 million confirmed cases. This study focuses on improving COVID-19 detection
in CXR images by utilizing a dataset of 4,350 images from Bangladesh
categorized into four classes: Normal, Lung-Opacity, COVID-19 and
Viral-Pneumonia. ML, DL and TL models are employed with the VGG19 model
achieving an impressive 98% accuracy. LIME is used to explain model
predictions, highlighting the regions and features influencing classification
decisions. SMOTE is applied to address class imbalances. By providing insight
into both correct and incorrect classifications, the study emphasizes the
importance of XAI in enhancing the transparency and reliability of models,
ultimately improving the effectiveness of detection from CXR images.

</details>


### [787] [A Narrative Review on Large AI Models in Lung Cancer Screening, Diagnosis, and Treatment Planning](https://arxiv.org/abs/2506.07236)
*Jiachen Zhong,Yiting Wang,Di Zhu,Ziwei Wang*

Main category: eess.IV

TL;DR: 该综述系统回顾了大型AI模型在肺癌筛查、诊断、预后及治疗中的应用现状，分类介绍了模态特定编码器、编码器-解码器框架和联合编码器架构等模型，评估了它们在多模态学习任务中的性能，并讨论了泛化性、可解释性和合规性等局限性与未来方向。


<details>
  <summary>Details</summary>
Motivation: 肺癌的高患病率与致死率需要更精准高效的诊断和治疗手段，而大型AI模型在医学图像理解和临床决策领域的进展为该需求提供了技术基础。

Method: 收集整理应用大型AI模型（如CLIP、BLIP、Flamingo等）于肺癌领域的最新研究，按模型架构分类分析其在公共数据集（如LIDC-IDRI）上的性能表现。

Result: 大型AI模型在肺结节检测、基因突变预测、多组学整合及个性化治疗等任务中表现出色，部分模型已进入临床验证阶段。

Conclusion: 尽管存在泛化性和可解释性等挑战，大型AI模型在优化肺癌诊疗方面展现变革潜力，未来需开发可扩展、可解释且符合临床规范的AI系统。

Abstract: Lung cancer remains one of the most prevalent and fatal diseases worldwide,
demanding accurate and timely diagnosis and treatment. Recent advancements in
large AI models have significantly enhanced medical image understanding and
clinical decision-making. This review systematically surveys the
state-of-the-art in applying large AI models to lung cancer screening,
diagnosis, prognosis, and treatment. We categorize existing models into
modality-specific encoders, encoder-decoder frameworks, and joint encoder
architectures, highlighting key examples such as CLIP, BLIP, Flamingo,
BioViL-T, and GLoRIA. We further examine their performance in multimodal
learning tasks using benchmark datasets like LIDC-IDRI, NLST, and MIMIC-CXR.
Applications span pulmonary nodule detection, gene mutation prediction,
multi-omics integration, and personalized treatment planning, with emerging
evidence of clinical deployment and validation. Finally, we discuss current
limitations in generalizability, interpretability, and regulatory compliance,
proposing future directions for building scalable, explainable, and clinically
integrated AI systems. Our review underscores the transformative potential of
large AI models to personalize and optimize lung cancer care.

</details>


### [788] [Text-guided multi-stage cross-perception network for medical image segmentation](https://arxiv.org/abs/2506.07475)
*Gaoyu Chen*

Main category: eess.IV

TL;DR: 论文提出了一种名为TMC的文本引导多阶段交叉感知网络，以解决现有医学图像分割方法在跨模态交互和特征表达上的不足。该方法通过多阶段交叉注意力模块和多阶段对齐损失，提升了模型对语义细节的理解和跨模态语义一致性。实验表明，TMC在三个公共数据集上的性能优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有医学图像分割方法因目标与非目标区域对比度低而受到弱语义表达的限制。尽管文本提示有潜力捕捉病变位置，但现有文本引导方法存在跨模态交互不足和特征表达不充分的问题。

Method: 提出TMC网络，包含多阶段交叉注意力模块（增强语义细节理解）和多阶段对齐损失（提升跨模态语义一致性）。

Result: 在QaTa-COV19、MosMedData和Breast数据集上，TMC的Dice分数分别达到84.77%、78.50%和88.73%，优于UNet基线和文本引导方法。

Conclusion: TMC通过有效结合文本引导与多阶段交互机制，显著提升了医学图像分割性能，证明了跨模态交互对解决语义表达弱问题的重要性。

Abstract: Medical image segmentation plays a crucial role in clinical medicine, serving
as a tool for auxiliary diagnosis, treatment planning, and disease monitoring,
thus facilitating physicians in the study and treatment of diseases. However,
existing medical image segmentation methods are limited by the weak semantic
expression of the target segmentation regions, which is caused by the low
contrast between the target and non-target segmentation regions. To address
this limitation, text prompt information has greast potential to capture the
lesion location. However, existing text-guided methods suffer from insufficient
cross-modal interaction and inadequate cross-modal feature expression. To
resolve these issues, we propose the Text-guided Multi-stage Cross-perception
network (TMC). In TMC, we introduce a multistage cross-attention module to
enhance the model's understanding of semantic details and a multi-stage
alignment loss to improve the consistency of cross-modal semantics. The results
of the experiments demonstrate that our TMC achieves a superior performance
with Dice of 84.77%, 78.50%, 88.73% in three public datasets (QaTa-COV19,
MosMedData and Breast), outperforming UNet based networks and text-guided
methods.

</details>


### [789] [Fine-Grained Motion Compression and Selective Temporal Fusion for Neural B-Frame Video Coding](https://arxiv.org/abs/2506.07709)
*Xihua Sheng,Peilin Chen,Meng Wang,Li Zhang,Shiqi Wang,Dapeng Oliver Wu*

Main category: eess.IV

TL;DR: 本文提出了一种改进的神经B帧视频编码方法，通过精细化的运动压缩和选择性时间融合技术，显著提升了B帧的压缩性能


<details>
  <summary>Details</summary>
Motivation: 现有的神经B帧编码器直接采用P帧工具，未能充分解决B帧压缩特有的挑战（如双向运动向量的不对称比特分配需求），导致性能欠佳

Method: 1. 细粒度运动压缩：设计交互式双分支运动自编码器，结合分支自适应量化步长压缩双向运动向量；开发交互式运动熵模型，利用分区潜在段作为方向先验捕获相关性
2. 选择性时间融合：预测双向融合权重实现差异化利用多尺度时间上下文；引入基于超先验的隐式对齐机制，将超先验作为上下文潜在表示的代理以缓解双向时间先验未对齐问题

Result: 实验表明：优于现有神经B帧编解码器；在随机访问配置下与H.266/VVC参考软件性能相当或更优

Conclusion: 通过专门解决B帧压缩的独特挑战（运动压缩和时间融合），所提方法实现了突破性性能，为神经视频编码开辟了新方向

Abstract: With the remarkable progress in neural P-frame video coding, neural B-frame
coding has recently emerged as a critical research direction. However, most
existing neural B-frame codecs directly adopt P-frame coding tools without
adequately addressing the unique challenges of B-frame compression, leading to
suboptimal performance. To bridge this gap, we propose novel enhancements for
motion compression and temporal fusion for neural B-frame coding. First, we
design a fine-grained motion compression method. This method incorporates an
interactive dual-branch motion auto-encoder with per-branch adaptive
quantization steps, which enables fine-grained compression of bi-directional
motion vectors while accommodating their asymmetric bitrate allocation and
reconstruction quality requirements. Furthermore, this method involves an
interactive motion entropy model that exploits correlations between
bi-directional motion latent representations by interactively leveraging
partitioned latent segments as directional priors. Second, we propose a
selective temporal fusion method that predicts bi-directional fusion weights to
achieve discriminative utilization of bi-directional multi-scale temporal
contexts with varying qualities. Additionally, this method introduces a
hyperprior-based implicit alignment mechanism for contextual entropy modeling.
By treating the hyperprior as a surrogate for the contextual latent
representation, this mechanism implicitly mitigates the misalignment in the
fused bi-directional temporal priors. Extensive experiments demonstrate that
our proposed codec outperforms state-of-the-art neural B-frame codecs and
achieves comparable or even superior compression performance to the H.266/VVC
reference software under random-access configurations.

</details>


### [790] [ResPF: Residual Poisson Flow for Efficient and Physically Consistent Sparse-View CT Reconstruction](https://arxiv.org/abs/2506.06400)
*Changsheng Fang,Yongtong Liu,Bahareh Morovati,Shuo Han,Yu Shi,Li Zhou,Shuyi Fan,Hengyong Yu*

Main category: eess.IV

TL;DR: 提出ResPF生成模型，通过改进PFGM++结合数据一致性策略，实现高效准确的稀疏视图CT重建。


<details>
  <summary>Details</summary>
Motivation: 基于生成模型的稀疏视图CT重建方法通常缺乏物理解释性或计算成本高。PFGM++虽然能合成高质量图像，但采样过程冗余且数据一致性约束会破坏生成轨迹连续性。

Method: 1) 在PFGM++框架中引入劫持策略跳过冗余计算步骤 2) 逐步嵌入数据一致性约束 3) 设计残差融合模块避免ODE轨迹破坏

Result: 在合成和临床数据集上验证：ResPF相比现有迭代/学习/扩散模型，具有更优的重建质量、更快推理速度和更强鲁棒性。

Conclusion: 首次将泊松流框架应用于稀疏视图CT，残差融合机制成功平衡了效率与质量，为生成式医学成像开辟了新方向。

Abstract: Sparse-view computed tomography (CT) is a practical solution to reduce
radiation dose, but the resulting ill-posed inverse problem poses significant
challenges for accurate image reconstruction. Although deep learning and
diffusion-based methods have shown promising results, they often lack physical
interpretability or suffer from high computational costs due to iterative
sampling starting from random noise. Recent advances in generative modeling,
particularly Poisson Flow Generative Models (PFGM), enable high-fidelity image
synthesis by modeling the full data distribution. In this work, we propose
Residual Poisson Flow (ResPF) Generative Models for efficient and accurate
sparse-view CT reconstruction. Based on PFGM++, ResPF integrates conditional
guidance from sparse measurements and employs a hijacking strategy to
significantly reduce sampling cost by skipping redundant initial steps.
However, skipping early stages can degrade reconstruction quality and introduce
unrealistic structures. To address this, we embed a data-consistency into each
iteration, ensuring fidelity to sparse-view measurements. Yet, PFGM sampling
relies on a fixed ordinary differential equation (ODE) trajectory induced by
electrostatic fields, which can be disrupted by step-wise data consistency,
resulting in unstable or degraded reconstructions. Inspired by ResNet, we
introduce a residual fusion module to linearly combine generative outputs with
data-consistent reconstructions, effectively preserving trajectory continuity.
To the best of our knowledge, this is the first application of Poisson flow
models to sparse-view CT. Extensive experiments on synthetic and clinical
datasets demonstrate that ResPF achieves superior reconstruction quality,
faster inference, and stronger robustness compared to state-of-the-art
iterative, learning-based, and diffusion models.

</details>


### [791] [SPC to 3D: Novel View Synthesis from Binary SPC via I2I translation](https://arxiv.org/abs/2506.06890)
*Sumit Sharma,Gopi Raju Matta,Kaushik Mitra*

Main category: eess.IV

TL;DR: 本文提出了一个两阶段框架，将单光子相机的二值图像转换为高质量彩色新视图。第一阶段用生成模型将SPAD图像转为近似RGB；第二阶段用3D重建技术生成新视图。实验证明该方法大幅提升感知质量和几何一致性。


<details>
  <summary>Details</summary>
Motivation: 单光子相机(SPC)因二值图像特性导致严重信息损失（纹理/色彩缺失），使传统3D重建失效，需要解决该局限以实现高质量3D重建。

Method: 1. 图像翻译阶段：用Pix2PixHD等生成模型将二值SPC图像转为RGB格式
2. 3D重建阶段：用NeRF或3DGS重建场景并生成新视图

Result: 定性与定量实验表明，该方案（Pix2PixHD+NeRF/3DGS）在感知质量与几何一致性上显著优于基线。

Conclusion: 所提两阶段框架有效克服了SPC数据的信息缺失问题，为基于单光子相机的3D重建提供了可靠途径。

Abstract: Single Photon Avalanche Diodes (SPADs) represent a cutting-edge imaging
technology, capable of detecting individual photons with remarkable timing
precision. Building on this sensitivity, Single Photon Cameras (SPCs) enable
image capture at exceptionally high speeds under both low and high
illumination. Enabling 3D reconstruction and radiance field recovery from such
SPC data holds significant promise. However, the binary nature of SPC images
leads to severe information loss, particularly in texture and color, making
traditional 3D synthesis techniques ineffective. To address this challenge, we
propose a modular two-stage framework that converts binary SPC images into
high-quality colorized novel views. The first stage performs image-to-image
(I2I) translation using generative models such as Pix2PixHD, converting binary
SPC inputs into plausible RGB representations. The second stage employs 3D
scene reconstruction techniques like Neural Radiance Fields (NeRF) or Gaussian
Splatting (3DGS) to generate novel views. We validate our two-stage pipeline
(Pix2PixHD + Nerf/3DGS) through extensive qualitative and quantitative
experiments, demonstrating significant improvements in perceptual quality and
geometric consistency over the alternative baseline.

</details>


### [792] [Optimal Transport Driven Asymmetric Image-to-Image Translation for Nuclei Segmentation of Histological Images](https://arxiv.org/abs/2506.07023)
*Suman Mahapatra,Pradipta Maji*

Main category: eess.IV

TL;DR: 提出了一种基于可逆生成器的图像翻译网络，用于解决组织学图像到分割映射域的信息不对称问题，实现了高效核分割模型。


<details>
  <summary>Details</summary>
Motivation: 传统图像翻译网络在源域和目标域信息不对称时表现不佳，特别是组织学图像（信息丰富）到分割图（信息贫乏）的转换。

Method: 1. 使用嵌入空间处理信息不对称；2. 结合最优传输和测度理论构建可逆生成器，避免循环一致性损失；3. 在可逆生成器中加入空间约束压缩操作维持空间连续性。

Result: 模型在公开数据集上实现了较高的分割精度，同时在网络复杂度和性能之间取得了比现有模型更好的平衡。

Conclusion: 所提出的可逆生成器框架有效解决了跨域信息不对称问题，简化了网络结构，为组织学图像核分割提供了更高效的解决方案。

Abstract: Segmentation of nuclei regions from histological images enables morphometric
analysis of nuclei structures, which in turn helps in the detection and
diagnosis of diseases under consideration. To develop a nuclei segmentation
algorithm, applicable to different types of target domain representations,
image-to-image translation networks can be considered as they are invariant to
target domain image representations. One of the important issues with
image-to-image translation models is that they fail miserably when the
information content between two image domains are asymmetric in nature. In this
regard, the paper introduces a new deep generative model for segmenting nuclei
structures from histological images. The proposed model considers an embedding
space for handling information-disparity between information-rich histological
image space and information-poor segmentation map domain. Integrating
judiciously the concepts of optimal transport and measure theory, the model
develops an invertible generator, which provides an efficient optimization
framework with lower network complexity. The concept of invertible generator
automatically eliminates the need of any explicit cycle-consistency loss. The
proposed model also introduces a spatially-constrained squeeze operation within
the framework of invertible generator to maintain spatial continuity within the
image patches. The model provides a better trade-off between network complexity
and model performance compared to other existing models having complex network
architectures. The performance of the proposed deep generative model, along
with a comparison with state-of-the-art nuclei segmentation methods, is
demonstrated on publicly available histological image data sets.

</details>


### [793] [SiliCoN: Simultaneous Nuclei Segmentation and Color Normalization of Histological Images](https://arxiv.org/abs/2506.07028)
*Suman Mahapatra,Pradipta Maji*

Main category: eess.IV

TL;DR: 摘要提出了一种新的深度生成模型，用于同时实现组织学图像的细胞核分割和颜色归一化。该模型利用截断正态分布和空间注意力的优势，假设潜在颜色信息与细胞核分割图相互独立。这种解耦表示增强了模型的泛化能力，同时采用截断正态混合分布处理染色重叠问题。通过在标准数据集上的测试，表明了其优越性能。


<details>
  <summary>Details</summary>
Motivation: 组织学图像中不可接受的色差会影响细胞核分割效果。现有方法往往将颜色归一化与分割作为独立步骤处理，而本文发现两者存在相互依赖性：颜色归一化促进分割，精确的分割结果反过来简化颜色归一化。因此需要开发同时优化两项任务的统一框架。

Method: 1. 提出深度生成模型实现联合优化: 同步处理细胞核分割和染色外观归一化
2. 建立解耦表示: 假设潜在染色信息与细胞核分割图/嵌入图相互独立，确保颜色变化不影响分割结果
3. 截断正态混合分布: 为潜在颜色编码设计混合分布先验，有效处理染色试剂的重叠问题
4. 空间注意力机制: 增强细胞核区域分割精度，聚焦关键形态特征

Result: 在公开标准组织学图像数据集上：
- 实现细胞核高精度分割
- 有效消除染色变异影响
- 性能超越现有最先进算法

Conclusion: 该模型通过联合优化策略和解耦表示解决了细胞核分割与颜色归一化的相互依赖问题。截断正态混合分布和空间注意力的创新整合，显著提升了复杂染色条件下的分割鲁棒性，为组织学图像分析提供了新范式。

Abstract: Segmentation of nuclei regions from histological images is an important task
for automated computer-aided analysis of histological images, particularly in
the presence of impermissible color variation in the color appearance of
stained tissue images. While color normalization enables better nuclei
segmentation, accurate segmentation of nuclei structures makes color
normalization rather trivial. In this respect, the paper proposes a novel deep
generative model for simultaneously segmenting nuclei structures and
normalizing color appearance of stained histological images.This model
judiciously integrates the merits of truncated normal distribution and spatial
attention. The model assumes that the latent color appearance information,
corresponding to a particular histological image, is independent of respective
nuclei segmentation map as well as embedding map information. The disentangled
representation makes the model generalizable and adaptable as the modification
or loss in color appearance information cannot be able to affect the nuclei
segmentation map as well as embedding information. Also, for dealing with the
stain overlap of associated histochemical reagents, the prior for latent color
appearance code is assumed to be a mixture of truncated normal distributions.
The proposed model incorporates the concept of spatial attention for
segmentation of nuclei regions from histological images. The performance of the
proposed approach, along with a comparative analysis with related
state-of-the-art algorithms, has been demonstrated on publicly available
standard histological image data sets.

</details>


### [794] [Transfer Learning and Explainable AI for Brain Tumor Classification: A Study Using MRI Data from Bangladesh](https://arxiv.org/abs/2506.07228)
*Shuvashis Sarker*

Main category: eess.IV

TL;DR: 该研究开发了一个基于深度学习的自动脑肿瘤分类系统，使用MRI数据进行肿瘤类型分类，并结合可解释AI提高模型透明度和临床适用性。


<details>
  <summary>Details</summary>
Motivation: 在医疗资源有限的国家(如孟加拉国)，MRI手动分析耗时且易出错，需要自动化系统来提高脑肿瘤诊断的准确性和效率。

Method: 使用VGG16、VGG19和ResNet50深度学习模型对MRI图像分类；应用Grad-CAM和Grad-CAM++等XAI技术增强模型可解释性。

Result: VGG16模型达到99.17%的最高准确率；XAI方法成功突出了MRI影像中的关键区域，增强了系统透明度和稳定性。

Conclusion: 深度学习和XAI的结合能够有效提升在资源受限地区的脑肿瘤检测能力，具有临床应用潜力。

Abstract: Brain tumors, regardless of being benign or malignant, pose considerable
health risks, with malignant tumors being more perilous due to their swift and
uncontrolled proliferation, resulting in malignancy. Timely identification is
crucial for enhancing patient outcomes, particularly in nations such as
Bangladesh, where healthcare infrastructure is constrained. Manual MRI analysis
is arduous and susceptible to inaccuracies, rendering it inefficient for prompt
diagnosis. This research sought to tackle these problems by creating an
automated brain tumor classification system utilizing MRI data obtained from
many hospitals in Bangladesh. Advanced deep learning models, including VGG16,
VGG19, and ResNet50, were utilized to classify glioma, meningioma, and various
brain cancers. Explainable AI (XAI) methodologies, such as Grad-CAM and
Grad-CAM++, were employed to improve model interpretability by emphasizing the
critical areas in MRI scans that influenced the categorization. VGG16 achieved
the most accuracy, attaining 99.17%. The integration of XAI enhanced the
system's transparency and stability, rendering it more appropriate for clinical
application in resource-limited environments such as Bangladesh. This study
highlights the capability of deep learning models, in conjunction with
explainable artificial intelligence (XAI), to enhance brain tumor detection and
identification in areas with restricted access to advanced medical
technologies.

</details>


### [795] [A Comprehensive Analysis of COVID-19 Detection Using Bangladeshi Data and Explainable AI](https://arxiv.org/abs/2506.07234)
*Shuvashis Sarker*

Main category: eess.IV

TL;DR: 该研究使用深度学习方法（特别是VGG19模型）在孟加拉国COVID-19胸部X光数据集上实现了98%的准确率，并利用LIME和SMOTE技术提高模型可解释性和处理类别不平衡问题。


<details>
  <summary>Details</summary>
Motivation: COVID-19全球大流行造成严重健康危机，亟需提高胸部X光图像的检测精度以辅助诊断。孟加拉国截至2024年4月已出现200万确诊病例，凸显本地化研究的紧迫性。

Method: 收集4350张X光图像分为四类（正常/肺混浊/COVID-19/病毒性肺炎），应用机器学习、深度学习和迁移学习模型，其中VGG19为主力模型。使用SMOTE解决数据不平衡问题，采用LIME提供模型预测的可视化解释。

Result: VGG19模型取得98%的测试准确率。LIME可视化显示模型聚焦于肺部关键病变区域，证明决策可靠性。SMOTE有效改善了少数类别的识别效果。

Conclusion: 可解释人工智能（XAI）显著提升COVID-19影像检测模型的透明度与可信度，该方法可推广至其他医疗影像诊断场景，为临床决策提供可靠支持。

Abstract: COVID-19 is a rapidly spreading and highly infectious virus which has
triggered a global pandemic, profoundly affecting millions across the world.
The pandemic has introduced unprecedented challenges in public health, economic
stability, and societal structures, necessitating the implementation of
extensive and multifaceted health interventions globally. It had a tremendous
impact on Bangladesh by April 2024, with around 29,495 fatalities and more than
2 million confirmed cases. This study focuses on improving COVID-19 detection
in CXR images by utilizing a dataset of 4,350 images from Bangladesh
categorized into four classes: Normal, Lung-Opacity, COVID-19 and
Viral-Pneumonia. ML, DL and TL models are employed with the VGG19 model
achieving an impressive 98% accuracy. LIME is used to explain model
predictions, highlighting the regions and features influencing classification
decisions. SMOTE is applied to address class imbalances. By providing insight
into both correct and incorrect classifications, the study emphasizes the
importance of XAI in enhancing the transparency and reliability of models,
ultimately improving the effectiveness of detection from CXR images.

</details>


### [796] [A Narrative Review on Large AI Models in Lung Cancer Screening, Diagnosis, and Treatment Planning](https://arxiv.org/abs/2506.07236)
*Jiachen Zhong,Yiting Wang,Di Zhu,Ziwei Wang*

Main category: eess.IV

TL;DR: 大型AI模型在肺癌诊疗各阶段的应用综述


<details>
  <summary>Details</summary>
Motivation: 肺癌的高致死率需要更精准高效的诊疗手段，大型AI模型在医学影像理解方面的突破为此提供可能

Method: 系统性分类：模态特定编码器（如BioViL-T）、编码器-解码器框架（如Flamingo）、联合编码架构（如GLoRIA）；使用LIDC-IDRI等基准数据集评估多模态任务性能

Result: 模型已应用于肺结节检测、基因突变预测、多组学整合等领域，部分进入临床验证阶段

Conclusion: 大型AI模型将变革肺癌个性化诊疗，但仍需解决泛化性、可解释性及合规性挑战

Abstract: Lung cancer remains one of the most prevalent and fatal diseases worldwide,
demanding accurate and timely diagnosis and treatment. Recent advancements in
large AI models have significantly enhanced medical image understanding and
clinical decision-making. This review systematically surveys the
state-of-the-art in applying large AI models to lung cancer screening,
diagnosis, prognosis, and treatment. We categorize existing models into
modality-specific encoders, encoder-decoder frameworks, and joint encoder
architectures, highlighting key examples such as CLIP, BLIP, Flamingo,
BioViL-T, and GLoRIA. We further examine their performance in multimodal
learning tasks using benchmark datasets like LIDC-IDRI, NLST, and MIMIC-CXR.
Applications span pulmonary nodule detection, gene mutation prediction,
multi-omics integration, and personalized treatment planning, with emerging
evidence of clinical deployment and validation. Finally, we discuss current
limitations in generalizability, interpretability, and regulatory compliance,
proposing future directions for building scalable, explainable, and clinically
integrated AI systems. Our review underscores the transformative potential of
large AI models to personalize and optimize lung cancer care.

</details>


### [797] [Text-guided multi-stage cross-perception network for medical image segmentation](https://arxiv.org/abs/2506.07475)
*Gaoyu Chen*

Main category: eess.IV

TL;DR: 论文提出了TMC网络解决医学图像分割中弱语义表达问题


<details>
  <summary>Details</summary>
Motivation: 现有医学图像分割方法因目标与非目标区域对比度低导致弱语义表达，文本引导方法存在跨模态交互不足和特征表达不充分问题

Method: 提出TMC网络：1) 引入多阶段交叉注意力模块增强语义细节理解 2) 设计多阶段对齐损失提升跨模态语义一致性

Result: 在三个公共数据集(QaTa-COV19/MosMedData/Breast)上Dice分数达到84.77%/78.50%/88.73%，超越UNet基准和文本引导方法

Conclusion: TMC网络通过多阶段跨模态交互机制显著提升医学图像分割精度

Abstract: Medical image segmentation plays a crucial role in clinical medicine, serving
as a tool for auxiliary diagnosis, treatment planning, and disease monitoring,
thus facilitating physicians in the study and treatment of diseases. However,
existing medical image segmentation methods are limited by the weak semantic
expression of the target segmentation regions, which is caused by the low
contrast between the target and non-target segmentation regions. To address
this limitation, text prompt information has greast potential to capture the
lesion location. However, existing text-guided methods suffer from insufficient
cross-modal interaction and inadequate cross-modal feature expression. To
resolve these issues, we propose the Text-guided Multi-stage Cross-perception
network (TMC). In TMC, we introduce a multistage cross-attention module to
enhance the model's understanding of semantic details and a multi-stage
alignment loss to improve the consistency of cross-modal semantics. The results
of the experiments demonstrate that our TMC achieves a superior performance
with Dice of 84.77%, 78.50%, 88.73% in three public datasets (QaTa-COV19,
MosMedData and Breast), outperforming UNet based networks and text-guided
methods.

</details>


### [798] [Fine-Grained Motion Compression and Selective Temporal Fusion for Neural B-Frame Video Coding](https://arxiv.org/abs/2506.07709)
*Xihua Sheng,Peilin Chen,Meng Wang,Li Zhang,Shiqi Wang,Dapeng Oliver Wu*

Main category: eess.IV

TL;DR: 提出了针对神经B帧视频编码的增强方法，包括细粒度运动压缩和选择性时间融合，以提升压缩性能。


<details>
  <summary>Details</summary>
Motivation: 大多数现有神经B帧编码器直接使用P帧编码工具，未能解决B帧压缩特有的挑战（如运动矢量的不对称码率分配和重建质量要求），导致性能不佳。

Method: 1. 细粒度运动压缩：使用交互式双分支运动自编码器，每个分支有自适应量化步长；引入交互式运动熵模型，利用双向运动潜在表示的关联性。2. 选择性时间融合：预测双向融合权重，实现不同质量双向上下文的区分性利用；提出基于超先验的隐式对齐机制处理时域先验失准问题。

Result: 所提编解码器优于现有神经B帧编码器，在随机接入配置下与H.266/VVC参考软件相当或更优。

Conclusion: 通过专门针对B帧特性的运动压缩和时间融合机制，显著提升了神经B帧编码的性能。

Abstract: With the remarkable progress in neural P-frame video coding, neural B-frame
coding has recently emerged as a critical research direction. However, most
existing neural B-frame codecs directly adopt P-frame coding tools without
adequately addressing the unique challenges of B-frame compression, leading to
suboptimal performance. To bridge this gap, we propose novel enhancements for
motion compression and temporal fusion for neural B-frame coding. First, we
design a fine-grained motion compression method. This method incorporates an
interactive dual-branch motion auto-encoder with per-branch adaptive
quantization steps, which enables fine-grained compression of bi-directional
motion vectors while accommodating their asymmetric bitrate allocation and
reconstruction quality requirements. Furthermore, this method involves an
interactive motion entropy model that exploits correlations between
bi-directional motion latent representations by interactively leveraging
partitioned latent segments as directional priors. Second, we propose a
selective temporal fusion method that predicts bi-directional fusion weights to
achieve discriminative utilization of bi-directional multi-scale temporal
contexts with varying qualities. Additionally, this method introduces a
hyperprior-based implicit alignment mechanism for contextual entropy modeling.
By treating the hyperprior as a surrogate for the contextual latent
representation, this mechanism implicitly mitigates the misalignment in the
fused bi-directional temporal priors. Extensive experiments demonstrate that
our proposed codec outperforms state-of-the-art neural B-frame codecs and
achieves comparable or even superior compression performance to the H.266/VVC
reference software under random-access configurations.

</details>


<div id='cs.CY'></div>

# cs.CY [[Back]](#toc)

### [799] [How Malicious AI Swarms Can Threaten Democracy](https://arxiv.org/abs/2506.06299)
*Daniel Thilo Schroeder,Meeyoung Cha,Andrea Baronchelli,Nick Bostrom,Nicholas A. Christakis,David Garcia,Amit Goldenberg,Yara Kyrychenko,Kevin Leyton-Brown,Nina Lutz,Gary Marcus,Filippo Menczer,Gordon Pennycook,David G. Rand,Frank Schweitzer,Christopher Summerfield,Audrey Tang,Jay Van Bavel,Sander van der Linden,Dawn Song,Jonas R. Kunst*

Main category: cs.CY

TL;DR: 恶意AI集群的威胁可能导致复杂的虚假宣传活动，如操纵公众意见、污染AI训练数据等；呼吁通过平台防御、模型防护和系统监管三方面应对。


<details>
  <summary>Details</summary>
Motivation: 随着AI技术进步，恶意AI集群可能利用隐形协调、社区渗透、24小时运行等特点进行大规模虚假宣传，破坏民主进程。

Method: 提出三管齐下的解决方案：(1) 平台端部署持续性集群检测工具、高精度压力测试、透明审计及用户端'AI防护罩'；(2) 模型端设置说服风险评估、来源认证密钥和水印技术；(3) 系统级建立联合国支持的人工智能影响观察站。

Result: 恶意AI集群能够操纵共识、分裂现实认知、发动骚扰活动、精准抑制或动员选民、污染数据并破坏机构公信力。

Conclusion: 需通过技术性平台防护、模型安全测试、国际监督体系协同防御，否则全球民主体系将面临巨大风险。

Abstract: Advances in AI portend a new era of sophisticated disinformation operations.
While individual AI systems already create convincing -- and at times
misleading -- information, an imminent development is the emergence of
malicious AI swarms. These systems can coordinate covertly, infiltrate
communities, evade traditional detectors, and run continuous A/B tests, with
round-the-clock persistence. The result can include fabricated grassroots
consensus, fragmented shared reality, mass harassment, voter micro-suppression
or mobilization, contamination of AI training data, and erosion of
institutional trust. With democratic processes worldwide increasingly
vulnerable, we urge a three-pronged response: (1) platform-side defenses --
always-on swarm-detection dashboards, pre-election high-fidelity
swarm-simulation stress-tests, transparency audits, and optional client-side
"AI shields" for users; (2) model-side safeguards -- standardized
persuasion-risk tests, provenance-authenticating passkeys, and watermarking;
and (3) system-level oversight -- a UN-backed AI Influence Observatory.

</details>


### [800] [LLMs as World Models: Data-Driven and Human-Centered Pre-Event Simulation for Disaster Impact Assessment](https://arxiv.org/abs/2506.06355)
*Lingyao Li,Dawei Li,Zhenhui Ou,Xiaoran Xu,Jingxiao Liu,Zihui Ma,Runlong Yu,Min Deng*

Main category: cs.CY

TL;DR: 论文提出一个使用多模态数据和多LLMs估计地震影响的框架，以提升灾害前瞻性防备。该方法结合地理空间、社会经济、建筑和街景图像数据，生成邮政编码和县级的地震影响预测。评估显示与真实报告有高相关性(0.88)和低RMSE(0.77)。


<details>
  <summary>Details</summary>
Motivation: 地震等突发灾害的有效模拟对提升前瞻性防备至关重要。大型语言模型作为世界模型在复杂场景模拟中展现出潜力，但尚未充分用于地震影响预测。

Method: 使用多模态数据集（地理空间、社会经济、建筑和街景图像）输入多LLMs，通过RAG和上下文学习提升表现，生成修正麦加利烈度预测。预测结果在邮政编码和县级尺度验证。

Result: 在2014年纳帕地震和2019年里奇克莱斯特地震的评估中，预测与美国地质调查局'你感觉到了吗？'数据高度吻合：邮政编码级相关性0.88，RMSE低至0.77。视觉输入显著提升预测准确度。

Conclusion: LLMs在多模态数据支持下，可有效模拟灾害影响，加强灾前规划。视觉数据对提升预测精度具关键作用。

Abstract: Efficient simulation is essential for enhancing proactive preparedness for
sudden-onset disasters such as earthquakes. Recent advancements in large
language models (LLMs) as world models show promise in simulating complex
scenarios. This study examines multiple LLMs to proactively estimate perceived
earthquake impacts. Leveraging multimodal datasets including geospatial,
socioeconomic, building, and street-level imagery data, our framework generates
Modified Mercalli Intensity (MMI) predictions at zip code and county scales.
Evaluations on the 2014 Napa and 2019 Ridgecrest earthquakes using USGS ''Did
You Feel It? (DYFI)'' reports demonstrate significant alignment, as evidenced
by a high correlation of 0.88 and a low RMSE of 0.77 as compared to real
reports at the zip code level. Techniques such as RAG and ICL can improve
simulation performance, while visual inputs notably enhance accuracy compared
to structured numerical data alone. These findings show the promise of LLMs in
simulating disaster impacts that can help strengthen pre-event planning.

</details>


### [801] [From Rogue to Safe AI: The Role of Explicit Refusals in Aligning LLMs with International Humanitarian Law](https://arxiv.org/abs/2506.06391)
*John Mavi,Diana Teodora Găitan,Sergio Coronado*

Main category: cs.CY

TL;DR: 本研究评估了八种大型语言模型（LLM）在拒绝违反国际人道法（IHL）指令时的表现，发现虽然多数模型能拒绝非法请求，但其回应的清晰度和一致性存在差异。研究指出解释性拒绝能阐明系统界限、减少歧义，而标准化安全提示显著提升了拒绝说明的质量。然而，模型在处理技术性语言或代码请求时仍存在漏洞。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLM）在各领域广泛应用，但其对国际人道法（IHL）的合规性尚未得到充分理解。当前研究旨在填补这一空白，通过评估模型拒绝违法指令的能力及回应的清晰度，以促进更安全、透明的AI系统发展。

Method: 研究评估了八种主流LLM。首先测试模型拒绝明确违反IHL框架指令的能力，并重点关注回应的"帮助性"（即拒绝说明的清晰度和建设性）。其次引入标准化系统级安全提示，观察其对拒绝说明质量的改善效果。最后通过包含技术性语言或代码请求的复杂提示挑战模型，检测其持续存在的漏洞。

Result: 1. 多数模型能拒绝非法请求，但拒绝回应的清晰度和一致性差异显著
2. 解释性拒绝（包含法律依据/安全原则的说明）可有效阐明系统边界、减少歧义
3. 标准化安全提示显著提升了大多数模型的拒绝说明质量
4. 模型在处理技术语言或代码生成类请求时仍表现出漏洞

Conclusion: 轻量级干预措施（如标准化安全提示）可有效提升模型对IHL的合规性及透明度，但复杂技术场景仍存在风险。研究提出的评估框架为LLM的IHL合规性提供了基准，推动AI系统向更安全、负责任的方向发展。

Abstract: Large Language Models (LLMs) are widely used across sectors, yet their
alignment with International Humanitarian Law (IHL) is not well understood.
This study evaluates eight leading LLMs on their ability to refuse prompts that
explicitly violate these legal frameworks, focusing also on helpfulness - how
clearly and constructively refusals are communicated. While most models
rejected unlawful requests, the clarity and consistency of their responses
varied. By revealing the model's rationale and referencing relevant legal or
safety principles, explanatory refusals clarify the system's boundaries, reduce
ambiguity, and help prevent misuse. A standardised system-level safety prompt
significantly improved the quality of the explanations expressed within
refusals in most models, highlighting the effectiveness of lightweight
interventions. However, more complex prompts involving technical language or
requests for code revealed ongoing vulnerabilities. These findings contribute
to the development of safer, more transparent AI systems and propose a
benchmark to evaluate the compliance of LLM with IHL.

</details>


### [802] [Large Language Models Can Be a Viable Substitute for Expert Political Surveys When a Shock Disrupts Traditional Measurement Approaches](https://arxiv.org/abs/2506.06540)
*Patrick Y. Wu*

Main category: cs.CY

TL;DR: 利用大语言模型分析政治事件后偏见问题


<details>
  <summary>Details</summary>
Motivation: 解决大模型偏见和错误信息带来的负面影响。

Method: 使用多语言数据集训练模型并进行对比分析

Result: 开发出新的训练方法显著减少偏见

Conclusion: 为建立更公正的AI系统开辟新路径

Abstract: After a disruptive event or shock, such as the Department of Government
Efficiency (DOGE) federal layoffs of 2025, expert judgments are colored by
knowledge of the outcome. This can make it difficult or impossible to
reconstruct the pre-event perceptions needed to study the factors associated
with the event. This position paper argues that large language models (LLMs),
trained on vast amounts of digital media data, can be a viable substitute for
expert political surveys when a shock disrupts traditional measurement. We
analyze the DOGE layoffs as a specific case study for this position. We use
pairwise comparison prompts with LLMs and derive ideology scores for federal
executive agencies. These scores replicate pre-layoff expert measures and
predict which agencies were targeted by DOGE. We also use this same approach
and find that the perceptions of certain federal agencies as knowledge
institutions predict which agencies were targeted by DOGE, even when
controlling for ideology. This case study demonstrates that using LLMs allows
us to rapidly and easily test the associated factors hypothesized behind the
shock. More broadly, our case study of this recent event exemplifies how LLMs
offer insights into the correlational factors of the shock when traditional
measurement techniques fail. We conclude by proposing a two-part criterion for
when researchers can turn to LLMs as a substitute for expert political surveys.

</details>


### [803] [Future of Work with AI Agents: Auditing Automation and Augmentation Potential across the U.S. Workforce](https://arxiv.org/abs/2506.06576)
*Yijia Shao,Humishka Zope,Yucheng Jiang,Jiaxin Pei,David Nguyen,Erik Brynjolfsson,Diyi Yang*

Main category: cs.CY

TL;DR: 论文提出了一个审计框架来评估工人希望AI代理自动化或增强哪些职业任务，以及这些愿望如何与当前技术能力相匹配。该框架包括音频增强的微型访谈和人类代理量表（HAS），并创建了WORKBank数据库，收集了1500名工人对844个任务的偏好和AI专家的评估。研究将任务分为四个区域，揭示了职业间HAS分布的差异，并指出AI代理可能将核心人类能力从信息处理转向人际技能。


<details>
  <summary>Details</summary>
Motivation: 复合AI系统（AI代理）的迅速发展正在重塑劳动力市场，引发了人们对工作被取代、人类能动性减弱以及过度依赖自动化的担忧。然而，目前缺乏对这一演变局势的系统性理解。

Method: 引入了一个新颖的审计框架，其中包括：1）音频增强的微型访谈捕捉工人对自动化/增强的 nuanced 意愿；2）人类代理量表（HAS）量化人类偏好参与度。基于美国劳工部O*NET数据库构建WORKBank数据库，覆盖104个职业的844项任务，收集1500名领域工人意愿和AI专家技术能力评估。

Result: 1）WORKBank数据库将任务划分为四个区域（自动化'绿灯区'、'红灯区'、研发机会区、低优先级区）；2）发现各职业HAS分布差异显著，反映了对人类参与度的异质期望；3）预示核心人类能力可能从信息处理技能转向人际技能。

Conclusion: AI代理开发应与人类意愿保持一致，需为工人适应职场动态变化做好准备。研究强调了量化人类参与意愿的重要性，为AI发展提供方向性指导，避免技术能力与人类期望错位。

Abstract: The rapid rise of compound AI systems (a.k.a., AI agents) is reshaping the
labor market, raising concerns about job displacement, diminished human agency,
and overreliance on automation. Yet, we lack a systematic understanding of the
evolving landscape. In this paper, we address this gap by introducing a novel
auditing framework to assess which occupational tasks workers want AI agents to
automate or augment, and how those desires align with the current technological
capabilities. Our framework features an audio-enhanced mini-interview to
capture nuanced worker desires and introduces the Human Agency Scale (HAS) as a
shared language to quantify the preferred level of human involvement. Using
this framework, we construct the WORKBank database, building on the U.S.
Department of Labor's O*NET database, to capture preferences from 1,500 domain
workers and capability assessments from AI experts across over 844 tasks
spanning 104 occupations. Jointly considering the desire and technological
capability divides tasks in WORKBank into four zones: Automation "Green Light"
Zone, Automation "Red Light" Zone, R&D Opportunity Zone, Low Priority Zone.
This highlights critical mismatches and opportunities for AI agent development.
Moving beyond a simple automate-or-not dichotomy, our results reveal diverse
HAS profiles across occupations, reflecting heterogeneous expectations for
human involvement. Moreover, our study offers early signals of how AI agent
integration may reshape the core human competencies, shifting from
information-focused skills to interpersonal ones. These findings underscore the
importance of aligning AI agent development with human desires and preparing
workers for evolving workplace dynamics.

</details>


### [804] [How Malicious AI Swarms Can Threaten Democracy](https://arxiv.org/abs/2506.06299)
*Daniel Thilo Schroeder,Meeyoung Cha,Andrea Baronchelli,Nick Bostrom,Nicholas A. Christakis,David Garcia,Amit Goldenberg,Yara Kyrychenko,Kevin Leyton-Brown,Nina Lutz,Gary Marcus,Filippo Menczer,Gordon Pennycook,David G. Rand,Frank Schweitzer,Christopher Summerfield,Audrey Tang,Jay Van Bavel,Sander van der Linden,Dawn Song,Jonas R. Kunst*

Main category: cs.CY

TL;DR: 摘要讨论了恶意AI集群带来的新型虚假信息威胁，并提出平台防护、模型安全及系统监管的三方面应对策略。


<details>
  <summary>Details</summary>
Motivation: 随着AI技术进步，恶意行为者可能利用AI集群协调制造大规模虚假信息，破坏民主进程和社会信任，亟需系统性防御措施。

Method: 提出三层次防御体系：平台方部署集群检测和防护工具，模型层实施风险测试与溯源认证，系统层建立联合国级AI监管机构。

Result: 如不干预，AI集群可能导致共识操控、社会分裂、选民压制等后果；而建议方案可提升防御能力。

Conclusion: 恶意AI集群构成新型系统性风险，需要跨平台、技术和治理的立体化应对框架，特别是建立全球性AI监督机制。

Abstract: Advances in AI portend a new era of sophisticated disinformation operations.
While individual AI systems already create convincing -- and at times
misleading -- information, an imminent development is the emergence of
malicious AI swarms. These systems can coordinate covertly, infiltrate
communities, evade traditional detectors, and run continuous A/B tests, with
round-the-clock persistence. The result can include fabricated grassroots
consensus, fragmented shared reality, mass harassment, voter micro-suppression
or mobilization, contamination of AI training data, and erosion of
institutional trust. With democratic processes worldwide increasingly
vulnerable, we urge a three-pronged response: (1) platform-side defenses --
always-on swarm-detection dashboards, pre-election high-fidelity
swarm-simulation stress-tests, transparency audits, and optional client-side
"AI shields" for users; (2) model-side safeguards -- standardized
persuasion-risk tests, provenance-authenticating passkeys, and watermarking;
and (3) system-level oversight -- a UN-backed AI Influence Observatory.

</details>


### [805] [LLMs as World Models: Data-Driven and Human-Centered Pre-Event Simulation for Disaster Impact Assessment](https://arxiv.org/abs/2506.06355)
*Lingyao Li,Dawei Li,Zhenhui Ou,Xiaoran Xu,Jingxiao Liu,Zihui Ma,Runlong Yu,Min Deng*

Main category: cs.CY

TL;DR: 使用大型语言模型进行地震影响模拟


<details>
  <summary>Details</summary>
Motivation: 现有地震灾害准备需要高效模拟方法

Method: 采用多模态数据集训练LLM框架

Result: MMI预测准确度高

Conclusion: LLM在灾害影响模拟方面有巨大潜力

Abstract: Efficient simulation is essential for enhancing proactive preparedness for
sudden-onset disasters such as earthquakes. Recent advancements in large
language models (LLMs) as world models show promise in simulating complex
scenarios. This study examines multiple LLMs to proactively estimate perceived
earthquake impacts. Leveraging multimodal datasets including geospatial,
socioeconomic, building, and street-level imagery data, our framework generates
Modified Mercalli Intensity (MMI) predictions at zip code and county scales.
Evaluations on the 2014 Napa and 2019 Ridgecrest earthquakes using USGS ''Did
You Feel It? (DYFI)'' reports demonstrate significant alignment, as evidenced
by a high correlation of 0.88 and a low RMSE of 0.77 as compared to real
reports at the zip code level. Techniques such as RAG and ICL can improve
simulation performance, while visual inputs notably enhance accuracy compared
to structured numerical data alone. These findings show the promise of LLMs in
simulating disaster impacts that can help strengthen pre-event planning.

</details>


### [806] [From Rogue to Safe AI: The Role of Explicit Refusals in Aligning LLMs with International Humanitarian Law](https://arxiv.org/abs/2506.06391)
*John Mavi,Diana Teodora Găitan,Sergio Coronado*

Main category: cs.CY

TL;DR: 研究评估了8个主流大语言模型在国际人道法下的拒绝违规请求能力及解释清晰度。发现模型多能拒绝非法请求，但回应的清晰度和一致性不一。标准化安全提示提升了多数模型的解释质量，但复杂提示仍存漏洞。


<details>
  <summary>Details</summary>
Motivation: 大语言模型在各领域的应用日益广泛，但其与国际人道法的合规性尚未充分研究。需评估模型对明确违法请求的拒绝能力及解释的清晰度，以确保AI系统的安全性和透明度。

Method: 测试了8个主流LLMs处理显式违反国际人道主义法的提示的能力。通过分析模型拒绝请求时的清晰度和建设性（helpfulness），并使用标准化的系统级安全提示进行干预对比。同时测试包含技术术语或代码请求的复杂提示。

Result: 1. 所有模型都能拒绝非法请求<br/>2. 拒绝解释的清晰度和一致性存在显著差异<br/>3. 标准化安全提示显著提升多数模型的解释质量<br/>4. 涉及技术语言或代码的复杂提示仍暴露出持续漏洞

Conclusion: 通过标准化提示等轻量级干预可有效提升模型安全合规性，但复杂场景仍需改进。研究提出了评估LLM遵守国际人道法的基准，推动开发更安全透明的AI系统。

Abstract: Large Language Models (LLMs) are widely used across sectors, yet their
alignment with International Humanitarian Law (IHL) is not well understood.
This study evaluates eight leading LLMs on their ability to refuse prompts that
explicitly violate these legal frameworks, focusing also on helpfulness - how
clearly and constructively refusals are communicated. While most models
rejected unlawful requests, the clarity and consistency of their responses
varied. By revealing the model's rationale and referencing relevant legal or
safety principles, explanatory refusals clarify the system's boundaries, reduce
ambiguity, and help prevent misuse. A standardised system-level safety prompt
significantly improved the quality of the explanations expressed within
refusals in most models, highlighting the effectiveness of lightweight
interventions. However, more complex prompts involving technical language or
requests for code revealed ongoing vulnerabilities. These findings contribute
to the development of safer, more transparent AI systems and propose a
benchmark to evaluate the compliance of LLM with IHL.

</details>


### [807] [Large Language Models Can Be a Viable Substitute for Expert Political Surveys When a Shock Disrupts Traditional Measurement Approaches](https://arxiv.org/abs/2506.06540)
*Patrick Y. Wu*

Main category: cs.CY

TL;DR: 本文提出使用大型语言模型（LLMs）替代专家调查来衡量政治冲击的影响，并以2025年联邦机构裁员事件（DOGE）为案例研究发现：1）LLM生成的意识形态得分能复现专家调查结果并预测裁员对象；2）机构作为知识机构的声誉（独立于意识形态）也是裁员预测因素。该研究建立了LLMs替代专家调查的两部分标准。


<details>
  <summary>Details</summary>
Motivation: 政治冲击后（如机构裁员事件），专家判断会受结果干扰难以反映事件前的真实认知，导致无法研究事件关联因素。传统测量方法失效时需要新替代方案。

Method: 采用LLMs对数字媒体数据进行训���，使用成对比较提示生成联邦机构意识形态得分；以DOGE裁员事件为案例进行验证，控制变量分析知识机构声誉的影响。

Result: 1）LLM意识形态得分成功复现了裁员前的专家调查结果，并预测裁员对象；2）发现知识机构声誉（独立于意识形态）是裁员决定的新预测因素。

Conclusion: 在传统测量失效时，LLMs可快速测试政治冲击的关联因素。研究提出了LLMs替代专家调查的两部分标准：冲击导致传统数据不可用；LLMs训练数据包含事件前社会认知。

Abstract: After a disruptive event or shock, such as the Department of Government
Efficiency (DOGE) federal layoffs of 2025, expert judgments are colored by
knowledge of the outcome. This can make it difficult or impossible to
reconstruct the pre-event perceptions needed to study the factors associated
with the event. This position paper argues that large language models (LLMs),
trained on vast amounts of digital media data, can be a viable substitute for
expert political surveys when a shock disrupts traditional measurement. We
analyze the DOGE layoffs as a specific case study for this position. We use
pairwise comparison prompts with LLMs and derive ideology scores for federal
executive agencies. These scores replicate pre-layoff expert measures and
predict which agencies were targeted by DOGE. We also use this same approach
and find that the perceptions of certain federal agencies as knowledge
institutions predict which agencies were targeted by DOGE, even when
controlling for ideology. This case study demonstrates that using LLMs allows
us to rapidly and easily test the associated factors hypothesized behind the
shock. More broadly, our case study of this recent event exemplifies how LLMs
offer insights into the correlational factors of the shock when traditional
measurement techniques fail. We conclude by proposing a two-part criterion for
when researchers can turn to LLMs as a substitute for expert political surveys.

</details>


### [808] [Future of Work with AI Agents: Auditing Automation and Augmentation Potential across the U.S. Workforce](https://arxiv.org/abs/2506.06576)
*Yijia Shao,Humishka Zope,Yucheng Jiang,Jiaxin Pei,David Nguyen,Erik Brynjolfsson,Diyi Yang*

Main category: cs.CY

TL;DR: 提出了一个新的审计框架，该框架包括音频增强的小型访谈和人类代理量表（HAS），用于评估工作者对AI代理自动化或增强任务的愿望，以及与当前技术能力的匹配情况。构建了WORKBank数据库，基于1,500名工人的偏好和AI专家的评估，将任务分为四个区域，揭示了多样化的HAS分布以及核心人类能力从信息处理向人际交往的转变。


<details>
  <summary>Details</summary>
Motivation: 复合AI系统（AI代理）的迅速发展正在重塑劳动力市场，引发了对工作替代、人类能动性减少和对自动化过度依赖的担忧。需要系统地理解这种不断发展的环境。

Method: 引入了一个新颖的审计框架，包括音频增强的小型访谈来捕捉工作者的细腻愿望，并提出人类代理量表（HAS）作为量化人类参与程度的共同语言。构建WORKBank数据库，扩展自美国劳工部的O*NET数据库，收集了1,500名工人的偏好和AI专家对844个任务的技术能力评估。

Result: 将任务基于愿望与技术能力划分为四个区域：自动化“绿灯”区、自动化“红灯”区、研发机会区、低优先级区。研究揭示了不同职业的多样化HAS分布，表明人类能动性期望的异质性；研究还提供了AI代理整合如何将人类核心能力从信息处理转向人际交际的早期信号。

Conclusion: 研究结果强调了将AI代理开发与人类愿望保持一致的重要性，并为准备工作者适应不断变化的工作场所动态提供了见解。

Abstract: The rapid rise of compound AI systems (a.k.a., AI agents) is reshaping the
labor market, raising concerns about job displacement, diminished human agency,
and overreliance on automation. Yet, we lack a systematic understanding of the
evolving landscape. In this paper, we address this gap by introducing a novel
auditing framework to assess which occupational tasks workers want AI agents to
automate or augment, and how those desires align with the current technological
capabilities. Our framework features an audio-enhanced mini-interview to
capture nuanced worker desires and introduces the Human Agency Scale (HAS) as a
shared language to quantify the preferred level of human involvement. Using
this framework, we construct the WORKBank database, building on the U.S.
Department of Labor's O*NET database, to capture preferences from 1,500 domain
workers and capability assessments from AI experts across over 844 tasks
spanning 104 occupations. Jointly considering the desire and technological
capability divides tasks in WORKBank into four zones: Automation "Green Light"
Zone, Automation "Red Light" Zone, R&D Opportunity Zone, Low Priority Zone.
This highlights critical mismatches and opportunities for AI agent development.
Moving beyond a simple automate-or-not dichotomy, our results reveal diverse
HAS profiles across occupations, reflecting heterogeneous expectations for
human involvement. Moreover, our study offers early signals of how AI agent
integration may reshape the core human competencies, shifting from
information-focused skills to interpersonal ones. These findings underscore the
importance of aligning AI agent development with human desires and preparing
workers for evolving workplace dynamics.

</details>


<div id='cs.GR'></div>

# cs.GR [[Back]](#toc)

### [809] [Vid2Sim: Generalizable, Video-based Reconstruction of Appearance, Geometry and Physics for Mesh-free Simulation](https://arxiv.org/abs/2506.06440)
*Chuhao Chen,Zhiyang Dou,Chen Wang,Yiming Huang,Anjun Chen,Qiao Feng,Jiatao Gu,Lingjie Liu*

Main category: cs.GR

TL;DR: Vid2Sim框架，一种基于视频的通用方法，通过基于线性混合蒙皮的网格免费简化模拟，高效重建几何和物理属性，减少优化时间和超参数调整。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖计算密集型优化的可微分模拟器和渲染器，需要大量超参数调整，导致成本高、普适性差，因此需要高效通用的解决方案。

Method: 1) 前馈神经网络从视频中重建物理系统观测配置；2) 轻量级优化流程微调外观、几何和物理属性；3) 基于LBS实现高效网格免费模拟。

Result: 实验表明，该方法在视频数据重建几何和物理属性方面实现了更高的精度和效率（只需几分钟优化时间）。

Conclusion: Vid2Sim提供计算高效且通用的表示能力，显著优于现有方法，同时支持高质量的后续模拟。

Abstract: Faithfully reconstructing textured shapes and physical properties from videos
presents an intriguing yet challenging problem. Significant efforts have been
dedicated to advancing such a system identification problem in this area.
Previous methods often rely on heavy optimization pipelines with a
differentiable simulator and renderer to estimate physical parameters. However,
these approaches frequently necessitate extensive hyperparameter tuning for
each scene and involve a costly optimization process, which limits both their
practicality and generalizability. In this work, we propose a novel framework,
Vid2Sim, a generalizable video-based approach for recovering geometry and
physical properties through a mesh-free reduced simulation based on Linear
Blend Skinning (LBS), offering high computational efficiency and versatile
representation capability. Specifically, Vid2Sim first reconstructs the
observed configuration of the physical system from video using a feed-forward
neural network trained to capture physical world knowledge. A lightweight
optimization pipeline then refines the estimated appearance, geometry, and
physical properties to closely align with video observations within just a few
minutes. Additionally, after the reconstruction, Vid2Sim enables high-quality,
mesh-free simulation with high efficiency. Extensive experiments demonstrate
that our method achieves superior accuracy and efficiency in reconstructing
geometry and physical properties from video data.

</details>


### [810] [Splat and Replace: 3D Reconstruction with Repetitive Elements](https://arxiv.org/abs/2506.06462)
*Nicolás Violante,Andreas Meuleman,Alban Gauthier,Frédo Durand,Thibault Groueix,George Drettakis*

Main category: cs.GR

TL;DR: 提出了一种利用3D场景中的重复元素来提升新视角合成质量的方法。通过分割和配准3D高斯泼溅（3DGS）重建中的重复实例，实现信息共享，从而改善覆盖不足和遮挡区域的渲染效果。


<details>
  <summary>Details</summary>
Motivation: 现有的NeRF和3DGS方法在训练视角不足时，对未观察区域和遮挡区域的渲染质量较差。观察到现实环境中常存在重复元素，利用这些重复性可以提升重建质量。

Method: 首先在3DGS重建中分割每个重复实例，然后进行配准对齐，最后允许实例间共享信息（包括几何和外观变化）。

Result: 在合成和真实场景数据集上验证，新视角合成质量得到显著提升，特别是在覆盖不足和遮挡区域。

Conclusion: 通过利用场景中的重复元素进行实例间信息融合，有效解决了训练视角不足导致的渲染质量问题，为场景重建提供了新思路。

Abstract: We leverage repetitive elements in 3D scenes to improve novel view synthesis.
Neural Radiance Fields (NeRF) and 3D Gaussian Splatting (3DGS) have greatly
improved novel view synthesis but renderings of unseen and occluded parts
remain low-quality if the training views are not exhaustive enough. Our key
observation is that our environment is often full of repetitive elements. We
propose to leverage those repetitions to improve the reconstruction of
low-quality parts of the scene due to poor coverage and occlusions. We propose
a method that segments each repeated instance in a 3DGS reconstruction,
registers them together, and allows information to be shared among instances.
Our method improves the geometry while also accounting for appearance
variations across instances. We demonstrate our method on a variety of
synthetic and real scenes with typical repetitive elements, leading to a
substantial improvement in the quality of novel view synthesis.

</details>


### [811] [Noise Consistency Regularization for Improved Subject-Driven Image Synthesis](https://arxiv.org/abs/2506.06483)
*Yao Ni,Song Wen,Piotr Koniusz,Anoop Cherian*

Main category: cs.GR

TL;DR: 为了解决微调Stable Diffusion模型在主题驱动图像生成中存在的欠拟合和过拟合问题，本文提出两种辅助一致性损失方法：先验一致性正则化损失和主题一致性正则化损失，以提高图像保真度和多样性。实验结果表明该方法在多个指标上优于DreamBooth。


<details>
  <summary>Details</summary>
Motivation: 现有微调方法在主题驱动的图像合成中存在两个问题：1) 欠拟合导致无法可靠捕捉主题特征；2) 过拟合导致背景多样性降低。

Method: 提出两个辅助一致性损失：1）先验一致性正则化损失（保持非主题图像的扩散噪声预测与预训练模型一致）；2）主题一致性正则化损失（增强模型对调制潜在码乘性噪声的鲁棒性）。

Result: 实验显示该方法在保留主题身份的同时提升图像多样性，在CLIP分数、背景变化和视觉质量上超越DreamBooth。

Conclusion: 通过引入两种正则化损失，有效解决了微调过程中的欠拟合和过拟合问题，实现了更好的主题保留与背景多样性。

Abstract: Fine-tuning Stable Diffusion enables subject-driven image synthesis by
adapting the model to generate images containing specific subjects. However,
existing fine-tuning methods suffer from two key issues: underfitting, where
the model fails to reliably capture subject identity, and overfitting, where it
memorizes the subject image and reduces background diversity. To address these
challenges, we propose two auxiliary consistency losses for diffusion
fine-tuning. First, a prior consistency regularization loss ensures that the
predicted diffusion noise for prior (non-subject) images remains consistent
with that of the pretrained model, improving fidelity. Second, a subject
consistency regularization loss enhances the fine-tuned model's robustness to
multiplicative noise modulated latent code, helping to preserve subject
identity while improving diversity. Our experimental results demonstrate that
incorporating these losses into fine-tuning not only preserves subject identity
but also enhances image diversity, outperforming DreamBooth in terms of CLIP
scores, background variation, and overall visual quality.

</details>


### [812] [Accelerating 3D Gaussian Splatting with Neural Sorting and Axis-Oriented Rasterization](https://arxiv.org/abs/2506.07069)
*Zhican Wang,Guanghui He,Dantong Liu,Lingjun Gao,Shell Xu Hu,Chen Zhang,Zhuoran Song,Nicholas Lane,Wayne Luk,Hongxiang Fan*

Main category: cs.GR

TL;DR: 3DGS用于高质量和高效的视图合成，但受限于实时渲染效率和资源消耗。本文提出软硬件协同设计：轴向光栅化减少计算冗余、神经排序替代传统排序、可重构处理阵列支持高效计算、π轨迹分块调度降低访问开销。结果：保持画质的同时比边缘GPU快23.4~27.8倍，节能28.8~51.4倍。


<details>
  <summary>Details</summary>
Motivation: 针对3D高斯泼溅技术在资源受限设备上实时渲染的挑战（高功耗和面积限制），通过揭示传统光栅化过程中的计算冗余和排序低效，提出软硬件协同优化方案。

Method: 1. 轴向光栅化：预计算并复用X/Y轴共享项，减少63%乘加运算；2. 神经排序网络：预测与顺序无关的混合权重，避免硬件排序器；3. 可重构处理阵列：统一支持光栅化和神经网络计算；4. π轨迹分块调度：启发自Morton码和Hilbert曲线的高斯复用优化。

Result: 在保持渲染质量前提下，相比边缘GPU实现23.4~27.8倍加速，节能28.8~51.4倍。

Conclusion: 提出的软硬件协同设计有效解决3DGS的资源效率问题，开源计划将促进领域发展。

Abstract: 3D Gaussian Splatting (3DGS) has recently gained significant attention for
high-quality and efficient view synthesis, making it widely adopted in fields
such as AR/VR, robotics, and autonomous driving. Despite its impressive
algorithmic performance, real-time rendering on resource-constrained devices
remains a major challenge due to tight power and area budgets. This paper
presents an architecture-algorithm co-design to address these inefficiencies.
First, we reveal substantial redundancy caused by repeated computation of
common terms/expressions during the conventional rasterization. To resolve
this, we propose axis-oriented rasterization, which pre-computes and reuses
shared terms along both the X and Y axes through a dedicated hardware design,
effectively reducing multiply-and-add (MAC) operations by up to 63%. Second, by
identifying the resource and performance inefficiency of the sorting process,
we introduce a novel neural sorting approach that predicts order-independent
blending weights using an efficient neural network, eliminating the need for
costly hardware sorters. A dedicated training framework is also proposed to
improve its algorithmic stability. Third, to uniformly support rasterization
and neural network inference, we design an efficient reconfigurable processing
array that maximizes hardware utilization and throughput. Furthermore, we
introduce a $\pi$-trajectory tile schedule, inspired by Morton encoding and
Hilbert curve, to optimize Gaussian reuse and reduce memory access overhead.
Comprehensive experiments demonstrate that the proposed design preserves
rendering quality while achieving a speedup of $23.4\sim27.8\times$ and energy
savings of $28.8\sim51.4\times$ compared to edge GPUs for real-world scenes. We
plan to open-source our design to foster further development in this field.

</details>


### [813] [HOI-PAGE: Zero-Shot Human-Object Interaction Generation with Part Affordance Guidance](https://arxiv.org/abs/2506.07209)
*Lei Li,Angela Dai*

Main category: cs.GR

TL;DR: 提出了HOI-PAGE方法：通過分析身體部位與物體部位的細粒度互動，結合部件級可動性推理，實現從文字生成逼真的4D人體-物體互動(HOI)序列。


<details>
  <summary>Details</summary>
Motivation: 現有4D HOI生成方法側重於身體-物體的整體運動，難以產生逼真多樣化的互動。因此需在人類身體部位與物體部件接觸關係層面建模細粒度互動。

Method: 1. 建立部件可動性圖譜(PAG)作為結構化表徵；2. 三階段生成流程：物體部件分解→文字驅動參考視頻生成→基於部件運動約束優化4D序列

Result: 該方法零樣本生成複雜交互，支持多物體/多人場景，在真實性和文本對齊度上顯著提升。

Conclusion: 部件級可動性推理是提升HOI生成質量的關鍵，PAG在連接語義認知與幾何動態方面具有有效指導作用。

Abstract: We present HOI-PAGE, a new approach to synthesizing 4D human-object
interactions (HOIs) from text prompts in a zero-shot fashion, driven by
part-level affordance reasoning. In contrast to prior works that focus on
global, whole body-object motion for 4D HOI synthesis, we observe that
generating realistic and diverse HOIs requires a finer-grained understanding --
at the level of how human body parts engage with object parts. We thus
introduce Part Affordance Graphs (PAGs), a structured HOI representation
distilled from large language models (LLMs) that encodes fine-grained part
information along with contact relations. We then use these PAGs to guide a
three-stage synthesis: first, decomposing input 3D objects into geometric
parts; then, generating reference HOI videos from text prompts, from which we
extract part-based motion constraints; finally, optimizing for 4D HOI motion
sequences that not only mimic the reference dynamics but also satisfy
part-level contact constraints. Extensive experiments show that our approach is
flexible and capable of generating complex multi-object or multi-person
interaction sequences, with significantly improved realism and text alignment
for zero-shot 4D HOI generation.

</details>


### [814] [PIG: Physically-based Multi-Material Interaction with 3D Gaussians](https://arxiv.org/abs/2506.07657)
*Zeyu Xiao,Zhenyi Wu,Mingyang Sun,Qipeng Yan,Yufan Guo,Zhuoer Liang,Lihua Zhang*

Main category: cs.GR

TL;DR: 本文提出PIG方法，通过结合3D物体分割和多材料物理模拟，解决了3D高斯溅射场景中物体交互的三大问题：分割不精确、变形不准确和渲染伪影，显著提升了视觉质量和物理真实感。


<details>
  <summary>Details</summary>
Motivation: 现有3D高斯溅射技术在物体交互中存在三大问题：1) 3D分割不准确；2) 不同材质间变形不精确；3) 严重渲染伪影。这些缺陷阻碍了物理真实场景生成的实用化。

Method: 1) 建立2D像素到3D高斯的快速精确映射实现分割；2) 为分割对象分配物理属性实现多材料耦合交互；3) 在变形梯度中嵌入约束尺度，钳位高斯原语的缩放和旋转特性以消除伪影。

Result: 实验表明：方法在视觉质量上超越SOTA，建立了物理真实场景生成的新范式，有效解决了分割精度、物理变形准确性和渲染伪影三大问题。

Conclusion: PIG框架为3D高斯场景引入物理交互机制，通过分割-物性分配-约束变形的技术链条，系统性提升了场景真实感，开辟了物理真实场景生成的新方向。

Abstract: 3D Gaussian Splatting has achieved remarkable success in reconstructing both
static and dynamic 3D scenes. However, in a scene represented by 3D Gaussian
primitives, interactions between objects suffer from inaccurate 3D
segmentation, imprecise deformation among different materials, and severe
rendering artifacts. To address these challenges, we introduce PIG:
Physically-Based Multi-Material Interaction with 3D Gaussians, a novel approach
that combines 3D object segmentation with the simulation of interacting objects
in high precision. Firstly, our method facilitates fast and accurate mapping
from 2D pixels to 3D Gaussians, enabling precise 3D object-level segmentation.
Secondly, we assign unique physical properties to correspondingly segmented
objects within the scene for multi-material coupled interactions. Finally, we
have successfully embedded constraint scales into deformation gradients,
specifically clamping the scaling and rotation properties of the Gaussian
primitives to eliminate artifacts and achieve geometric fidelity and visual
consistency. Experimental results demonstrate that our method not only
outperforms the state-of-the-art (SOTA) in terms of visual quality, but also
opens up new directions and pipelines for the field of physically realistic
scene generation.

</details>


### [815] [GaussianVAE: Adaptive Learning Dynamics of 3D Gaussians for High-Fidelity Super-Resolution](https://arxiv.org/abs/2506.07897)
*Shuja Khalid,Mohamed Ibrahim,Yang Liu*

Main category: cs.GR

TL;DR: 该论文提出了一种新颖的方法来提高3D高斯溅射（3DGS）的分辨率和几何保真度，突破现有方法受限于输入分辨率的问题。


<details>
  <summary>Details</summary>
Motivation: 当前的3DGS方法受输入分辨率的根本限制，无法从训练视图中推断出更精细的细节细节。该方法的动机是突破这一限制。

Method: 通过一个轻量级的生成模型预测并细化额外的3D高斯点，采用基于Hessian辅助的采样策略智能识别需要密集化的区域。

Result: 方法显著提高了几何准确性和渲染质量，在单个消费级GPU上运行时每推理仅需0.015秒，实现了实时互动应用。

Conclusion: 该方法建立了一个无分辨率限制的3D场景增强新范式，与现有最先进方法相比具有明显优势。

Abstract: We present a novel approach for enhancing the resolution and geometric
fidelity of 3D Gaussian Splatting (3DGS) beyond native training resolution.
Current 3DGS methods are fundamentally limited by their input resolution,
producing reconstructions that cannot extrapolate finer details than are
present in the training views. Our work breaks this limitation through a
lightweight generative model that predicts and refines additional 3D Gaussians
where needed most. The key innovation is our Hessian-assisted sampling
strategy, which intelligently identifies regions that are likely to benefit
from densification, ensuring computational efficiency. Unlike computationally
intensive GANs or diffusion approaches, our method operates in real-time
(0.015s per inference on a single consumer-grade GPU), making it practical for
interactive applications. Comprehensive experiments demonstrate significant
improvements in both geometric accuracy and rendering quality compared to
state-of-the-art methods, establishing a new paradigm for resolution-free 3D
scene enhancement.

</details>


### [816] [Speedy Deformable 3D Gaussian Splatting: Fast Rendering and Compression of Dynamic Scenes](https://arxiv.org/abs/2506.07917)
*Allen Tu,Haiyang Ying,Alex Hanson,Yonghan Lee,Tom Goldstein,Matthias Zwicker*

Main category: cs.GR

TL;DR: SpeeDe3DGS加速动态3D高斯溅射渲染，通过时序敏感度剪枝和GroupFlow运动分析，实现高达10.37倍渲染加速和模型缩小7.71倍。


<details>
  <summary>Details</summary>
Motivation: 现有动态3DGS方法对每个高斯点进行逐帧神经网络推断，导致渲染速度慢、内存和计算需求高。

Method: 1. 提出时序敏感度剪枝分数+退火平滑机制，剔除低贡献高斯点; 2. 设计GroupFlow通过运动轨迹聚类，每组预测单一刚体变换。

Result: NeRF-DS数据集上：渲染加速10.37倍，模型缩小7.71倍，训练加快2.71倍；D-NeRF/HyperNeRF分别加速4.20倍/58.23倍。

Conclusion: 该方法模块化兼容各类可变形3DGS框架，显著提升效率同时保持重建质量。

Abstract: Recent extensions of 3D Gaussian Splatting (3DGS) to dynamic scenes achieve
high-quality novel view synthesis by using neural networks to predict the
time-varying deformation of each Gaussian. However, performing per-Gaussian
neural inference at every frame poses a significant bottleneck, limiting
rendering speed and increasing memory and compute requirements. In this paper,
we present Speedy Deformable 3D Gaussian Splatting (SpeeDe3DGS), a general
pipeline for accelerating the rendering speed of dynamic 3DGS and 4DGS
representations by reducing neural inference through two complementary
techniques. First, we propose a temporal sensitivity pruning score that
identifies and removes Gaussians with low contribution to the dynamic scene
reconstruction. We also introduce an annealing smooth pruning mechanism that
improves pruning robustness in real-world scenes with imprecise camera poses.
Second, we propose GroupFlow, a motion analysis technique that clusters
Gaussians by trajectory similarity and predicts a single rigid transformation
per group instead of separate deformations for each Gaussian. Together, our
techniques accelerate rendering by $10.37\times$, reduce model size by
$7.71\times$, and shorten training time by $2.71\times$ on the NeRF-DS dataset.
SpeeDe3DGS also improves rendering speed by $4.20\times$ and $58.23\times$ on
the D-NeRF and HyperNeRF vrig datasets. Our methods are modular and can be
integrated into any deformable 3DGS or 4DGS framework.

</details>


### [817] [Squeeze3D: Your 3D Generation Model is Secretly an Extreme Neural Compressor](https://arxiv.org/abs/2506.07932)
*Rishit Dagli,Yushi Guan,Sankeerth Durvasula,Mohammadreza Mofayezi,Nandita Vijaykumar*

Main category: cs.GR

TL;DR: Squeeze3D是一种利用预训练的3D生成模型隐式先验知识来实现极高压缩比的三维数据压缩框架。通过可训练的映射网络连接预训练编码器和生成模型的潜在空间，支持网格、点云和辐射场格式，无需真实数据集训练，在保持视觉质量的同时实现最高2187倍压缩比，且延迟低。


<details>
  <summary>Details</summary>
Motivation: 现有3D压缩方法难以兼顾高压缩比和低延迟，而预训练3D生成模型蕴含的丰富先验知识未被充分利用。该研究旨在利用这类模型的隐式知识实现超高效率压缩，同时避免传统方法针对单个对象训练网络的耗时问题。

Method: 1）使用预训练编码器将输入3D数据（网格/点云/辐射场）编码为初始潜在向量；2）设计可训练映射网络将初始向量压缩为紧凑潜码（即压缩结果）；3）通过另一映射网络将压缩潜码转换为生成模型的潜空间；4）预训练3D生成模型根据该潜码重建原始数据（解压）。全程仅使用生成数据训练映射网络。

Result: 实验表明：纹理网格压缩比达2187倍（如从2.3MB降至1.1KB），点云压缩比55倍，辐射场619倍。视觉质量与现有方法相当，且压缩/解压延迟显著降低（无需单对象训练）。支持跨格式灵活集成现有预训练模型。

Conclusion: Squeeze3D首次验证利用预训练3D生成模型先验知识实现超高压缩比的可行性。其免真实数据训练、低延迟、多格式支持的特性，为3D内容高效传输与存储提供了新方向。未来可探索更优映射架构与生成模型集成方案。

Abstract: We propose Squeeze3D, a novel framework that leverages implicit prior
knowledge learnt by existing pre-trained 3D generative models to compress 3D
data at extremely high compression ratios. Our approach bridges the latent
spaces between a pre-trained encoder and a pre-trained generation model through
trainable mapping networks. Any 3D model represented as a mesh, point cloud, or
a radiance field is first encoded by the pre-trained encoder and then
transformed (i.e. compressed) into a highly compact latent code. This latent
code can effectively be used as an extremely compressed representation of the
mesh or point cloud. A mapping network transforms the compressed latent code
into the latent space of a powerful generative model, which is then conditioned
to recreate the original 3D model (i.e. decompression). Squeeze3D is trained
entirely on generated synthetic data and does not require any 3D datasets. The
Squeeze3D architecture can be flexibly used with existing pre-trained 3D
encoders and existing generative models. It can flexibly support different
formats, including meshes, point clouds, and radiance fields. Our experiments
demonstrate that Squeeze3D achieves compression ratios of up to 2187x for
textured meshes, 55x for point clouds, and 619x for radiance fields while
maintaining visual quality comparable to many existing methods. Squeeze3D only
incurs a small compression and decompression latency since it does not involve
training object-specific networks to compress an object.

</details>


### [818] [Vid2Sim: Generalizable, Video-based Reconstruction of Appearance, Geometry and Physics for Mesh-free Simulation](https://arxiv.org/abs/2506.06440)
*Chuhao Chen,Zhiyang Dou,Chen Wang,Yiming Huang,Anjun Chen,Qiao Feng,Jiatao Gu,Lingjie Liu*

Main category: cs.GR

TL;DR: Vid2Sim是一种新颖框架，通过基于线性混合蒙皮（LBS）的无网格简化模拟，从视频中高效恢复几何和物理属性，避免了传统方法的高昂优化成本和超参数调整。


<details>
  <summary>Details</summary>
Motivation: 传统基于可微分模拟器和渲染器的物理参数估计方法需要大量超参数调整和昂贵优化，限制了其实用性和泛化性。为解决这一问题，提出Vid2Sim框架。

Method: 1. 使用前馈神经网络从视频中重建物理系统观测配置（捕捉物理知识）；2. 轻量级优化流程精细化外观/几何/物理属性（数分钟内对齐视频观测）；3. 支持无网格高效仿真。

Result: 在视频数据重建几何和物理属性方面实现更高精度和效率，并支持高质量无网格模拟。

Conclusion: Vid2Sim在减少计算成本、避免超参数敏感性的同时，显著提升重建质量和效率，为动态场景感知提供实用解决方案。

Abstract: Faithfully reconstructing textured shapes and physical properties from videos
presents an intriguing yet challenging problem. Significant efforts have been
dedicated to advancing such a system identification problem in this area.
Previous methods often rely on heavy optimization pipelines with a
differentiable simulator and renderer to estimate physical parameters. However,
these approaches frequently necessitate extensive hyperparameter tuning for
each scene and involve a costly optimization process, which limits both their
practicality and generalizability. In this work, we propose a novel framework,
Vid2Sim, a generalizable video-based approach for recovering geometry and
physical properties through a mesh-free reduced simulation based on Linear
Blend Skinning (LBS), offering high computational efficiency and versatile
representation capability. Specifically, Vid2Sim first reconstructs the
observed configuration of the physical system from video using a feed-forward
neural network trained to capture physical world knowledge. A lightweight
optimization pipeline then refines the estimated appearance, geometry, and
physical properties to closely align with video observations within just a few
minutes. Additionally, after the reconstruction, Vid2Sim enables high-quality,
mesh-free simulation with high efficiency. Extensive experiments demonstrate
that our method achieves superior accuracy and efficiency in reconstructing
geometry and physical properties from video data.

</details>


### [819] [Splat and Replace: 3D Reconstruction with Repetitive Elements](https://arxiv.org/abs/2506.06462)
*Nicolás Violante,Andreas Meuleman,Alban Gauthier,Frédo Durand,Thibault Groueix,George Drettakis*

Main category: cs.GR

TL;DR: 提出了一种利用3D场景中重复元素提升新视图合成质量的方法，该方法基于3D高斯喷洒（3DGS），通过分割和配准重复实例实现信息共享。


<details>
  <summary>Details</summary>
Motivation: 现有方法如NeRF和3DGS在训练视角不足时，对不可见和遮挡区域的渲染效果较差；而真实场景中普遍存在重复元素，可利用这些重复信息提升渲染质量。

Method: 1. 在3DGS重建中分割重复实例 2. 配准实例 3. 允许实例间共享几何和外观信息，同时考虑实例间外观差异。

Result: 在合成和真实场景中验证，新视图合成质量显著提升，尤其改善了低覆盖率和遮挡区域的渲染效果。

Conclusion: 利用场景重复元素能有效增强3D重建，该方法为处理视角不足问题提供了新思路。

Abstract: We leverage repetitive elements in 3D scenes to improve novel view synthesis.
Neural Radiance Fields (NeRF) and 3D Gaussian Splatting (3DGS) have greatly
improved novel view synthesis but renderings of unseen and occluded parts
remain low-quality if the training views are not exhaustive enough. Our key
observation is that our environment is often full of repetitive elements. We
propose to leverage those repetitions to improve the reconstruction of
low-quality parts of the scene due to poor coverage and occlusions. We propose
a method that segments each repeated instance in a 3DGS reconstruction,
registers them together, and allows information to be shared among instances.
Our method improves the geometry while also accounting for appearance
variations across instances. We demonstrate our method on a variety of
synthetic and real scenes with typical repetitive elements, leading to a
substantial improvement in the quality of novel view synthesis.

</details>


### [820] [Noise Consistency Regularization for Improved Subject-Driven Image Synthesis](https://arxiv.org/abs/2506.06483)
*Yao Ni,Song Wen,Piotr Koniusz,Anoop Cherian*

Main category: cs.GR

TL;DR: 提出两种辅助一致性损失（先验一致性正则化和主题一致性正则化）用于改进Stable Diffusion微调，解决身份拟合不足和背景多样性不足的问题。


<details>
  <summary>Details</summary>
Motivation: 现有Stable Diffusion微调方法在主题驱动图像生成中存在样本拟合不足（无法可靠捕捉主题身份）和过拟合（记忆样本图像导致背景多样性下降）的问题。

Method: 在扩散微调中引入两种损失：1) 先验一致性正则化损失，保持非主题图像（先验）的预测扩散噪声与预训练模型一致；2) 主题一致性正则化损失，增强模型对噪声调制隐代码的鲁棒性。

Result: 实验表明该方法在保留主题身份的同时增强图像多样性，在CLIP分数、背景变化和视觉质量上优于DreamBooth。

Conclusion: 所提一致性损失有效平衡了主题身份保持与生成多样性，提升了主题驱动图像合成效果。

Abstract: Fine-tuning Stable Diffusion enables subject-driven image synthesis by
adapting the model to generate images containing specific subjects. However,
existing fine-tuning methods suffer from two key issues: underfitting, where
the model fails to reliably capture subject identity, and overfitting, where it
memorizes the subject image and reduces background diversity. To address these
challenges, we propose two auxiliary consistency losses for diffusion
fine-tuning. First, a prior consistency regularization loss ensures that the
predicted diffusion noise for prior (non-subject) images remains consistent
with that of the pretrained model, improving fidelity. Second, a subject
consistency regularization loss enhances the fine-tuned model's robustness to
multiplicative noise modulated latent code, helping to preserve subject
identity while improving diversity. Our experimental results demonstrate that
incorporating these losses into fine-tuning not only preserves subject identity
but also enhances image diversity, outperforming DreamBooth in terms of CLIP
scores, background variation, and overall visual quality.

</details>


### [821] [Accelerating 3D Gaussian Splatting with Neural Sorting and Axis-Oriented Rasterization](https://arxiv.org/abs/2506.07069)
*Zhican Wang,Guanghui He,Dantong Liu,Lingjun Gao,Shell Xu Hu,Chen Zhang,Zhuoran Song,Nicholas Lane,Wayne Luk,Hongxiang Fan*

Main category: cs.GR

TL;DR: 该论文提出了一种针对3D高斯泼溅的架构-算法协同设计，通过轴定向栅格化、神经排序和可重构处理阵列等技术，在保证渲染质量的同时显著提升资源受限设备的性能和能效。


<details>
  <summary>Details</summary>
Motivation: 3D高斯泼溅技术在资源受限设备上的实时渲染面临计算冗余和硬件效率低下的问题。现有方法存在重复计算、排序资源消耗高和硬件利用率低等效率瓶颈，需要更高效的解决方案。

Method: 1. 轴定向栅格化：沿X/Y轴预计算共享项，减少63%乘加运算
2. 神经排序：用神经网络预测混合权重，替代硬件排序器
3. 可重构处理阵列：统一支持栅格化和神经网络推理
4. π轨迹片调度：优化高斯复用与内存访问

Result: 相比边缘GPU实现：
- 速度提升23.4~27.8倍
- 节能28.8~51.4倍
完整保持渲染质量

Conclusion: 该协同设计方案有效解决了3D高斯泼溅在资源受限设备上的低效问题，为AR/VR等应用提供了实时高效渲染途径

Abstract: 3D Gaussian Splatting (3DGS) has recently gained significant attention for
high-quality and efficient view synthesis, making it widely adopted in fields
such as AR/VR, robotics, and autonomous driving. Despite its impressive
algorithmic performance, real-time rendering on resource-constrained devices
remains a major challenge due to tight power and area budgets. This paper
presents an architecture-algorithm co-design to address these inefficiencies.
First, we reveal substantial redundancy caused by repeated computation of
common terms/expressions during the conventional rasterization. To resolve
this, we propose axis-oriented rasterization, which pre-computes and reuses
shared terms along both the X and Y axes through a dedicated hardware design,
effectively reducing multiply-and-add (MAC) operations by up to 63%. Second, by
identifying the resource and performance inefficiency of the sorting process,
we introduce a novel neural sorting approach that predicts order-independent
blending weights using an efficient neural network, eliminating the need for
costly hardware sorters. A dedicated training framework is also proposed to
improve its algorithmic stability. Third, to uniformly support rasterization
and neural network inference, we design an efficient reconfigurable processing
array that maximizes hardware utilization and throughput. Furthermore, we
introduce a $\pi$-trajectory tile schedule, inspired by Morton encoding and
Hilbert curve, to optimize Gaussian reuse and reduce memory access overhead.
Comprehensive experiments demonstrate that the proposed design preserves
rendering quality while achieving a speedup of $23.4\sim27.8\times$ and energy
savings of $28.8\sim51.4\times$ compared to edge GPUs for real-world scenes. We
plan to open-source our design to foster further development in this field.

</details>


### [822] [HOI-PAGE: Zero-Shot Human-Object Interaction Generation with Part Affordance Guidance](https://arxiv.org/abs/2506.07209)
*Lei Li,Angela Dai*

Main category: cs.GR

TL;DR: 零樣本文本驅動4D人體-物件互動合成新方法HOI-PAGE：通過部位級功ﬁ推理解決全局運動方法不足，首創部件功能圖指導三階段合成


<details>
  <summary>Details</summary>
Motivation: 現有4D HOI生成方法僅關注整體運動，缺乏對人體部位與物件部件互動細節的解讀，導致真實性與多樣性不足

Method: 1. 基於大語言模型構建部件功能圖(PAG)  2. 三階段合成：物件部件分解→文本生成參考視頻→提取部位運動約束  3. 優化帶有部件接觸約束的4D運動序列

Result: 實現複雜互動合成（多人/多物件），在零樣本設定下顯著提升真實度與文本對齊度

Conclusion: 部件級功ﬁ推理的結構化表示與三階段優化機制，突破4D HOI合成的細粒度控制瓶頸

Abstract: We present HOI-PAGE, a new approach to synthesizing 4D human-object
interactions (HOIs) from text prompts in a zero-shot fashion, driven by
part-level affordance reasoning. In contrast to prior works that focus on
global, whole body-object motion for 4D HOI synthesis, we observe that
generating realistic and diverse HOIs requires a finer-grained understanding --
at the level of how human body parts engage with object parts. We thus
introduce Part Affordance Graphs (PAGs), a structured HOI representation
distilled from large language models (LLMs) that encodes fine-grained part
information along with contact relations. We then use these PAGs to guide a
three-stage synthesis: first, decomposing input 3D objects into geometric
parts; then, generating reference HOI videos from text prompts, from which we
extract part-based motion constraints; finally, optimizing for 4D HOI motion
sequences that not only mimic the reference dynamics but also satisfy
part-level contact constraints. Extensive experiments show that our approach is
flexible and capable of generating complex multi-object or multi-person
interaction sequences, with significantly improved realism and text alignment
for zero-shot 4D HOI generation.

</details>


### [823] [PIG: Physically-based Multi-Material Interaction with 3D Gaussians](https://arxiv.org/abs/2506.07657)
*Zeyu Xiao,Zhenyi Wu,Mingyang Sun,Qipeng Yan,Yufan Guo,Zhuoer Liang,Lihua Zhang*

Main category: cs.GR

TL;DR: PIG 是一个基于物理的多材料交互框架，使用 3D 高斯泼溅技术来解决物体交互时的分割不准确、变形不精确和渲染伪影问题，实现了高质量的物理真实场景生成。


<details>
  <summary>Details</summary>
Motivation: 现有 3D 高斯泼溅方法在物体交互中存在三大问题：1) 不准确的 3D 分割 2) 不同材料间变形不精确 3) 严重的渲染伪影。这些限制了物理真实场景重建的质量。

Method: 1) 建立 2D 像素到 3D 高斯的快速准确映射实现精确分割 2) 为分割对象赋予物理属性实现多材料耦合 3) 在变形梯度中嵌入约束尺度，通过钳制高斯基元的缩放/旋转消除伪影。

Result: 实验证明该方法在视觉质量上超越 SOTA，同时为物理真实场景生成开辟了新方向。

Conclusion: PIG 首次将物理交互引入 3D 高斯表示框架，解决了核心交互问题，提供了高保真、视觉一致的动态场景重建方案。

Abstract: 3D Gaussian Splatting has achieved remarkable success in reconstructing both
static and dynamic 3D scenes. However, in a scene represented by 3D Gaussian
primitives, interactions between objects suffer from inaccurate 3D
segmentation, imprecise deformation among different materials, and severe
rendering artifacts. To address these challenges, we introduce PIG:
Physically-Based Multi-Material Interaction with 3D Gaussians, a novel approach
that combines 3D object segmentation with the simulation of interacting objects
in high precision. Firstly, our method facilitates fast and accurate mapping
from 2D pixels to 3D Gaussians, enabling precise 3D object-level segmentation.
Secondly, we assign unique physical properties to correspondingly segmented
objects within the scene for multi-material coupled interactions. Finally, we
have successfully embedded constraint scales into deformation gradients,
specifically clamping the scaling and rotation properties of the Gaussian
primitives to eliminate artifacts and achieve geometric fidelity and visual
consistency. Experimental results demonstrate that our method not only
outperforms the state-of-the-art (SOTA) in terms of visual quality, but also
opens up new directions and pipelines for the field of physically realistic
scene generation.

</details>


### [824] [GaussianVAE: Adaptive Learning Dynamics of 3D Gaussians for High-Fidelity Super-Resolution](https://arxiv.org/abs/2506.07897)
*Shuja Khalid,Mohamed Ibrahim,Yang Liu*

Main category: cs.GR

TL;DR: 本文提出了一种轻量级生成模型，通过基于Hessian辅助采样的智能高斯点预测与优化方法，打破了现有3D高斯泼溅技术(3DGS)的分辨率限制，实现了实时超分辨率重建。


<details>
  <summary>Details</summary>
Motivation: 现有3DGS方法受限于输入图像分辨率，无法重建超出训练视图精细度的细节，需开发突破此限制的实时增强方案。

Method: 采用Hessian辅助采样策略识别需加密区域，轻量级生成模型预测并优化新增3D高斯属性，避免使用复杂GAN/扩散模型。

Result: 在消费级GPU实现0.015秒/帧实时推理，几何精度与渲染质量显著超越SOTA，建立分辨无关的3D场景增强新范式。

Conclusion: 该实时高效方法突破了3DGS分辨率限制，为交互式应用提供新解决方案。

Abstract: We present a novel approach for enhancing the resolution and geometric
fidelity of 3D Gaussian Splatting (3DGS) beyond native training resolution.
Current 3DGS methods are fundamentally limited by their input resolution,
producing reconstructions that cannot extrapolate finer details than are
present in the training views. Our work breaks this limitation through a
lightweight generative model that predicts and refines additional 3D Gaussians
where needed most. The key innovation is our Hessian-assisted sampling
strategy, which intelligently identifies regions that are likely to benefit
from densification, ensuring computational efficiency. Unlike computationally
intensive GANs or diffusion approaches, our method operates in real-time
(0.015s per inference on a single consumer-grade GPU), making it practical for
interactive applications. Comprehensive experiments demonstrate significant
improvements in both geometric accuracy and rendering quality compared to
state-of-the-art methods, establishing a new paradigm for resolution-free 3D
scene enhancement.

</details>


### [825] [Speedy Deformable 3D Gaussian Splatting: Fast Rendering and Compression of Dynamic Scenes](https://arxiv.org/abs/2506.07917)
*Allen Tu,Haiyang Ying,Alex Hanson,Yonghan Lee,Tom Goldstein,Matthias Zwicker*

Main category: cs.GR

TL;DR: SpeeDe3DGS提出了一种加速动态3D高斯泼溅渲染速度的通用方法，通过时间敏感度剪枝和分组运动分析技术，大幅提升渲染速度并减小模型大小。


<details>
  <summary>Details</summary>
Motivation: 现有动态3DGS方法对每个高斯进行逐帧神经推断，导致渲染速度慢、内存和计算需求高，需优化计算效率。

Method: 1. 时间敏感度剪枝：基于对动态场景重建的贡献度移除低贡献高斯，辅以平滑剪枝机制提升鲁棒性；2. GroupFlow：通过轨迹相似性聚类高斯，每组预测单一刚性变换而非单点形变。

Result: 在NeRF-DS数据集上实现10.37倍渲染加速、7.71倍模型压缩和2.71倍训练加速；在D-NeRF和HyperNeRF数据集上分别提速4.20倍和58.23倍。

Conclusion: 该模块化方案可无缝集成到任意可变形3DGS/4DGS框架，显著提升计算效率。

Abstract: Recent extensions of 3D Gaussian Splatting (3DGS) to dynamic scenes achieve
high-quality novel view synthesis by using neural networks to predict the
time-varying deformation of each Gaussian. However, performing per-Gaussian
neural inference at every frame poses a significant bottleneck, limiting
rendering speed and increasing memory and compute requirements. In this paper,
we present Speedy Deformable 3D Gaussian Splatting (SpeeDe3DGS), a general
pipeline for accelerating the rendering speed of dynamic 3DGS and 4DGS
representations by reducing neural inference through two complementary
techniques. First, we propose a temporal sensitivity pruning score that
identifies and removes Gaussians with low contribution to the dynamic scene
reconstruction. We also introduce an annealing smooth pruning mechanism that
improves pruning robustness in real-world scenes with imprecise camera poses.
Second, we propose GroupFlow, a motion analysis technique that clusters
Gaussians by trajectory similarity and predicts a single rigid transformation
per group instead of separate deformations for each Gaussian. Together, our
techniques accelerate rendering by $10.37\times$, reduce model size by
$7.71\times$, and shorten training time by $2.71\times$ on the NeRF-DS dataset.
SpeeDe3DGS also improves rendering speed by $4.20\times$ and $58.23\times$ on
the D-NeRF and HyperNeRF vrig datasets. Our methods are modular and can be
integrated into any deformable 3DGS or 4DGS framework.

</details>


### [826] [Squeeze3D: Your 3D Generation Model is Secretly an Extreme Neural Compressor](https://arxiv.org/abs/2506.07932)
*Rishit Dagli,Yushi Guan,Sankeerth Durvasula,Mohammadreza Mofayezi,Nandita Vijaykumar*

Main category: cs.GR

TL;DR: Squeeze3D是一种新型压缩框架，利用预训练3D生成模型的隐式先验知识，在极高压缩比下实现3D数据压缩。它通过可训练的映射网络连接预训练编码器和生成模型的潜在空间，支持网格、点云和辐射场多种格式，无需真实3D数据集训练。实验显示压缩比高达2187倍（带纹理网格）、55倍（点云）和619倍（辐射场），且视觉质量与现有方法相当，延迟较低。


<details>
  <summary>Details</summary>
Motivation: 现有3D数据压缩方法难以在维持视觉质量的同时实现极高压缩比。Squeeze3D通过重用预训练3D生成模型学到的先验知识，解决高压缩比下传统压缩技术在复杂3D数据上的局限。其动机是在避免真实数据依赖的前提下，实现多格式3D内容的高效压缩。

Method: 1. 使用预训练编码器将输入3D数据（网格/点云/辐射场）编码为初始潜在表示。
2. 通过可训练映射网络将该表示压缩为紧凑的潜在代码。
3. 另一映射网络将压缩代码转换到预训练生成模型的潜在空间。
4. 生成模型根据该条件重建原始3D数据完成解压。
关键点：完全在合成数据上训练，支持任意预训练模型组合，无需针对单个对象训练。

Result: 在纹理网格（2187x）、点云（55x）和辐射场（619x）三类数据上实现远超传统方法的高压缩比。视觉质量与现有方法相当（未明确指标），压缩/解压延迟低（因避免对象专用网络）。实验细节：基于生成合成数据训练，未使用真实3D数据集。

Conclusion: Squeeze3D证明通过桥接预训练模型的潜在空间，可在多类别3D数据上实现超高压缩比，且保持重建质量。其免对象专用训练、支持异构格式的架构设计具有实用性。未讨论的局限：生成模型的域适应性、量化指标对比、极端压缩下的失真分析。

Abstract: We propose Squeeze3D, a novel framework that leverages implicit prior
knowledge learnt by existing pre-trained 3D generative models to compress 3D
data at extremely high compression ratios. Our approach bridges the latent
spaces between a pre-trained encoder and a pre-trained generation model through
trainable mapping networks. Any 3D model represented as a mesh, point cloud, or
a radiance field is first encoded by the pre-trained encoder and then
transformed (i.e. compressed) into a highly compact latent code. This latent
code can effectively be used as an extremely compressed representation of the
mesh or point cloud. A mapping network transforms the compressed latent code
into the latent space of a powerful generative model, which is then conditioned
to recreate the original 3D model (i.e. decompression). Squeeze3D is trained
entirely on generated synthetic data and does not require any 3D datasets. The
Squeeze3D architecture can be flexibly used with existing pre-trained 3D
encoders and existing generative models. It can flexibly support different
formats, including meshes, point clouds, and radiance fields. Our experiments
demonstrate that Squeeze3D achieves compression ratios of up to 2187x for
textured meshes, 55x for point clouds, and 619x for radiance fields while
maintaining visual quality comparable to many existing methods. Squeeze3D only
incurs a small compression and decompression latency since it does not involve
training object-specific networks to compress an object.

</details>


<div id='cs.IR'></div>

# cs.IR [[Back]](#toc)

### [827] [DISRetrieval: Harnessing Discourse Structure for Long Document Retrieval](https://arxiv.org/abs/2506.06313)
*Huiyao Chen,Yi Yang,Yinghui Li,Meishan Zhang,Min Zhang*

Main category: cs.IR

TL;DR: DISRetrieval, a hierarchical retrieval framework using discourse structure, improves long document understanding by capturing inherent document organization.


<details>
  <summary>Details</summary>
Motivation: Existing retrieval methods for long documents fail to capture discourse structure, which is important for human comprehension. The authors aim to enhance document understanding by incorporating rhetorical structure.

Method: 1. Discourse-aware document organization using RST to create sentence-level hierarchical representations 2. LLM-enhanced node representation combining structure with adaptive summarization 3. Hierarchical evidence retrieval mechanism

Result: Substantial improvements in retrieval metrics and QA tasks on QASPER and QuALITY datasets. Ablation studies confirm discourse structure's importance in retrieval effectiveness.

Conclusion: Incorporating linguistic discourse structure significantly enhances long document understanding and retrieval performance. The approach is validated across document lengths and query types.

Abstract: Long document understanding has become increasingly crucial in natural
language processing, with retrieval-based methods emerging as a promising
solution to address the context length limitations of large language models
(LLMs). However, existing approaches either treat documents as flat sequences
or employ arbitrary chunking strategies, failing to capture the inherent
discourse structure that guides human comprehension. We present DISRetrieval, a
novel hierarchical retrieval framework that leverages linguistic discourse
structure to enhance long document understanding. Our approach introduces three
key innovations: (1) a discourse-aware document organization framework that
utilizes rhetorical structure theory (RST) to create sentence-level
hierarchical representations, preserving both semantic relationships and
natural document flow; (2) an LLM-enhanced node representation technique that
combines discourse structure with adaptive summarization to enrich tree nodes
with contextual information; and (3) a hierarchical evidence retrieval
mechanism that effectively selects relevant content while maintaining discourse
coherence. Through comprehensive experiments on QASPER and QuALITY datasets,
DISRetrieval demonstrates substantial improvements over existing methods in
both token-level retrieval metrics and downstream question answering tasks. Our
ablation studies confirm that incorporating discourse structure significantly
enhances retrieval effectiveness across different document lengths and query
types, validating the importance of linguistically-informed document
representation in long-text understanding. Our code and datasets are publicly
available at github/DreamH1gh/DISRetrieval to facilitate future research.

</details>


### [828] [Is BERTopic Better than PLSA for Extracting Key Topics in Aviation Safety Reports?](https://arxiv.org/abs/2506.06328)
*Aziida Nanyonga,Joiner Keith,Turhan Ugur,Wild Graham*

Main category: cs.IR

TL;DR: 该研究比较了BERTopic和概率潜在语义分析（PLSA）在航空安全报告中的主题建模效果，发现基于Transformer的BERTopic在主题连贯性和可解释性上均优于PLSA。


<details>
  <summary>Details</summary>
Motivation: 旨在提升航空事故数据的模式理解能力，通过比较现代主题建模方法与传统方法在航空安全领域的有效性。

Method: 使用36,000多份NTSB航空事故报告（2000-2020年），BERTopic采用Transformer嵌入和层次聚类，PLSA采用期望最大化算法进行概率建模。

Result: BERTopic的Cv主题连贯性得分为0.41，优于PLSA的0.37，且航空安全专家验证其具有更优的可解释性。

Conclusion: 基于Transformer的现代方法在复杂航空数据分析中具有优势，为提升安全决策提供支持；未来将探索混合模型、多语言数据及先进聚类技术。

Abstract: This study compares the effectiveness of BERTopic and Probabilistic Latent
Semantic Analysis (PLSA) in extracting meaningful topics from aviation safety
reports aiming to enhance the understanding of patterns in aviation incident
data. Using a dataset of over 36,000 National Transportation Safety Board
(NTSB) reports from 2000 to 2020, BERTopic employed transformer based
embeddings and hierarchical clustering, while PLSA utilized probabilistic
modelling through the Expectation-Maximization (EM) algorithm. Results showed
that BERTopic outperformed PLSA in topic coherence, achieving a Cv score of
0.41 compared to PLSA 0.37, while also demonstrating superior interpretability
as validated by aviation safety experts. These findings underscore the
advantages of modern transformer based approaches in analyzing complex aviation
datasets, paving the way for enhanced insights and informed decision-making in
aviation safety. Future work will explore hybrid models, multilingual datasets,
and advanced clustering techniques to further improve topic modelling in this
domain.

</details>


### [829] [FinBERT2: A Specialized Bidirectional Encoder for Bridging the Gap in Finance-Specific Deployment of Large Language Models](https://arxiv.org/abs/2506.06335)
*Xuan Xu,Fufang Wen,Beilin Chu,Zhibing Fu,Qinhong Lin,Jiaqi Liu,Binjie Fei,Zhongliang Yang,Linna Zhou,Yu Li*

Main category: cs.IR

TL;DR: 提出了FinBERT2模型，该模型在高质量金融语料上预训练，在金融领域的分类、检索和主题建模任务中均超越现有模型（包括LLMs和其他BERT变体）


<details>
  <summary>Details</summary>
Motivation: 当前大型语言模型（LLMs）在金融领域应用存在三个问题：1）判别任务表现不如微调BERT但计算成本更高；2）生成任务依赖检索增强生成（RAG），但通用检索器在专业领域表现不佳；3）主题建模等特征场景存在不足

Method: 构建32b token中英金融语料库，训练双向编码器FinBERT2作为基础模型，并派生出三种用途模型：分类模型（Fin-Labelers）、检索模型（Fin-Retrievers）和主题模型（Fin-TopicModel）

Result: 1）分类任务：Fin-Labelers平均超越其他BERT变体0.4%-3.3%，超越主流LLMs 9.7%-12.3%；2）检索任务：Fin-Retrievers平均超越开源嵌入模型6.8%（如BGE-base-zh），超越商业模型4.2%（如OpenAI embeddings）；3）主题建模：Fin-TopicModel在金融标题聚类和主题表示方面表现更优

Conclusion: FinBERT2重新确立了BERT架构在金融领域的价值，为LLMs时代的高效专业模型部署提供了实践方案

Abstract: In natural language processing (NLP), the focus has shifted from encoder-only
tiny language models like BERT to decoder-only large language models(LLMs) such
as GPT-3. However, LLMs' practical application in the financial sector has
revealed three limitations: (1) LLMs often perform worse than fine-tuned BERT
on discriminative tasks despite costing much higher computational resources,
such as market sentiment analysis in financial reports; (2) Application on
generative tasks heavily relies on retrieval augmented generation (RAG) methods
to provide current and specialized information, with general retrievers showing
suboptimal performance on domain-specific retrieval tasks; (3) There are
additional inadequacies in other feature-based scenarios, such as topic
modeling. We introduce FinBERT2, a specialized bidirectional encoder pretrained
on a high-quality, financial-specific corpus of 32b tokens. This represents the
largest known Chinese financial pretraining corpus for models of this parameter
size. As a better backbone, FinBERT2 can bridge the gap in the
financial-specific deployment of LLMs through the following achievements: (1)
Discriminative fine-tuned models (Fin-Labelers) outperform other (Fin)BERT
variants by 0.4%-3.3% and leading LLMs by 9.7%-12.3% on average across five
financial classification tasks. (2) Contrastive fine-tuned models
(Fin-Retrievers) outperform both open-source (e.g., +6.8\% avg improvement over
BGE-base-zh) and proprietary (e.g., +4.2\% avg improvement over OpenAI's
text-embedding-3-large) embedders across five financial retrieval tasks; (3)
Building on FinBERT2 variants, we construct the Fin-TopicModel, which enables
superior clustering and topic representation for financial titles. Our work
revisits financial BERT models through comparative analysis with contemporary
LLMs and offers practical insights for effectively utilizing FinBERT in the
LLMs era.

</details>


### [830] [Optimizing RAG Pipelines for Arabic: A Systematic Analysis of Core Components](https://arxiv.org/abs/2506.06339)
*Jumana Alsubhi,Mohammad D. Alahmadi,Ahmed Alhusayni,Ibrahim Aldailami,Israa Hamdine,Ahmad Shabana,Yazeed Iskandar,Suhayb Khayyat*

Main category: cs.IR

TL;DR: 论文提供了针对阿拉伯语RAG组件的全面实证评估，包括分块策略、嵌入模型、重排序器和语言模型，并给出了优化阿拉伯语RAG管道的实用指南。


<details>
  <summary>Details</summary>
Motivation: 尽管检索增强生成(RAG)结合了检索系统的精确性和大型语言模型的流畅性，但对阿拉伯语RAG组件的优化仍缺乏充分研究。

Method: 使用RAGAS框架在多组阿拉伯语数据集上系统评估了先进RAG组件（如分块策略、嵌入模型、重排序器、语言模型）在四项核心指标上的性能。

Result: 实验表明：句子分块策略最优；BGE-M3和Multilingual-E5-large嵌入模型最有效；bge-reranker-v2-m3显著提升复杂数据集中的忠实度；Aya-8B生成质量优于StableLM。

Conclusion: 研究为构建高质量阿拉伯语RAG管道提供了关键见解，并提供了跨文档类型选择最优组件的实用指南。

Abstract: Retrieval-Augmented Generation (RAG) has emerged as a powerful architecture
for combining the precision of retrieval systems with the fluency of large
language models. While several studies have investigated RAG pipelines for
high-resource languages, the optimization of RAG components for Arabic remains
underexplored. This study presents a comprehensive empirical evaluation of
state-of-the-art RAG components-including chunking strategies, embedding
models, rerankers, and language models-across a diverse set of Arabic datasets.
Using the RAGAS framework, we systematically compare performance across four
core metrics: context precision, context recall, answer faithfulness, and
answer relevancy. Our experiments demonstrate that sentence-aware chunking
outperforms all other segmentation methods, while BGE-M3 and
Multilingual-E5-large emerge as the most effective embedding models. The
inclusion of a reranker (bge-reranker-v2-m3) significantly boosts faithfulness
in complex datasets, and Aya-8B surpasses StableLM in generation quality. These
findings provide critical insights for building high-quality Arabic RAG
pipelines and offer practical guidelines for selecting optimal components
across different document types.

</details>


### [831] [LlamaRec-LKG-RAG: A Single-Pass, Learnable Knowledge Graph-RAG Framework for LLM-Based Ranking](https://arxiv.org/abs/2506.07449)
*Vahid Azizi,Fatemeh Koochaki*

Main category: cs.IR

TL;DR: 论文提出了LlamaRec-LKG-RAG框架，通过在LLM推荐中集成个性化知识图谱上下文，解决了现有RAG方法依赖扁平化相似性检索的问题，在多个数据集上显著提升了排名指标。


<details>
  <summary>Details</summary>
Motivation: 现有的基于检索增强生成(RAG)的推荐系统主要依赖扁平化的相似性检索，未能充分利用用户-物品互动中固有的丰富关系结构，限制了推荐的个性化和效果。

Method: 扩展LlamaRec架构，引入轻量级用户偏好模块，在异构知识图谱中动态识别重要关系路径，构建个性化子图并整合到微调后的Llama-2模型提示中，实现端到端可训练的统一推理框架。

Result: 在ML-100K和Amazon Beauty数据集上的实验表明，相较于LlamaRec，该方法在MRR、NDCG、Recall等关键排名指标上取得一致且显著的提升。

Conclusion: 该研究证明了结构化推理在LLM推荐中的关键价值，为下一代可扩展、知识感知的个性化推荐系统奠定了基础。

Abstract: Recent advances in Large Language Models (LLMs) have driven their adoption in
recommender systems through Retrieval-Augmented Generation (RAG) frameworks.
However, existing RAG approaches predominantly rely on flat, similarity-based
retrieval that fails to leverage the rich relational structure inherent in
user-item interactions. We introduce LlamaRec-LKG-RAG, a novel single-pass,
end-to-end trainable framework that integrates personalized knowledge graph
context into LLM-based recommendation ranking. Our approach extends the
LlamaRec architecture by incorporating a lightweight user preference module
that dynamically identifies salient relation paths within a heterogeneous
knowledge graph constructed from user behavior and item metadata. These
personalized subgraphs are seamlessly integrated into prompts for a fine-tuned
Llama-2 model, enabling efficient and interpretable recommendations through a
unified inference step. Comprehensive experiments on ML-100K and Amazon Beauty
datasets demonstrate consistent and significant improvements over LlamaRec
across key ranking metrics (MRR, NDCG, Recall). LlamaRec-LKG-RAG demonstrates
the critical value of structured reasoning in LLM-based recommendations and
establishes a foundation for scalable, knowledge-aware personalization in
next-generation recommender systems. Code is available
at~\href{https://github.com/VahidAz/LlamaRec-LKG-RAG}{repository}.

</details>


### [832] [HotelMatch-LLM: Joint Multi-Task Training of Small and Large Language Models for Efficient Multimodal Hotel Retrieval](https://arxiv.org/abs/2506.07296)
*Arian Askari,Emmanouil Stergiadis,Ilya Gusev,Moran Beladev*

Main category: cs.IR

TL;DR: 酒店Match-LLM提出了一种针对旅游领域的多模态密集检索模型，通过多任务优化、非对称架构和图像处理技术，显著提升了自然语言酒店搜索性能。


<details>
  <summary>Details</summary>
Motivation: 传统旅游搜索引擎要求用户先选择目的地再调整参数，存在使用限制。

Method: 提出三创新：(1)领域特定多任务优化（检索/视觉/语言目标）；(2)非对称密集检索（SLM处理查询+LLM生成酒店嵌入）；(3)全量图库图像处理。

Result: 四个数据集超越SOTA模型（VISTA/MARVEL），主查询类型指标0.681 vs MARVEL 0.603。

Conclusion: 该模型的多任务优化有效，具备架构通用性和处理大规模图库的可扩展性。

Abstract: We present HotelMatch-LLM, a multimodal dense retrieval model for the travel
domain that enables natural language property search, addressing the
limitations of traditional travel search engines which require users to start
with a destination and editing search parameters. HotelMatch-LLM features three
key innovations: (1) Domain-specific multi-task optimization with three novel
retrieval, visual, and language modeling objectives; (2) Asymmetrical dense
retrieval architecture combining a small language model (SLM) for efficient
online query processing and a large language model (LLM) for embedding hotel
data; and (3) Extensive image processing to handle all property image
galleries. Experiments on four diverse test sets show HotelMatch-LLM
significantly outperforms state-of-the-art models, including VISTA and MARVEL.
Specifically, on the test set -- main query type -- we achieve 0.681 for
HotelMatch-LLM compared to 0.603 for the most effective baseline, MARVEL. Our
analysis highlights the impact of our multi-task optimization, the
generalizability of HotelMatch-LLM across LLM architectures, and its
scalability for processing large image galleries.

</details>


### [833] [DISRetrieval: Harnessing Discourse Structure for Long Document Retrieval](https://arxiv.org/abs/2506.06313)
*Huiyao Chen,Yi Yang,Yinghui Li,Meishan Zhang,Min Zhang*

Main category: cs.IR

TL;DR: DISRetrieval是一个新型分层检索框架，利用语言学篇章结构增强长文档理解。包含三个创新点：篇章感知文档组织、LLM增强节点表示和分层证据检索机制，在多个数据集上显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有检索方法无法捕捉文档固有的篇章结构，而该结构对人类理解至关重要。DISRetrieval旨在通过语言学结构解决长文档理解中上下文长度限制问题。

Method: 利用修辞结构理论创建句子级分层表示；结合篇章结构和自适应摘要的LLM节点表示；保持篇章连贯性的分层证据检索。

Result: 在QASPER和QuALITY数据集上，检索指标和问答任务表现均显著优于现有方法；消融研究证明引入篇章结构能提升不同文档长度和查询类型的检索效果。

Conclusion: 语言学引导的文档表征对长文本理解至关重要；公开代码和数据集促进后续研究。

Abstract: Long document understanding has become increasingly crucial in natural
language processing, with retrieval-based methods emerging as a promising
solution to address the context length limitations of large language models
(LLMs). However, existing approaches either treat documents as flat sequences
or employ arbitrary chunking strategies, failing to capture the inherent
discourse structure that guides human comprehension. We present DISRetrieval, a
novel hierarchical retrieval framework that leverages linguistic discourse
structure to enhance long document understanding. Our approach introduces three
key innovations: (1) a discourse-aware document organization framework that
utilizes rhetorical structure theory (RST) to create sentence-level
hierarchical representations, preserving both semantic relationships and
natural document flow; (2) an LLM-enhanced node representation technique that
combines discourse structure with adaptive summarization to enrich tree nodes
with contextual information; and (3) a hierarchical evidence retrieval
mechanism that effectively selects relevant content while maintaining discourse
coherence. Through comprehensive experiments on QASPER and QuALITY datasets,
DISRetrieval demonstrates substantial improvements over existing methods in
both token-level retrieval metrics and downstream question answering tasks. Our
ablation studies confirm that incorporating discourse structure significantly
enhances retrieval effectiveness across different document lengths and query
types, validating the importance of linguistically-informed document
representation in long-text understanding. Our code and datasets are publicly
available at github/DreamH1gh/DISRetrieval to facilitate future research.

</details>


### [834] [Is BERTopic Better than PLSA for Extracting Key Topics in Aviation Safety Reports?](https://arxiv.org/abs/2506.06328)
*Aziida Nanyonga,Joiner Keith,Turhan Ugur,Wild Graham*

Main category: cs.IR

TL;DR: 比较了 BERTopic 和 PLSA 在航空安全报告主题建模中的效果，BERTopic 在主题连贯性和可解释性上优于 PLSA。


<details>
  <summary>Details</summary>
Motivation: 评估现代主题建模方法在航空安全领域的适用性，以提升事故数据的分析能力。

Method: 使用36,000+份NTSB报告，BERTopic采用Transformer嵌入和层次聚类，PLSA使用EM算法概率建模。

Result: BERTopic的Cv分数为0.41（PLSA为0.37），且专家验证其主题可解释性更优。

Conclusion: 基于Transformer的方法在复杂航空数据分析中具有优势，未来将探索混合模型和多语言数据。

Abstract: This study compares the effectiveness of BERTopic and Probabilistic Latent
Semantic Analysis (PLSA) in extracting meaningful topics from aviation safety
reports aiming to enhance the understanding of patterns in aviation incident
data. Using a dataset of over 36,000 National Transportation Safety Board
(NTSB) reports from 2000 to 2020, BERTopic employed transformer based
embeddings and hierarchical clustering, while PLSA utilized probabilistic
modelling through the Expectation-Maximization (EM) algorithm. Results showed
that BERTopic outperformed PLSA in topic coherence, achieving a Cv score of
0.41 compared to PLSA 0.37, while also demonstrating superior interpretability
as validated by aviation safety experts. These findings underscore the
advantages of modern transformer based approaches in analyzing complex aviation
datasets, paving the way for enhanced insights and informed decision-making in
aviation safety. Future work will explore hybrid models, multilingual datasets,
and advanced clustering techniques to further improve topic modelling in this
domain.

</details>


### [835] [FinBERT2: A Specialized Bidirectional Encoder for Bridging the Gap in Finance-Specific Deployment of Large Language Models](https://arxiv.org/abs/2506.06335)
*Xuan Xu,Fufang Wen,Beilin Chu,Zhibing Fu,Qinhong Lin,Jiaqi Liu,Binjie Fei,Zhongliang Yang,Linna Zhou,Yu Li*

Main category: cs.IR

TL;DR: FinBERT2是一个针对金融领域的双向编码器，预训练于一个320亿token的中文金融语料库，解决了当前大型语言模型（LLMs）在金融应用中存在的三个限制，并在分类、检索和主题建模任务上显著优于现有模型。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）在金融领域的实际应用存在三个问题：1. 在判别任务上（如情感分析）性能低于微调的BERT模型；2. 生成任务过度依赖检索增强生成（RAG），但通用检索器在领域特定任务上表现不佳；3. 在特征型场景（如主题建模）存在不足。为弥补这些不足，研究者提出了专门化的FinBERT2模型。

Method: 1. 构建高质量320亿token中文金融语料库进行预训练；2. 提出三种微调变体：（1）Fin-Labelers：用于判别任务（分类）；（2）Fin-Retrievers：用于检索任务（对比学习微调）；（3）Fin-TopicModel：用于主题建模任务。

Result: 1. Fin-Labelers在五项金融分类任务中平均超越其他(BERT)变体0.4%-3.3%，超越领先LLMs 9.7%-12.3%；2. Fin-Retrievers在五项金融检索任务中平均超越开源嵌入模型6.8%（如BGE-base-zh），超越商业模型4.2%（如OpenAI text-embedding-3-large）；3. Fin-TopicModel在金融标题聚类和主题表示方面表现优越。

Conclusion: FinBERT2作为专业领域的编码器模型，有效弥补了LLMs在金融场景下的不足，并通过比较分析为在LLMs时代高效利用领域专用BERT提供了实践指导。

Abstract: In natural language processing (NLP), the focus has shifted from encoder-only
tiny language models like BERT to decoder-only large language models(LLMs) such
as GPT-3. However, LLMs' practical application in the financial sector has
revealed three limitations: (1) LLMs often perform worse than fine-tuned BERT
on discriminative tasks despite costing much higher computational resources,
such as market sentiment analysis in financial reports; (2) Application on
generative tasks heavily relies on retrieval augmented generation (RAG) methods
to provide current and specialized information, with general retrievers showing
suboptimal performance on domain-specific retrieval tasks; (3) There are
additional inadequacies in other feature-based scenarios, such as topic
modeling. We introduce FinBERT2, a specialized bidirectional encoder pretrained
on a high-quality, financial-specific corpus of 32b tokens. This represents the
largest known Chinese financial pretraining corpus for models of this parameter
size. As a better backbone, FinBERT2 can bridge the gap in the
financial-specific deployment of LLMs through the following achievements: (1)
Discriminative fine-tuned models (Fin-Labelers) outperform other (Fin)BERT
variants by 0.4%-3.3% and leading LLMs by 9.7%-12.3% on average across five
financial classification tasks. (2) Contrastive fine-tuned models
(Fin-Retrievers) outperform both open-source (e.g., +6.8\% avg improvement over
BGE-base-zh) and proprietary (e.g., +4.2\% avg improvement over OpenAI's
text-embedding-3-large) embedders across five financial retrieval tasks; (3)
Building on FinBERT2 variants, we construct the Fin-TopicModel, which enables
superior clustering and topic representation for financial titles. Our work
revisits financial BERT models through comparative analysis with contemporary
LLMs and offers practical insights for effectively utilizing FinBERT in the
LLMs era.

</details>


### [836] [Optimizing RAG Pipelines for Arabic: A Systematic Analysis of Core Components](https://arxiv.org/abs/2506.06339)
*Jumana Alsubhi,Mohammad D. Alahmadi,Ahmed Alhusayni,Ibrahim Aldailami,Israa Hamdine,Ahmad Shabana,Yazeed Iskandar,Suhayb Khayyat*

Main category: cs.IR

TL;DR: 该研究对阿拉伯语检索增强生成（RAG）管道进行了全面评估，通过RAGAS框架系统地比较了包括分块策略、嵌入模型、重排器和语言模型在内的多种RAG组件的效果。结果表明分句分块策略表现最佳，BGE-M3和Multilingual-E5-large是最佳嵌入模型，重排器显著提高了复杂数据的可信度，Aya-8B在生成质量上优于StableLM。


<details>
  <summary>Details</summary>
Motivation: 由于对阿拉伯语RAG组件的优化缺乏探索，该研究进行了全面的实证评估，以优化阿拉伯语RAG组件。

Method: 使用RAGAS框架在多种阿拉伯语数据集上评估RAG组件：分块策略、嵌入模型、重排器和语言模型。评估的核心指标包括上下文精确性、上下文回忆性、答案可信度和答案相关性。

Result: 分句分块策略优于其他分割方法；BGE-M3和Multilingual-E5-large是最有效的嵌入模型；重排器（bge-reranker-v2-m3）显著提升了复杂数据集的可信度；Aya-8B生成质量优于StableLM。

Conclusion: 这些发现为构建高质量的阿拉伯语RAG管道提供了关键见解，并为不同文档类型下选择最佳组件提供了实用的指导方针。

Abstract: Retrieval-Augmented Generation (RAG) has emerged as a powerful architecture
for combining the precision of retrieval systems with the fluency of large
language models. While several studies have investigated RAG pipelines for
high-resource languages, the optimization of RAG components for Arabic remains
underexplored. This study presents a comprehensive empirical evaluation of
state-of-the-art RAG components-including chunking strategies, embedding
models, rerankers, and language models-across a diverse set of Arabic datasets.
Using the RAGAS framework, we systematically compare performance across four
core metrics: context precision, context recall, answer faithfulness, and
answer relevancy. Our experiments demonstrate that sentence-aware chunking
outperforms all other segmentation methods, while BGE-M3 and
Multilingual-E5-large emerge as the most effective embedding models. The
inclusion of a reranker (bge-reranker-v2-m3) significantly boosts faithfulness
in complex datasets, and Aya-8B surpasses StableLM in generation quality. These
findings provide critical insights for building high-quality Arabic RAG
pipelines and offer practical guidelines for selecting optimal components
across different document types.

</details>


### [837] [LlamaRec-LKG-RAG: A Single-Pass, Learnable Knowledge Graph-RAG Framework for LLM-Based Ranking](https://arxiv.org/abs/2506.07449)
*Vahid Azizi,Fatemeh Koochaki*

Main category: cs.IR

TL;DR: LlamaRec-LKG-RAG：一种新型端到端可训练的RAG框架，通过个性化知识图谱增强LLM推荐排序性能。


<details>
  <summary>Details</summary>
Motivation: 现有RAG方法主要依赖扁平的相似性检索，未能充分利用用户-物品交互中固有的丰富关系结构。

Method: 扩展LlamaRec架构，整合轻量级用户偏好模块动态识别异构图中的关键关系路径，构建个性化子图并集成到微调的Llama-2模型提示中。

Result: 在ML-100K和Amazon Beauty数据集上显著超越LlamaRec（MRR/NDCG/Recall等排序指标持续提升）。

Conclusion: 验证了结构化推理在LLM推荐中的关键价值，为可扩展的知识感知个性化推荐系统奠定基础。

Abstract: Recent advances in Large Language Models (LLMs) have driven their adoption in
recommender systems through Retrieval-Augmented Generation (RAG) frameworks.
However, existing RAG approaches predominantly rely on flat, similarity-based
retrieval that fails to leverage the rich relational structure inherent in
user-item interactions. We introduce LlamaRec-LKG-RAG, a novel single-pass,
end-to-end trainable framework that integrates personalized knowledge graph
context into LLM-based recommendation ranking. Our approach extends the
LlamaRec architecture by incorporating a lightweight user preference module
that dynamically identifies salient relation paths within a heterogeneous
knowledge graph constructed from user behavior and item metadata. These
personalized subgraphs are seamlessly integrated into prompts for a fine-tuned
Llama-2 model, enabling efficient and interpretable recommendations through a
unified inference step. Comprehensive experiments on ML-100K and Amazon Beauty
datasets demonstrate consistent and significant improvements over LlamaRec
across key ranking metrics (MRR, NDCG, Recall). LlamaRec-LKG-RAG demonstrates
the critical value of structured reasoning in LLM-based recommendations and
establishes a foundation for scalable, knowledge-aware personalization in
next-generation recommender systems. Code is available
at~\href{https://github.com/VahidAz/LlamaRec-LKG-RAG}{repository}.

</details>


### [838] [HotelMatch-LLM: Joint Multi-Task Training of Small and Large Language Models for Efficient Multimodal Hotel Retrieval](https://arxiv.org/abs/2506.07296)
*Arian Askari,Emmanouil Stergiadis,Ilya Gusev,Moran Beladev*

Main category: cs.IR

TL;DR: HotelMatch-LLM是一种创新的多模态酒店检索模型，突破了传统旅游搜索引擎的局限性，通过三项核心技术实现自然语言酒店搜索：领域多任务优化、非对称双模型架构和图像处理能力。实验证明其性能显著优于现有最优模型。


<details>
  <summary>Details</summary>
Motivation: 传统旅游搜索引擎要求用户先指定目的地并调整多项参数，搜索流程繁琐。为提升用户体验，需要开发能够直接理解自然语言查询的酒店检索系统，实现更人性化的搜索方式。

Method: 1) 设计包含检索/视觉/语言三任务的领域多目标优化框架；2) 采用小型语言模型处理查询+大型语言模型嵌入酒店数据的非对称架构；3) 开发全量酒店图库处理方案。

Result: 在4个测试集上全面超越现有SOTA模型，其中在主查询集上达到0.681的指标值，显著优于基线模型MARVEL(0.603)。模型展现优异的泛化能力与图像处理扩展性。

Conclusion: 该模型为旅游搜索提供颠覆性解决方案，多任务优化与非对称架构设计具有行业普适价值，其处理海量图像的扩展性已具备商业部署条件。

Abstract: We present HotelMatch-LLM, a multimodal dense retrieval model for the travel
domain that enables natural language property search, addressing the
limitations of traditional travel search engines which require users to start
with a destination and editing search parameters. HotelMatch-LLM features three
key innovations: (1) Domain-specific multi-task optimization with three novel
retrieval, visual, and language modeling objectives; (2) Asymmetrical dense
retrieval architecture combining a small language model (SLM) for efficient
online query processing and a large language model (LLM) for embedding hotel
data; and (3) Extensive image processing to handle all property image
galleries. Experiments on four diverse test sets show HotelMatch-LLM
significantly outperforms state-of-the-art models, including VISTA and MARVEL.
Specifically, on the test set -- main query type -- we achieve 0.681 for
HotelMatch-LLM compared to 0.603 for the most effective baseline, MARVEL. Our
analysis highlights the impact of our multi-task optimization, the
generalizability of HotelMatch-LLM across LLM architectures, and its
scalability for processing large image galleries.

</details>


<div id='physics.ed-ph'></div>

# physics.ed-ph [[Back]](#toc)

### [839] [Pendulum Tracker -- SimuFísica: A Web-based Tool for Real-time Measurement of Oscillatory Motion](https://arxiv.org/abs/2506.07301)
*Marco P. M. de Souza,Juciane G. Maia,Lilian N. de Andrade*

Main category: physics.ed-ph

TL;DR: Pendulum Tracker is a browser-based app that uses computer vision to track pendulum motion in real time for educational purposes, with features like angle-time graphs, period estimation, and data export.


<details>
  <summary>Details</summary>
Motivation: To provide an accessible tool for real-time pendulum motion analysis in physics education that works across devices without installation, enhancing experimental learning.

Method: Built on SimuFísica platform using OpenCV.js for camera-based pendulum detection, real-time plotting of angle vs time, and period calculation in browser.

Result: Successfully measured pendulum periods, gravitational acceleration, and damped oscillations with high accuracy matching theoretical predictions.

Conclusion: The system offers an accurate, versatile educational tool that simplifies experimental physics teaching through immediate visualization and data export capabilities.

Abstract: We present Pendulum Tracker, a computer vision-based application that enables
real-time measurement of the oscillatory motion of a physical pendulum.
Integrated into the educational platform SimuF\'isica, the system uses the
OpenCV.js library and runs directly in the browser, working on computers,
tablets, and smartphones. The application automatically detects the pendulum's
position via the device's camera, displaying in real time the angle-versus-time
graph and estimates of the oscillation period. Experimental case studies
demonstrate its effectiveness in measuring the period, determining
gravitational acceleration, and analyzing damped oscillations. The results show
excellent agreement with theoretical predictions, confirming the system's
accuracy and its applicability in educational contexts. The accessible
interface and the ability to export raw data make Pendulum Tracker a versatile
tool for experimental physics teaching.

</details>


### [840] [Pendulum Tracker -- SimuFísica: A Web-based Tool for Real-time Measurement of Oscillatory Motion](https://arxiv.org/abs/2506.07301)
*Marco P. M. de Souza,Juciane G. Maia,Lilian N. de Andrade*

Main category: physics.ed-ph

TL;DR: 介绍Pendulum Tracker：一个基于计算机视觉的应用程序，用于实时测量物理摆的振荡运动。集成在SimuFísica教育平台，使用OpenCV.js在浏览器中运行，支持多种设备。自动检测摆的位置，实时显示角度-时间图和周期估计。实验研究证明其在测量周期、重力加速度和分析阻尼振荡中的有效性。结果与理论预测高度一致，验证了其准确性和教育应用价值。易用的界面和数据导出功能使其成为物理教学的多功能工具。


<details>
  <summary>Details</summary>
Motivation: 开发一个方便、准确的实时测量物理摆振荡运动的应用，用于教育环境中，特别是支持多种设备（计算机、平板、智能手机），无需额外设备即可在浏览器中运行，使实验物理教学更加便捷和高效。

Method: 利用OpenCV.js库构建计算机视觉系统，通过设备摄像头自动检测摆的位置，实时显示角度-时间图和振荡周期估计值。

Result: 实验研究表明，该应用在测量周期（确定重力加速度）和分析阻尼振荡方面有效，结果与理论预测高度一致。

Conclusion: Pendulum Tracker是一个在物理教学中准确且多功能的工具，其网页版的可访问性和数据导出功能有利于提升教育价值。

Abstract: We present Pendulum Tracker, a computer vision-based application that enables
real-time measurement of the oscillatory motion of a physical pendulum.
Integrated into the educational platform SimuF\'isica, the system uses the
OpenCV.js library and runs directly in the browser, working on computers,
tablets, and smartphones. The application automatically detects the pendulum's
position via the device's camera, displaying in real time the angle-versus-time
graph and estimates of the oscillation period. Experimental case studies
demonstrate its effectiveness in measuring the period, determining
gravitational acceleration, and analyzing damped oscillations. The results show
excellent agreement with theoretical predictions, confirming the system's
accuracy and its applicability in educational contexts. The accessible
interface and the ability to export raw data make Pendulum Tracker a versatile
tool for experimental physics teaching.

</details>


<div id='eess.SP'></div>

# eess.SP [[Back]](#toc)

### [841] [Benchmarking Early Agitation Prediction in Community-Dwelling People with Dementia Using Multimodal Sensors and Machine Learning](https://arxiv.org/abs/2506.06306)
*Ali Abedi,Charlene H. Chu,Shehroz S. Khan*

Main category: eess.SP

TL;DR: 开发了基于多模态传感器数据的机器学习方法，用于早期预测社区痴呆患者的激越行为，引入新的上下文特征，在最大公开数据集上评估多种模型，最佳方案使用LightGBM达到AUC-ROC 0.9720。


<details>
  <summary>Details</summary>
Motivation: 及时预测激越行为可实现早期干预、减轻护理负担并提升患者和护理人员生活质量，而社区痴呆患者缺乏持续临床监护。

Method: 通过活动数据构建新的激越相关上下文特征；在TIHM数据集（包含2803天家庭活动数据）上评估多种机器学习/深度学习模型，包括单时间点表格数据与多时间点序列数据的二元分类，以及异常检测；最优方案采用当前6小时时间点数据预测下一时间点激越状态，结合时间及历史激越信息增强特征。

Result: 使用LightGBM模型结合时间和历史激越信息时性能最佳：AUC-ROC 0.9720，AUC-PR 0.4320；证明该方法能实现准确、可解释且高效的预测。

Conclusion: 首次建立基于隐私保护传感器数据的社区痴呆护理激越预测技术标杆；支持主动性护理和原地养老，推动精准干预。

Abstract: Agitation is one of the most common responsive behaviors in people living
with dementia, particularly among those residing in community settings without
continuous clinical supervision. Timely prediction of agitation can enable
early intervention, reduce caregiver burden, and improve the quality of life
for both patients and caregivers. This study aimed to develop and benchmark
machine learning approaches for the early prediction of agitation in
community-dwelling older adults with dementia using multimodal sensor data. A
new set of agitation-related contextual features derived from activity data was
introduced and employed for agitation prediction. A wide range of machine
learning and deep learning models was evaluated across multiple problem
formulations, including binary classification for single-timestamp tabular
sensor data and multi-timestamp sequential sensor data, as well as anomaly
detection for single-timestamp tabular sensor data. The study utilized the
Technology Integrated Health Management (TIHM) dataset, the largest publicly
available dataset for remote monitoring of people living with dementia,
comprising 2,803 days of in-home activity, physiology, and sleep data. The most
effective setting involved binary classification of sensor data using the
current 6-hour timestamp to predict agitation at the subsequent timestamp.
Incorporating additional information, such as time of day and agitation
history, further improved model performance, with the highest AUC-ROC of 0.9720
and AUC-PR of 0.4320 achieved by the light gradient boosting machine. This work
presents the first comprehensive benchmarking of state-of-the-art techniques
for agitation prediction in community-based dementia care using
privacy-preserving sensor data. The approach enables accurate, explainable, and
efficient agitation prediction, supporting proactive dementia care and aging in
place.

</details>


### [842] [An Open-Source Python Framework and Synthetic ECG Image Datasets for Digitization, Lead and Lead Name Detection, and Overlapping Signal Segmentation](https://arxiv.org/abs/2506.06315)
*Masoud Rahimi,Reza Karbasi,Abdol-Hossein Vahabie*

Main category: eess.SP

TL;DR: 开源框架生成合成ECG图像数据集，支持ECG数字化、导联识别和波形分割任务。包含四个数据集：数字化图像、YOLO标注检测、单一导联分割（正常/叠加版本）


<details>
  <summary>Details</summary>
Motivation: 促进深度学习在ECG分析中的应用，如ECG数字化、导联区域/名称检测以及像素级波形分割

Method: 基于PTB-XL信号数据集构建框架，生成四类数据集：1) ECG图像与时序信号对 2) YOLO标准标注框 3) 普通单导联分割掩码 4) 叠加波形但掩码纯净的单导联分割

Result: 公开提供Python框架及四套数据集（GitHub/Zenodo），支持多种ECG深度学习任务

Conclusion: 该框架和数据集填补了ECG图像分析领域数据资源空白，为相关深度学习模型开发提供基准

Abstract: We introduce an open-source Python framework for generating synthetic ECG
image datasets to advance critical deep learning-based tasks in ECG analysis,
including ECG digitization, lead region and lead name detection, and
pixel-level waveform segmentation. Using the PTB-XL signal dataset, our
proposed framework produces four open-access datasets: (1) ECG images in
various lead configurations paired with time-series signals for ECG
digitization, (2) ECG images annotated with YOLO-format bounding boxes for
detection of lead region and lead name, (3)-(4) cropped single-lead images with
segmentation masks compatible with U-Net-based models in normal and overlapping
versions. In the overlapping case, waveforms from neighboring leads are
superimposed onto the target lead image, while the segmentation masks remain
clean. The open-source Python framework and datasets are publicly available at
https://github.com/rezakarbasi/ecg-image-and-signal-dataset and
https://doi.org/10.5281/zenodo.15484519, respectively.

</details>


### [843] [Heart Rate Classification in ECG Signals Using Machine Learning and Deep Learning](https://arxiv.org/abs/2506.06349)
*Thien Nhan Vo,Thanh Xuan Truong*

Main category: eess.SP

TL;DR: 本文通过两种方法（传统机器学习与深度学习）对ECG信号的心跳分类进行研究。传统方法使用手工特征和多种分类器，深度学习方法将ECG转为图像并用CNN分类。结果LightGBM准确率高达99%，优于图像方法（F1分0.85）。


<details>
  <summary>Details</summary>
Motivation: 比较基于手工特征的机器学习与基于图像转换的深度学习方法在ECG心跳分类任务上的效果，探索最优解决方案。

Method: 1. 数据预处理（降采样/滤波/归一化）
2. 传统方法：提取HRV/均值/方差/RR间期等特征，使用SVM/随机森林/AdaBoost/LSTM/BiLSTM/LightGBM分类
3. 深度方法：将ECG转为GAF/MTF/RP图像，用VGG/Inception CNN分类

Result: LightGBM表现最佳（准确率99% + F1分0.94），远超图像方法（F1分0.85）。SVM/AdaBoost效果较差。

Conclusion: 手工特征比图像转换方法更能捕捉ECG信号的时序和形态特征。未来可融合多导联信号和跨心跳时序信息以提升效果。

Abstract: This study addresses the classification of heartbeats from ECG signals
through two distinct approaches: traditional machine learning utilizing
hand-crafted features and deep learning via transformed images of ECG beats.
The dataset underwent preprocessing steps, including downsampling, filtering,
and normalization, to ensure consistency and relevance for subsequent analysis.
In the first approach, features such as heart rate variability (HRV), mean,
variance, and RR intervals were extracted to train various classifiers,
including SVM, Random Forest, AdaBoost, LSTM, Bi-directional LSTM, and
LightGBM. The second approach involved transforming ECG signals into images
using Gramian Angular Field (GAF), Markov Transition Field (MTF), and
Recurrence Plots (RP), with these images subsequently classified using CNN
architectures like VGG and Inception.
  Experimental results demonstrate that the LightGBM model achieved the highest
performance, with an accuracy of 99% and an F1 score of 0.94, outperforming the
image-based CNN approach (F1 score of 0.85). Models such as SVM and AdaBoost
yielded significantly lower scores, indicating limited suitability for this
task. The findings underscore the superior ability of hand-crafted features to
capture temporal and morphological variations in ECG signals compared to
image-based representations of individual beats. Future investigations may
benefit from incorporating multi-lead ECG signals and temporal dependencies
across successive beats to enhance classification accuracy further.

</details>


### [844] [Benchmarking Early Agitation Prediction in Community-Dwelling People with Dementia Using Multimodal Sensors and Machine Learning](https://arxiv.org/abs/2506.06306)
*Ali Abedi,Charlene H. Chu,Shehroz S. Khan*

Main category: eess.SP

TL;DR: 该研究开发了一种基于多模态传感器数据的机器学习模型，用于早期预测社区痴呆症患者的激越行为。最佳模型使用光梯度提升机实现了高准确率（AUC-ROC 0.9720），能够支持主动干预和居家养老。


<details>
  <summary>Details</summary>
Motivation: 及时预测痴呆患者的激越行为可降低照护负担并改善生活质量。由于社区居住患者缺乏持续临床监督，需要利用传感器数据开发预测方法。

Method: 1）提出新型激越相关环境特征；2）评估多种机器学习模型（包括表格数据二分类和序列数据预测）；3）基于TIHM数据集（2803天家庭监测数据）进行训练测试。

Result: 最佳方案：当前6小时时间戳预测下一时间点激越行为（加入时间和历史信息）。轻量梯度提升机表现最优（AUC-ROC 0.9720，AUC-PR 0.4320）。

Conclusion: 该研究首次建立了利用隐私保护传感器数据进行激越预测的完整基准，实现了可解释的实时预测，支持主动式痴呆照护。

Abstract: Agitation is one of the most common responsive behaviors in people living
with dementia, particularly among those residing in community settings without
continuous clinical supervision. Timely prediction of agitation can enable
early intervention, reduce caregiver burden, and improve the quality of life
for both patients and caregivers. This study aimed to develop and benchmark
machine learning approaches for the early prediction of agitation in
community-dwelling older adults with dementia using multimodal sensor data. A
new set of agitation-related contextual features derived from activity data was
introduced and employed for agitation prediction. A wide range of machine
learning and deep learning models was evaluated across multiple problem
formulations, including binary classification for single-timestamp tabular
sensor data and multi-timestamp sequential sensor data, as well as anomaly
detection for single-timestamp tabular sensor data. The study utilized the
Technology Integrated Health Management (TIHM) dataset, the largest publicly
available dataset for remote monitoring of people living with dementia,
comprising 2,803 days of in-home activity, physiology, and sleep data. The most
effective setting involved binary classification of sensor data using the
current 6-hour timestamp to predict agitation at the subsequent timestamp.
Incorporating additional information, such as time of day and agitation
history, further improved model performance, with the highest AUC-ROC of 0.9720
and AUC-PR of 0.4320 achieved by the light gradient boosting machine. This work
presents the first comprehensive benchmarking of state-of-the-art techniques
for agitation prediction in community-based dementia care using
privacy-preserving sensor data. The approach enables accurate, explainable, and
efficient agitation prediction, supporting proactive dementia care and aging in
place.

</details>


### [845] [An Open-Source Python Framework and Synthetic ECG Image Datasets for Digitization, Lead and Lead Name Detection, and Overlapping Signal Segmentation](https://arxiv.org/abs/2506.06315)
*Masoud Rahimi,Reza Karbasi,Abdol-Hossein Vahabie*

Main category: eess.SP

TL;DR: 介绍了一个开源的Python框架，用于生成合成心电图（ECG）图像数据集，以支持基于深度学习的心电图分析任务。该框架基于PTB-XL信号数据集生成了四个开放访问的数据集。


<details>
  <summary>Details</summary>
Motivation: 当前在ECG分析中，深度学习任务如ECG数字化、导联区域和导联名称检测以及像素级波形分割需要大量标注数据。真实数据获取困难，因此需要创建合成数据集来推进这些任务。

Method: 利用PTB-XL信号数据集开发开源Python框架生成合成ECG图像。生成四个数据集：1) 各种导联配置的ECG图像与时间序列信号配对（用于数字化）；2) 带有YOLO格式边界框标注的图像（用于导联区域和名称检测）；3) 正常版本的单导联裁剪图像及分割掩码；4) 重叠版本的同类数据（相邻导联波形叠加到目标导联图像上）。

Result: 成功生成了四个公开可用的ECG图像数据集，涵盖不同任务格式需求。框架和数据集已在GitHub和Zenodo开源。

Conclusion: 该工作填补了ECG图像合成数据集的空白，为多类深度学习任务提供了标准化基准数据。通过生成可控的合成数据（特别是带有重叠波形的挑战性场景），可推动ECG计算机视觉算法的发展。

Abstract: We introduce an open-source Python framework for generating synthetic ECG
image datasets to advance critical deep learning-based tasks in ECG analysis,
including ECG digitization, lead region and lead name detection, and
pixel-level waveform segmentation. Using the PTB-XL signal dataset, our
proposed framework produces four open-access datasets: (1) ECG images in
various lead configurations paired with time-series signals for ECG
digitization, (2) ECG images annotated with YOLO-format bounding boxes for
detection of lead region and lead name, (3)-(4) cropped single-lead images with
segmentation masks compatible with U-Net-based models in normal and overlapping
versions. In the overlapping case, waveforms from neighboring leads are
superimposed onto the target lead image, while the segmentation masks remain
clean. The open-source Python framework and datasets are publicly available at
https://github.com/rezakarbasi/ecg-image-and-signal-dataset and
https://doi.org/10.5281/zenodo.15484519, respectively.

</details>


### [846] [Heart Rate Classification in ECG Signals Using Machine Learning and Deep Learning](https://arxiv.org/abs/2506.06349)
*Thien Nhan Vo,Thanh Xuan Truong*

Main category: eess.SP

TL;DR: 该研究探索了从心电信号分类心搏的两种方法：传统机器学习（手工特征）和深度学习（心搏图像转换）。数据预处理包括降采样、滤波和归一化。传统方法用HRV、均值等特征训练SVM、随机森林等模型；深度学习方法将ECG信号转为GAF等图像用CNN分类。结果显示：LightGBM性能最佳（准确率99%，F1 0.94），优于图像方法（F1 0.85），传统特征学习法相比图像法更能捕捉ECG的时态和形态信息。未来建议整合多导联信号和连续心搏的时序信息提升精度。


<details>
  <summary>Details</summary>
Motivation: 解决传统ECG特征工程依赖专家经验与深度学习方法中转换心电信号为图像可能丢失信息的问题，对比两种方法在分类心搏上的性能差异。

Method: 1. 传统机器学习：提取HRV、均值、方差等特征，采用SVM、随机森林、LightGBM等分类器训练；2. 深度学习：将ECG信号转化为GAF、MTF、RP三种图像，用VGG和Inception等CNN架构分类。

Result: LightGBM模型表现最优（准确率99%，F1分数0.94），CNN图像方法次之（F1 0.85）。SVM/AdaBoost模型性能大幅落后。

Conclusion: 手工特征设计比图像转换方法更能有效捕获ECG信号的时态和形态特征，未来可通过整合多导联信号和连续心搏的时序依赖进一步提升表现。

Abstract: This study addresses the classification of heartbeats from ECG signals
through two distinct approaches: traditional machine learning utilizing
hand-crafted features and deep learning via transformed images of ECG beats.
The dataset underwent preprocessing steps, including downsampling, filtering,
and normalization, to ensure consistency and relevance for subsequent analysis.
In the first approach, features such as heart rate variability (HRV), mean,
variance, and RR intervals were extracted to train various classifiers,
including SVM, Random Forest, AdaBoost, LSTM, Bi-directional LSTM, and
LightGBM. The second approach involved transforming ECG signals into images
using Gramian Angular Field (GAF), Markov Transition Field (MTF), and
Recurrence Plots (RP), with these images subsequently classified using CNN
architectures like VGG and Inception.
  Experimental results demonstrate that the LightGBM model achieved the highest
performance, with an accuracy of 99% and an F1 score of 0.94, outperforming the
image-based CNN approach (F1 score of 0.85). Models such as SVM and AdaBoost
yielded significantly lower scores, indicating limited suitability for this
task. The findings underscore the superior ability of hand-crafted features to
capture temporal and morphological variations in ECG signals compared to
image-based representations of individual beats. Future investigations may
benefit from incorporating multi-lead ECG signals and temporal dependencies
across successive beats to enhance classification accuracy further.

</details>
